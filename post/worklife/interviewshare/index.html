<!DOCTYPE html>

<html lang="zh-cn">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="author" content="fatedier">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="description" content="流程 常见流程，先自我介绍，然后对着简历挨个问一遍，项目经历，面试官根据感兴趣的方向着重问，会根据要招的岗位问一些相关的话题，这个阶段可以自己主动一点，介绍一些自己的创新，有技术含量的设计和架构，把面试变成交流，所以要熟悉简历。
然后做一两道算法题，之后就是互相问，了解入职后要做的事，当前的一些架构，你有什么看法。
myself 那我就简单的自我介绍一下，首先，我叫蒋春银，目前就定居南京，一直从事后端研发工作，已经有六年多的相关工作经验了，个人呢，目前主要是往后端服务器，云计算，架构的方向发展，也一直致力于相关的项目的架构设计开发，比如简历中最近做的容器基础平台，容器监控平台，容器日志平台等项目，都是云平台相关的项目，在项目中，一直做的都是架构设计开发的工作，在这方面还是有一定的经验能力的。大体就是这样，最后，希望能够有机会进行合作。
项目 容器基础平台  项目介绍
 其实就是容器基础平台的建设，基于k8s&#43;docker生态搭建的paas云平台。
 主要工作
 主要做的是k8s的持续集成，核心是k8s的应用，集成包括重上层的rancher，到基础的k8s调度，再到CDCI的devops的建设，到监控日志建设，在到rbac的权限建设等。
 核心
 k8s的应用
paas生态调研架构落地使用
容器监控平台  项目介绍
 顾名思义，这个项目就是对容器的监控的一个平台，是paas平台的核心部分。主要是对k8s集群自身的一些属性（比如master和node节点的一些组件的健康状态，比如节点的cpu内存使用率，网络io等），包括业务的一些监控需求（比如redis，mysql的一些常规监控）提供监控和告警的能力。同时提供了平台性质给用户各种简单操作的流程。
 主要工作
 这个平台的重需求到技术选型到最后的架构设计落地，都是我完成的。主要用了prometheus的开源的生态进行参考设计了符合我们环境的可落地的架构实现，开发一整套的流程化的操作管理平台（包括自动手动的，部署，注册，配置），这些所有的架构和流程设计包括代码开发都是我完成的。
 核心
 管理平台
底层技术的架构
k8s监控
容器日志平台  项目介绍
 这个也能很明显的看出来，主要是采集容器日志的，也是paas平台的核心部分，主要的对容器的日志进行采集，处理，存储，最终展示日志，供用户查询排除问题。
 主要工作
 这个平台的重需求到技术选型到最后的架构设计落地，也都是我完成的。我采用了EFK的基本架构，这块的主要着力点在于filebaet的改造，以及容器的日志采集动态处理，其他的都很成熟。
 核心
 服务发现设计,日志采集的架构(todo)
[es基本使用]()(todo)
数据处理平台  项目介绍
 这个项目主要就是处理数据的，可以支持不同的协议（grpc，tcp，http），将数据落地到不同的输出（kafka，file），主要的在于大量数据的高速处理，利用了golang的高并发。
 主要工作
 这个项目完全我架构设计开发的，主要使用了工作池加队列的并发处理模式完成了数据传输的要求，在公司内得到了很好的使用。
 核心
 内部架构可以参考goroutine
常规基础 架构  prometheus生态
 架构
域名--grafana的vip--》vm --》ptometheus（consul，consul-template）---探针  使用情况">
<meta property="og:url" content="https://kingjcy.github.io/"><meta property="og:type" content="article">
<meta property="og:title" content="总结 - kingjcy blog"><meta property="og:site_name" content="kingjcy blog">

<title>
    
    总结
    
</title>

<link rel="stylesheet" href="/onlyone/onlyone.css">
<link rel="shortcut icon" href="/assets/favicon.ico">
<script src="/onlyone/onlyone.js"></script>
<link rel="alternate" type="application/rss+xml" title="RSS" href="/index.xml">
</head>
<body>


<div class="container">
    <header class="nav">
        <nav class="navbar navbar-default">
            <div class="container-fluid">
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="/">kingjcy blog</a>
                </div>

                <div class="collapse navbar-collapse" id="navbar-collapse">
                    <ul class="nav navbar-nav">
                        <li><a href="/categories/技术文章/">技术文章</a></li>
                        <li><a href="/categories/读书笔记/">读书笔记</a></li>
                        <li><a href="/categories/人生感悟/">人生感悟</a></li>
                        <li><a href="/tags/">分类</a></li>
                        <li><a href="/about/">关于我</a></li>
                        <li>
                            <form method="get" style="padding: 8px" action="https://www.google.com/search" target="_blank">
                                <input type="hidden" name="sitesearch" value="kingjcy.github.io"/>
                                <input type="text" class="form-control" name="q" placeholder="Press enter to search">
                            </form>
                        </li>
                    </ul>

                </div>
            </div>
        </nav>
    </header>


<div class="row">
    <div class="col-md-8">
        <article class="post single">

            <header>
                <div class="post-date">
                    2017年04月17日 
                </div>
                <h1 class="post-title">总结</h1>
            </header>

            <div class="post-content">
                

<h1 id="流程">流程</h1>

<p>常见流程，先自我介绍，然后对着简历挨个问一遍，项目经历，面试官根据感兴趣的方向着重问，会根据要招的岗位问一些相关的话题，这个阶段可以自己主动一点，介绍一些自己的创新，有技术含量的设计和架构，把面试变成交流，所以要熟悉简历。</p>

<p>然后做一两道算法题，之后就是互相问，了解入职后要做的事，当前的一些架构，你有什么看法。</p>

<h1 id="myself">myself</h1>

<p>那我就简单的自我介绍一下，首先，我叫蒋春银，目前就定居南京，一直从事后端研发工作，已经有六年多的相关工作经验了，个人呢，目前主要是往后端服务器，云计算，架构的方向发展，也一直致力于相关的项目的架构设计开发，比如简历中最近做的容器基础平台，容器监控平台，容器日志平台等项目，都是云平台相关的项目，在项目中，一直做的都是架构设计开发的工作，在这方面还是有一定的经验能力的。大体就是这样，最后，希望能够有机会进行合作。</p>

<h1 id="项目">项目</h1>

<h3 id="容器基础平台">容器基础平台</h3>

<blockquote>
<p>项目介绍</p>
</blockquote>

<p>其实就是容器基础平台的建设，基于k8s+docker生态搭建的paas云平台。</p>

<blockquote>
<p>主要工作</p>
</blockquote>

<p>主要做的是k8s的持续集成，核心是k8s的应用，集成包括重上层的rancher，到基础的k8s调度，再到CDCI的devops的建设，到监控日志建设，在到rbac的权限建设等。</p>

<blockquote>
<p>核心</p>
</blockquote>

<p><a href="/posts/cloud/container/kubernetes/k8s-tutorial/">k8s的应用</a></p>

<p><a href="/posts/cloud/compute/">paas生态调研架构落地使用</a></p>

<h3 id="容器监控平台">容器监控平台</h3>

<blockquote>
<p>项目介绍</p>
</blockquote>

<p>顾名思义，这个项目就是对容器的监控的一个平台，是paas平台的核心部分。主要是对k8s集群自身的一些属性（比如master和node节点的一些组件的健康状态，比如节点的cpu内存使用率，网络io等），包括业务的一些监控需求（比如redis，mysql的一些常规监控）提供监控和告警的能力。同时提供了平台性质给用户各种简单操作的流程。</p>

<blockquote>
<p>主要工作</p>
</blockquote>

<p>这个平台的重需求到技术选型到最后的架构设计落地，都是我完成的。主要用了prometheus的开源的生态进行参考设计了符合我们环境的可落地的架构实现，开发一整套的流程化的操作管理平台（包括自动手动的，部署，注册，配置），这些所有的架构和流程设计包括代码开发都是我完成的。</p>

<blockquote>
<p>核心</p>
</blockquote>

<p><a href="/posts/monitor/prometheus/monitor-scheme/promes-admin/">管理平台</a></p>

<p><a href="/posts/monitor/prometheus/monitor-scheme/infrastructure/">底层技术的架构</a></p>

<p><a href="/posts/monitor/prometheus/monitor-scheme/k8s/">k8s监控</a></p>

<h3 id="容器日志平台">容器日志平台</h3>

<blockquote>
<p>项目介绍</p>
</blockquote>

<p>这个也能很明显的看出来，主要是采集容器日志的，也是paas平台的核心部分，主要的对容器的日志进行采集，处理，存储，最终展示日志，供用户查询排除问题。</p>

<blockquote>
<p>主要工作</p>
</blockquote>

<p>这个平台的重需求到技术选型到最后的架构设计落地，也都是我完成的。我采用了EFK的基本架构，这块的主要着力点在于filebaet的改造，以及容器的日志采集动态处理，其他的都很成熟。</p>

<blockquote>
<p>核心</p>
</blockquote>

<p><a href="/posts/log/collect/filebeat/filebeat/">服务发现设计,日志采集的架构</a>(todo)</p>

<p>[es基本使用]()(todo)</p>

<h3 id="数据处理平台">数据处理平台</h3>

<blockquote>
<p>项目介绍</p>
</blockquote>

<p>这个项目主要就是处理数据的，可以支持不同的协议（grpc，tcp，http），将数据落地到不同的输出（kafka，file），主要的在于大量数据的高速处理，利用了golang的高并发。</p>

<blockquote>
<p>主要工作</p>
</blockquote>

<p>这个项目完全我架构设计开发的，主要使用了工作池加队列的并发处理模式完成了数据传输的要求，在公司内得到了很好的使用。</p>

<blockquote>
<p>核心</p>
</blockquote>

<p><a href="/posts/programe/tracechain/datacollector/">内部架构</a>可以参考<a href="/posts/golang/go-goroutinechannel/">goroutine</a></p>

<h1 id="常规基础">常规基础</h1>

<h3 id="架构">架构</h3>

<blockquote>
<p>prometheus生态</p>
</blockquote>

<p><a href="/posts/monitor/prometheus/monitor-scheme/infrastructure/">架构</a></p>

<pre><code>域名--grafana的vip--》vm --》ptometheus（consul，consul-template）---探针
</code></pre>

<p>使用情况</p>

<pre><code>2。12
数据量（NJYH  700W/s，77M/s,查询1G/s）
部署量（三四十台40c256g，分软件类型业务）
性能（1T*32  2m   10%cpu 45G）
</code></pre>

<p>如何解决跨机房数据中心问题</p>

<pre><code>nginx（直接转发）
</code></pre>

<p>为什么不用operator？</p>

<p>为什么用consul不用etcd</p>

<blockquote>
<p>EFK生态</p>
</blockquote>

<p><a href="/posts/log/collect/filebeat/filebeat/">服务发现设计,日志采集的架构</a>(todo)</p>

<pre><code>log-polit-filebaet-kakfa-es-kibinea
</code></pre>

<p>[es基本使用]()(todo)</p>

<p>[平台]()(todo)</p>

<pre><code>删除新增相关应用的配置文件，设置标志。
</code></pre>

<p>使用情况</p>

<pre><code>几万行/s的规模

20000lines/s

2C 2G
</code></pre>

<p>filebeat核心</p>

<pre><code>Crawler-Input-Harvester
module
Registrar

Pipeline（publisher）: 负责管理缓存、Harvester 的信息写入以及 Output 的消费等，是 Filebeat 最核心的组件。
    client: 提供Publish接口让filebeat将事件发送到Publisher。在发送到队列之前，内部会先调用processors（包括input 内部的processors和全局processors）进行处理。
    processor: 事件处理器，可对事件按照配置中的条件进行各种处理（比如删除事件、保留指定字段等）。配置项
    queue: 事件队列，有memqueue（基于内存）和spool（基于磁盘文件）两种实现。配置项
    outputs: 事件的输出端，比如ES、Logstash、kafka等。配置项
    acker: 事件确认回调，在事件发送成功后进行回调
autodiscover：用于自动发现容器并将其作为输入源
</code></pre>

<blockquote>
<p><a href="/posts/distributed/distributed/">分布式系统</a>(todo)</p>
</blockquote>

<p>架构</p>

<pre><code>其实就是将系统进行服务化，
1、可以很好的减少依赖（每个服务都只要开发测试自己的逻辑数据，），
2、可以简单的进行扩展，（分布式存储这种）
3、能够很简单的支持高可用（负载均衡到多实例）
4、容错性（将数据以备份的信息存储多分）
</code></pre>

<p>问题</p>

<p><a href="/posts/distributed/distributed-event/">分布式事务</a></p>

<p><a href="/posts/distributed/distributed-lock/">分布式锁</a></p>

<p>MQ（<a href="/posts/middleware/mq/kafka/">kafka</a>）</p>

<pre><code>1、kafka如何保证数据的有序性
2、kafka的partion是什么作用，如何保证一致性
3、kafka为什么有那么高的吞吐量
</code></pre>

<blockquote>
<p><a href="/posts/architecture/architecture/">常规的架构思想</a></p>
</blockquote>

<p>服务化&ndash;服务的治理（服务发现，监控，高可用）</p>

<pre><code>将服务独立，对外通过api，微服务
</code></pre>

<p>高可用</p>

<pre><code>负载均衡+多实例
主备
</code></pre>

<p>可扩展</p>

<pre><code>集群
负载均衡+多实例
</code></pre>

<p>高可靠</p>

<p>容错机制</p>

<pre><code>主备
</code></pre>

<p>高并发,高性能</p>

<pre><code>多协程

* 如何提高并发

    垂直扩展，机器配置升级，这种最原始的方式

    水平扩展，这个有很多，实例，进程，线程，协程，数据库。。。

    组件优化，这个就需要大量的实践经验，比如减少交互等。

    架构完善，这个就需要大量的调优经验，比如使用缓存等

其实数据库是很多需求的响应的瓶颈所在，在数据库上花功夫才是重点，一般数据库正常使用情况

    mysql 的合理上限不应该超过500万
    oracle。20亿数据。  清单
    HBase在50000条数据批量写的性能大概是在2s左右，单个查，5-10ms左右
    redis qps 500-2000。     几百G
    prometheus。
</code></pre>

<blockquote>
<p>ms系统的后台服务端开发</p>
</blockquote>

<p><a href="/posts/architecture/enterprise-architecture/">企业架构</a></p>

<h3 id="go基础">go基础</h3>

<blockquote>
<p><a href="/posts/golang/go-concurrence/">工作池的实现</a></p>
</blockquote>

<p>工作池+job队列 先启动一定数量的goroutine，使用channel，让当前goroutine处于阻塞状态，当有task往通道里传输，然后进行处理</p>

<p>将请求放入队列,通过一定数量(例如CPU核心数)goroutine组成一个worker池(pool),workder池中的worker读取队列执行任务</p>

<pre><code>worker-初始化-将自己放进worklist

schedule--[]worker--队列来任务，则重worklist获取一个worker，把任务丢进去，
</code></pre>

<p>正常使用使用于大规模的并发请求场景，可以处理百万级请求</p>

<blockquote>
<p><a href="/posts/golang/go-map/">map</a></p>
</blockquote>

<p>写一个map（非线程安全的），golang标准库非线程安全的map的是怎么实现的</p>

<pre><code>就是一个hash表查找的简单实现

hash数组 + 桶 + 溢出的桶链表
</code></pre>

<p>什么时候转化为红黑树</p>

<pre><code>在java中超过8个桶，就会转化为红黑树，和查询次数也即是时间复杂度有关，因为Map中桶的元素初始化是数组保存的，其查找性能是O(n)，而树结构能将查找性能提升到O(log(n))。当数组长度很小的时候，即使遍历，速度也非常快，但是当链表长度不断变长，肯定会对查询性能有一定的影响，所以才需要转成树。有利于减少查询的次数
</code></pre>

<p>map的扩容机制</p>

<pre><code>按倍扩容，延迟迁移策略

还可以等量扩容，寻找empty
</code></pre>

<p>map并发安全,sync.map</p>

<pre><code>map并发安全就是用锁来实现
sync.map使用了空间换取时间，两个map读写分离，提供无锁读，实现高效的并发安全map
</code></pre>

<p>map如何顺序读取</p>

<pre><code>对key进行排序，然后按key输出，或者先遍历再排序。
</code></pre>

<blockquote>
<p><a href="/posts/golang/go-channel/">channel</a></p>
</blockquote>

<p>channel是怎么实现的</p>

<pre><code>channel是使用了循环队列作为缓存，设置了send和recv的的两个队列，用于发送，接受数据，还有一把锁，在读写数据的时候来实现同步。
</code></pre>

<p>channel 实现一个信号量</p>

<pre><code>信号量就是通过pv操作来完成对资源的控制

正常信号量是用于进程同步

    package main

    import (
        &quot;fmt&quot;
        &quot;sync&quot;
    )

    func funcA(ch chan struct{},group *sync.WaitGroup)  {
        &lt;-ch
        fmt.Println(&quot;A函数执行完毕&quot;)
        ch&lt;- struct{}{}
        group.Done()
    }

    func funcB(ch chan struct{},group *sync.WaitGroup)  {
        ch&lt;- struct{}{}
        fmt.Println(&quot;B函数执行完毕&quot;)
        &lt;-ch
        group.Done()
    }
    func main() {
        var wg sync.WaitGroup
        wg.Add(2)
        ch:=make(chan struct{},1)
        go funcA(ch,&amp;wg)
        go funcB(ch,&amp;wg)
        wg.Wait()
    }

channel还可以实现互斥，就是上面两个线程相互争抢，也就是互斥量的作用。
</code></pre>

<blockquote>
<p><a href="/posts/golang/go-goroutinechannel/">并发</a></p>
</blockquote>

<p>Linux epoll 模型</p>

<pre><code>epoll是io多路复用，同时监听多个io事件，有事件就去处理，主要体现在并发性。同步非阻塞io，解决了select，poll模型的缺点（文件句柄，fd_set内核）。
</code></pre>

<p>golang 并发模型</p>

<pre><code>Golang实现了 CSP（Communicating Sequential Process） 并发模型（就是两个协程通过channel进行通信）做为并发基础，底层使用goroutine做为并发实体，goroutine非常轻量级可以创建几十万个实体。实体间通过 channel 继续匿名消息传递使之解耦，在语言层面实现了自动调度，这样屏蔽了很多内部细节，对外提供简单的语法关键字，大大简化了并发编程的思维转换和管理线程的复杂性。
其实就是通过通信来共享内存，而不是通过共享内存来通信的概念。

基于csp模型实现了GPM的并发调度架构。

G-P-M 模型概述

G: 表示Goroutine

P: Processor,调度器，它也维护了一个goroutine队列，里面存储了所有需要它来执行的goroutine.

M: 内核线程，（真正干活的对象）

当通过go关键字创建一个新的goroutine的时候，它会优先被放入P的本地队列。为了运行goroutine，M需要持有（绑定）一个P，接着M会启动一个OS线程，循环从P的本地队列里取出一个goroutine并执行。当然还有上文提及的 work-stealing调度算法：当M执行完了当前P的Local队列里的所有G后，P也不会就这么在那躺尸啥都不干，它会先尝试从Global队列寻找G来执行，如果Global队列为空，它会随机挑选另外一个P，从它的队列里中拿走一半的G到自己的队列中执行。也就是work-stealing 的均衡调度算法
</code></pre>

<blockquote>
<p><a href="/posts/golang/go-net-http/">http的实现原理</a></p>
</blockquote>

<p>调用的net的监听，路由使用了DefaultServeMux，路由到我们注册的函数进行处理。其实就是底层是tcp那一套，然后加上路由。</p>

<blockquote>
<p>连接池</p>
</blockquote>

<p>和工作池一样，只不过是存放连接的</p>

<blockquote>
<p><a href="/posts/golang/go-gc/">gc</a></p>
</blockquote>

<p>怎么使用（强制，阈值，定时，手动）（三色标记法+混合保障机制）</p>

<blockquote>
<p><a href="/posts/golang/go-interface/">interface</a></p>
</blockquote>

<p>interface如何存储所有的类型的</p>

<p>有mothod和没有mothod（类型——数据指针）</p>

<blockquote>
<p>小问题</p>
</blockquote>

<p>slice如何扩容的（dobble，1。25）</p>

<p>goroutine为什么轻量级？</p>

<p>go有什么好</p>

<pre><code>天生并发，性能好
开发部署简单快捷，标准库也比较丰富，很适合服务端开发，web网络开发。
</code></pre>

<p>变量的传递context</p>

<p>selsct的default是不是一定要有</p>

<blockquote>
<p><a href="/posts/golang/go-channel/">死锁</a></p>
</blockquote>

<h3 id="容器相关技术">容器相关技术</h3>

<blockquote>
<p><a href="/posts/cloud/container/docker/docker/">docker</a></p>
</blockquote>

<p>容器 = cgroup + namespace + rootfs + 容器引擎</p>

<pre><code>Cgroup： 资源控制
namespace： 访问隔离
rootfs：文件系统隔离。镜像的本质就是一个rootfs文件
容器引擎：生命周期控制
</code></pre>

<blockquote>
<p>为什么使用docker</p>

<p><a href="/posts/cloud/container/kubernetes/k8s-tutorial/">k8s</a></p>
</blockquote>

<p>组件</p>

<pre><code>etcd：保存了整个集群的状态；

kube-apiserver：提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制；

kube-controller-manager:负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；

kube-scheduler:负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上；

kubelet:负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理；

Container runtime:负责镜像管理以及Pod和容器的真正运行（CRI）；

kube-proxy:负责为Service提供cluster内部的服务发现和负载均衡；
</code></pre>

<p>除了核心组件，还有一些推荐的Add-ons：</p>

<pre><code>kube-dns负责为整个集群提供DNS服务,现在已经不用了，使用coredns
Ingress Controller为服务提供外网入口
kube-state-metrics提供资源监控
Dashboard提供GUI
Federation,thanos,vm提供跨可用区的集群
</code></pre>

<blockquote>
<p><a href="/posts/architecture/microservices/microservices/">微服务</a></p>
</blockquote>

<p>注册中心和服务发现
服务间的通信层</p>

<blockquote>
<p><a href="/posts/cloud/compute/">云计算</a></p>
</blockquote>

<h3 id="计算机网络">计算机网络</h3>

<p>七层协议是指OSI七层协议模型，主要是：应用层（Application）、表示层（Presentation）、会话层（Session）、传输层（Transport）、网络层（Network）、数据链路层（Data Link）、物理层（Physical）。</p>

<p>TCP/IP四层模型，主要包括：应用层（http）、传输层（tcp）、网络层（ip）和链路层。</p>

<blockquote>
<p><a href="/posts/middleware/network/tcp/">tcp/ip</a></p>
</blockquote>

<p>ip</p>

<p>1IP报文和ip地址</p>

<p>icmp</p>

<p>1ping原理，在ip的基础上构造icmp报文发送。</p>

<p>tcp数据</p>

<pre><code>|&lt;-IP报文       -&gt;|
      |&lt;-tcp报文段 -&gt;|
ip首部|tcp首部|tcp数据
20字节|20字节
</code></pre>

<p>解决粘包（发送太快）半包（缓存太小）问题：</p>

<pre><code>1、发送定长包
2、利用结构体，发送包头为数据的长度
3、使用\r\n来按行读取
</code></pre>

<p>tcp连接的三次握手，四次挥手</p>

<pre><code>客户端发送SYN，表明要向服务器建立连接。同时带上序列号ISN

服务器返回ACK（序号为客户端序列号+1）作为确认。同时发送SYN作为应答（SYN的序列号为服务端唯一的序号）

客户端发送ACK确认收到回复（序列号为服务端序列号+1）

三次握手确保双方都有接受和发送数据的能力

主动关闭的一方发送FIN，表示要单方面关闭数据的传输

服务端收到FIN后，发送一个ACK作为确认（序列号为收到的序列号+1）

等服务器数据传输完毕，也发送一个FIN标识，表示关闭这个方向的数据传输

客户端回复ACK以确认回复

四次挥手保证双方都关闭了，因为每个端都有关闭的能力，支持半关闭的
</code></pre>

<p>tcp的十一种状态：</p>

<pre><code>服务端创建一个socket：closing状态
服务端监听这个套接口：listen状态   被动  只能被动接受连接
客户端创建套接字后connect：syn_sent状态
服务端accept：syn_rcvd状态
连接状态：established

关闭tcp：
客户端的fin_wait_1，fin_wait_2，time_wait
服务端的close_wait，last_ack，closed    状态
</code></pre>

<p>time_wait和close_wait状态</p>

<pre><code>time_wait状态为什么存在（预留足够的时间给接收端收ack），如何处理，可以快速回收
close_wait是服务端没有关闭连接，只有重启服务，改bug
</code></pre>

<p>tcp和udp的区别</p>

<pre><code>可靠性，连接
</code></pre>

<p>重传机制</p>

<pre><code>tcp报文头加一个sack表示哪些数据收到了
</code></pre>

<p>为什么迅雷下载是基于UDP的</p>

<pre><code>避免数据重传过程，可以提高数据包传输效率，降低延迟，但会有丢包现象存在。即接收的UDP数据不一定是完整的。对于视频应用，视频编码算法可以容许一定程度的数据差错，所以UDP更为适合。这一方面通过编码算法保证了存在丢包状态下的视频观看体验，另一方面可以获得高效传输低延迟。
</code></pre>

<blockquote>
<p><a href="/posts/middleware/network/http/">http/https</a></p>
</blockquote>

<p>http协议特点</p>

<pre><code>无状态
无连接
</code></pre>

<p>持久连接</p>

<pre><code>设置
文件传输结束判断
</code></pre>

<p>状态码 类别 描述</p>

<pre><code>200，400，404，503
</code></pre>

<p>http请求报文头和响应头</p>

<p>断点续传</p>

<pre><code>Content-Range:bytes 512000-/1024000
</code></pre>

<p>http2对比http1。1，http1。0</p>

<pre><code>多路复用（帧和流）和keep_alive
</code></pre>

<p>一次完整的请求（报文*路由）</p>

<p>https</p>

<p>Cache算法</p>

<pre><code>* LRU算法实现（伪代码）

如果一个数据在最近一段时间没有被访问到，那么在将来它被访问的可能性也很小。

* FIFO（First in First out），先进先出。

如果一个数据最先进入缓存中，则应该最早淘汰掉。不就是队列嘛

* LFU（Least Frequently Used）

最近最少使用算法。它是基于“如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小”的思路。

LRU的淘汰规则是基于访问时间，而LFU是基于访问次数的
</code></pre>

<blockquote>
<p><a href="/posts/middleware/network/application-netprotocol/rpc/grpc/">grpc</a></p>
</blockquote>

<p>gRPC是一个高性能、通用的开源RPC框架，其由Google 2015年主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf(Protocol Buffers)序列化协议开发，且支持众多开发语言。</p>

<p>RPC主要来解决三件事情：</p>

<pre><code>1. 进程间通讯
2. 提供和本地方法调用一样的调用机制
3. 屏蔽程序员对远程调用的细节实现
</code></pre>

<p>rpc和http</p>

<pre><code>http 和 rpc 并不是一个并行概念。

rpc是远端调用协议, 包含传输协议和编码协议。传输协议包含: 如著名的 gRPC 使用的 http2 协议，也有如dubbo一类的自定义报文的tcp协议。编码协议包含: 如基于文本编码的 xml json，也有二进制编码的 protobuf binpack 等。

把一个http server容器上封装一层服务发现和函数代理调用，那它就已经可以做一个rpc框架了。所以为什么要用rpc调用？因为良好的rpc调用是面向服务的封装，针对服务的可用性和效率等都做了优化。单纯使用http调用则缺少了这些特性。
</code></pre>

<p>http1.1 和2.0</p>

<pre><code>相对http1.1协议，http2.0协议已经优化编码效率问题，grpc这种rpc库使用的就是http2.0协议。

1. http协议是支持连接池复用的，也就是建立一定数量的连接不断开，并不会频繁的创建和销毁连接。
2. 要说的是http也可以使用protobuf这种二进制编码协议对内容进行编码，
</code></pre>

<p>http1.1和tcp</p>

<pre><code>通用定义的http1.1协议的tcp报文包含太多废信息，一个POST协议的格式大致如下

    HTTP/1.0 200 OK
    Content-Type: text/plain
    Content-Length: 137582
    Expires: Thu, 05 Dec 1997 16:00:00 GMT
    Last-Modified: Wed, 5 August 1996 15:55:28 GMT
    Server: Apache 0.84

    &lt;html&gt;
      &lt;body&gt;Hello World&lt;/body&gt;
    &lt;/html&gt;

即使编码协议也就是body是使用二进制编码协议，报文元数据也就是header头的键值对却用了文本编码，非常占字节数。如上图所使用的报文中有效字节数仅仅占约 30%，也就是70%的时间用于传输元数据废编码。当然实际情况下报文内容可能会比这个长，但是报头所占的比例也是非常可观的。那么假如我们使用自定义tcp协议的报文报头占用的字节数也就只有16个byte，极大地精简了传输内容。这也就是为什么后端进程间通常会采用自定义tcp协议的rpc来进行通信的原因。
</code></pre>

<p>rpc和rest也不是一个概念</p>

<pre><code>rest是一种规范，一种资源抽象的设计思想。是靠原生的http api实现的，rpc是对http的一种封装，（最重要的是实现了批量操作和本地化调用方式）有大量已经开发的框架，能够直接使用，算的上一种上层协议。
</code></pre>

<h3 id="数据库">数据库</h3>

<blockquote>
<p><a href="/posts/monitor/prometheus/prometheus/">prometheus</a></p>
</blockquote>

<p>时序数据库的理解（为什么要使用时序数据库）</p>

<pre><code>时序数据库基本上是基于缓存（nosql思想）的基础上处理大规模的数据，记录以时间为主轴的数据以及展现出来的变化趋势

主要是写入和查询操作，数据量大，数据特别有规律，便于压缩
</code></pre>

<p>常见的tsdb</p>

<pre><code>influxdb（不开源）
opentsdb（过度依赖hbase）
</code></pre>

<p>配置使用方式</p>

<pre><code>1。参数路径等

2。relabel：一些默认的Metadata（替换address，加标签等）

3。hashmod

4。remote

5。加密

6。reload

7。sd

    客户端
    服务端

    都是维护数据注册中心（file）
</code></pre>

<p>数据量</p>

<pre><code>每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（引用官方PPT）
我们实际环境中，Node Exporter 有 251 个测量点，Prometheus 服务本身有 775 个测量点。每一千个时间序列大约需要 1M 内存。每条数据占用了1K的空间。
</code></pre>

<p>压缩</p>

<p>promeql</p>

<pre><code>提供http API
</code></pre>

<p>分布式</p>

<pre><code>联合-thanos-vm
</code></pre>

<p>高可用</p>

<pre><code>双采
</code></pre>

<p>adapter</p>

<p>启动</p>

<pre><code>组件初始化（采集，存储，promeql（查询）），配置文件解析配置，启动组件
</code></pre>

<p>采集</p>

<pre><code>每一个job有一个与之对应的scrape pool，每一个target有一个与之对应的loop，每个loop内部执 Http Get请求拉取数据。通过一些控制参数，控制采集周期以及结束等逻辑。
</code></pre>

<p>数据类型</p>

<pre><code>4种
</code></pre>

<p>存储</p>

<pre><code>存储引擎v2（leveldb），v3版本（block按时间分块）

Prometheus将Timeseries数据按2小时一个block进行存储。每个block由一个目录组成，该目录里包含：一个或者多个chunk文件（保存timeseries数据）、一个metadata文件、一个index文件（通过metric name和labels查找timeseries数据在chunk文件的位置）。最新写入的数据保存在内存block中，达到2小时后写入磁盘。为了防止程序崩溃导致数据丢失，实现了WAL（write-ahead-log）机制，将timeseries原始数据追加写入log中进行持久化。删除timeseries时，删除条目会记录在独立的tombstone文件中，而不是立即从chunk文件删除。启动时会以写入日志(WAL)的方式来实现重播，从而恢复数据。

这些2小时的block会在后台压缩成更大的block，数据压缩合并成更高level的block文件后删除低level的block文件。这个和leveldb、rocksdb等LSM树的思路一致。

v3借用了LSM的思想

LSM 树了解吗? 是一种什么存储结构?

    将对数据的修改增量保存在内存中，达到指定大小限制之后批量把数据flush到磁盘中，磁盘中树定期可以做merge操作，合并成一棵大树


WAL机制write-ahead-log

将timeseries原始数据追加写入log中进行持久化,启动时会以写入日志(WAL)的方式来实现重播，从而恢复数据,类似于redis的aof
</code></pre>

<blockquote>
<p><a href="/posts/database/redis/redis/">redis</a></p>
</blockquote>

<p>你们系统中redis的部署方式是什么？cluster的原理是什么，默认多少个槽位，有多个db？</p>

<pre><code>standalone（单点），cluster（集群）,sentinel（哨兵）

正常我们使用的集群和哨兵模式

cluster采用的是预分片的模式，默认分配了16384个slot（槽位），然后对key进行mod取值，决定放到哪个实例上，完成了集群的分布式功能。集群采取的是无中心化的架构，每个节点上都保留集群的状态，通过gossip协议进行同步。

默认有16个db，这个是可以修改的，默认连接db0
</code></pre>

<p>redis如何实现分布式锁</p>

<pre><code>锁分为进程内的正常锁，进程间的分布式锁。分布式锁就是应用于分布式系统而产生的，因为实例分布在不同的节点进程中，如果需要资源同步，就需要分布式锁，也就是说分布式锁是用于进程间的资源同步。
分布式锁一般都是基于缓存数据库实现的，比如redis，最常用的就是使用set命令加默认值的，同时设置超时时间,如果可以设置成功代表获取到锁，不成功代表被占用。当然也可以直接使用setNX但是这个有缺点（死锁）。

set key value EX 10 NX
</code></pre>

<p>redis支持事务吗？它这个事务和我们通常讲的数据库的事务有什么区别？实现原理是什么？</p>

<pre><code>支持，最大的区别就是不支持回滚（错了，不会重试或者回滚，返回错误继续执行，错误都是编码导致的，不需要回滚），没有实现原子特性，传统数据库都是实现ACID的特性的。

开始事务
命令入队
命令执行
</code></pre>

<p>redis的缓存过期机制是怎么实现的？</p>

<pre><code>1. 客户端访问这个key时，发现其过期，进行删除操作，返回nil
2. 每隔10S，随机抽取20个key，删除过期的key，如果删除的大于25%，重复此操作
3. 在复制aof文件期间，发现过期key就会将del操作一起合并到aof文件中
</code></pre>

<p>跳跃表</p>

<pre><code>redis里的跳跃表，其实就是在一个有序链表上继续提取索引，然后形成新的链表，这个链表的中的节点一个指向下一级的节点，一个指向下一个数据，从而减少查询的次数，但是建立新链表是需要空间的，所以是一种空间换时间的方式。
</code></pre>

<p>Redis为什么要设计成单线程的（读写，单节点）</p>

<pre><code>因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）。

官方提供的数据是可以达到100000+的QPS（每秒内查询次数）

1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；

2、数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；

3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；

4、使用多路I/O复用模型，非阻塞IO；


表述了从Redis 4.0版本开始会支持多线程的方式
</code></pre>

<p>gossip协议和raft协议</p>

<pre><code>gossip协议就是基于传染病的原理实现最终一致性，定时随机选择几个进行传播，依次类推很快就全部同步了，redis的cluster集群和consul都是使用了这种协议

raft是实现一致性的协议，主要在三个方面做的处理，选举，leader，follower，Candidate的角色，可以实现高可用，选择的时候会选择版本高的，最后就是日志复制所有节点执行，保证了一致性，redis sentinel使用这个协议，etcd，zookeeper
</code></pre>

<p>如果Redis有1亿个key，使用keys命令是否会影响线上服务？如何处理</p>

<pre><code>会，肯定会导致cpu的上升。一般公司都会做权限控制，禁止keys这种命令的执行。

分业务分集群

如果获取其中几个key如何做

scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。
</code></pre>

<p>Redis的持久化方式，aof和rdb，具体怎么实现，</p>

<pre><code>追加日志和备份文件(原理)，恢复是先重rdb恢复的比较快，然后使用aof，正常最多丢失一秒数据
</code></pre>

<p>延时队列</p>

<pre><code>zadd source为timesmap
</code></pre>

<p>缓存穿透，击穿，雪崩</p>

<pre><code>1、穿透 是一个不存在的id大量访问--id校验，bloom
2、雪崩，是大量key失效--失效随机
3、击穿是一个热点key失效--不过期，互斥锁
</code></pre>

<p>redis有几种数据结构</p>

<pre><code>五种，基本底层结构，基本操作，最适合的场景。
</code></pre>

<p>redis使用场景</p>

<pre><code>我们主要是使用redis缓存了机器的信息，在注册的时候能够快速的查询完成注册。减轻每次查数据库的压力，同时也能够满足请求的快速相应。
1、session缓存
2、服务信息缓存
3、队列，探针安装
4、分布式锁


计数器(incr)/排行榜（有序集合）
点赞
抽奖
购物车
公众号消息
</code></pre>

<p>redis实现BloomFilter（布隆过滤器）</p>

<pre><code>使用一个数组，通过多次hash，来判断是否存在中集合中，牺牲来一点准确性，来解决大量数据查询，发生缓存穿透的情况。
</code></pre>

<p>Redis的list是怎么实现的，</p>

<pre><code>quicklist实现的，ziplist压缩空间，quicklist实现链表。
</code></pre>

<p>sortedset怎么实现的，使用dict+skiplist实现的，问我skiplist的数据结构，</p>

<pre><code>层级结构
</code></pre>

<p>为什么使用redis</p>

<pre><code>有些场景，传统数据库性能不够（并发崩了），需要缓存数据库，完成高性能查询服务
</code></pre>

<p>如果有大量的key需要设置同一时间过期，一般需要注意什么？</p>

<pre><code> 如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象。严重的话会出现缓存雪崩，我们一般需要在时间上加一个随机值，使得过期时间分散一些。

 电商首页经常会使用定时任务刷新缓存，可能大量的数据失效时间都十分集中，如果失效时间一样，又刚好在失效的时间点大量用户涌入，就有可能造成缓存雪崩
</code></pre>

<p>redis 异步队列</p>

<p>redis失效策略，相关算法</p>

<pre><code>6种
</code></pre>

<p>redis的主从复制原理</p>

<pre><code>全量（增量）
</code></pre>

<blockquote>
<p><a href="/posts/database/mysql/mysql/">mysql</a></p>
</blockquote>

<p>查看表大小</p>

<pre><code>select concat(round(sum(DATA_LENGTH/1024/1024),2),'MB') as data from information_schema.TABLES 
    where table_schema='数据库名' and table_name='表名';
</code></pre>

<p>mysql创建定时任务，每月1号删除上月数据</p>

<pre><code>存储过程
</code></pre>

<p>升序</p>

<pre><code>order by    desc
</code></pre>

<p>事务和锁</p>

<pre><code>innodb支持事务（ACID）myisam不支持
innodb是行锁，myisam是表锁


粒度

    1、MDL                   ：元数据锁，也是锁表，就是对information_sechme表进行加锁，一般DDL操作就会进行加锁，所以在生产上需要减少DDL操作，因为元数据表被锁，会影响所有的操作。
    2、table lock            ：表锁，锁起整张表，开销比较大
    3、record（row）lock      ：行锁，也叫记录锁，其实锁住的是索引，也叫索引锁，主要是对数据行（的索引）进行加锁
    4、GAP                   ：间隙锁，锁住两个数据行之间的锁，也是锁住这些索引
    5、next lock             ：下一键锁，也是row+GAP

功能

乐观锁：多版本控制

悲观锁：    共享锁（S）：事务执行read时，可以持有这个锁，读锁
        排它锁（X）：事务执行update或delete时，可以持有这个锁，写锁
</code></pre>

<p>mvcc主要实现了undo的日志回滚策略，mvcc通过悲观锁和乐观锁实现的</p>

<pre><code>1、先用排他锁锁定行数据
2、然后将数据copy到undo日志中去
3、记录修改的事务id形成版本链

    trx_id
    这个id用来存储的每次对某条聚簇索引记录进行修改的时候的事务id。

    roll_pointer
    每次对哪条聚簇索引记录有修改的时候，都会把老版本写入undo日志中。这个roll_pointer就是存了一个指针，它指向这条聚簇索引记录的上一个版本的位置，通过它来获得上一个版本的记录信息。(注意插入操作的undo日志没有这个属性，因为它没有老版本)

    max_id
    已经创建的最大的事务id，包括已经提交的和未提交的

    readview
    版本快照是有未提交的事务id组成的数组和已经创建的所有的id的最大值组成

mvcc比较规则

    1、trx_id如果小于未提交的事务id的最小值，那么说明这个事务是在这些事务之前创建提交的，就是这条数据
    2、trx_id如果大于max_id，说明是最新的事务id，肯定不是查询的时候创建的，绝对不是这条数据
    3、trx_id如果在未提交的事务id的最小值和max_id之间，就有两种情况
        1、如果trx_id在未提交的事务id组成的数组中，说明没有提交，所以不是这个数据
        2、如果trx_id不在未提交的事务id组成的数组中，说明已经提交，所以是这个数据
</code></pre>

<p>mysql事务</p>

<pre><code>Atomic（原子性）--undo

所有语句作为一个单元全部成功执行或全部取消。不能出现中间状态。


Consistent（一致性）--AID

如果数据库在事务开始时处于一致状态，则在执行该事务期间将保留一致状态。是最终的目的，通过AID来保障

Isolated（隔离性）--mvcc

事务之间不相互影响。

Durable（持久性）--redo

    事务成功完成后，所做的所有更改都会准确地记录在数据库中。所做的更改不会丢失。
</code></pre>

<p>MySQL的事务隔离级别，分别解决什么问题。</p>

<pre><code>四个级别

    RU （read uncommit）  : 读未提交,会出现脏读,不可重复读，幻读，一般生产不会设置出现
        脏读：其他事务还没有提交的，被查询的时候查询出来
        不可重复读：在操作本事务的时候，不同的时候对同一个数据有不同的值，也就是在操作的时候其他commit被查询出来了
        幻读：就是在范围查询修改的时候，其他事务在在这一范围内进行操作，出现修改不如意的情况。
    RC （read commit） : 读已提交,可能出现幻读，不可重复读,可以防止脏读，主要是因为它只读取commit后的数据，所以可以防止脏读
    RR （read review） : 可重复读，默认级别。解决了脏读（和rc一样），不可重复读（主要是使用快照功能，每次读取的都是这个快照的数据）快照可以防止&quot;幻读&quot;现象 ,但是不可能完全解决，完全解决需要利用的是undo的快照技术+GAP(间隙锁)+NextLock(下键锁)，这个隔离是借助mvcc实现的
    SR （read）  : 可串行化,就是串行，可以解决上面所有问题，可以防止死锁,但是并发事务性能较差
</code></pre>

<p>MySQL的索引原理</p>

<pre><code>MySQL索引使用的是B+Tree数据结构。构成B+树，每个枝节点保存的是数据的范围，然后进行分块范围查找。

聚簇索引
辅佐索引

单列

    普通索引INDEX：加速查找
    主键索引PRIMARY KEY：加速查找+约束（不为空、不能重复）
    唯一索引UNIQUE:加速查找+约束（不能重复）
    前缀索引

多列

    联合索引--注意最左原则，比如新建索引inx（a,b,c）—–》相关于创建了a，ab，abc三个索引，看到这三个索引能不能走索引就很能简单的理解了
</code></pre>

<p>是否走索引</p>

<pre><code>explain（desc）

type：ALL，INDEx，range，ref，eq_ref，system，const
</code></pre>

<p>不走索引</p>

<pre><code>函数，计算
%

大范围，隐氏转化，&lt;&gt; not in
</code></pre>

<p>回表</p>

<pre><code>辅佐索引查询的都是索引值，还是要带着这个索引回到聚簇索引查原始数据，这就是回表
</code></pre>

<p>如何减少回表</p>

<pre><code>查询尽量使用主键
联合索引尽量包含聚簇索引
</code></pre>

<p>sql的循序</p>

<pre><code>1.select
2.from
3.where
4.group by
5.having
6.order by
7.limit
</code></pre>

<p>段区页</p>

<pre><code>段==一个或者多个区（1M）==64个页（16K）==4个block（4K）===8个扇区（512B）
</code></pre>

<p>MySQL 的聚簇索引和非聚簇索引有什么区别?</p>

<pre><code>聚集索引只能有一个,非空唯一,一般时主键
辅助索引,可以有多个,配合聚集索引使用的
聚簇索引是实时更新的。辅助索引不是实时更新的
</code></pre>

<p>MySQL对于千万级的大表要怎么优化</p>

<pre><code>优化索引sql（分页）

    索引调优
    sql调优
    分页

加缓存

分区分库分表
</code></pre>

<p>MySQL处理达到百万级数据时，如何优化</p>

<pre><code>正常是能支持百万级查询，这块主要就是优化索引sql（分页：*。。。）就可以
</code></pre>

<p>我们公司业务慢,请你从数据库的角度分析原因，其实也就是平时中如何进行sql索引调优的。其实我们最长做的就是找到慢的sql语句看执行计划，建索引，改语句走索引这样的操作</p>

<pre><code>mysql出现性能问题,我总结有两种情况:

1、应急性的慢：突然夯住

    应急情况:数据库hang(卡了,资源耗尽)
    处理过程:
    1.show processlist;  获取到导致数据库hang的语句
    2. explain 分析SQL的执行计划,有没有走索引,索引的类型情况
    3. 建索引,改语句

2、一段时间慢(持续性的):

    (1)记录慢日志slowlog,分析slowlog
    (2)explain 分析SQL的执行计划,有没有走索引,索引的类型情况
    (3)建索引,改语句
</code></pre>

<p>双11这种情况下如何出来mysql</p>

<pre><code>1、双11的时候，并发度很高，提前一两周将热点商品数据放入到tair（redis，memcached）集群中（查询）
2、设置一个队列，将数据先缓存到队列中，然后缓慢消费进入mysql（存储）
3、所以和索引实时性没有太大关系
4、查看slog，对其进行分析，然后去建索引，加快查询
</code></pre>

<p>mysql的binlog</p>

<pre><code>使用binlog日志进行数据恢复

mysqlbinlog --start-position=1227 --stop-position=2342 /data/binlog/mysql-bin.000004 &gt;/tmp/bin.sql
</code></pre>

<p>mysql的slowlog</p>

<pre><code>mysqldumpslow 分析慢日志

    mysqldumpslow -s c -t 10 /data/mysql/slow.log
</code></pre>

<p>备份</p>

<pre><code>  基于SQL语句进行备份
  mysqldump       *****
  mysqlbinlog     *****
</code></pre>

<h3 id="难题">难题</h3>

<blockquote>
<p><a href="/posts/product/filebeat_leak/">filebeat内存和cpu剧增</a></p>
</blockquote>

<pre><code>6--》泄漏
7。relaod重载泄漏
</code></pre>

<blockquote>
<p><a href="/posts/product/pings/">大量ping延时（负载均衡有问题）</a></p>
</blockquote>

<pre><code>先判断是我们探测机器有问题，看cpu和连接数，有几台是高的，怀疑出现了网络抖动，倒是请求都处于time_wait状态，开启复用和回收同时加大对tcp连接的检查，果然有发生，都是连接状态，这个时候就怀疑任务不均了，但是使用的是vip，咨询就是轮训，没有办法只有打开debug日志，那个日志量大的，但是可以看到每个请求都是完成的，并木有出现超时等待，怀疑vip，自己搭建了nginx，ok
</code></pre>

<blockquote>
<p><a href="/posts/product/memory/">内存被使用完（大量数据的读写）</a></p>
</blockquote>

<pre><code>大量定时任务失败吃内存，大量io读写吃内存
</code></pre>

<p>4、优化</p>

<p>主要是在设计的时候就要考虑到</p>

<pre><code>* 如何提高并发

    垂直扩展，机器配置升级，这种最原始的方式

    水平扩展，这个有很多，实例，进程，线程，协程，数据库。。。

    组件优化，这个就需要大量的实践经验，比如减少交互等。比如collector的工作池，比如sql优化

    架构完善，这个就需要大量的调优经验，比如使用缓存等，比如redis的分布式队列和锁
</code></pre>

<h3 id="看书">看书</h3>

<p>狼道</p>

<pre><code>执行力最重要，野心和理想都离不开行动的支持。
</code></pre>

<p>prometheus原理应用源码讲解的书</p>

<h3 id="算法与数据结构">算法与数据结构</h3>

<p>直接看平时总结的<a href="/posts/computerbase/algorithm/algotithm/">算法</a>与<a href="/posts/computerbase/datastruct/datastruct/">数据结构</a></p>

<h3 id="过程记录">过程记录</h3>

<pre><code>1、在原生的基础上做了哪些改造？
2、interface如何存储所有的类型的
3、slice如何扩容的
4、goroutine为什么轻量级？GPM模型
5、go有什么好
6、EMQ是什么
7、调度算法
7、redis持久化
7、使用了什么类型的redis
7、redis失效策略，相关算法
8、redis的主从复制原理
9、redis的gossip协议，raft协议，还要具体
10、redis的zset的实现
11、redis的使用场景
12、如何解决缓存穿透
13、什么是聚簇索引
14、如何减少回表
15、架构的理解
16、pod的资源分配
17、如何看待云计算
18、go的框架
19、kafka如何保证数据的有序性
20、kafka的partion是什么作用，如何保证一致性
21、kafka为什么有那么高的吞吐量
22、为什么不用operator？
23、为什么用consul不用etcd

1、etcd的raft的实现
2、mysql的事务是怎么实现的，参考这个来设计一个分布式事务
3、秒杀系统的设计
4、变量的传递context
5、promes-admin后台是怎么实现的
6、http如何实现爬虫
7、https的tls
8、企业架构
9、并发会不会出现死锁
10、select没有default有没有问题？

1、k8s认证是在哪
2、pod创建的流程



1、k8s达到一千个节点的时候遇到的管理问题
2、k8s运行在物理机和运行在虚拟机上的区别
3、docker的架构
4、k8s网络和虚拟机混合网络问题
</code></pre>

<h1 id="历史记录-杂乱无章-待整理">历史记录（杂乱无章，待整理）</h1>

<p>项目</p>

<p>1.paas</p>

<p>paas平台是一个运行管理监控容器应用的自动化平台，首先是我们的应用都容器化，然后需要一个运行管理监控的平台，提供界面的自动化操作，简单点说就是通过我们的paas平台可以界面部署应用，对应用进行监控运维。这样可以减少很多工作，也解决了很多的问题，可以提高效率。但是项目实现还是比较复杂的，后台用了很多的技术，比如k8s，docker，prometheus等等</p>

<p>1.k8s的持续集成，这个是paas平台的基础，主要是对k8s的生态系统进行调研，了解各个组件的 原理应用发展，主要是</p>

<p>a。k8s的组件，原理，使用&ndash;1.8.8，    9台机器，两个k8s集群1m／4n</p>

<pre><code>apiserver提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制；8080，6443
</code></pre>

<p>apiserver负责各个模块之间的通信，集群里的功能模块通过apiserver将信息存入到etcd中，其他模块通过apiserver读取这些信息，实现来模块之间的交互，比如，node上的kubelet隔一段时间将自身的信息报告给apiserver，apiserver接受这些信息存入到etcd中，controller manager 中的node controller定期读取这些信息然后作出相应的处理。</p>

<pre><code>controller manager管理器的控制者。使用是集群管理控制中心，负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；
</code></pre>

<ol>
<li>replication controller副本控制 ,它的主要作用是确保规定数量的pod正常运行。当然他是通过rc机制实现的。</li>
</ol>

<p>它的作用：</p>

<pre><code>1. 重新调度 就是上面说的能确保规定数量的pod运行

2. 弹性伸缩 可以通过spec.replicas来改变pod的数量

3. 滚动更新 一个一个pod的更新
</code></pre>

<ol>
<li>node controller节点管理。</li>
</ol>

<p>首先我们需要了解kubelet通过apiserver想etcd中存储的节点信息有节点健康状况，节点资源，节点名称地址，操作系统版本，docker版本，kubelet版本等等，其中一个节点健康状况分为三种True，false，unknown三种状态，也是最直接的节点状态</p>

<p>然后这个控制器就会重etcd中逐个节点读取这些状态，将来自kubelet状态来改变node controller中nodestatusmap中状态，对于状态不对的node节点加入一个队列，等待确认node是否有问题，有问题就进行信息同步，并且删除节点。</p>

<ol>
<li>resourcequota controller资源配额</li>
</ol>

<p>这一个功能十分必要，它确保任何对象任何时候都不会超量占用资源，确保来系统的稳定性。目前k8s支持三个层次的资源配额</p>

<ol>
<li><p>容器级别  可以限制cpu和memory</p></li>

<li><p>pod级别  对pod内所有容器的可用资源进行限制</p></li>

<li><p>namespace级别  pod数量，rc数量 service数量，rq数量，secret数量，persistent volume数量</p></li>
</ol>

<p>实现机制：准入机制（admission caotrol）</p>

<p>在etcd中会维护一个资源配额记录，每次用户通过apiserver进行请求时，这个控制器会先进行计算，如果资源不过就会拒绝请求。</p>

<ol>
<li><p>namespace controller主要是监控namespace的状态，在其失效的情况下,对其进行处理</p></li>

<li><p>serviceAccount controller和token controller</p></li>
</ol>

<p>这是两个安全监控，在apiserver启动的时候使用serviceaccount，就会产生一个key和crt，那么在controller mansge启动的时候通过参数指定这个key就会自动创建一个secret，也会创建一个token controller完成对serviceaccount的监控。</p>

<ol>
<li>service controller和endpoint controller</li>
</ol>

<p>这两个就是对service和endpoint进行监控对管理器。</p>

<pre><code>scheduler负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上；并将信息写入到etcd中去。
</code></pre>

<p>策略：都是用的默认的，没有调整过</p>

<pre><code>kubelet负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理；
</code></pre>

<p>kubelet自身会在apiserver中注册自身信息，然后定期向master回报节点信息，比如一些资源的使用情况，节点状态，并且通过cadvisor（4194）监控节点资源和容器。</p>

<p>节点管理</p>

<p>pod管理</p>

<p>启动参数配置</p>

<p>监听etcd</p>

<p>容器健康检查-探针</p>

<p>heapster是k8s的监控平台</p>

<p>cadvisor&ndash;分析资源和性能的工具</p>

<p>kubelet通过cadvisor获取所在节点及容器的信息数据，heapster通过关联标签的pod分组这些信息，将这些数据推送出去给监控。</p>

<pre><code>kube-proxy负责为Service提供cluster内部的服务发现和负载均衡；
</code></pre>

<p>kube-proxy实现了service机制，其实就是一个反向代理，类似于nginx，为每个service启动一个socket，指定虚拟ip和端口，然后连接来了进行轮训，还提供session保持机制，就是sesssion没有过期的情况下，下次还是访问同一个后端pod，所以service就是负载均衡</p>

<p>kube-dns负责为整个集群提供DNS服务，也就是服务发现</p>

<p>k8s的服务发现</p>

<p>使用kubectl create -f nginx-deployment.yaml指令创建，这样便可以得到两个运行nginx服务的Pod。待Pod运行之后查看一下它们的IP，并在k8s集群内通过podIP和containerPort来访问Nginx服务：</p>

<p>每次收到获取podIP太扯了，总不能每次都要手动改程序或者配置才能访问服务吧，要怎么提前知道podIP呢？
Pod在运行中可能会重建，IP变了怎么解？
如何在多个Pod中实现负载均衡嘞？</p>

<p>所以</p>

<p>下面为两个Nginx Pod创建一个Service。获取Service的Cluster-IP，再结合Port访问Nginx服务。Service可以将pod  IP封装起来，即使Pod发生重建，依然可以通过Service来访问Pod提供的服务。此外，Service还解决了负载均衡的问题，大家可以多访问几次Service，然后通过kubectl logs <Pod Name>来查看两个Nginx Pod的访问日志来确认。</p>

<p>不提前知道Service的IP，还是需要改程序或配置啊。</p>

<p>所以</p>

<p>kube-dns可以解决Service的发现问题，k8s将Service的名称当做域名注册到kube-dns中，通过Service的名称就可以访问其提供的服务。</p>

<p>kube-dns插件只是运行在kube-system命名空间下的Pod，完全可以手动创建它。</p>

<p>kube-dns原理</p>

<p>kube-dns是由四个容器组成的</p>

<p>SkyDNS是用于服务发现的开源框架，构建于etcd之上。作用是为kubernetes集群中的Pod提供DNS查询接口。项目托管于<a href="https://github.com/skynetservices/skydns">https://github.com/skynetservices/skydns</a></p>

<p>etcd是一种开源的分布式key-value存储，其功能与ZooKeeper类似。在kube-dns中的作用为存储SkyDNS需要的各种数据，写入方为kube2sky，读取方为SkyDNS。项目托管于<a href="https://github.com/coreos/etcd。">https://github.com/coreos/etcd。</a></p>

<p>kube2sky是k8s实现的一个适配程序，它通过名为kubernetes的Service（通过kubectl get svc可以查看到该Service，由集群自动创建）调用k8s的list和watch API来监听k8s Service资源的变更，从而修改etcd中的SkyDNS记录。代码可以在k8s源码（v1.2）的cluster/addons/dns/kube2sky/目录中找到。</p>

<p>exec-healthz是k8s提供的一种辅助容器，多用于side car模式中。它的原理是定期执行指定的Linux指令，从而判断当前Pod中关键容器的健康状态。在kube-dns中的作用就是通过nslookup指令检查DNS查询服务的健康状态，k8s livenessProbe通过访问exec-healthz提供的Http API了解健康状态，并在出现故障时重启容器。其源码位于<a href="https://github.com/kubernetes/contrib/tree/master/exec-healthz。">https://github.com/kubernetes/contrib/tree/master/exec-healthz。</a></p>

<p>服务发现的实现可以参考服务发现篇。</p>

<p>Ingress Controller为服务提供外网入口
Heapster提供资源监控
Dashboard提供GUI
Federation提供跨可用区的集群</p>

<p>etcd3.2.11&mdash;&mdash;&mdash;&mdash;3个节点
etcd保存了整个集群的状态；</p>

<p>ETCD是用于共享配置和服务发现的高可用的，强一致性的KV存储系统。</p>

<p>watch机制</p>

<p>raft协议</p>

<p>内存存储，目前没有持久化</p>

<p>2是直接使用json持久化文件</p>

<p>3支持后端存储，目前用boltdb
boltdb是一个单机的支持事务的kv存储，Etcd 的事务是基于boltdb的事务实现的。Etcd 在boltdb中存储的key是reversion，value是 Etcd 自己的key-value组合，也就是说 Etcd 会在boltdb中把每个版本都保存下，从而实现了多版本机制。</p>

<p>具体操作看etcd篇</p>

<p>flannel和calico</p>

<p>v3.1.0&mdash;&ndash;calico
从源容器经过源宿主机，经过数据中心的路由，然后到达目的宿主机最后分配到目的容器的过程。始终都是根据iptables规则进行路由转发，并没有进行封包，解包的过程，这和flannel比起来效率就会快多了。</p>

<p>v0.9.1&ndash;flannel&mdash;每个节点上都部署了
flannel 先试源容器docker0转发到虚拟网卡flannel0，flanneld监听在flannel0网卡的另一端（flannel维护一张路由表，所以可以监控flanenl0），源主机的flanneld对数据进行udp封装打包，根据维护的路由表发送到对面的flanneld，这个flanneld进行解包，发送到flannel0，然后再转发到docker1上</p>

<p>深入研究vxlan(virtual Extensible LAN)虚拟可扩展局域网</p>

<p>ssl&ndash;Secure Sockets Layer</p>

<p>UI／cli &mdash;&ndash;api&mdash;&mdash;-master&mdash;&mdash;-node</p>

<p>基本类型操作</p>

<p>yaml</p>

<p>docker。 17</p>

<p>harbor  1.2.0    目前就一个</p>

<p>ceph</p>

<p>b。kong api gateway</p>

<p>kong 0.12.1</p>

<p>物理部署2个，目前注册了几百个api，流量大概几十到几百每秒，现在完全没有压力</p>

<p>一个网关的基本功能有：统一接入、安全防护、协议适配、流量管控、长短链接支持、容错能力。</p>

<p>API网关更专注于安全、流量、路由等问题</p>

<p>技术选型</p>

<p>kong tyK  zuul  apiaxle: Nodejs 实现的一个 API 网关。
api-umbrella: Ruby</p>

<p>对比了几个开源项目觉得Mashape/kong和TykTechnologies/tyk 可以选用，从star数来看空占优支持性较好，</p>

<p>但是微服务过渡团队更多的会使用golang作为开发语言，个人更倾向于tyk。</p>

<p>tyk部分功能存在收费，闭源问题。</p>

<p>kong 有nginx作支持更有保障，安装简单，扩展性强一点</p>

<p>并且选择kong的人多过tyk。</p>

<p>可扩展性，Kong依赖一个数据库来实现配置存储，</p>

<p>依赖 serf 来实现 instance 之间的通信。</p>

<p>任何一个节点修改了其他节点会收到通知并重新reload配置。</p>

<p>模块化，Kong 可以方便地增加新的插件，并且插件可以通过 Restful API 进行管理
Kong采用插件机制进行功能定制，插件集（可以是0或n个）在API请求响应循环的生命周期中被执行。插件使用Lua编写，目前已有几个基础功能：HTTP基本认证、密钥认证、CORS（ Cross-origin Resource Sharing，跨域资源共享）、TCP、UDP、文件日志、API请求限流、请求转发以及nginx监控。</p>

<p>数量瓶颈</p>

<p>水平扩展多个Kong服务器，通过前置的负载均衡配置把请求均匀地分发到各个Server，来应对大批量的网络请求。</p>

<p>kong 集群将使得系统通过增加更多机器，从而实现水平扩展，承接更多的请求流量。它们将共享同样的配置且使用同一个数据库。kong 集群中的的所有节点都连接同一个数据库。</p>

<p>你需要在 kong 集群的上一层架设一个负载均衡的代理服务器，以便请求能够平均分散转发到 kong 的各个节点上。</p>

<p>考虑到性能原因，当 kong 代理请求的时候，为了避免频繁的数据库连接操作，kong 将会把以下 db 内容缓存到本机内存中。这些缓存包括：API定义，用户信息，插件信息，授权认证信息等。由于这些值在本机缓存中，通过 Admin api 去更新任何一个节点本地缓存中的值，都需要传播给其他节点。</p>

<p>所以在一个节点上进行操作时，其他节点会由于本地缓存不会立即更新，所以需要更新时间设置</p>

<p>◦ db_update_frequency (默认: 5 秒)</p>

<p>原理</p>

<p>通过8001端口注册api的请求参数和url</p>

<p>直接通过8000端口调用</p>

<p>使用插件对请求进行处理，如下</p>

<p>1.消息转发</p>

<p>就是不出来直接送到后端api中，也就是直接通过8000端口进行请求</p>

<p>用户鉴权</p>

<p>1、首先kong自身使用basic-auth插件进行检验</p>

<p>2.调用鉴权模块的api，这边写了一个插件，可以参考文档，有时间学习一些</p>

<p>流量控制</p>

<p>使用插件rate-limiting，
根据年、月、日、时、分、秒设置限流规则，多个限制同时生效。</p>

<p>比如：每天不能超过10次调用，每分不能超过3次。</p>

<p>当一分钟内，访问超过3次，第四次就会报错。</p>

<p>当一天内，访问次数超过10次，第十一次就会报错。</p>

<p>在过滤器的run方法中判断请求剩余次数，小于0就拦截请求：</p>

<p>熔断</p>

<p>当调用满足失败次数，失败比例就会触发熔断器打开，有程序自动切断当前的RPC调用,来防止错误进一步扩大。实现一个熔断器主要是考虑三种模式，关闭，打开，半开。各个状态的转换如下图。</p>

<p>熔断关闭: 熔断关闭不会对服务进行熔断，当请求服务失败次数符合设定的规则则进入熔断机制
半熔断： 部分请求根据规则调用当前服务，如果请求成功且符合规则则认为当前服务恢复正常，关闭熔断；
熔断打开：请求不再进行调用当前服务，内部设置时钟一般为(MTTR：平均故障处理时间)，当打开时长达到所设时钟则进入半熔断状态。
基于服务策略触发</p>

<p>问题处理</p>

<p>容错</p>

<p>网关的可降级、可限流、可隔离等等一系列容错能力
我们常见的降级，限流，熔断器，超时重试等等都是容错的方法。</p>

<p>1.使用nio异步非阻塞机制抗量
2.使用缓存，脱离db&ndash;多级缓存：本地缓存&ndash;reids&ndash;redis直接作为db，可以使用实效时间来实现冷热数据，穿透率：比如查询方法queryOrder(调用次数1000/1s)里面嵌套查询DB方法queryProductFromDb(调用次数300/s)，那么redis的穿透率就是300/1000,在这种使用缓存的方式下，是要重视穿透率的，穿透率大了说明缓存的效果不好。也可以不用失效时间，直接通过时间戳对比
3。超时重试
4.熔断
5。线程池隔离
6.降级，流量控制</p>

<p>网关监控与统计</p>

<p>那么每一步发生的异常要记录下来，统一存储到一个地方比如elasticserach中，便于后续对调用异常的分析</p>

<p>c。权限控制</p>

<p>版本 自己定的0.2   就是一个模块，物理部署启动</p>

<p>harbor</p>

<p>基于rbac的管理。。。。。用户，角色，权限&mdash;&mdash;paas系统，harbor系统，kubernetes系统</p>

<p>租户。 集群</p>

<p>用户组 域</p>

<p>用户   角色。  权限。  资源</p>

<p>paas</p>

<p>Sysadmin
唯一，运维人员使用，具有所有权限
实际权限和Groupadmin一致，可在用户登录的时候，选择命名空间进行操作
系统管理员可在页面创建的namespace默认放到group为system的组下，系统管理员默认为system组的groupadmin
字段标识：0
systemAdmin只能创建admin，然后admin去创建其他用户。</p>

<p>Groupadmin
由sysadmin授权
只能管理自己所在组
对应harbor中的admin角色(只能管理自己组)
对应k8s中管理员角色(只能管理自己组)
可创建当前组用户
可创建当前组域
字段标识：1
只有sysadmin可以增删改查group
只能获取当前用户组下的用户</p>

<p>Namespaceadmin
1、管理独立域下的资源
2、可以将当前组下的用户设置为开发者
3、可创建当前域下的开发者用户
4、只能查询当前组下的namespace
5、只有groupadmin可以创建namespace，groupadmin创建的namespace只能在当前group下
6、创建namespace会在数据库中有一条记录，在harbor创建一个project，在k8s中创建一个namespace，有一个失败就报错。
7、删除修改逻辑还没有实现，目前只是修改数据库中的数据。</p>

<p>Dev
1、无rbac操作权限
2、角色权限由系统管理员分配</p>

<p>自定义角色
1、只归属于一个域，不共享，创建时候需要指定域
2、可以由组管理员、域管理员来创建</p>

<p>初始化流程
1. 初始化一个rbac的admin用户，用户名密码支持可配置，group为-1</p>

<ol>
<li><p>调用k8sapi来创建这些角色&rdquo;groupadmin&rdquo;,&ldquo;namespaceadmin&rdquo;,&ldquo;developer&rdquo;,&ldquo;guest对应的clusterrole，用户后面的角色授权模板</p></li>

<li><p>初始化rbac基本角色&rdquo;sysadmin&rdquo;,&ldquo;groupadmin&rdquo;,&ldquo;namespaceadmin&rdquo;,&ldquo;developer&rdquo;,&ldquo;guest&rdquo;</p></li>

<li><p>初始化k8s中已经存在的namespace同步到rbac中，并且划分到对应的group，group不存在则创建一个。</p></li>
</ol>

<p>登录
登录就是把输入的密码和数据库中的密码进行对比，登录成功后则将相关用户信息保存到session中，后面调用api前全部要检查是否登录，通过获取session中的user信息进行判断。登录结束时会返回当前用户的token，namespace，role.</p>

<p>授权
Namespacemember关联了Namespace ，User， Role表，给某个用户授予一个角色，先在数据库中创建一条关系数据，然后在harbor中创建这个角色(分配groupadmin不需要操作harbor),主要是同步用户，获取project，然后给他一个角色，最后在k8s中授予角色，同样需要同步用户，创建角色，还要进行角色绑定。</p>

<p>目前回收权限，修改权限还没有实现，只是操作数据库中的关系表。</p>

<p>角色
目前只能查看到当前角色权限之下的角色，自定义角色的的权重都是10，而上述说的角色的权重分别为1,2,3,4,5存在数据库中，同样删除修改只能在当前角色权重之下的角色。</p>

<p>Secret
目前是重harbor中获取auth然后到k8s中的当前namespace去创建一个名为currUser.Username + &ldquo;-pull-secret&rdquo;的secret。
K8s_proxy
用户授权
Api
/nl/api/rolebindings
参数：
Name：默认无，不填时 username+“-”+ roleName
Apiversion: 不填
Group：
Namespace：
roleName
userName
roleflag：0:sysadmin 1:groupadmin 2:其他</p>

<p>业务逻辑
授予系统管理员
条件：Roleflag = 0
流程：
创建系统管理员命名空间和组
namespace = &ldquo;default&rdquo; group := &ldquo;system&rdquo;
创建sa账户
在group为system，namespace为system，创建入参为username的用户
判断是否存在当前ClusterRole
创建ClusterRoleBinding</p>

<p>授予组管理员
条件：Roleflag = 1
流程：
查询入参group下的所有namespace
遍历所有namespace
查找入参roleName角色
若无，创建
查找入参为userName的所有sa
若无，创建
创建RoleBinding
完成</p>

<p>授予其他角色
条件：Roleflag != 0 &amp;&amp; Roleflag != 1
流程：
查找入参roleName、namespace下的serviceaccout，若无报错
查找入参roleName、namespace下的role，若无报错
创建rolebinding
创建namespace
创建ns
角色同步
创建完ns, 需要将该ns纳入到对应的用户管理下（比如groupAdmin），具体参见2.1.2.3</p>

<p>d。监控告警</p>

<p>prometheus 2.2.0</p>

<p>node——exporter。0.15.2</p>

<p>alertmanager 0.14.0</p>

<p>grafana。 5.0.0</p>

<p>heapster。   v1.5.0</p>

<p>prometheus+grafana告警</p>

<p>同步k8s到本地的prometheus，使用prometheus告警模块</p>

<p>部署，脚本的自动化部署</p>

<p>在k8s中部署prometheus（9093），，结合kubelet中的cadvisor（4194），heapster和k8s的服务发现机制，将数据采集到prometheus中，prometheus采用多副本数，形成一个service，完成高可用，然后采用分集群部署多个prometheus，最后过prometheus的faferation将相关的数据进行聚合</p>

<p>将alertmanager部署在k8s中，配置对应的告警规则</p>

<p>通过http api采集数据给ui使用，参考grafana的后端。</p>

<p>深入可以参考监考告警篇</p>

<p>几十个pod</p>

<p>指标也就几千个</p>

<p>采集频率30S</p>

<p>一个多月的数据。 几个G的数据，所以目前就是使用了本地内存，在考虑远程存储数据，保证数据的不丢失实现高可用</p>

<p>各种exporter，node_exporter（）都是物理部署采集到prometheus，以这个为主，，，k8s集群中部署Prometheus的数据存储层可以简单的使用emptyDir,数据只保留24小时(或更短时间)即可，部署在k8s集群上的这个Prometheus实例即使发生故障也可以放心的让它在集群节点中漂移。然后采集出来</p>

<p>部署cpu 48核 256G</p>

<p>部署前端的界面服务，部署kong网关，部署权限模块，部署资源管理模块，部署应用管理模块，部署能力集成模块&mdash;-</p>

<p>通过界面部署集群，监控告警，应用</p>

<p>登陆&ndash;申请资源&ndash;审批&mdash;自动化创建集群&mdash;创建应用&mdash;创建监控</p>

<p>部署很快。几分钟。集群也很快，几分钟</p>

<p>后面准备写脚本部署</p>

<p>2.应用云化</p>

<p>这个项目主要是对现有的应用产品，比如计费账务等业务相关的进程服务，能开平台cachecloud监控平台等产品，还有新开发的需求实现在容器中运行，主要是对一些简单的业务进程服务进行云化。</p>

<p>a.写dockerflie，打包镜像，docker跑容器</p>

<p>具体使用参考docker</p>

<p>docker一些原理</p>

<p>b。压测，问题</p>

<p>压测，ab工具，6容器100并发，99-1S</p>

<p>镜像数据问题</p>

<p>由于容器重启后数据会被清空，所以docker中的数据需要通过映射存放到本地磁盘持久化，启动docker镜像的时候加-V diskPath:dockerPath的参数。如:</p>

<pre><code>docker run -d -e MYSQL_ROOT_PASSWORD=admin --name mysql -v /opt/data/mysql:/var/lib/mysql -p 3306:3306 mysql
</code></pre>

<p>容器存放问题</p>

<p>Docker的存放位置为:/var/lib/Docker。一般根下分区我们不会给太大。镜像和容器越存越多一般我们有两种解决方法</p>

<p>挂载大分区到/var/lib/docker：</p>

<p>指定镜像和容器存放路径的参数是&ndash;graph=/var/lib/docker。</p>

<p>docker使用systemctl需要</p>

<p>在启动的时候把sys/fs/cgroup映射到docker容器中。</p>

<pre><code>docker run --privileged --name=test --hostname=test -v /sys/fs/cgroup:/sys/fs/cgroup image /usr/sbin/init
</code></pre>

<p>垃圾镜像容器清理</p>

<p>docker ps -a | grep &lsquo;weeks ago&rsquo; | awk &lsquo;{print $1}&rsquo; | xargs &ndash;no-run-if-empty docker rm</p>

<p>docker images | grep &ldquo;<none>&rdquo; | awk &lsquo;{print $3}&rsquo; | xargs docker rmi</p>

<p>cpu问题</p>

<p>cpuset设置cpu</p>

<p>cpu怎么也跑不起来，增加容器，cpu使用率就是那么多</p>

<p>rps设置一下就好</p>

<p>内存问题</p>

<p>-m 200M 分配内存</p>

<p>docker原理</p>

<p>docker有着比虚拟机更少的抽象层。由于docker不需要Hypervisor实现硬件资源虚拟化，运行在docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上docker将会在效率上有优势，当新建一个容器时，docker不需要和虚拟机一样重新加载一个操作系统内核。我们知道，引导、加载操作系统内核是一个比较费时费资源的过程，当新建一个虚拟机时，虚拟机软件需要加载Guest OS，这个新建过程是分钟级别的。</p>

<p>3.webserver</p>

<p>go的高并发部署</p>

<p>多进程部署，将前端请求划分，比如按地市分通道（路由），然后同一个进程部署多套，加nginx之类的负载均衡进行调度，然后到进程中，也就是官方提供的http的那个listen，进入具体的业务，就可以采用了1.简单并发，2，工作池，3异步处理。这边可以在逻辑里进行业务划分，到了这一边就是业务相关逻辑，优化业务，解决哪些很耗时间的操作，for循环什么的，最后就是数据库的优化，使用缓存数据库，优化数据库正常先对我们写的sql进行优化，可以看执行计划，然后数据库索引进行优化，然后就是分区，分表，分库的各种切分。</p>

<p>简单的业务，查询套餐配置模版</p>

<p>10-100台</p>

<p>单机20W并发连接   48核256G</p>

<p>&mdash;-&gt;20W的请求加入句柄队列，1分钟不到</p>

<p>qps.   1W左右.      10*50*20&mdash;&mdash;<sup>1000</sup>&frasl;<sub>20</sub>=50ms-100ms</p>

<p>万兆网     10G/s</p>

<p>mysql／pq／redis／mongo</p>

<p>1、服务器端口数和端口复用设置</p>

<p>默认情况下，客户端关闭TCP连接后本地的临时端口会长时间进入TIME_WAIT状态（默认120s），TIME_WAIT状态是为了保护TCP协议的正确性，避免端口发生复用后老的TCP连接残留在网络上的报文进入新的连接里。但这也引入了一个问题，临时端口数量有限，耗尽后，新建连接就会报错EADDRNOTAVAIL</p>

<p>首先要增加临时端口的数量，增加可被消耗的临时端口资源
sysctl -w &ldquo;net.ipv4.ip_local_port_range=1024 65535”</p>

<p>然后要加速临时端口回收</p>

<p>第一种方法是启用tw_reuse，tw_reuse能加速TIME_WAIT状态端口在几秒时间内安全的回收
sysctl -w net.ipv4.tcp_timestamps=1
sysctl -w net.ipv4.tcp_tw_reuse=1
2.6.32内核下启动tw_reuse短连接可以达到2w，性能并不稳定；</p>

<p>第二种方法更激进些，启用tw_recycle，tw_recycle允许在两个RTT。当多个客户端处于NAT后时，在服务器端开启tw_recycle会引起丢包问题，如果丢SYN包，就会造成新建连接失败
sysctl -w net.ipv4.tcp_timestamps=1
sysctl -w net.ipv4.tcp_tw_recycle=1
2.6.32内核下启动tw_recycle短连接可以达到6w，比较稳定；</p>

<p>第三种方法是给socket配置SO_LINGER，on设为1，linger设为0，这样关闭连接后TCP状态从ESTAB直接进入CLOSED，向服务器发rst包而不是fin包来关闭连接。这种方法风险最高，会丢弃buffer里未发送完的数据，不过通过设计协议（客户端和服务器协议上协商后再关闭TCP连接）可以规避这个问题，使用需要小心，选择合适的场景。
这个方法可以完全解掉TIME_WAIT问题，短连接达到20w，很稳定</p>

<p>短连接QPS达到20w后，网卡pps接近百万，耗时主要在软中断，内核spin_lock和网卡驱动里，也基本让内核态网络协议栈负载饱和了</p>

<p>调整系统参数
10m并发连接对系统是个挑战，需要调整相关的参数</p>

<p>sysctl -w fs.file-max=10485760 #系统允许的文件描述符数量10m
sysctl -w net.ipv4.tcp_rmem=1024 #每个tcp连接的读取缓冲区1k，一个连接1k
sysctl -w net.ipv4.tcp_wmem=1024 #每个tcp连接的写入缓冲区1k
#修改默认的本地端口范围
sysctl -w net.ipv4.ip_local_port_range=&lsquo;1024 65535&rsquo;
sysctl -w net.ipv4.tcp_tw_recycle=1  #快速回收time_wait的连接
sysctl -w net.ipv4.tcp_tw_reuse=1
sysctl -w net.ipv4.tcp_timestamps=1
#用户单进程的最大文件数，用户登录时生效
echo &lsquo;* soft nofile 1048576&rsquo; &gt;&gt; /etc/security/limits.conf
echo &lsquo;* hard nofile 1048576&rsquo; &gt;&gt; /etc/security/limits.conf
ulimit -n 1048576 #用户单进程的最大文件数 当前会话生效</p>

<p>并发连接数到达千万时，有诸多方面的问题需要解决：</p>

<p>. 单进程最大文件数量限制：limit -n 最多能把这个数字修改到1048575，因此单个进程最多能够打开百万个文件，千万并发连接需要千万个文件描述符，于是我们使用多进程来做到千万文件的支持</p>

<p>.多进程之间的负载均衡：nginx使用多进程来增加自己的吞吐量，原先采用共享锁的方式来平衡负载，对核数较多的服务器，较多的进程并没有达到性能的线性提升。最新的linux内核引入了SO_REUSEPORT选项，该选项可以自动平衡监听同一端口的多进程，是内核级的解决方案。handy采用该方案，优于nginx的旧有方式（最新的nginx也支持SO_REUSEPORT）。</p>

<p>.测试中客户端本地端口不够：让服务器监听了200个端口，这样客户端连接服务器的每个端口只有50k个连接，然后加大默认的本地端口范围就可以满足要求（见前面的服务器系统参数）</p>

<p>测试中如果一次性创建千万个连接，则绝大部分的连接创建都会失败，因此让客户端每100ms创建2000个连接，提高连接创建的成功率。</p>

<p>系统在运行中，并没有多少的负载，当然啦，一部分负载跑到底层的hypervisor去了</p>

<p>小编实验的机器上内存占用大约40G，平均一个连接前后一共用了4k，不多不多</p>

<p>大家可以通过iptraf，nload等工具来查看系统的网络情况</p>

<p>写到这里，顺便给出我测是的ucloud主机的性能参数吧：
网卡流量最多可以到1.2GBit/s，并非所有时间都到了这么高，并不稳定，一般在800M-1.2G之间波动
tcp收包发包的最高qps是12w/s，多了就上不去了</p>

<p>看基础</p>

<p>1.分布式原理</p>

<ol>
<li>go</li>
</ol>

<p>看go文档</p>

<p>3.shell</p>

<p>看shell文档</p>

<p>awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大</p>

<p>last -n 5 | awk  &lsquo;{print $1}&rsquo;</p>

<p>sed &ldquo;s/a/b/g&rdquo; filename</p>

<p>4.网络编程（tcp／ip协议）</p>

<p>创建一个套接字
int socket(int domain,     &mdash;&mdash;-协议族
int type,          &mdash;&mdash;socket类型
int protocol)          &mdash;&mdash;协议类型                          返回值是一个非负整数，失败返回-1</p>

<p>绑定一个本地地址到套接字
int bind(int sockfd,      &mdash;&mdash;&mdash;-创建套接字的描述符
const struct sockaddr *addr, &mdash;&mdash;&ndash;绑定的地址，强制指定struct sockaddr *类型
socklen_t addrlen);    地址的长度</p>

<p>使套接字进入由close进入监听状态
int listen（int sockfd,   &mdash;&mdash;&mdash;&mdash;-创建套接字的描述符
int backlog);              &mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-内核为套接字排队的最大连接数，建议用SOMAXCONN这个宏
监听两个队列，一个是未完成三次握手的队列，一个是已完成三次握手的队列</p>

<p>取已完成队列的第一个连接，无则柱塞    &mdash;-已完成套接字，主动套接字
int accept(int sockfd,&mdash;&mdash;&mdash;&mdash;-创建套接字的描述符
struct sockaddr *addr,&mdash;&mdash;&mdash;&ndash;对方套接字地址
socklen_t *addrlen);  &mdash;&mdash;&mdash;&mdash;对方套接字地址的长度</p>

<p>客户端：
建立一个套接字</p>

<p>连接至addr    &mdash;-已连接套接字，主动套接字
int connect(int sockfd,     &mdash;&mdash;&mdash;&mdash;-创建套接字的描述符
const struct sockaddr *addr,   &mdash;&mdash;&mdash;要连接套接字的地址
socklen_t addrlen)            &mdash;&mdash;地址长度</p>

<p>read（int sockfd，char *buf，sizeof（buf））
write（int sockfd，char *buf，sizeof（buf））</p>

<p>tcp的十一种状态：
服务端创建一个socket：closing状态
服务端监听这个套接口：listen状态   被动  只能被动接受连接
客户端创建套接字后connect：syn_sent状态
服务端accept：syn_rcvd状态
连接状态：established</p>

<p>关闭tcp：
客户端的fin_wait_1，fin_wait_2，time_wait
服务端的close_wait，last_ack，closed    状态</p>

<p>数据先由上往下将数据装包，然后由下往上拆包</p>

<p>sigpipe信号产生一般是服务器端关闭了，继续向其write，一般都是sig_int忽略</p>

<p>5.多线程</p>

<p>进程                   线程
fork             pthread_create
waitpid(僵进程)      pthread_join(僵线程)&mdash;&mdash;脱离pthread_detach&mdash;-代码中如果没有pthread_join主线程会很快结束从而使整个进程结束，从而使创建的线程没有机会开始执行就结                                    束了。加入pthread_join后，主线程会一直等待直到等待的线程结束自己才结束，使创建的线程有机会执行
exit                 pthread_exit
在main中return       在入口函数中return</p>

<p>kill                 pthread_cancel</p>

<p>getpid               pthread_self</p>

<p>线程：
int pthread_create(pthread_t *thread,&mdash;-线程id
const pthread_attr_t *attr,&mdash;&mdash;&ndash;线程属性
void *(*start_routine) (void *), &mdash;&mdash;入口函数地址&mdash;是void *类型，传参也是void * 类型
void *arg);&mdash;&mdash;&mdash;-传入入口函数的参数</p>

<p>int pthread_join(pthread_t thread,&mdash;&mdash;&mdash;-线程id
void **retval);&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;返回状态</p>

<p>void pthread_exit(void *retval);&mdash;&mdash;&mdash;&ndash;退出状态，类似于return 后面的数据</p>

<p>pthread_t pthread_self(void);</p>

<p>int pthread_cancel(pthread_t thread);</p>

<p>6.数据结构和常用算法</p>

<p>排序</p>

<p>7.数据库，redis，mysql</p>

<p>第一优化你的sql和索引；第二加缓存，memcached,redis；第三以上都做了后，还是慢，就做主从复制或主主复制，读写分离，可以在应用层做，效率高，也可以用三方工具，第三方工具推荐360的atlas,其它的要么效率不高，要么没人维护；第四如果以上都做了还是慢，不要想着去做切分，mysql自带分区表，先试试这个，对你的应用是透明的，无需更改代码,但是sql语句是需要针对分区表做优化的，sql条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区，另外分区表还有一些坑，在这里就不多说了；第五如果以上都做了，那就先做垂直拆分，其实就是根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；第六才是水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding</p>

<p>将连接指定到对应的机器上，减少切换啊</p>

<p>问题总结</p>

<p>docker资源隔离&mdash;k8s&mdash;-cgroup，namespace</p>

<p>cgroups ，其名称源自控制组群（ control groups ）的简写，是 Linux 内核的一个功能，用来限制，控制与分离一个进程组群的资源（如 CPU 、内存、磁盘输入输出等）。</p>

<p>网络实现原理&mdash;flanenl。caclio&mdash;&ndash;vxlan</p>

<p>应用部署，拉去镜像</p>

<p>调用harbor的api去拉去镜像。</p>

<p>并行和并发</p>

<p>并行就是同时执行的，并发是串行的，只不过不是cpu时间片的调度。</p>

<p>goroutine是在线程上串行跑的</p>

<p>go并发有哪些实现点</p>

<p>简单的并发
工作池+job
异步处理</p>

<p>并发流程，go协程并发调度，cpu时间片是怎么调度的</p>

<p>一旦发生阻塞就就进行切换</p>

<p>go协程和线程的区别</p>

<p>本质上协程就是用户空间下的线程</p>

<p>进程拥有自己独立的堆和栈，既不共享堆，亦不共享栈，进程由操作系统调度。
线程拥有自己独立的栈和共享的堆，共享堆，不共享栈，线程亦由操作系统调度(标准线程是的)。
协程和线程一样共享堆，不共享栈，协程由程序员在协程的代码里显示调度。</p>

<p>goroutine其实就是也是协程</p>

<p>一个豪华版线程池，拿来即用，减少了线程的创建销毁的消耗。</p>

<p>遇到阻塞或者同步动作时，怎么让线程池更容易扩展，不会因为其中一个任务的阻塞或者同步独占线程，甚至怎么避免由此问题带来的死锁，发起的同步或者channel动作，哪怕网络操作，都会把自身goroutine切换出去，让下一个预备好的goroutine去运行。而且Golang其本身还在此基础上很容易的做到对线程池的扩展，根据程序行为自动扩展或者收缩线程，尽可能的让线程保持在一个合适的数目。</p>

<p>Go的调度器内部有三个重要的结构：M，P，S
M:代表真正的内核OS线程，和POSIX里的thread差不多，真正干活的人
G:代表一个goroutine，它有自己的栈，instruction pointer和其他信息（正在等待的channel等等），用于调度。
P:代表调度的上下文，可以把它看做一个局部的调度器，使go代码在一个线程上跑，它是实现从N:1到N:M映射的关键。</p>

<p>用户空间线程和内核空间线程之间的映射关系有：N:1,1:1和M:N</p>

<p>N:1是说，多个（N）用户线程始终在一个内核线程上跑，context上下文切换确实很快，但是无法真正的利用多核。</p>

<p>1：1是说，一个用户线程就只在一个内核线程上跑，这时可以利用多核，但是上下文switch很慢。</p>

<p>M:N是说， 多个goroutine在多个内核线程上跑，这个看似可以集齐上面两者的优势，但是无疑增加了调度的难度。</p>

<p>线程和协程</p>

<p>1.内存占用</p>

<p>创建一个goroutine不需要太多的内存 - 大概2KB左右的栈空间。如果需要更多的栈空间，就从堆里分配额外的空间来使用。[2][3] 新创建的线程会占用1MB的内存空间（这大约是goroutine的500倍）</p>

<p>2.创建和销毁的开销</p>

<p>线程需要从操作系统里请求资源并在用完之后释放回去，因此创建和销毁线程的开销非常大。为了避免这些开销，我们通常的做法是维护一个线程池。Goroutine的创建和销毁是由运行环境（runtime）完成的。这些操作的开销就比较小。Go语言不支持手工管理goroutine。</p>

<p>3.切换开销
当一个线程阻塞的时候，另外一个线程需要被调度到当前处理器上运行。线程的调度是抢占式的（preemptively）。当切换一个线程的时候，调度器需要保存／恢复所有的寄存器。这包括16个通用寄存器，程序指针（program counter），栈指针（stack pointer），段寄存器（segment registers）和16个XMM寄存器，浮点协处理器状态，16个AVX寄存器，所有的特殊模块寄存器（MSR）等。当在线程间快速切换的时候这些开销就变得非常大了。</p>

<p>Goroutine的调度是协同合作式的（cooperatively）。当切换goroutine的时候，调度器只需要保存和恢复三个寄存器 - 程序指针，栈指针和DX。切换的开销就小多了。</p>

<p>前面已经谈到了，goroutine的数目会比线程多很多，但这并不影响切换的时间。有两个原因：第一，只有可以运行的goroutine才会被考虑，正在阻塞的goroutine会被忽略。第二，现代的调度器的复杂度都是O(1)的。这意味着选择的数目（线程或者是goroutine）不会影响切换的时间。[5]</p>

<p>map的本质是什么</p>

<p>Go中的map在底层是用哈希表实现的</p>

<p>type hmap struct {
    count     int // # 元素个数
    flags     uint8
    B         uint8  // 说明包含2^B个bucket
    noverflow uint16 // 溢出的bucket的个数
    hash0     uint32 // hash种子</p>

<pre><code>buckets    unsafe.Pointer // buckets的数组指针
oldbuckets unsafe.Pointer // 结构扩容的时候用于复制的buckets数组
nevacuate  uintptr        // 搬迁进度（已经搬迁的buckets数量）

extra *mapextra
</code></pre>

<p>}</p>

<p>HashMap和Hashtable的底层实现都是数组+链表结构实现</p>

<p>怎么实现一个map</p>

<p>常用的数据结构</p>

<p>hashmap</p>

<p>数组和链表的区别</p>

<p>数组与链表的优缺点；<br />
    数组:</p>

<pre><code>优点：使用方便 ，查询效率 比链表高，内存为一连续的区域 

缺点：大小固定，不适合动态存储，不方便动态添加
链表：

 优点：可动态添加删除   大小可变   
 缺点：只能通过顺次指针访问，查询效率低
</code></pre>

<p>补充：</p>

<p>顺序表的优点:查找方便,适合随机查找
顺序表的缺点:插入、删除操作不方便，因为插入、删除操作会导致大量元素的移动</p>

<p>链接表的优点:插入、删除操作方便，不会导致元素的移动，因为元素增减，只需要调整指针。
顺序表的缺点:查找方便，不适合随机查找</p>

<p>hash表的实现</p>

<p>散列表（Hash table，也叫哈希表），是根据键（Key）而直接访问在内存存储位置的数据结构。 哈希表就是一种以 键-值(key-indexed) 存储数据的结构，一对对形成一张类似于表的结构</p>

<p>typedef struct Node{
    const char* key;
    const char* value;
    Node *next;
}Node;</p>

<p>哈希查找</p>

<p>第一步就是要将key转为value的索引，这种转化方法就是哈希函数，</p>

<p>第二步就是用索引查找值，值放在对应的数组中。</p>

<p>这边转化后的索引可能指向同一个，也就是hash冲突，所以需要采取处理：拉链法和线性处理法。</p>

<p>拉链是指将数组指向一个链表，链表有对应的key-value且属于同一索引组成，然后再根据key匹配到对应的值。</p>

<p>线性探测：是还是将key-value放在数组中，在匹配key，命中也就是一样则找到，否则顺延往下找。也就是把同一索引的顺延往下存放。</p>

<p>当然最好减少hash冲突</p>

<p>1.尽量使关键字对应的记录均匀分配在哈希表里面（比如说某厂商卖30栋房子，均匀划分ABC3个区域，如果你划分A区域1个房子，B区域1个房子，C区域28个房子，有人来查找C区域的某个房子最坏的情况就是要找28次）。</p>

<p>2.关键字极小的变化可以引起哈希值极大的变化。</p>

<p>哈希函数：time33
数据较少的时候可以用直接定址，用一个线性函数完成映射，空间复杂度高一点
一般用除余法，选择一个较大的素数。一般最好是接近或者等于哈希表的长度。
数字选择法，在key过大的时候。</p>

<p>最熟悉的开源项目</p>

<p>redis</p>

<p>大量的数据结构，映射才能支撑那么高效灵活的内存存在。</p>

<p>zmalloc内存分配的重新实现(<a href="http://blog.csdn.net/androidlushangderen/article/details/40659331)。Redis的作者在内存分配上显然是早有准备，不会傻傻的还是调用系统的mallo和free方法，人家在这里做了一个小小的封装，便于管理者更方便的控制系统的内存">http://blog.csdn.net/androidlushangderen/article/details/40659331)。Redis的作者在内存分配上显然是早有准备，不会傻傻的还是调用系统的mallo和free方法，人家在这里做了一个小小的封装，便于管理者更方便的控制系统的内存</a></p>

<p>zipmap压缩结构的设计(<a href="http://blog.csdn.net/androidlushangderen/article/details/39994599)。Redis在内存处理上可谓是想尽了办法，ziplist压缩列表和zipmap压缩图就是非常典型的设计。与往常的结构体内直接放一个int64类型的整形变量，这样就占了8个字节，但是一般情况下，我们保存的数值都比较小，1个字节差不多就够了，所有就浪费了7个字节，所以zip压缩系列结构体，就可以动态分配字节应对不同的情况，这个设计非常精彩，要确定这个key-value">http://blog.csdn.net/androidlushangderen/article/details/39994599)。Redis在内存处理上可谓是想尽了办法，ziplist压缩列表和zipmap压缩图就是非常典型的设计。与往常的结构体内直接放一个int64类型的整形变量，这样就占了8个字节，但是一般情况下，我们保存的数值都比较小，1个字节差不多就够了，所有就浪费了7个字节，所以zip压缩系列结构体，就可以动态分配字节应对不同的情况，这个设计非常精彩，要确定这个key-value</a> 的位置，通过前面保留的长度做偏移量的定位。</p>

<p>k8s</p>

<p>自己做的项目</p>

<p>blog</p>

<p>frp</p>

<p>分布式存储的项目</p>

<p>读什么书</p>

<p>redis实战
docker进阶
google运维解密sre</p>

<p>遇到解决的问题超出自己的范畴</p>

<p>cachecloud的句柄数过多</p>

<p>应用cpu集中在一个核上跑，</p>

<p>c/c++</p>

<p>自我介绍</p>

<p>我叫蒋春银，本科毕业，目前定居南京，一直从事后端研发工作，已经工作四年了，目前主要是往服务器，高并发，容器化的方向发展，和我在贵公司应聘的这个职位应该还是比较契合的，希望能胜任。</p>

<p>项目</p>

<ol>
<li>银行对账系统</li>
</ol>

<p>、这个项目主要是银行和移动运营商之间的帐务对比,解决差异化问题，设计一套系统，完成业务需要。</p>

<p>基类，时间模块，日志模块，错误处理模块，配置解析模块实现</p>

<p>基类：</p>

<p>/<em>&ndash;常用函数&ndash;</em>/
    //进程初始化
    virtual int  initialize(int argc, char* argv[]);
    //启动进程前的准备工作
    virtual void prepare();
    //业务处理函数
    virtual void handle();
    //进程退出
    virtual void finish();</p>

<pre><code>//进程运行，执行顺序prepare -&gt; 循环执行handle -&gt; finish
void run();
</code></pre>

<p>设置initialize，prepare，handle，finish四个虚函数，分别初始化一些配置参数，启动进程前的准备工作比如数据库的链接，业务处理函数，进程退出&ndash;关闭连接，释放内存，然后在子类中具体实现，
 还有一个主函数run，
进程运行，执行顺序prepare -&gt; 循环执行handle -&gt; finish</p>

<p>时间模块：通过系统函数库，实现时间的基本获取，和加减乘除    virtual time_t mkTime() const;      //获取从1970年开始到指定日期的秒数
    virtual string getSysTime();        //获取系统时间
    int getHour() const;                //获取小时
    int getMinute() const;              //获取分钟
    int getSecond() const;              //获取秒
    void addDay(int nDay);              //增加天数
    void addHour(int nHour);            //增加小时
    void addMinute(int nMinute);        //增加分钟
    void addSecond(int nSecond);        //增加秒</p>

<p>日志模块：
先用c++的stream的组成日志的基本格式类型，然后打印输出</p>

<p>然后定日志的等级，根据规则数据固定的日志</p>

<p>enum FaLogLevel
{
    FAFATAL,    //0
    FAERROR,    //1
    FAWARN,     //2
    FAINFO,     //3
    FADEBUG     //4
};</p>

<p>错误模块：</p>

<p>基于c++的exception库获取异常编码和异常信息。</p>

<p>配置解析模块</p>

<p>就是配置文件中的配置信息加载到map中去，用于进程的获取。</p>

<p>通用函数：
比如数一些类型转化啊</p>

<p>业务模块</p>

<p>ftp上穿下载文件</p>

<p>使用了ftp的库，连接传输，</p>

<p>数据对比</p>

<p>将数据存到内存中的数据结构中去，根据给的规则进行对比矫正</p>

<p>数据入库，生产文件</p>

<p>分地市部署的，13套</p>

<ol>
<li>oracle数据导入redis</li>
</ol>

<p>这个项目只要是把oracle数据加载到redis中去，并对redis进行监控部署。</p>

<p>1.每条数据可以对应多个key,根据配置来决定key的个数.不停更新,oracle中数据发生改变,删除之类的对应的redis中数据进行改变,删除.</p>

<p>redis的使用</p>

<p>按表进行部署的，目前主要是检查一个配置信息，热点数据。</p>

<p>3.webserver开发</p>

<p>整理以前整理过的</p>

<p>传输协议</p>

<p>OSI七层模型
OSI 中的层            功能                                                        TCP/IP协议族
应 用层                 文件传输，电子邮件，文件服务，虚拟终 端         TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet
表示层                 数据格式化，代码转换，数据加密                                    没有协议
会话 层                 解除或建立与别的接点的联系                                          没有协议
传输层                 提供端对端的接口                                                        TCP，UDP （RTP）
网 络层                 为数据包选择路由                                                        IP，ICMP，RIP，OSPF，BGP，IGMP
数据链路层           传输有地址的帧以及错误检测功能                            SLIP，CSLIP，PPP，ARP，RARP，MTU
物 理层                 以二进制数据形式在物理媒体上传输数据                             ISO2110，IEEE802，IEEE802.2</p>

<hr />

<p>TCP/IP五层模型的协议</p>

<p>应用层
传输层：四层交换机、也有工作在四层的路由器</p>

<p>网络层：路由器、三层交换机</p>

<p>数据链路层：网桥（现已很少使用）、以太网交换机（二层交换机）、网卡（其实网卡是一半工作在物理层、一半工作在数据链路层）</p>

<p>物理层：中继器、集线器、还有我们通常说的双绞线也工作在物理层</p>

<p>视频流协议</p>

<p>rtp/rtcp/rtsp/</p>

<p>UDP协议是面向非连接的协议，它没有建立连接的过程。这里RTP正采用了因为UDP协议没有连接的过程，所以结果是它的通信效果高；
但同时也正因为如此，它的可靠性不如TCP协议高。
所以控制协议采用RTSP，视频流传输采用RTP进行快速通讯。</p>

<p>编解码</p>

<p>stl。boost</p>

<p>java</p>

<p>我叫蒋春银，本科毕业，目前定居南京，一直从事后端研发工作，已经工作四年了，目前主要是往服务器，高并发，大数据，容器化的方向发展，和我在贵公司应聘的这个职位应该还是比较契合的，希望能胜任。</p>

<p>paas项目</p>

<p>看go里面的paas</p>

<p>权限控制</p>

<p>银行对账系统</p>

<p>字节跳动面试经验总结</p>

<p>一面
1。说一下项目，balabala 疯狂吹
2。写一个map（非线程安全的），golang标准库非线程安全的map的是怎么实现的，map并发
3。channel 实现一个信号量
3。Linux epoll 模型，golang 并发模型，channel的实现，
4。MySQL的版本控制
5。GPM 模型，goroutine 切换的时机，channel 的实现</p>

<p>二面
1。说一下项目，boots-scaling， boots-operator，boots-proxy，dora-proxy 这些疯狂吹就是了
2。https，http2，grpc
3。二叉树的路径和问题
4。平时工作遇到了什么问题，怎么解决
5。蓝绿发布如何做的？ 说一下 mesh 的功能，解决了什么问题？
6。说一下 frp 这个项目解决什么问题，跟 nginx 的区别
7。为什么自研 discovery 组件，开源是 sentinel，consul，etcd，zk 不行么？ 性能怎么样？</p>

<p>三面
1。说一下项目，有什么挑战
2。如果有一个业务场景，在抖音上有一个活动，但是不能影响主业务，如何设计
3。24点游戏，写代码，奶奶的，这个真的难， 在 LeetCode hard 级别还增加了点难度， 加了排列组合的问题在里面，不过还是写出来了。
4。蓝绿发布怎么做的，灰度发布怎么做的
5。sidecar的资源占用情况如何？ 如果要你去优化，怎么做？ 说一下方案</p>

<p>朋友的java面试</p>

<p>一面：</p>

<p>1、dubbo的序列化默认是什么方式
2、在改造旧系统的时候，我们把现有的服务要改造成dubbo，一般类上加service（dubbo的）即可，那么现在有个service叫A，有个service叫B。那么A如何把用户信息带给B，也就是request对象怎么通过服务调用传递。
3、dubbo的注册中心挂了，会有什么影响？
4、dubbo的spi是怎么实现的
5、技术选型的时候为什么选择dubbo而不选择其他的
6、你们系统中redis的部署方式是什么？cluster的原理是什么，默认多少个槽位，有多个db？
7、redis如何实现分布式锁
8、redis支持事务吗？它这个事务和我们通常讲的数据库的事务有什么区别？实现原理是什么？
9、redis的缓存过期机制是怎么实现的？
10、MySQL的几个简单sql，其中考到了分组函数等
11、MySQL的索引原理
12、select * from table where a in (select b from table) and b=1，建的是单列索引，问索引的执行过程
13、乐观锁和悲观锁的含义，乐观锁怎么避免并发问题
14、事务隔离级别有哪几种，脏读、可重复读、 幻读的解释
15、spring的事务，一个普通方法a，调用了方法b，方法b上有事务声明，问事务是否生效。
16、springMVC的表达入参对象的注解是什么，一个方法里可以定义几个地方。IntercepterHandle的用法
17、rabbitmq的topic模式下，如果send后，添加一个队列，那么还会收到消息吗？
18、spring默认是单例，不想用单例用哪个属性（送分）</p>

<p>二面</p>

<p>1、jvm内存模型
2、GC
3、一致性哈希算法
4、线程池
5、自旋锁的理解
6、职业规划</p>

<p>三面</p>

<p>1、zookeeper的应用场景，为什么集群搭建要是奇数个
2、谈谈对分布式的理解，cap原则是什么
3、职业规划
4、为什么要这么高薪资</p>

<p>京东的面试官简单说</p>

<p>今天京东的架构说了句大并发，大数据下的业务其实还是靠堆机器保证的</p>

<p>我们现在研究的是如何在堆机器的情况下保证业务的连贯性，容错性，可用性</p>

<p>所以，要准备的就是:</p>

<ol>
<li>基本功，语言相关，算法相关，操作系统和网络相关。</li>
<li>项目经历，偏架构和后端常见设计，缓存，负载均衡，流控等等。根据项目经历自己扩展，能说的点以及可能被问到的点。</li>
</ol>

<p>我的工作，目前基本上就是优化，重构代码，提高我刚刚说的各个点的可靠性，稳定性，性能。
然后做好监控，告警，自动化运维。
目的就是承载更高的 qps，可扩展支持更多的业务需求，减少运维和后续开发上的人力消耗。</p>

<p>而且每个点，不是说有一个最优解，全盘通吃。
一般都是有取舍的，不同的项目，不同的系统，需要重视的地方不同，架构师就是要做出这个决定。</p>

<p>研究一个东西，就要研究透一些，找同类项目比较一些，优势是什么？有哪些点是可以有优化空间的？
如果是你做这个，你会怎么设计。</p>

<p>你就好好做后端，路随便走。。。</p>

<p>我出去面试go，走k8s，docker这个路线需要有什么建议
BOSS-王成龙  14:01:03
会用就行。。。
BOSS-王成龙  14:01:12
其他都是基本功
Smileヾ哩晓呏つ。  14:02:07
这个和没有说的一样啊
Smileヾ哩晓呏つ。  14:02:12
一般会问什么
Smileヾ哩晓呏つ。  14:02:24
你应该熟悉点
BOSS-王成龙  14:05:00
常见流程，先自我介绍，然后对着简历挨个问一遍，项目经历，面试官根据感兴趣的方向着重问，会根据要招的岗位问一些相关的话题，这个阶段可以自己主动一点，介绍一些自己的创新，有技术含量的设计和架构。</p>

<p>然后做一两道算法题，之后就是互相问，了解入职后要做的事，当前的一些架构，你有什么看法。
BOSS-王成龙  14:07:04
所以，要准备的就是:
1. 基本功，语言相关，算法相关，操作系统和网络相关。
2. 项目经历，偏架构和后端常见设计，缓存，负载均衡，流控等等。根据项目经历自己扩展，能说的点以及可能被问到的点。
Smileヾ哩晓呏つ。  14:09:56
你们有paas平台吗
BOSS-王成龙  14:11:45
有
Smileヾ哩晓呏つ。  14:12:01
能不能说说
Smileヾ哩晓呏つ。  14:12:11
我估计会问这个
Smileヾ哩晓呏つ。  14:12:20
我想知道点具体的东西
Smileヾ哩晓呏つ。  14:12:41
你们现在这个方向发展到什么程度了？
BOSS-王成龙  14:12:58
这个其实没什么具体的
BOSS-王成龙  14:13:08
大的方向没什么
Smileヾ哩晓呏つ。  14:13:09
我看看以后要是走上这条路后面是要干嘛
Smileヾ哩晓呏つ。  14:13:17
具体架构啊
BOSS-王成龙  14:13:19
都是常规技术的实现
Smileヾ哩晓呏つ。  14:13:41
多了解技术选型
BOSS-王成龙  14:14:28
说到底，后端还是就那么些东西
Smileヾ哩晓呏つ。  14:14:54
好吧
BOSS-王成龙  14:14:58
就是在每个方向不断优化
Smileヾ哩晓呏つ。  14:15:06
那你现在在做什么啊
BOSS-王成龙  14:15:12
撇开这些谈架构，就是扯淡
Smileヾ哩晓呏つ。  14:15:31
不是架构，就是技术选型呗
Smileヾ哩晓呏つ。  14:16:25
搞这个后面会和大数据接轨吗？
BOSS-王成龙  14:16:43
我建议你按照常见的要点来列一下清单，逐个了解下相关的内容
BOSS-王成龙  14:17:19
方向没那么大区分，后面想做什么做什么
Smileヾ哩晓呏つ。  14:17:20
我现在是什么都搞搞，没有体系，没有突出的方向走出去，不知道下面干嘛
Smileヾ哩晓呏つ。  14:17:43
现在唯一的就是搞这个云了
BOSS-王成龙  14:18:04
比如，负载均衡，你弄透了没有
BOSS-王成龙  14:18:15
就这一个点，可以无限扩展出去
BOSS-王成龙  14:18:25
比如，服务发现
Smileヾ哩晓呏つ。  14:18:33
都不能说弄透了，只能说知道会用
Smileヾ哩晓呏つ。  14:18:59
所以需要进一步的发展啊
BOSS-王成龙  14:19:20
从简单的角度来看，是没什么内容，写个普通的服务可能用起来也很简单。
但是放到实际环境中就不一样了，节点增多，QPS 提高后，要考虑的点就多了。
BOSS-王成龙  14:19:29
后面的就是经验了
BOSS-王成龙  14:19:48
还有 流量控制，限流，熔断
BOSS-王成龙  14:19:52
也是一个点
Smileヾ哩晓呏つ。  14:19:53
好吧，就是缺乏经验
BOSS-王成龙  14:20:07
存储，分布式，这个就是架构
Smileヾ哩晓呏つ。  14:20:16
和我搞定api 网关差不多
Smileヾ哩晓呏つ。  14:20:24
好吧
Smileヾ哩晓呏つ。  14:20:43
那你现在还是在这些点上不断优化维护啊
BOSS-王成龙  14:20:45
后端，说到底了，就是接收请求，数据处理，存储，返回请求
Smileヾ哩晓呏つ。  14:20:55
没有做什么其他的吗
BOSS-王成龙  14:21:18
在不同的系统里，这些点需要的技术可能是不一样的
Smileヾ哩晓呏つ。  14:21:26
你研究人工智能了没
Smileヾ哩晓呏つ。  14:21:28
是的
Smileヾ哩晓呏つ。  14:21:46
还是不同的环境不同的业务也是这个道理
BOSS-王成龙  14:21:58
没有，人工智能主要还是做算法的人搞
BOSS-王成龙  14:22:03
我们提供平台，跑服务
Smileヾ哩晓呏つ。  14:23:08
好吧，新大陆这边在搞人脸识别呢
Smileヾ哩晓呏つ。  14:23:16
[图片]
Smileヾ哩晓呏つ。  14:23:27
今年去试试这个
Smileヾ哩晓呏つ。  14:23:52
你过两年可以回来了
BOSS-王成龙  14:24:40
我的工作，目前基本上就是优化，重构代码，提高我刚刚说的各个点的可靠性，稳定性，性能。
然后做好监控，告警，自动化运维。
目的就是承载更高的 qps，可扩展支持更多的业务需求，减少运维和后续开发上的人力消耗。
Smileヾ哩晓呏つ。  14:25:11
这个就厉害了
BOSS-王成龙  14:25:22
如果是专门招某一个方面的职位，就多了解点。
BOSS-王成龙  14:25:31
不过，其实你基本功好，这些都不是很重要
Smileヾ哩晓呏つ。  14:25:48
我也准备向这个方向发展
Smileヾ哩晓呏つ。  14:26:00
什么能叫基本功好呢
BOSS-王成龙  14:26:17
说的这么明显了，就多用用 k8s，想想 k8s 上怎么解决我说的那些问题的。
Smileヾ哩晓呏つ。  14:26:18
反正我的基本功不是太好的
Smileヾ哩晓呏つ。  14:26:24
嗯
BOSS-王成龙  14:26:25
基本功就是我说的那些店
BOSS-王成龙  14:26:27
点
Smileヾ哩晓呏つ。  14:26:29
嗯
BOSS-王成龙  14:26:30
后端基础
Smileヾ哩晓呏つ。  14:26:34
我知道
BOSS-王成龙  14:26:45
稍微聊一聊，就知道了
BOSS-王成龙  14:27:05
你是只知皮毛，还是对各个点有实际的开发经验
Smileヾ哩晓呏つ。  14:27:10
对啊，这就是面试
BOSS-王成龙  14:27:10
解决过各种复杂的问题
BOSS-王成龙  14:27:42
人脸识别，主要靠算法工程师了，和我们关系不大了
Smileヾ哩晓呏つ。  14:28:09
我算有只知皮毛的开发经验吧
BOSS-王成龙  14:28:18
你已经工作不少年了
BOSS-王成龙  14:28:25
就看你平时的总结了
Smileヾ哩晓呏つ。  14:28:33
搞了一段时间的paas平台，基本知道，但是没有深入
Smileヾ哩晓呏つ。  14:28:43
是的，已经工作不少年了
Smileヾ哩晓呏つ。  14:28:52
是时候了
Smileヾ哩晓呏つ。  14:29:02
往前走走了
Smileヾ哩晓呏つ。  14:29:07
[表情]
BOSS-王成龙  14:29:18
而且每个点，不是说有一个最优解，全盘通吃。
一般都是有取舍的，不同的项目，不同的系统，需要重视的地方不同，架构师就是要做出这个决定。
BOSS-王成龙  14:29:41
这个也是看经验
BOSS-王成龙  14:29:54
新手一般是，看到有什么技术就往上涌
BOSS-王成龙  14:29:55
用
Smileヾ哩晓呏つ。  14:30:04
完全同意啊
Smileヾ哩晓呏つ。  14:31:14
开始总结，然后出去看看，自己现在是个什么水平
BOSS-王成龙  14:31:30
最好的方式，是你自己平时工作积累。然后通过项目输出。
BOSS-王成龙  14:31:38
可以不断迭代
Smileヾ哩晓呏つ。  14:33:31
嗯，还是项目推动，现在环境欠佳
Smileヾ哩晓呏つ。  14:33:34
[表情]
BOSS-王成龙  14:34:26
你平时可以自己做的，要有自己的拿手项目，可以堆新技术的地方。
然后其他地方看到什么好的代码，技术，都往上用，当做试验品。
BOSS-王成龙  14:34:47
随着你的进步，基本上每隔一段时间，这个代码都能重构。
BOSS-王成龙  14:35:06
你对于同样的功能，看法就不一样了。
Smileヾ哩晓呏つ。  14:36:23
好吧，还是自己看的少了，做的少了
BOSS-王成龙  14:36:49
 你可能做的不少了，总结呢
BOSS-王成龙  14:37:09
新大陆也不小了，技术上还是有很多可以肯定的地方的
BOSS-王成龙  14:37:35
对了，还有各种数据库的使用，也是基本功了
BOSS-王成龙  14:37:39
最好了解下
Smileヾ哩晓呏つ。  14:37:55
数据库基本都会用
Smileヾ哩晓呏つ。  14:38:11
就是优化不是全部会优化
Smileヾ哩晓呏つ。  14:38:23
我主要用reids
Smileヾ哩晓呏つ。  14:38:29
mysql
BOSS-王成龙  14:38:37
性能测试下，常见优化，如何扩展
Smileヾ哩晓呏つ。  14:39:11
现在在看
Smileヾ哩晓呏つ。  14:39:23
大体了解下
Smileヾ哩晓呏つ。  14:39:31
不常用的
BOSS-王成龙  14:39:36
恩，其实我觉得，基本功扎实了，去面试就是聊天
Smileヾ哩晓呏つ。  14:39:52
现在就当聊天了
BOSS-王成龙  14:39:58
我上次面试的几家，都没什么太担心了，心态很轻松
BOSS-王成龙  14:40:04
就是和面试官聊聊
Smileヾ哩晓呏つ。  14:40:08
没有以前面试那种心态了
BOSS-王成龙  14:40:10
沟通一下
Smileヾ哩晓呏つ。  14:40:16
是啊
Smileヾ哩晓呏つ。  14:40:35
以后不换工作也可以面试一下，也是教练过程
BOSS-王成龙  14:40:35
当然，除了算法题
BOSS-王成龙  14:40:43
还是要大量练习准备一下的
BOSS-王成龙  14:40:59
把面试官引导到你擅长的方向很重要
Smileヾ哩晓呏つ。  14:41:11
就是感觉没有什么擅长的
Smileヾ哩晓呏つ。  14:41:14
尴尬
BOSS-王成龙  14:41:19
你会发现你在这些方面可能比面试官更擅长
BOSS-王成龙  14:41:24
这样更容易沟通
Smileヾ哩晓呏つ。  14:42:02
是啊，有这个当然更好了
BOSS-王成龙  14:43:10
恩，我的意思就是要自信
BOSS-王成龙  14:43:32
现在真没多少人在这些基本功上能真的做得好的
BOSS-王成龙  14:44:09
我这边，也还是会看到一些人，做后端，对网络也没有很深刻的认识
BOSS-王成龙  14:44:20
对操作系统原理也一知半解
Smileヾ哩晓呏つ。  14:44:42
很正常啊，很多都是做语言框架上去的
BOSS-王成龙  14:44:49
所以，面试你的人也不一定比你强
Smileヾ哩晓呏つ。  14:45:31
我没有想那么多，我只是想自己以后走哪条路，怎么走而已
BOSS-王成龙  14:45:43
研究一个东西，就要研究透一些，找同类项目比较一些，优势是什么？有哪些点是可以有优化空间的？
如果是你做这个，你会怎么设计。
BOSS-王成龙  14:46:01
你就好好做后端，路随便走。。。
Smileヾ哩晓呏つ。  14:46:06
就是向你取取经
BOSS-王成龙  14:46:06
想搞什么搞什么
BOSS-王成龙  14:46:41
搞平台，k8s 容器，没问题。大数据，数据挖掘没问题，人工智能也没问题
Smileヾ哩晓呏つ。  14:46:43
哪能，后端路这么多，要找一个擅长的，有潜力的啊
BOSS-王成龙  14:47:00
这些都是表象
BOSS-王成龙  14:47:12
今年火，明年可能就不火了
BOSS-王成龙  14:47:20
你的内功才是实实在在的
BOSS-王成龙  14:47:26
想练什么就练什么
Smileヾ哩晓呏つ。  14:47:37
我目前看到的不是表象啊，我觉得做大数据和云计算的完全学习不同的技术
Smileヾ哩晓呏つ。  14:48:19
以后就没有那么多精力了，可能走一个中的一项专研呢
BOSS-王成龙  14:48:37
好好修炼内功啊
Smileヾ哩晓呏つ。  14:48:59
有一个有深度，然后才能考虑广度的架构啊
BOSS-王成龙  14:48:59
其他的，都是表象，就是底层各种技术的不同结合
Smileヾ哩晓呏つ。  14:49:07
是的，内功不是也不同吗
BOSS-王成龙  14:49:31
内功就是基础，每一项都深入才最好
Smileヾ哩晓呏つ。  14:49:47
你看现在大数据的不同处理技术，和云的使用技术不一样啊
BOSS-王成龙  14:49:57
。。。
BOSS-王成龙  14:50:03
有什么不一样的
Smileヾ哩晓呏つ。  14:51:25
我想表达的是现在必须有一项拿得出手的技术，这个是我目前想要做的
Smileヾ哩晓呏つ。  14:52:08
其实你说的基础我也懂
Smileヾ哩晓呏つ。  14:52:26
也要内功深厚啊
BOSS-王成龙  14:52:43
那就你自己做一个项目，把你的积累都用上，通过项目展示你自己的技术
Smileヾ哩晓呏つ。  14:52:57
后面在考虑
BOSS-王成龙  14:53:38
你说的那些，真的不用操心，能做什么做什么，对什么感兴趣做什么
BOSS-王成龙  14:53:43
没有哪一个能长久的
BOSS-王成龙  14:54:04
大数据都快冷了（也不能说冷，只是回归正常，不炒作了）
BOSS-王成龙  14:54:25
人工智能是现在最热，两三年没大的突破，也要淡化下去
BOSS-王成龙  14:55:07
对于我来说，这些问题都是抽象的，抽象成，多少节点，多少请求，如何存储
Smileヾ哩晓呏つ。  14:56:01
嗯，是这么个情况，现在就是用我现在有的知识去找个拿到更多钱的好工作
Smileヾ哩晓呏つ。  14:56:21
前提是能找到满意的
BOSS-王成龙  14:56:56
说到底，我觉得体现你能力的一般是解决问题的时候
Smileヾ哩晓呏つ。  14:57:24
是啊
BOSS-王成龙  14:57:30
一般都是，遇到问题，如何优化，需不需要重构，要不要另外提出一个方案。
BOSS-王成龙  14:57:42
很容易就看出你的水平了
Smileヾ哩晓呏つ。  14:58:12
那就让它们看看我的水平吧
Smileヾ哩晓呏つ。  14:58:15
哈哈
Smileヾ哩晓呏つ。  14:58:19
希望找个好的
Smileヾ哩晓呏つ。  14:59:27
哦了，问你个私密问题
Smileヾ哩晓呏つ。  14:59:36
你现在拿多少啊
BOSS-王成龙  14:59:48
之前不是和你说了吗
Smileヾ哩晓呏つ。  14:59:55
你不涨啊
Smileヾ哩晓呏つ。  14:59:59
都这么久了‘
BOSS-王成龙  15:00:04
下个月
Smileヾ哩晓呏つ。  15:00:23
好吧，还想看看好公司的涨幅呢
BOSS-王成龙  15:01:19
一般内部涨薪不会太多，10% -15% 吧
Smileヾ哩晓呏つ。  15:01:26
在问你一个白痴的问题，我要15过分不
BOSS-王成龙  15:01:43
想涨钱，还是跳槽最实在
Smileヾ哩晓呏つ。  15:01:54
阿里来南京，你回来不
Smileヾ哩晓呏つ。  15:02:37
不对，应该问你还有回南京的意愿不
BOSS-王成龙  15:04:57
你要的钱，看一下那边你这个工作年限和水平，招聘网站上的报价
BOSS-王成龙  15:05:21
找两三个小公司试一下，要的高一些
BOSS-王成龙  15:05:42
然后看最后 offer 的水平，再去心怡的公司报
BOSS-王成龙  15:05:46
通常高2-3k
Smileヾ哩晓呏つ。  15:05:58
可以
Smileヾ哩晓呏つ。  15:06:03
上海呢
Smileヾ哩晓呏つ。  15:06:06
你关注美
Smileヾ哩晓呏つ。  15:06:08
没
BOSS-王成龙  15:07:29
没有，我要是跳槽的话，可能预计能接受的底线就是年薪40w了，按照正常跳槽的涨幅来算
Smileヾ哩晓呏つ。  15:07:59
年薪40w，这么猛
BOSS-王成龙  15:08:03
跳槽涨幅 20-30% 比较正常
Smileヾ哩晓呏つ。  15:08:45
这个涨幅有点低啊
BOSS-王成龙  15:10:43
这个是正常的跳槽涨幅，你不能指望每次都翻倍啊
Smileヾ哩晓呏つ。  15:11:10
这个是你这种程度的，对我来说没有50%就没有太大的意义
BOSS-王成龙  15:11:53
对了，通常工作年限高了，就可以找猎头了
BOSS-王成龙  15:12:02
不过，南京的我不认识
BOSS-王成龙  15:13:05
多参与 github 项目，及时更新各个招聘网站上的简历
BOSS-王成龙  15:13:35
然后会有一些人主动找你的
Smileヾ哩晓呏つ。  15:16:06
有猎头找你了
Smileヾ哩晓呏つ。  15:16:07
？
BOSS-王成龙  15:16:34
这个很正常的，还有其他人给我推荐的猎头
BOSS-王成龙  15:16:37
也有主动找的
Smileヾ哩晓呏つ。  15:16:44
厉害了
BOSS-王成龙  15:16:52
就加个微信，然后以后有意向可以互相联系
Smileヾ哩晓呏つ。  15:17:12
可以了，以后多个机会多条路
BOSS-王成龙  15:18:02
大公司很多都会从网上搜简历的
BOSS-王成龙  15:18:13
阿里的，我已经收到大概四个了
Smileヾ哩晓呏つ。  15:18:28
那你没有去试一下
BOSS-王成龙  15:18:33
v2ex 上也可以看看
Smileヾ哩晓呏つ。  15:18:44
那个是上海的
BOSS-王成龙  15:18:48
没有，暂时不打算换
Smileヾ哩晓呏つ。  15:19:22
现在主要就是拉钩，boss
Smileヾ哩晓呏つ。  15:19:30
没有在其他地方找
BOSS-王成龙  15:19:39
可以了
BOSS-王成龙  15:19:49
面试的时候也多结交一下
BOSS-王成龙  15:19:51
HR，猎头
BOSS-王成龙  15:19:54
CTO
BOSS-王成龙  15:20:01
后面路很多
Smileヾ哩晓呏つ。  15:20:04
嗯
Smileヾ哩晓呏つ。  15:20:11
后面注意这方面的
BOSS-王成龙  15:20:24
很多人要招人了朋友圈里也会发一下，让帮推荐
Smileヾ哩晓呏つ。  15:21:17
嗯
BOSS-王成龙  15:23:09
还是建议你多参与开源项目，这是一条捷径。
有项目，省事很多，没项目，然后工作经历不够丰富的话，要靠基本功的话，还是比较累的，不管是面试还是交流。
BOSS-王成龙  15:24:43
你既然要换工作，怎么不来上海呆两年
BOSS-王成龙  15:26:03
[图片]
Smileヾ哩晓呏つ。  15:26:08
开源需要大量的时间和精力，后面有时间还是想搞搞的，后面带带我，我可能会拖后腿
BOSS-王成龙  15:26:20
[图片]
Smileヾ哩晓呏つ。  15:26:45
这个是啥
BOSS-王成龙  15:26:52
我们的内推职位
Smileヾ哩晓呏つ。  15:26:59
这么多
Smileヾ哩晓呏つ。  15:29:46
招的都是高端职位啊
BOSS-王成龙  15:30:06
没什么高不高端
Smileヾ哩晓呏つ。  15:30:13
想去上海啊，有了家庭不是那么容易的
Smileヾ哩晓呏つ。  15:30:23
南京能解决的，就不会出去的
BOSS-王成龙  15:30:30
你老婆现在还是在之前的公司？
BOSS-王成龙  15:30:41
上海也是可以每周回去的。。。
Smileヾ哩晓呏つ。  15:30:45
嗯，她已经入股了
Smileヾ哩晓呏つ。  15:30:56
不一样，以后你有小孩就知道
Smileヾ哩晓呏つ。  15:31:11
得舍之间还是选择下一代吧
BOSS-王成龙  15:31:20
。。。
BOSS-王成龙  15:31:23
为啥选择下一代
BOSS-王成龙  15:31:33
下一代当然自力更生了
Smileヾ哩晓呏つ。  15:31:50
不是，现在小孩就要教了
Smileヾ哩晓呏つ。  15:32:06
我家儿子明年就要上学了，你可以想象吗
BOSS-王成龙  15:32:12
这个两个人有一个主抓教育就好了吧
BOSS-王成龙  15:32:17
幼儿园啊
Smileヾ哩晓呏つ。  15:32:31
需要引导啊
Smileヾ哩晓呏つ。  15:32:43
反正就是一个人搞不定
Smileヾ哩晓呏つ。  15:32:50
反正就是事多
BOSS-王成龙  15:34:10
你爸妈呢
Smileヾ哩晓呏つ。  15:34:23
不和你说那么多
Smileヾ哩晓呏つ。  15:34:59
这个事情没有必要辩解
Smileヾ哩晓呏つ。  15:35:04
家庭不一样
BOSS-王成龙  15:35:33
不是辩解，本身也没什么对错的事
Smileヾ哩晓呏つ。  15:35:40
嗯
Smileヾ哩晓呏つ。  15:36:05
就是解释显得苍白无力
Smileヾ哩晓呏つ。  15:36:11
[表情]
BOSS-王成龙  15:37:14
就是和你说说，说不定哪天你的想法就变了
Smileヾ哩晓呏つ。  15:37:25
哈哈，希望我变了
BOSS-王成龙  15:37:39
我以前有个朋友，在家里开药店，收入也不错，带小孩，每天很多时间玩游戏
BOSS-王成龙  15:38:01
后来不知道怎么了，估计日子太无聊了，就跟着人家出去做工程了
BOSS-王成龙  15:38:06
一年也就回去几次
BOSS-王成龙  15:38:21
可能不同阶段各种想法
Smileヾ哩晓呏つ。  15:39:02
可能吧
Smileヾ哩晓呏つ。  15:39:27
也行孩子大了，我想法也不一样
BOSS-王成龙  15:39:41
所以，没事和你说说，说不定你后面就过来了
BOSS-王成龙  15:40:12
呆两年，可能不合适就回去了，然后受到新鲜环境的刺激，回去说不定就做大事了
Smileヾ哩晓呏つ。  15:40:43
说不定你结婚了，想法也不一样了
BOSS-王成龙  15:41:05
我觉得不太可能了，我不太能接受日复一日的无聊生活
BOSS-王成龙  15:41:17
肯定是大量时间花在工作上了
Smileヾ哩晓呏つ。  15:43:55
[表情]
Smileヾ哩晓呏つ。  15:44:00
实业家
BOSS-王成龙  15:45:32
获取成就感和愉悦心情的方式不一样
BOSS-王成龙  15:45:47
可能有的人看着小孩成长就有很大的成就感
BOSS-王成龙  15:45:53
就像养成游戏。。。
Smileヾ哩晓呏つ。  15:46:16
额，我其实不是你想的那样，我更多的是责任
Smileヾ哩晓呏つ。  15:46:43
只不过不能通过你说的那种方式来承担
BOSS-王成龙  15:47:53
心态不同吧，就好比外国人，可能更在意自己的生活。国人还是重血缘
Smileヾ哩晓呏つ。  15:48:08
嗯
BOSS-王成龙  20:52:07
你要不要来我们这面试看看，反正不来也没关系，可以尝试尝试
BOSS-王成龙  20:52:18
都当积累面试经验</p>

            </div>
            
            <div style="border: 1px dashed #e0e0e0; margin-bottom: 15px; padding: 10px 10px 10px 10px; background-color: #fffeee; background-repeat: no-repeat; background-attachment: scroll; background-position: 1% 50%; -moz-background-size: auto auto; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;">
                <div>
                    <p style="margin-top:0px;">作者：<a target="_blank" href="http://blog.fatedier.com/">kingjcy</a>
                    <br />本文出处：<a target="_blank" href="https://kingjcy.github.io/post/worklife/interviewshare/">https://kingjcy.github.io/post/worklife/interviewshare/</a>
                    <br />
                    文章版权归本人所有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文链接，否则保留追究法律责任的权利。 </p>
                </div>
            </div>

            <aside>
                
                <ul class="list-inline post-tags">
                    
                    <li>
                        <a href="/tags/interview/">
                            <i class="fa fa-tags"></i>
                            interview
                        </a>
                    </li>
                    
                </ul>

                
                
                <h4 id="real-rels">相关文章</h4>
                <ul class="post-rels" id="real-rels"></ul>
            </aside>
                
            
            <footer>
                <nav>
                    <ul class="pager">

                        
                        <li class="previous"><a href="/post/cloud/paas/platform/racher/"><span aria-hidden="true">&larr;</span> Prev</a></li>
                        

                        <li><a href="/post/">All Posts</a></li>

                        
                        <li class="next"><a href="/post/linux/system/fs/">Next <span aria-hidden="true">&rarr;</span></a></li>
                        

                    </ul>
                </nav>
            </footer>

        </article>
    </div>
    <div class="col-md-4">
        
<aside>
        <div class="toc panel panel-default hidden-xs hidden-sm affix-top" data-spy="affix" data-offset-top="125" data-offset-bottom="300">
            <div class="panel-heading">
                <h2 class="panel-title">Catalog</h2>
            </div>

            <nav id="TableOfContents">
<ul>
<li><a href="#流程">流程</a></li>
<li><a href="#myself">myself</a></li>
<li><a href="#项目">项目</a>
<ul>
<li>
<ul>
<li><a href="#容器基础平台">容器基础平台</a></li>
<li><a href="#容器监控平台">容器监控平台</a></li>
<li><a href="#容器日志平台">容器日志平台</a></li>
<li><a href="#数据处理平台">数据处理平台</a></li>
</ul></li>
</ul></li>
<li><a href="#常规基础">常规基础</a>
<ul>
<li>
<ul>
<li><a href="#架构">架构</a></li>
<li><a href="#go基础">go基础</a></li>
<li><a href="#容器相关技术">容器相关技术</a></li>
<li><a href="#计算机网络">计算机网络</a></li>
<li><a href="#数据库">数据库</a></li>
<li><a href="#难题">难题</a></li>
<li><a href="#看书">看书</a></li>
<li><a href="#算法与数据结构">算法与数据结构</a></li>
<li><a href="#过程记录">过程记录</a></li>
</ul></li>
</ul></li>
<li><a href="#历史记录-杂乱无章-待整理">历史记录（杂乱无章，待整理）</a></li>
</ul>
</nav>
        </div>
</aside>

    </div>
</div>

</div>
<hr>

<footer class="container copy">
    <p>&copy; 2020  kingjcy blog </p>
	<p>Powered by <a href="https://gohugo.io" target="_blank">Hugo</a></p>
</footer>

<script>hljs.initHighlightingOnLoad();</script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?ace3ec99de96c4080ead1eb8d52db3b3";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-92600390-2', 'auto');
  ga('send', 'pageview');
</script>
</body>
</html>


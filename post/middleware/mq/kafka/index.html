<!DOCTYPE html>

<html lang="zh-cn">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="author" content="fatedier">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="description" content="Apache Kafka由著名职业社交公司LinkedIn开发，最初是被设计用来解决LinkedIn公司内部海量日志传输等问题。Kafka使用Scala语言编写，于2011年开源并进入Apache孵化器，2012年10月正式毕业，现在为Apache顶级项目。Kafka是一个分布式数据流平台，具有高吞吐、低延迟、高容错等特点。">
<meta property="og:url" content="https://kingjcy.github.io/"><meta property="og:type" content="article">
<meta property="og:title" content="消息队列系列---- Kafka - kingjcy blog"><meta property="og:site_name" content="kingjcy blog">

<title>
    
    消息队列系列---- Kafka
    
</title>

<link rel="stylesheet" href="/onlyone/onlyone.css">
<link rel="shortcut icon" href="/assets/favicon.ico">
<script src="/onlyone/onlyone.js"></script>
<link rel="alternate" type="application/rss+xml" title="RSS" href="/index.xml">
</head>
<body>


<div class="container">
    <header class="nav">
        <nav class="navbar navbar-default">
            <div class="container-fluid">
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="/">kingjcy blog</a>
                </div>

                <div class="collapse navbar-collapse" id="navbar-collapse">
                    <ul class="nav navbar-nav">
                        <li><a href="/categories/技术文章/">技术文章</a></li>
			<li><a href="/categories/读书笔记/">读书笔记</a></li>
                        <li><a href="/categories/人生感悟/">人生感悟</a></li>
                        <li><a href="/categories/">归档</a></li>
                        <li><a href="/tags/">分类</a></li>
                        <li><a href="/about/">关于我</a></li>
                        <li>
                            <form method="get" style="padding: 8px" action="https://www.google.com/search" target="_blank">
                                <input type="hidden" name="sitesearch" value="https://kingjcy.github.io/"/>
                                <input type="text" class="form-control" name="q" placeholder="Press enter to search">
                            </form>
                        </li>
                    </ul>

                </div>
            </div>
        </nav>
    </header>


<div class="row">
    <div class="col-md-8">
        <article class="post single">

            <header>
                <div class="post-date">
                    2017年07月19日 
                </div>
                <h1 class="post-title">消息队列系列---- Kafka</h1>
            </header>

            <div class="post-content">
                <p>Apache Kafka由著名职业社交公司LinkedIn开发，最初是被设计用来解决LinkedIn公司内部海量日志传输等问题。Kafka使用Scala语言编写，于2011年开源并进入Apache孵化器，2012年10月正式毕业，现在为Apache顶级项目。Kafka是一个分布式数据流平台，具有高吞吐、低延迟、高容错等特点。</p>

<h1 id="kafka简介">Kafka简介</h1>

<h2 id="基本术语">基本术语</h2>

<blockquote>
<p>消息message</p>
</blockquote>

<p>先不管其他的，我们使用Kafka这个消息系统肯定是先关注消息这个概念，在Kafka中，每一个消息由键、值和一个时间戳组成（key、value和timestamp）</p>

<blockquote>
<p>主题topic</p>
</blockquote>

<p>Kafka集群存储同一类别的消息流称为主题</p>

<p>主题会有多个订阅者（0个1个或多个），当主题发布消息时，会向订阅者推送记录</p>

<blockquote>
<p>日志 offset</p>
</blockquote>

<p>针对每一个主题，Kafka集群维护了一个像下面这样的分区日志offset：</p>

<p>这些分区位offset于不同的服务器上，每一个分区可以看做是一个结构化的提交日志offset，每写入一条记录都会记录到其中一个分区并且分配一个唯一地标识其位置的数字称为偏移量offset</p>

<p>Kafka集群会将发布的消息保存一段时间，不管是否被消费。例如，如果设置保存天数为2天，那么从消息发布起的两天之内，该消息一直可以被消费，但是超过两天后就会被丢弃以节省空间。其次，Kafka的数据持久化性能很好，所以长时间存储数据不是问题</p>

<blockquote>
<p>分区 Partition</p>
</blockquote>

<p>每个topic可以有一个或多个partition（分区）。分区是在物理层面上的，不同的分区对应着不同的数据文件。Kafka使用分区支持物理上的并发写入和读取，从而大大提高了吞吐量</p>

<p>Kafka中采用分区的设计有几个目的。一是可以处理更多的消息，不受单台服务器的限制。Topic拥有多个分区意味着它可以不受限的处理更多的数据。第二，分区可以作为并行处理的单元，稍后会谈到这一点</p>

<p>Log的分区被分布到集群中的多个服务器上。每个服务器处理它分到的分区。根据配置每个分区还可以复制到其它服务器作为备份容错。 每个分区有一个leader，零或多个follower。Leader处理此分区的所有的读写请求，而follower被动的复制数据。如果leader宕机，其它的一个follower会被推举为新的leader。 一台服务器可能同时是一个分区的leader，另一个分区的follower。 这样可以平衡负载，避免所有的请求都只让一台或者某几台服务器处理。</p>

<blockquote>
<p>生产者 producer</p>
</blockquote>

<p>生产者往某个Topic上发布消息。生产者还可以选择将消息分配到Topic的哪个节点上。最简单的方式是轮询分配到各个分区以平衡负载，也可以根据某种算法依照权重选择分区</p>

<blockquote>
<p>消费者 consumer</p>
</blockquote>

<p>Kafka有一个消费者组的概念，生产者把消息发到的是消费者组，在消费者组里面可以有很多个消费者实例。</p>

<blockquote>
<p>消费者组 Consumer Group</p>
</blockquote>

<p>一个消费者组可以包含一个或多个消费者。使用多分区+多消费者方式可以极大提高数据下游的处理速度。</p>

<blockquote>
<p>节点 Broker</p>
</blockquote>

<p>消息队列中常用的概念，在Kafka中指部署了Kafka实例的服务器节点。</p>

<h1 id="安装部署">安装部署</h1>

<h2 id="单机">单机</h2>

<p>1、安装jdk</p>

<p>以oracle jdk为例，下载地址<a href="http://java.sun.com/javase/downloads/index.jsp">http://java.sun.com/javase/downloads/index.jsp</a></p>

<pre><code>yum -y install jdk-8u141-linux-x64.rpm
</code></pre>

<p>2、下载解压</p>

<p>下载地址：<a href="http://kafka.apache.org/downloads，如0.10.1.0版本的Kafka下载">http://kafka.apache.org/downloads，如0.10.1.0版本的Kafka下载</a></p>

<pre><code>wget http://apache.fayea.com/kafka/0.10.1.0/kafka_2.11-0.10.1.0.tgz
tar -xvf kafka_2.11-0.10.1.0.tgz
cd kafka_2.11-0.10.1.0
</code></pre>

<p>修改配置</p>

<pre><code>[root@localhost ~]# grep -Ev &quot;^#|^$&quot; /data/kafka/config/server.properties
broker.id=0
delete.topic.enable=true
listeners=PLAINTEXT://192.168.15.131:9092
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/data/kafka/data
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.flush.interval.messages=10000
log.flush.interval.ms=1000
log.retention.hours=168
log.retention.bytes=1073741824
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
zookeeper.connect=192.168.15.131:2181,192.168.15.132:2181,192.168.15.133:2181
zookeeper.connection.timeout.ms=6000
group.initial.rebalance.delay.ms=0
</code></pre>

<p>提示：其他主机将该机器的kafka目录拷贝即可，然后需要修改broker.id、listeners地址。有关kafka配置文件参数，参考：<a href="http://orchome.com/12；">http://orchome.com/12；</a></p>

<p>3、安装Zookeeper</p>

<p>Kafka需要Zookeeper的监控，所以先要安装Zookeeper。</p>

<pre><code>wget http://apache.forsale.plus/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gz
tar zxf zookeeper-3.4.9.tar.gz
mv zookeeper-3.4.9 /data/zk
</code></pre>

<p>修改配置文件内容如下所示:</p>

<pre><code>[root@localhost ~]# cat /data/zk/conf/zoo.cfg
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/data/zk/data/zookeeper
dataLogDir=/data/zk/data/logs
clientPort=2181
maxClientCnxns=60
autopurge.snapRetainCount=3
autopurge.purgeInterval=1

server.1=zk01:2888:3888
server.2=zk02:2888:3888
server.3=zk03:2888:3888
</code></pre>

<p>参数说明：</p>

<ul>
<li>server.id=host:port:port:表示了不同的zookeeper服务器的自身标识，作为集群的一部分，每一台服务器应该知道其他服务器的信息。用户可以从“server.id=host:port:port” 中读取到相关信息。</li>
</ul>

<p>在服务器的data(dataDir参数所指定的目录)下创建一个文件名为myid的文件，这个文件的内容只有一行，指定的是自身的id值。比如，服务器“1”应该在myid文件中写入“1”。这个id必须在集群环境中服务器标识中是唯一的，且大小在1～255之间。这一样配置中，zoo1代表第一台服务器的IP地址。第一个端口号（port）是从follower连接到leader机器的
端口，第二个端口是用来进行leader选举时所用的端口。所以，在集群配置过程中有三个非常重要的端口：clientPort：2181、port:2888、port:3888。</p>

<p>如果想更换日志输出位置，除了在zoo.cfg加入&rdquo;dataLogDir=/data/zk/data/logs&rdquo;外，还需要修改zkServer.sh文件，大概修改方式地方在125行左右，内容如下：</p>

<pre><code>125 ZOO_LOG_DIR=&quot;$($GREP &quot;^[[:space:]]*dataLogDir&quot; &quot;$ZOOCFG&quot; | sed -e 's/.*=//')&quot;
126 if [ ! -w &quot;$ZOO_LOG_DIR&quot; ] ; then
127 mkdir -p &quot;$ZOO_LOG_DIR&quot;
128 fi
</code></pre>

<p>在启动服务之前，还需要分别在zookeeper创建myid，方式如下：</p>

<pre><code>echo 1 &gt;  /data/zk/data/zookeeper/myid
</code></pre>

<p>启动服务</p>

<pre><code>/data/zk/bin/zkServer.sh start
</code></pre>

<p>验证服务</p>

<p>查看相关端口号</p>

<pre><code>[root@localhost ~]# ss -lnpt|grep java
LISTEN     0      50          :::34442                   :::*                   users:((&quot;java&quot;,pid=2984,fd=18))
LISTEN     0      50       ::ffff:192.168.15.133:3888                    :::*                   users:((&quot;java&quot;,pid=2984,fd=26))
LISTEN     0      50          :::2181                    :::*                   users:((&quot;java&quot;,pid=2984,fd=25))


###查看zookeeper服务状态
[root@localhost ~]# /data/zk/bin/zkServer.sh status

ZooKeeper JMX enabled by default

Using config: /data/zk/bin/../conf/zoo.cfgMode: follower
</code></pre>

<p>4、Kafka目录介绍</p>

<ul>
<li>/bin 操作kafka的可执行脚本，还包含windows下脚本</li>
<li>/config 配置文件所在目录</li>
<li>/libs 依赖库目录</li>
<li>/logs 日志数据目录，目录kafka把server端日志分为5种类型，分为:server,request,state，log-cleaner，controller</li>
</ul>

<p>5、启动Kafka</p>

<p>在每台服务器上进入Kafka目录，分别执行以下命令：</p>

<pre><code>bin/kafka-server-start.sh config/server.properties &amp;
</code></pre>

<p>检测2181与9092端口</p>

<pre><code>netstat -tunlp|egrep &quot;(2181|9092)&quot;
tcp        0      0 :::2181                     :::*                        LISTEN      19787/java          
tcp        0      0 :::9092                     :::*                        LISTEN      28094/java 
</code></pre>

<p>说明：</p>

<p>Kafka的进程ID为28094，占用端口为9092</p>

<p>QuorumPeerMain为对应的zookeeper实例，进程ID为19787，在2181端口监听</p>

<p>6、单机连通性测试</p>

<p>启动2个XSHELL客户端，一个用于生产者发送消息，一个用于消费者接受消息。</p>

<p>运行producer，随机敲入几个字符，相当于把这个敲入的字符消息发送给队列。</p>

<pre><code>bin/kafka-console-producer.sh --broker-list 192.168.153.118:9092 --topic test
</code></pre>

<p>说明：早版本的Kafka，–broker-list 192.168.1.181:9092需改为–zookeeper 192.168.1.181:2181</p>

<p>运行consumer，可以看到刚才发送的消息列表。</p>

<pre><code>bin/kafka-console-consumer.sh --zookeeper 192.168.153.118:2181 --topic test --from-beginning  
</code></pre>

<p>注意：</p>

<p>producer，指定的Socket(192.168.1.181+9092),说明生产者的消息要发往kafka，也即是broker</p>

<p>consumer, 指定的Socket(192.168.1.181+2181),说明消费者的消息来自zookeeper（协调转发）</p>

<p>上面的只是一个单个的broker，下面我们来实验一个多broker的集群。</p>

<h2 id="集群">集群</h2>

<p>搭建一个多个broker的伪集群，刚才只是启动了单个broker，现在启动有3个broker组成的集群，这些broker节点也都是在本机上。</p>

<p>1、为每一个broker提供配置文件</p>

<p>然后修改各个服务器的配置文件：进入Kafka的config目录，修改server.properties</p>

<pre><code># brokerid就是指各台服务器对应的id，所以各台服务器值不同
broker.id=0
# 端口号，无需改变
port=9092
# 当前服务器的IP，各台服务器值不同
host.name=192.168.0.10
# Zookeeper集群的ip和端口号
zookeeper.connect=192.168.0.10:2181,192.168.0.11:2181,192.168.0.12:2181
# 日志目录
log.dirs=/home/www/kafka-logs
</code></pre>

<p>我们先看看config/server0.properties配置信息：</p>

<pre><code>broker.id=0
listeners=PLAINTEXT://:9092
port=9092
host.name=192.168.1.181
num.network.threads=4
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/tmp/kafka-logs
num.partitions=5
num.recovery.threads.per.data.dir=1
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
log.cleaner.enable=false
zookeeper.connect=192.168.1.181:2181
zookeeper.connection.timeout.ms=6000
queued.max.requests =500
log.cleanup.policy = delete
</code></pre>

<p>说明：</p>

<p>broker.id为集群中唯一的标注一个节点，因为在同一个机器上，所以必须指定不同的端口和日志文件，避免数据被覆盖。</p>

<p>在上面单个broker的实验中，为什么kafka的端口为9092，这里可以看得很清楚。</p>

<p>kafka cluster怎么同zookeeper交互的，配置信息中也有体现。</p>

<p>那么下面，我们仿照上面的配置文件，提供2个broker的配置文件：</p>

<p>server2.properties:</p>

<pre><code>broker.id=2
listeners=PLAINTEXT://:9094
port=9094
host.name=192.168.1.181
num.network.threads=4
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/tmp/kafka-logs2
num.partitions=5
num.recovery.threads.per.data.dir=1
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
log.cleaner.enable=false
zookeeper.connect=192.168.1.181:2181
zookeeper.connection.timeout.ms=6000
queued.max.requests =500
log.cleanup.policy = delete
</code></pre>

<p>2、启动所有的broker</p>

<p>命令如下：</p>

<pre><code>bin/kafka-server-start.sh config/server0.properties &amp;   #启动broker0
bin/kafka-server-start.sh config/server1.properties &amp; #启动broker1
bin/kafka-server-start.sh config/server2.properties &amp; #启动broker2
</code></pre>

<p>查看2181、9092、9093、9094端口</p>

<pre><code>netstat -tunlp|egrep &quot;(2181|9092|9093|9094)&quot;
tcp        0      0 :::9093                     :::*                        LISTEN      29725/java          
tcp        0      0 :::2181                     :::*                        LISTEN      19787/java          
tcp        0      0 :::9094                     :::*                        LISTEN      29800/java          
tcp        0      0 :::9092                     :::*                        LISTEN      29572/java  
</code></pre>

<p>一个zookeeper在2181端口上监听，3个kafka cluster(broker)分别在端口9092,9093,9094监听。</p>

<p>3、创建topic</p>

<pre><code>bin/kafka-topics.sh --create --topic topic_1 --partitions 1 --replication-factor 3  \--zookeeper localhost:2181
bin/kafka-topics.sh --create --topic topic_2 --partitions 1 --replication-factor 3  \--zookeeper localhost:2181
bin/kafka-topics.sh --create --topic topic_3 --partitions 1 --replication-factor 3  \--zookeeper localhost:2181
</code></pre>

<p>查看topic创建情况：</p>

<pre><code>bin/kafka-topics.sh --list --zookeeper localhost:2181
test
topic_1
topic_2
topic_3
[root@atman081 kafka_2.10-0.9.0.0]# bin/kafka-topics.sh --describe --zookeeper localhost:2181
Topic:test  PartitionCount:1  ReplicationFactor:1 Configs:
  Topic: test Partition: 0  Leader: 0 Replicas: 0 Isr: 0
Topic:topic_1 PartitionCount:1  ReplicationFactor:3 Configs:
  Topic: topic_1  Partition: 0  Leader: 2 Replicas: 2,1,0 Isr: 2,1,0
Topic:topic_2 PartitionCount:1  ReplicationFactor:3 Configs:
  Topic: topic_2  Partition: 0  Leader: 1 Replicas: 1,2,0 Isr: 1,2,0
Topic:topic_3 PartitionCount:1  ReplicationFactor:3 Configs:
  Topic: topic_3  Partition: 0  Leader: 0 Replicas: 0,2,1 Isr: 0,2,1
</code></pre>

<p>第一个行显示所有partitions的一个总结，以下每一行给出一个partition中的信息，如果我们只有一个partition，则只显示一行。</p>

<p>leader 是在给出的所有partitons中负责读写的节点，每个节点都有可能成为leader</p>

<p>replicas 显示给定partiton所有副本所存储节点的节点列表，不管该节点是否是leader或者是否存活。</p>

<p>isr 副本都已同步的的节点集合，这个集合中的所有节点都是存活状态，并且跟leader同步</p>

<p>4、模拟客户端发送，接受消息</p>

<p>发送消息</p>

<pre><code>bin/kafka-console-producer.sh --topic topic_1 --broker-list 192.168.1.181:9092,192.168.1.181:9093,192.168.1.181:9094
</code></pre>

<p>接收消息</p>

<pre><code>bin/kafka-console-consumer.sh --topic topic_1 --zookeeper 192.168.1.181:2181 --from-beginning
</code></pre>

<p>需要注意，此时producer将topic发布到了3个broker中，现在就有点分布式的概念了。</p>

<p>5、kill some broker</p>

<pre><code>kill broker(id=0)
</code></pre>

<p>首先，我们根据前面的配置，得到broker(id=0)应该在9092监听,这样就能确定它的PID了。</p>

<p>broker0没kill之前topic在kafka cluster中的情况</p>

<pre><code>bin/kafka-topics.sh --describe --zookeeper localhost:2181
Topic:test  PartitionCount:1  ReplicationFactor:1 Configs:
  Topic: test Partition: 0  Leader: 0 Replicas: 0 Isr: 0
Topic:topic_1 PartitionCount:1  ReplicationFactor:3 Configs:
  Topic: topic_1  Partition: 0  Leader: 2 Replicas: 2,1,0 Isr: 2,1,0
Topic:topic_2 PartitionCount:1  ReplicationFactor:3 Configs:
  Topic: topic_2  Partition: 0  Leader: 1 Replicas: 1,2,0 Isr: 1,2,0
Topic:topic_3 PartitionCount:1  ReplicationFactor:3 Configs:
  Topic: topic_3  Partition: 0  Leader: 2 Replicas: 0,2,1 Isr: 2,1,0
</code></pre>

<p>kill之后，再观察，做下对比。很明显，主要变化在于Isr，以后再分析</p>

<pre><code>bin/kafka-topics.sh --describe --zookeeper localhost:2181
Topic:test  PartitionCount:1  ReplicationFactor:1 Configs:
  Topic: test Partition: 0  Leader: -1  Replicas: 0 Isr: 
Topic:topic_1 PartitionCount:1  ReplicationFactor:3 Configs:
  Topic: topic_1  Partition: 0  Leader: 2 Replicas: 2,1,0 Isr: 2,1
Topic:topic_2 PartitionCount:1  ReplicationFactor:3 Configs:
  Topic: topic_2  Partition: 0  Leader: 1 Replicas: 1,2,0 Isr: 1,2
Topic:topic_3 PartitionCount:1  ReplicationFactor:3 Configs:
  Topic: topic_3  Partition: 0  Leader: 2 Replicas: 0,2,1 Isr: 2,1
</code></pre>

<p>测试下，发送消息，接受消息，是否收到影响。</p>

<p>发送消息</p>

<pre><code>bin/kafka-console-producer.sh --topic topic_1 --broker-list 192.168.1.181:9092,192.168.1.181:9093,192.168.1.181:9094
</code></pre>

<p>接收消息</p>

<pre><code>bin/kafka-console-consumer.sh --topic topic_1 --zookeeper 192.168.1.181:2181 --from-beginning
</code></pre>

<p>可见，kafka的分布式机制，容错能力还是挺好的~</p>

<h1 id="kafka常用命令">Kafka常用命令</h1>

<p>1、新建一个主题</p>

<pre><code>bin/kafka-topics.sh --create --zookeeper hxf:2181,cfg:2181,jqs:2181,jxf:2181,sxtb:2181 --replication-factor 2 --partitions 2 --topic test
</code></pre>

<p>test有两个复制因子和两个分区</p>

<p>2、查看新建的主题</p>

<pre><code>bin/kafka-topics.sh --describe --zookeeper hxf:2181,cfg:2181,jqs:2181,jxf:2181,sxtb:2181 --topic test
</code></pre>

<p>2.8.8版本</p>

<pre><code>./kafka-create-topic.sh --partition 1 --replica 1 --zookeeper localhost:2181 --topic test

./kafka-list-topic.sh --zookeeper localhost:2181
</code></pre>

<p>我们来看一下查询的结果</p>

<pre><code>[root@dx3 bin]# ./kafka-topics.sh --describe --zookeeper localhost:2183 --topic test
Topic:test    PartitionCount:3    ReplicationFactor:3    Configs:
    Topic: test    Partition: 0    Leader: 0    Replicas: 0,1,2    Isr: 0,2,1
    Topic: test    Partition: 1    Leader: 1    Replicas: 1,2,0    Isr: 1,2,0
    Topic: test    Partition: 2    Leader: 2    Replicas: 2,0,1    Isr: 2,0,1

其中第一行是所有分区的信息，下面的每一行对应一个分区
Leader：负责某个分区所有读写操作的节点
Replicas：复制因子节点
Isr：存活节点
</code></pre>

<p>所以这个Kafka集群一共三个节点，test这个Topic, 编号为0的Partition,Leader在broker.id=0这个节点上，副本在broker.id为0 1 2这个三个几点，并且所有副本都存活，并跟broker.id=0这个节点同步</p>

<p>3、查看Kafka所有的主题</p>

<pre><code>bin/kafka-topics.sh --list --zookeeper hxf:2181,cfg:2181,jqs:2181,jxf:2181,sxtb:2181
</code></pre>

<p>4、在终端发送消息</p>

<pre><code>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
</code></pre>

<p>5、在终端接收（消费）消息</p>

<pre><code>bin/kafka-console-consumer.sh --zookeeper hxf:2181,cfg:2181,jqs:2181,jxf:2181,sxtb:2181 --bootstrap-server localhost:9092 --topic test --from-beginning
</code></pre>

<p>我们正常情况下不会使用自带的命令行进行数据的发送和消费，我们都是使用第三方库进行<a href="/post/middleware/mq/kafka-client/">客户端包括生产者和消费者</a>的编码，实现业务的正常使用。</p>

<h1 id="原理">原理</h1>

<p>先举一个例子</p>

<p><img src="/media/middleware/mq/kafka/20170719.png" alt="" /></p>

<p>Kafka集群有两台服务器，四个分区，此外有两个消费者组A和B，消费者组A具有2个消费者实例C1-2，消费者B具有4个消费者实例C3-6</p>

<p>例如此时我们创建了一个主题test，有两个分区，分别是Server1的P0和Server2的P1，假设此时我们通过test发布了一条消息，那么这条消息只会发到P0或P1其中之一，也就是消息只会发给其中的一个分区</p>

<p>分区接收到消息后会记录在分区日志中，记录的方式我们讲过了，就是通过offset，分区中的消息都是以k-v形式存在。k表示offset，称之为偏移量，一个64位整型的唯一标识，offset代表了Topic分区中所有消息流中该消息的起始字节位置。 v就是实际的消息内容,正因为有这个偏移量的存在，所以一个分区内的消息是有先后顺序的，即offset大的消息比offset小的消息后到。但是注意，由于消息随机发往主题的任意一个分区，因此虽然同一个分区的消息有先后顺序，但是不同分区之间的消息就没有先后顺序了，那么如果我们要求消费者顺序消费主题发的消息那该怎么办呢，此时只要在创建主题的时候只提供一个分区即可</p>

<p>讲完了主题发消息，接下来就该消费者消费消息了，假设上面test的消息发给了分区P0，此时从图中可以看到，有两个消费者组，那么P0将会把消息发到哪个消费者组呢？从图中可以看到，P0把消息既发给了消费者组A也发给了B，但是A中消息仅被C1消费，B中消息仅被C3消费。这就是我们要讲的，主题发出的消息会发往所有的消费者组，而每一个消费者组下面可以有很多消费者实例，这条消息只会被他们中的一个消费掉。</p>

<p>在多分区的情况下如何保证有序性呢？</p>

<ul>
<li>1、kafka分布式的单位是partition，同一个partition用一个write ahead log组织，记录的offset，所以可以保证FIFO的顺序。</li>
<li>2、不同partition之间不能保证顺序。但是绝大多数用户都可以通过message key来定义，因为同一个key的message可以保证只发送到同一个partition，比如说key是user id，table row id等等，所以同一个user或者同一个record的消息永远只会发送到同一个partition上，保证了同一个user或record的顺序。</li>
<li>3、消费出来自己根据一些数据进行排序，比如时间。</li>
</ul>

<blockquote>
<p>核心API</p>
</blockquote>

<p>Kafka具有4个核心API：</p>

<ul>
<li>Producer API：用于向Kafka主题发送消息。</li>
<li>Consumer API：用于从订阅主题接收消息并且处理这些消息。</li>
<li>Streams API：作为一个流处理器，用于从一个或者多个主题中消费消息流然后为其他主题生产消息流，高效地将输入流转换为输出流。</li>
<li>Connector API：用于构建和运行将Kafka主题和已有应用或者数据系统连接起来的可复用的生产者或消费者。例如一个主题到一个关系型数据库的连接能够捕获表的任意变化。</li>
</ul>

<blockquote>
<p>KAFKA吞吐量大的原因</p>
</blockquote>

<p>1、消息顺序写入磁盘，并且批量处理。</p>

<p>KAFKA维护一个Topic中的分区log，以顺序追加的方式向各个分区中写入消息，每个分区都是不可变的消息队列。分区中的消息都是以k-v形式存在。</p>

<ul>
<li>k表示offset，称之为偏移量，一个64位整型的唯一标识，offset代表了Topic分区中所有消息流中该消息的起始字节位置。</li>
<li>v就是实际的消息内容，每个分区中的每个offset都是唯一存在的，所有分区的消息都是一次写入，在消息未过期之前都可以调整offset来实现多次读取。</li>
</ul>

<p>我们知道现在的磁盘大多数都还是机械结构（SSD不在讨论的范围内），如果将消息以随机写的方式存入磁盘，就会按柱面、磁头、扇区的方式进行（寻址过程），缓慢的机械运动（相对内存）会消耗大量时间，导致磁盘的写入速度只能达到内存写入速度的几百万分之一，为了规避随机写带来的时间消耗，KAFKA采取顺序写的方式存储数据。</p>

<p>新来的消息只能追加到已有消息的末尾，并且已经生产的消息不支持随机删除以及随机访问，但是消费者可以通过重置offset的方式来访问已经消费过的数据。</p>

<p>即使顺序读写，过于频繁的大量小I/O操作一样会造成磁盘的瓶颈，所以KAFKA在此处的处理是把这些消息集合在一起批量发送，这样减少对磁盘IO的过度读写，而不是一次发送单个消息。</p>

<p>2、标准化二进制消息格式</p>

<p>尤其是在负载比较高的情况下无效率的字节复制影响是显着的。为了避免这种情况，KAFKA采用由Producer，broker和consumer共享的标准化二进制消息格式，这样数据块就可以在它们之间自由传输，无需转换，降低了字节复制的成本开销。</p>

<p>同时，KAFKA采用了MMAP(Memory Mapped Files，内存映射文件)技术。很多现代操作系统都大量使用主存做磁盘缓存，一个现代操作系统可以将内存中的所有剩余空间用作磁盘缓存，而当内存回收的时候几乎没有性能损失。</p>

<p>由于KAFKA是基于JVM的，并且任何与Java内存使用打过交道的人都知道两件事：</p>

<ul>
<li>对象的内存开销非常高，通常是实际要存储数据大小的两倍；</li>
<li>随着数据的增加，java的垃圾收集也会越来越频繁并且缓慢。</li>
</ul>

<p>基于此，使用文件系统，同时依赖页面缓存就比使用其他数据结构和维护内存缓存更有吸引力：</p>

<ul>
<li>不使用进程内缓存，就腾出了内存空间，可以用来存放页面缓存的空间几乎可以翻倍。</li>
<li>如果KAFKA重启，进行内缓存就会丢失，但是使用操作系统的页面缓存依然可以继续使用。</li>
</ul>

<p>可能有人会问KAFKA如此频繁利用页面缓存，如果内存大小不够了怎么办？</p>

<pre><code>KAFKA会将数据写入到持久化日志中而不是刷新到磁盘。实际上它只是转移到了内核的页面缓存。
</code></pre>

<p>利用文件系统并且依靠页缓存比维护一个内存缓存或者其他结构要好，它可以直接利用操作系统的页缓存来实现文件到物理内存的直接映射。完成映射之后对物理内存的操作在适当时候会被同步到硬盘上。</p>

<p>3、页缓存技术</p>

<p>为了优化读写性能，Kafka利用了操作系统本身的Page Cache，就是利用操作系统自身的内存而不是JVM空间内存。这样做的好处有：</p>

<ul>
<li>避免Object消耗：如果是使用 Java 堆，Java对象的内存消耗比较大，通常是所存储数据的两倍甚至更多。</li>
<li>避免GC问题：随着JVM中数据不断增多，垃圾回收将会变得复杂与缓慢，使用系统缓存就不会存在GC问题</li>
</ul>

<p>相比于使用JVM或in-memory cache等数据结构，利用操作系统的Page Cache更加简单可靠。首先，操作系统层面的缓存利用率会更高，因为存储的都是紧凑的字节结构而不是独立的对象。其次，操作系统本身也对于Page Cache做了大量优化，提供了 write-behind、read-ahead以及flush等多种机制。再者，即使服务进程重启，系统缓存依然不会消失，避免了in-process cache重建缓存的过程。</p>

<p>通过操作系统的Page Cache，Kafka的读写操作基本上是基于内存的，读写速度得到了极大的提升。</p>

<p>4、零拷贝</p>

<p>如下所示，数据从磁盘传输到socket要经过以下几个步骤：</p>

<ul>
<li>操作系统将数据从磁盘读入到内核空间的页缓存</li>
<li>应用程序将数据从内核空间读入到用户空间缓存中</li>
<li>应用程序将数据写回到内核空间到socket缓存中</li>
<li>操作系统将数据从socket缓冲区复制到网卡缓冲区，以便将数据经网络发出</li>
</ul>

<p>这里有四次拷贝，两次系统调用，这是非常低效的做法。如果使用sendfile，只需要一次拷贝就行</p>

<p>linux操作系统 “零拷贝” 机制使用了sendfile方法， 允许操作系统将数据从Page Cache 直接发送到网络，只需要最后一步的copy操作将数据复制到 NIC 缓冲区， 这样避免重新复制数据 。</p>

<p>通过这种 “零拷贝” 的机制，Page Cache 结合 sendfile 方法，Kafka消费端的性能也大幅提升。这也是为什么有时候消费端在不断消费数据时，我们并没有看到磁盘io比较高，此刻正是操作系统缓存在提供数据。</p>

<p>5、批量压缩</p>

<p>在很多情况下，系统的瓶颈不是CPU或磁盘，而是网络带宽，对于需要在广域网上的数据中心之间发送消息的数据流水线尤其如此。所以数据压缩就很重要。可以每个消息都压缩，但是压缩率相对很低。所以KAFKA使用了批量压缩，即将多个消息一起压缩而不是单个消息压缩。</p>

<p>KAFKA允许使用递归的消息集合，批量的消息可以通过压缩的形式传输并且在日志中也可以保持压缩格式，直到被消费者解压缩。</p>

<p>KAFKA支持Gzip和Snappy压缩协议。</p>

<p>6、批量读写</p>

<p>Kafka数据读写也是批量的而不是单条的。</p>

<p>除了利用底层的技术外，Kafka还在应用程序层面提供了一些手段来提升性能。最明显的就是使用批次。在向Kafka写入数据时，可以启用批次写入，这样可以避免在网络上频繁传输单个消息带来的延迟和带宽开销。假设网络带宽为10MB/S，一次性传输10MB的消息比传输1KB的消息10000万次显然要快得多。</p>

<blockquote>
<p>KAFKA数据可靠性深度解读</p>
</blockquote>

<p>KAFKA的消息保存在Topic中，Topic可分为多个分区，为保证数据的安全性，每个分区又有多个Replia。</p>

<p>多分区的设计的特点：</p>

<ul>
<li>为了并发读写，加快读写速度；</li>
<li>是利用多分区的存储，利于数据的均衡；</li>
<li>是为了加快数据的恢复速率，一但某台机器挂了，整个集群只需要恢复一部分数据，可加快故障恢复的时间。</li>
</ul>

<p>每个Partition分为多个Segment，每个Segment有.log和.index 两个文件，每个log文件承载具体的数据，每条消息都有一个递增的offset，Index文件是对log文件的索引，Consumer查找offset时使用的是二分法根据文件名去定位到哪个Segment，然后解析msg，匹配到对应的offset的msg。</p>

<p>Partition recovery过程</p>

<p>每个Partition会在磁盘记录一个RecoveryPoint,，记录已经flush到磁盘的最大offset。当broker 失败重启时，会进行loadLogs。首先会读取该Partition的RecoveryPoint，找到包含RecoveryPoint的segment及以后的segment， 这些segment就是可能没有完全flush到磁盘segments。然后调用segment的recover，重新读取各个segment的msg，并重建索引。每次重启KAFKA的broker时，都可以在输出的日志看到重建各个索引的过程。</p>

<blockquote>
<p>数据同步</p>
</blockquote>

<p>Producer和Consumer都只与Leader交互，每个Follower从Leader拉取数据进行同步。</p>

<p>如上图所示，ISR是所有不落后的replica集合，不落后有两层含义：距离上次FetchRequest的时间不大于某一个值或落后的消息数不大于某一个值，Leader失败后会从ISR中随机选取一个Follower做Leader，该过程对用户是透明的。</p>

<p>当Producer向Broker发送数据时,可以通过request.required.acks参数设置数据可靠性的级别。</p>

<p>此配置是表明当一次Producer请求被认为完成时的确认值。特别是，多少个其他brokers必须已经提交了数据到它们的log并且向它们的Leader确认了这些信息。</p>

<p>典型的值：</p>

<ul>
<li>0： 表示Producer从来不等待来自broker的确认信息。这个选择提供了最小的时延但同时风险最大（因为当server宕机时，数据将会丢失）。</li>
<li>1：表示获得Leader replica已经接收了数据的确认信息。这个选择时延较小同时确保了server确认接收成功。</li>
<li>-1：Producer会获得所有同步replicas都收到数据的确认。同时时延最大，然而，这种方式并没有完全消除丢失消息的风险，因为同步replicas的数量可能是1。如果你想确保某些replicas接收到数据，那么你应该在Topic-level设置中选项min.insync.replicas设置一下。</li>
</ul>

<p>仅设置 acks= -1 也不能保证数据不丢失,当ISR列表中只有Leader时,同样有可能造成数据丢失。要保证数据不丢除了设置acks=-1，还要保证ISR的大小大于等于2。</p>

<p>具体参数设置：</p>

<ul>
<li>request.required.acks:设置为-1 等待所有ISR列表中的Replica接收到消息后采算写成功。</li>
<li>min.insync.replicas: 设置为&gt;=2,保证ISR中至少两个Replica。</li>
<li>Producer：要在吞吐率和数据可靠性之间做一个权衡。</li>
</ul>

<p>KAFKA作为现代消息中间件中的佼佼者，以其速度和高可靠性赢得了广大市场和用户青睐，其中的很多设计理念都是非常值得我们学习的，本文所介绍的也只是冰山一角，希望能够对大家了解KAFKA有一定的作用。</p>

<h1 id="kafka的应用场景">Kafka的应用场景</h1>

<h2 id="kafka用作消息系统"><strong>Kafka用作消息系统</strong></h2>

<p>Kafka流的概念与传统企业消息系统有什么异同？</p>

<p>传统消息系统有两个模型：队列和发布-订阅系统。在队列模式中，每条服务器的消息会被消费者池中的一个所读取；而发布-订阅系统中消息会广播给所有的消费者。这两种模式各有优劣。队列模式的优势是可以将消息数据让多个消费者处理以实现程序的可扩展，然而这就导致其没有多个订阅者，只能用于一个进程。发布-订阅模式的好处在于数据可以被多个进程消费使用，但是却无法使单一程序扩展性能</p>

<p>Kafka中消费者组的概念同时涵盖了这两方面。对应于队列的概念，Kafka中每个消费者组中有多个消费者实例可以接收消息；对应于发布-订阅模式，Kafka中可以指定多个消费者组来订阅消息</p>

<p>相对传统消息系统，Kafka可以提供更强的顺序保证</p>

<h2 id="kafka用作存储系统"><strong>Kafka用作存储系统</strong></h2>

<p>任何发布消息与消费消息解耦的消息队列其实都可以看做是用来存放发布的消息的存储系统，而Kafka是一个非常高效的存储系统</p>

<p>写入Kafka的数据会被存入磁盘并且复制到集群中以容错。Kafka允许生产者等待数据完全复制并且确保持久化到磁盘的确认应答</p>

<p>Kafka使用的磁盘结构扩容性能很好——不管服务器上有50KB还是50TB，Kafka的表现都是一样的</p>

<p>由于能够精致的存储并且供客户端程序进行读操作，你可以把Kafka看做是一个用于高性能、低延迟的存储提交日志、复制及传播的分布式文件系统</p>

<h2 id="kafka的流处理"><strong>Kafka的流处理</strong></h2>

<p>仅仅读、写、存储流数据是不够的，Kafka的目的是实现实时流处理。</p>

<p>在Kafka中一个流处理器的处理流程是首先持续性的从输入主题中获取数据流，然后对其进行一些处理，再持续性地向输出主题中生产数据流。例如一个销售商应用，接收销售和发货量的输入流，输出新订单和调整后价格的输出流</p>

<p>可以直接使用producer和consumer API进行简单的处理。对于复杂的转换，Kafka提供了更强大的Streams API。可构建聚合计算或连接流到一起的复杂应用程序</p>

<p>流处理有助于解决这类应用面临的硬性问题：处理无序数据、代码更改的再处理、执行状态计算等</p>

<p>Streams API所依托的都是Kafka的核心内容：使用producer和consumer API作为输入，使用Kafka作为状态存储，在流处理实例上使用相同的组机制来实现容错</p>
            </div>
            
            <div style="border: 1px dashed #e0e0e0; margin-bottom: 15px; padding: 10px 10px 10px 10px; background-color: #fffeee; background-repeat: no-repeat; background-attachment: scroll; background-position: 1% 50%; -moz-background-size: auto auto; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;">
                <div>
                    <p style="margin-top:0px;">作者：<a target="_blank" href="https://kingjcy.github.io/">kingjcy</a>
                    <br />本文出处：<a target="_blank" href="https://kingjcy.github.io/post/middleware/mq/kafka/">https://kingjcy.github.io/post/middleware/mq/kafka/</a>
                    <br />
                    文章版权归本人所有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文链接，否则保留追究法律责任的权利。 </p>
                </div>
            </div>

            <aside>
                
                <ul class="list-inline post-tags">
                    
                    <li>
                        <a href="/tags/mq/">
                            <i class="fa fa-tags"></i>
                            mq
                        </a>
                    </li>
                    
                    <li>
                        <a href="/tags/kafka/">
                            <i class="fa fa-tags"></i>
                            kafka
                        </a>
                    </li>
                    
                    <li>
                        <a href="/tags/middleware/">
                            <i class="fa fa-tags"></i>
                            middleware
                        </a>
                    </li>
                    
                </ul>

                
                
                <h4 id="real-rels">相关文章</h4>
                <ul class="post-rels" id="real-rels"><li id="li-rels"><a href="/post/middleware/mq/kafka-client/">消息队列系列---- Kafka Client</a>&nbsp;&nbsp;<span class="post-date" style="font-size:14px">&nbsp;(2019年08月08日)</span></li><li id="li-rels"><a href="/post/middleware/serverdiscovery/zookeeper/">服务发现系列---- Zookeeper</a>&nbsp;&nbsp;<span class="post-date" style="font-size:14px">&nbsp;(2019年04月19日)</span></li><li id="li-rels"><a href="/post/middleware/mq/rocketmq/">消息队列系列---- Rocketmq</a>&nbsp;&nbsp;<span class="post-date" style="font-size:14px">&nbsp;(2019年03月28日)</span></li><li id="li-rels"><a href="/post/middleware/mq/mq-compare/">消息队列系列---- Mq Compare</a>&nbsp;&nbsp;<span class="post-date" style="font-size:14px">&nbsp;(2018年04月21日)</span></li><li id="li-rels"><a href="/post/middleware/mq/rabbitmq/">消息队列系列---- Rabbitmq</a>&nbsp;&nbsp;<span class="post-date" style="font-size:14px">&nbsp;(2018年03月20日)</span></li><li id="li-rels"><a href="/post/middleware/mq/activemq/">消息队列系列---- Activemq</a>&nbsp;&nbsp;<span class="post-date" style="font-size:14px">&nbsp;(2018年03月19日)</span></li><li id="li-rels"><a href="/post/middleware/mq/nsq/">消息队列系列---- Nsq</a>&nbsp;&nbsp;<span class="post-date" style="font-size:14px">&nbsp;(2017年06月19日)</span></li><li id="li-rels"><a href="/post/middleware/serverdiscovery/etcd/">服务发现系列---- Etcd</a>&nbsp;&nbsp;<span class="post-date" style="font-size:14px">&nbsp;(2017年02月14日)</span></li><li id="li-rels"><a href="/post/middleware/serverdiscovery/consul/">服务发现系列---- Consul</a>&nbsp;&nbsp;<span class="post-date" style="font-size:14px">&nbsp;(2017年02月12日)</span></li><li id="li-rels"><a href="/post/middleware/serverdiscovery/sd/">服务发现系列---- Sd</a>&nbsp;&nbsp;<span class="post-date" style="font-size:14px">&nbsp;(2017年02月12日)</span></li></ul>
            </aside>
                
            
            <footer>
                <nav>
                    <ul class="pager">

                        
                        <li class="previous"><a href="/post/golang/go-net-http/"><span aria-hidden="true">&larr;</span> Prev</a></li>
                        

                        <li><a href="/post/">All Posts</a></li>

                        
                        <li class="next"><a href="/post/monitor/metrics/prometheus/prometheus/">Next <span aria-hidden="true">&rarr;</span></a></li>
                        

                    </ul>
                </nav>
            </footer>

        </article>
    </div>
    <div class="col-md-4">
        
<aside>
        <div class="toc panel panel-default hidden-xs hidden-sm affix-top" data-spy="affix" data-offset-top="125" data-offset-bottom="300">
            <div class="panel-heading">
                <h2 class="panel-title">Catalog</h2>
            </div>

            <nav id="TableOfContents">
<ul>
<li><a href="#kafka简介">Kafka简介</a>
<ul>
<li><a href="#基本术语">基本术语</a></li>
</ul></li>
<li><a href="#安装部署">安装部署</a>
<ul>
<li><a href="#单机">单机</a></li>
<li><a href="#集群">集群</a></li>
</ul></li>
<li><a href="#kafka常用命令">Kafka常用命令</a></li>
<li><a href="#原理">原理</a></li>
<li><a href="#kafka的应用场景">Kafka的应用场景</a>
<ul>
<li><a href="#kafka用作消息系统"><strong>Kafka用作消息系统</strong></a></li>
<li><a href="#kafka用作存储系统"><strong>Kafka用作存储系统</strong></a></li>
<li><a href="#kafka的流处理"><strong>Kafka的流处理</strong></a></li>
</ul></li>
</ul>
</nav>
        </div>
</aside>

    </div>
</div>

</div>
<hr>

<footer class="container copy">
    <p>&copy; 2020  kingjcy blog </p>
	<p>Powered by <a href="https://gohugo.io" target="_blank">Hugo</a></p>
</footer>

<script>hljs.initHighlightingOnLoad();</script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?ace3ec99de96c4080ead1eb8d52db3b3";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-92600390-2', 'auto');
  ga('send', 'pageview');
</script>
</body>
</html>


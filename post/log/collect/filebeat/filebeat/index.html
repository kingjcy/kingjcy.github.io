<!DOCTYPE html>

<html lang="zh-cn">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="author" content="fatedier">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="description" content="日志采集系统四大模块：
数据采集模块：负责从各节点上实时采集数据，建议选用Flume-NG来实现。
数据接入模块：由于采集数据的速度和数据处理的速度不一定同步，因此添加一个消息中间件来作为缓冲，建议选用Kafka来实现。
流式计算模块：对采集到的数据进行实时分析，建议选用Storm来实现。
数据输出模块：对分析后的结果持久化,可以使用HDFS、MySQL等。
日志对开发和维护的重要性不言而喻。分布式应用中的日志分布在多台机器上，所以我们需要将日志采集到一个地方来集中管理。目前比较常见的日志方案是ElK，主要包括三大组件：Elasticsearch, Logstash和Kibana。这里主要说一下使用logstash收集Docker容器里应用的日志。
容器中应用的日志，其生命周期和容器相同。主要要两个去向：标准输出stdout到主机/var/lib/docker/containers//-json.log文件中，是应用在容器中的id；写日志到磁盘文件。
主要有以下两种收集方法：1.对于第一种写在容器里面的日志，其路径中的***是id，应用每次在容器里跑起来其id是不同的，这样不容易确定日志的路径。我们需要将应用的日志输出到固定目录并通过 -V 命令挂载出来到主机磁盘（转化成第二种日志去向），这样我们就可以通过Logstash采集宿主机固定目录的日志。2.另外一种方式我看阿里云也在采用，运行一个日志收集容器。借助docker的Volume功能。在host机器上开辟一个固定目录D；产生日志的容器将日志文件所在目录mount到D目录下的子目录中；收集日志的容器再把目录D mount到自己容器内。
基础使用
 filebeat基本配置使用？可以采集当前目录下的的所有文件吗？包括子目录？输出如果想加一些前缀怎么配置？
必须需要配置input和output， 在input中需要配置采集的路径，采集路径可以使用正则表达式，来采集当前目录下所有的文件，包括子目录下，比如/k8s_log/*/.log* 在output中主要配置输出组件，这边可以设计输出的格式，比如 codec.format: ignoreNotFound: true string: &lsquo;V1%{[split]}%{[ldc]}%{[split]}%{[hostgroup]}%{[split]}%{[appid]}%{[split]}%{[ip]}%{[split]}%{[path]}%{[split]}%{[lid]}%{[split]}%{[host.name]}%{[split]}%{[host.ip]}%{[split]}%{[@timestamp]}%{[split]}%{[message]}&rsquo;
 filebeat过滤和合并的怎么使用？过滤是使用白名单还是白名单，还是都支持？怎么支持？合并正常用于什么场景？
过滤和合并都是使用正则表达式配置在配置文件中的这些配置项
include_lines exclude_lines multiline.pattern multiline.negate: true multiline.match: after
过滤是支持黑白名单的，配置项不一样
合并一般用于不同的开头的日志行，比如java出错堆栈，合并成一行日志
 filebeat是否能动态加载配置文件？如果能，怎么加载？那reload后能够重新加载output？
可以动态加载，可以在配置文件中配置reload的时间，filebeat本身自动加载，但是这个加载不能更新output
 filebeat本身日志是否支持备份切换？如果能，具体默认是什么情况？
支持，默认一个文件10M，保留8个文件
 filebeat的性能情况
我们这边目前是需要20000line／s 消耗的资源很小，主要消耗cpu
 filebaet支持句柄保持和checkpoint吗？
支持
  代码原理
 filebeat源码流程
filebaet创建了一个beater实例启动 1.启动了一个Crawler，用于1.启动静态的 input (写在主配置里的)2.启动 reloader，动态的 input 由 reloader 管理。3.启动Registrar 2.每个input又启动了Harvester，Harvester就是负责采集日志 3.Harvester 连接 pipeline 时，调用 outlet factory 创建一个 outleter，Outleter 封装了 pipeline 的 producer，调用 outleter OnEvent 方法发送数据到 pipeline 4.">
<meta property="og:url" content="https://kingjcy.github.io/"><meta property="og:type" content="article">
<meta property="og:title" content="日志采集系列---- Filebeat - kingjcy blog"><meta property="og:site_name" content="kingjcy blog">

<title>
    
    日志采集系列---- Filebeat
    
</title>

<link rel="stylesheet" href="/onlyone/onlyone.css">
<link rel="shortcut icon" href="/assets/favicon.ico">
<script src="/onlyone/onlyone.js"></script>
<link rel="alternate" type="application/rss+xml" title="RSS" href="/index.xml">
</head>
<body>


<div class="container">
    <header class="nav">
        <nav class="navbar navbar-default">
            <div class="container-fluid">
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="/">kingjcy blog</a>
                </div>

                <div class="collapse navbar-collapse" id="navbar-collapse">
                    <ul class="nav navbar-nav">
                        <li><a href="/categories/技术文章/">技术文章</a></li>
                        <li><a href="/categories/读书笔记/">读书笔记</a></li>
                        <li><a href="/categories/人生感悟/">人生感悟</a></li>
                        <li><a href="/tags/">分类</a></li>
                        <li><a href="/about/">关于我</a></li>
                        <li>
                            <form method="get" style="padding: 8px" action="https://www.google.com/search" target="_blank">
                                <input type="hidden" name="sitesearch" value="kingjcy.github.io"/>
                                <input type="text" class="form-control" name="q" placeholder="Press enter to search">
                            </form>
                        </li>
                    </ul>

                </div>
            </div>
        </nav>
    </header>


<div class="row">
    <div class="col-md-8">
        <article class="post single">

            <header>
                <div class="post-date">
                    2018年07月08日 
                </div>
                <h1 class="post-title">日志采集系列---- Filebeat</h1>
            </header>

            <div class="post-content">
                <p>日志采集系统四大模块：</p>

<p>数据采集模块：负责从各节点上实时采集数据，建议选用Flume-NG来实现。</p>

<p>数据接入模块：由于采集数据的速度和数据处理的速度不一定同步，因此添加一个消息中间件来作为缓冲，建议选用Kafka来实现。</p>

<p>流式计算模块：对采集到的数据进行实时分析，建议选用Storm来实现。</p>

<p>数据输出模块：对分析后的结果持久化,可以使用HDFS、MySQL等。</p>

<p>日志对开发和维护的重要性不言而喻。分布式应用中的日志分布在多台机器上，所以我们需要将日志采集到一个地方来集中管理。目前比较常见的日志方案是ElK，主要包括三大组件：Elasticsearch, Logstash和Kibana。这里主要说一下使用logstash收集Docker容器里应用的日志。</p>

<p>容器中应用的日志，其生命周期和容器相同。主要要两个去向：标准输出stdout到主机/var/lib/docker/containers//<strong><em>-json.log文件中，</em></strong>是应用在容器中的id；写日志到磁盘文件。</p>

<p>主要有以下两种收集方法：1.对于第一种写在容器里面的日志，其路径中的***是id，应用每次在容器里跑起来其id是不同的，这样不容易确定日志的路径。我们需要将应用的日志输出到固定目录并通过 -V 命令挂载出来到主机磁盘（转化成第二种日志去向），这样我们就可以通过Logstash采集宿主机固定目录的日志。2.另外一种方式我看阿里云也在采用，运行一个日志收集容器。借助docker的Volume功能。在host机器上开辟一个固定目录D；产生日志的容器将日志文件所在目录mount到D目录下的子目录中；收集日志的容器再把目录D mount到自己容器内。</p>

<p>基础使用</p>

<ol>
<li><p>filebeat基本配置使用？可以采集当前目录下的的所有文件吗？包括子目录？输出如果想加一些前缀怎么配置？</p>

<p>必须需要配置input和output，
在input中需要配置采集的路径，采集路径可以使用正则表达式，来采集当前目录下所有的文件，包括子目录下，比如/k8s_log/*<em>/</em>.log*
在output中主要配置输出组件，这边可以设计输出的格式，比如
codec.format:
    ignoreNotFound: true
    string: &lsquo;V1%{[split]}%{[ldc]}%{[split]}%{[hostgroup]}%{[split]}%{[appid]}%{[split]}%{[ip]}%{[split]}%{[path]}%{[split]}%{[lid]}%{[split]}%{[host.name]}%{[split]}%{[host.ip]}%{[split]}%{[@timestamp]}%{[split]}%{[message]}&rsquo;</p></li>

<li><p>filebeat过滤和合并的怎么使用？过滤是使用白名单还是白名单，还是都支持？怎么支持？合并正常用于什么场景？</p>

<p>过滤和合并都是使用正则表达式配置在配置文件中的这些配置项</p>

<p>include_lines
exclude_lines
multiline.pattern
multiline.negate: true
multiline.match: after</p>

<p>过滤是支持黑白名单的，配置项不一样</p>

<p>合并一般用于不同的开头的日志行，比如java出错堆栈，合并成一行日志</p></li>

<li><p>filebeat是否能动态加载配置文件？如果能，怎么加载？那reload后能够重新加载output？</p>

<p>可以动态加载，可以在配置文件中配置reload的时间，filebeat本身自动加载，但是这个加载不能更新output</p></li>

<li><p>filebeat本身日志是否支持备份切换？如果能，具体默认是什么情况？</p>

<p>支持，默认一个文件10M，保留8个文件</p></li>

<li><p>filebeat的性能情况</p>

<p>我们这边目前是需要20000line／s
消耗的资源很小，主要消耗cpu</p></li>

<li><p>filebaet支持句柄保持和checkpoint吗？</p>

<p>支持</p></li>
</ol>

<p>代码原理</p>

<ol>
<li><p>filebeat源码流程</p>

<p>filebaet创建了一个beater实例启动
1.启动了一个Crawler，用于1.启动静态的 input (写在主配置里的)2.启动 reloader，动态的 input 由 reloader 管理。3.启动Registrar
2.每个input又启动了Harvester，Harvester就是负责采集日志
3.Harvester 连接 pipeline 时，调用 outlet factory 创建一个 outleter，Outleter 封装了 pipeline 的 producer，调用 outleter OnEvent 方法发送数据到 pipeline
4.Registrar 负责 checkpoint 文件的更新
5.启动Pipeline 模块
    Pipeline 是一个大的功能模块，包含 <code>queue</code>, <code>outputController</code>, <code>consumer</code>, <code>output</code>
    1.Queue (memqueue)
    真正的 queue 对象时 Broker。创建 broker 时启动事件循环，负责处理 publish 和 consume 等各种请求
    - 创建 broker
    - 事件循环
    - Consumer
    - Producer 真实创建的是 ackProducer
    2.- Output Controller
    负责管理 consumer。Consumer 负责从 queue 中获取 batch，然后发送到 workQueue(chan publisher.Batch)。
    3.- Consumer
    Consumer 会启动多个 outputWorker。outputWorker 负责从 workQueue 获取 batch，然后调用 output client 的 Publish 方法发送出去。
    4.- Retryer
    Retry 负责重试发送失败的请求
    5.- Output(kafka)
    Connect 调用 sarama 库，创建一个 kafka AsyncProducer。连接时会启动两个循环，处理成功响应和失败响应。
    6.- msgRef
    msgRef 注入到发送给 AsyncProducer 的事件中。在处理响应的时候回调。如果成功就调用 batch.ACK()。失败就调用 batch.OnRetry 重试。</p></li>

<li><p>filebeat中几个主要的模块？主要重要是什么？</p>

<p>Crawler</p>

<p>启动时加载配置文件中的 inputs。启动 reloader，定期加载动态配置文件目录中的 inputs。启动Registrar，负责checkpoint</p>

<p>Input</p>

<p>Input 是一个用来包装 <code>harvester</code> 的数据结构，对外提供生命周期管理接口。Input 在建立起来时，会调用 pipeline 的 <code>ConnectWith</code> 方法获取一个 client，用于发送 events。</p>

<p>Harvester
负责采集日志</p>

<p>Pipeline</p>

<p>Pipeline 是一个大的功能模块，包含 <code>queue</code>, <code>outputController</code>, <code>consumer</code>, <code>output</code></p>

<pre><code>OutputController

outputController 负责控制 queue 中的 events 发送到 output，包含 `retryer` 和 `consumer`。Output 中的 batch 发送失败时，会送到 retryer 重试。

Queue(mem)

工作机制:
- 队列容量为 `Events`
- 当队列中的 events 数量大于 `FlushMinEvents` 开始 flush
- 当队列中有 events 并且离上一次 flush 过了 `FlushTimeout` 时间，开始 flush
</code></pre></li>

<li><p>filebeat的中传输是一个通道还是多个通道？</p>

<p>一个通道</p></li>
</ol>

<p>4.filebeat输出到kafka可以支持多个kafka集群吗？如果不能怎么改造？</p>

<pre><code>不支持，kafka连接池
</code></pre>

<p>容器相关</p>

<ol>
<li>容器服务发现组件，原理是什么</li>
</ol>

<p>log-pilot，动态生成配置文件，让filebeat自动加载</p>

<ol>
<li>怎么部署？如果需要采集应用日志和物理日志怎么处理？</li>
</ol>

<p>目前我们是放在一个pod中，如果采集物理日志，就部署两个filebeat，一个针对应用，一个针对物理</p>

<p>3.容器中想控制资源问题有什么办法？
        1.带宽限制
        2.filebeat发送设置上限
        3.提供接口设置filebeat配置文件的disable
        4.每个镜像中安装filebeat，停止filebeat</p>

<p>1.支持日志采集开关                                                          80%
2.容器自动发现，配置动态生成，自动加载；                                           40%
3.支持物理日志采集                                                          50%
4.可添加tag，以制定格式输出                                                    50%
5.文件句柄保持；                                                               80%
    （1）物理日志目录下大文件，删掉，看能不能采集到最后
    （2）停掉filebeat，是否连续
6.同一台服务器上的日志收集组件可根据日志类型发送至不同的kafka集群；                   60%
7.日志内容过滤                                                                30%</p>

<p>1。 默认环境变量前缀是sn&mdash;解决</p>

<ol>
<li><p>当没有获取到对应字段的值的时候，默认使用-，分隔符默认为／t，代码中要处理&ndash;解决</p></li>

<li><p>build下除了dockerfile其他的是否有用，默认build目录是gitignore&ndash;已经解决</p></li>

<li><p>kafka的地址是在yaml文件中写死的，意思就是采集之前就必须知道kafka地址，然后生成configmap&ndash;目前pcp处理，后面待kafka的连接池开发，明天转连接池测试。使用连接池，检查到容器需要采集日志，则检查对应的kafka是否连接，如果连接，则直接发，如果不连接，则连接后发送</p></li>
</ol>

<p>连接池&ndash;解决</p>

<p>单个的容器实现了发送&ndash;解决</p>

<p>多个kafka&ndash;解决</p>

<ol>
<li><p>物理日志没有采集&ndash;解决</p>

<p>物理日志格式确定&ndash;解决
物理日志采集&ndash;解决
物理日志部署&ndash;解决</p></li>

<li><p>merge支持？&ndash;解决</p></li>

<li><p>prefix支持？格式问题&mdash;当prefix中配置，则使用配置用的版本，最后四位固定，hostname，hostip，timestmp，message，不配置默认使用配置文件中版本，已解决。</p></li>
</ol>

<p>8。 日志过滤&ndash;解决。先合并后过滤，过滤规则区分大小写</p>

<ol>
<li>环境变量名规范统一&ndash;解决</li>
</ol>

<p>10。 debug日志要全面，日志等级可设置，不然实用性和查问题都很难&ndash;解决，持续完善日志</p>

<ol>
<li><p>过滤和合并规则用法文档整理&ndash;解决</p></li>

<li><p>性能测试 20000line/s&ndash;解决</p></li>

<li><p>processAllContainers的mutex</p></li>

<li><p>不支持多个前缀？&ndash;需要支持，待改造&ndash;解决</p></li>

<li><p>logpath       string
datapath      string
loglevel      string
reloadtime    string
是否需要支持可配置，是否在pcp生成yaml？&mdash;-不需要支持，部署时候确定，联调的时候看pcp可填还是默认？看规划&ndash;</p></li>

<li><p>环境变量变动&ndash;解决
1.version去掉，重prefix中获取
2.sn_log_xxx修改成sn_log_xxx_xxx</p></li>

<li><p>kafka版本问题&ndash;目前兼容&ndash;解决</p></li>

<li><p>1）日志过滤新增环境变量发给陈浩宇&ndash;已经完成&ndash;解决
2）合并规则调查（YYYY-MM-DD开头，[开头，无合并规则），过滤规则大小写&ndash;已经完成，需要整理&ndash;解决
3）brokerlist等放环境变量的问题&ndash;已经解决&ndash;解决</p></li>
</ol>

<p>19。filebeat放内存问题&ndash;先放内存，目前是三次重试失败就drop可以关掉不drop，此采集到一定的时候内存达到上限就会停止采集，然后没有发现机制。验证&ndash;解决，目前改成多通道，然后每个channel，发生阻塞，会不断重试，在内存达到4096就会停止采集，直到kafka重新连接上发送出去。</p>

<p>20.目录部署规划，日志目录&ndash;解决</p>

<ol>
<li>性能，部署，一个物理机部署一个filebeat是否够用&ndash;解决</li>
</ol>

<p>22.日志级别等级采集，正则整理，合并几个规则，规则制定&ndash;解决</p>

<p>23.代码要加上注释，要有文档说明（目录作用），测试说明&ndash; 解决</p>

<p>24.多通道改造&ndash;解决</p>

<p>25.filbeat分离：1.资源管理，2.调整filebeat，修改启动，直接修改yaml&ndash;解决</p>

<p>2.物理日志没有采集，其他yaml&ndash;完善yaml&ndash;继续修改&ndash;修改完成&ndash;解决</p>

<p>（1）.不依赖centos7</p>

<p>（2）.registry目录持久化到本地：opt/filebeat/&ndash;&gt;/k8s_log</p>

<p>（3）.挂载目录：host&ndash;&gt; kubelet</p>

<p>3.过滤和合并规则用法文档整理，日志级别等级采集，正则整理，合并几个规则，规则制定&ndash;解决</p>

<p>4.目录部署规划，日志目录&ndash;解决
    1)FileBeats
    安装目录：/opt/filebeats
    registry目录：/k8s_log/filebeats/filebeat/data
    日志路径：/k8s_log/filebeats/filebeat/logs</p>

<pre><code>2）FileBeats物理
安装目录：/opt/filebeats
registry目录：/k8s_log/filebeats/filebeat-k8slog/data
日志路径：/k8s_log/filebeats/filebeat-k8slog/logs

3)log-pilot
安装目录：/opt/log-pilot
日志路径：/k8s_log/log-pilot
</code></pre>

<ol>
<li><p>代码要加上注释，要有文档说明（目录作用），测试说明&ndash;解决</p></li>

<li><p>多通道改造&ndash;解决</p></li>
</ol>

<p>8.kafka的连接池改造&ndash;解决</p>

<p>9.（1）性能测试 20000line/&ndash;解决s，性能，部署，（2）一个物理机部署一个filebeat是否够用，（3）功能测试：启停操作有什么影响，1m，1h，1d&mdash;连续日志</p>

<p>10.不支持多个前缀？&ndash;需要支持，已经支持&ndash;解决</p>

<p>11.sn_log_app_prefix内容解析你说写一个解析工具&ndash;解决</p>

<p>12.当环境变量定义了但是为空值，怎么处理&ndash;一律为-，已经支持&ndash;解决</p>

<p>13.正则匹配黑名单需要变量&ndash;要实现&ndash;解决</p>

<p>14.合并规则确认，目前合并是nomatch&ndash;不需要支持&ndash;解决</p>

<p>15.日志分割回归 规则制定 1G&ndash;解决，目前一个10M，保留8个备份</p>

<p>20.fiebeat走yaml部署&ndash;应该在k8s部署的时候就部署日志采集，包含物理日志采集&ndash;解决</p>

<p>21.各环境brokerlist整理&ndash;不需要了&ndash;解决</p>

<p>22.go升级1.10&ndash;解决</p>

<p>23.程序改变名字，加上suning的logo&ndash;目前不需要&ndash;解决</p>

<p>24.改物理采集的描述&ndash;解决</p>

<p>25.提供正常使用正则的场景&ndash;默认三种&ndash;解决
    合并：
    （1）以yymmdd格式开头的，yymmdd是时间
    （2）以[mmdd格式开头的，yymmdd是时间
    （3）为空的时候不合并
    过滤
    （1）包含什么内容
    （2）支持日志等级设置
    （3）不包含什么内容
26.物理日志格式有没有要求&ndash;格式一样，都是&mdash;解决</p>

<p>27.物理日志有子目录都要采集到&ndash;解决</p>

<p>28.日志切割规则&ndash;解决</p>

<p>大小切割，备份数</p>

<ol>
<li><p>是否需要安装bash&mdash;需要安装&ndash;解决</p></li>

<li><p>prefix规则</p></li>
</ol>

<p>V1,ldc,hostgroup,appid,ip,path,lid,hostname,hostip,time,message</p>

<p>3.yml文件错误无法删除掉问题&ndash;解决，配置不能出错</p>

<hr />

<p>2.支持日志切割规则可配置</p>

<pre><code>目前支持大小切割，备份数，默认一个10M，保留8个备份
</code></pre>

<p>5.processAllContainers的mutex</p>

<p>9.（1）性能测试 20000line/s，性能，部署，（2）一个物理机部署一个filebeat是否够用，（3）功能测试：启停操作有什么影响，1m，1h，1d&mdash;连续日志</p>

<p>10.代码要加上注释，要有文档说明（目录作用），测试说明</p>

<p>20.fiebeat走yaml部署&ndash;应该在k8s部署的时候就部署日志采集，包含物理日志采集</p>

<ol>
<li>开关：1.带宽限制
    2.filebeat发送设置上限
    3.提供接口设置filebeat配置文件的disable
    4.每个镜像中安装filebeat，停止filebeat</li>
</ol>

<p>网络，业务网络可以设置带宽限制
     主机网络是管理网络，不限制带宽</p>

<p>docker 重启</p>

<p>log-pilot重启</p>

<p>压测，平均字节，最大字节</p>

<p>部署：</p>

<ol>
<li>log-pilot镜像制作</li>
</ol>

<p>基础镜像：golang:1.9-alpine3.6，alpine:3.6</p>

<p>目录：/Users/chunyinjiang/jcy/work/go_workspace/log-pilot-sn/src/github.com/AliyunContainerService/log-pilot</p>

<p>docker build -t log-pilot:1.0.0 -f Dockerfile .</p>

<ol>
<li>filebeat镜像制作</li>
</ol>

<p>基础镜像：golang:1.10-alpine，centos:7</p>

<p>目录：/Users/chunyinjiang/jcy/work/go_workspace/filebeat-sn/src/github.com/elastic/beats</p>

<p>docker build -t filebeat:6.3.2-1 -f filebeat/Dockerfile .</p>

<p>将镜像传至镜像仓库
docker tag 3ef409f638bc 10.37.210.125:5001/filebeat:6.3.2-1
docker push  10.37.210.125:5001/filebeat:6.3.2-1</p>

<p>docker tag 48f45929373f 10.37.210.125:5001/log-pilot:1.0.0
docker push  10.37.210.125:5001/log-pilot:1.0.0</p>

<p>1.掌握代码：</p>

<p>Filebeat</p>

<p>beater 启动
<a href="https://github.com/elastic/beats/blob/v6.3.2/filebeat/beater/filebeat.go#L273">https://github.com/elastic/beats/blob/v6.3.2/filebeat/beater/filebeat.go#L273</a></p>

<p>Crawler
<a href="https://github.com/elastic/beats/blob/v6.3.2/filebeat/crawler/crawler.go#L33">https://github.com/elastic/beats/blob/v6.3.2/filebeat/crawler/crawler.go#L33</a>
- 启动静态的 input (写在主配置里的)
- 启动 reloader
○ 动态的 input 由 reloader 管理</p>

<p>Input
对 harvester 的封装
<a href="https://github.com/elastic/beats/blob/v6.3.2/filebeat/input/input.go#L35">https://github.com/elastic/beats/blob/v6.3.2/filebeat/input/input.go#L35</a></p>

<p>Harvester
负责采集日志
<a href="https://github.com/elastic/beats/blob/v6.3.2/filebeat/input/log/harvester.go#L88">https://github.com/elastic/beats/blob/v6.3.2/filebeat/input/log/harvester.go#L88</a></p>

<p>Outleter
Harvester 连接 pipeline 时，调用 outlet factory 创建一个 outleter
Outleter 封装了 pipeline 的 producer，调用 outleter OnEvent 方法发送数据到 pipeline
- Outleter 创建
○ <a href="https://github.com/elastic/beats/blob/v6.3.2/filebeat/channel/factory.go#L70">https://github.com/elastic/beats/blob/v6.3.2/filebeat/channel/factory.go#L70</a></p>

<p>Registrar
负责 checkpoint 文件的更新
<a href="https://github.com/elastic/beats/blob/v6.3.2/filebeat/registrar/registrar.go#L19">https://github.com/elastic/beats/blob/v6.3.2/filebeat/registrar/registrar.go#L19</a></p>

<p>Libbeat</p>

<p>Pipeline 模块启动
<a href="https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/module.go#L30">https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/module.go#L30</a>
- 加载 output <a href="https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/module.go#L85">https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/module.go#L85</a></p>

<p>Pipeline
Pipeline 包含 queue, output controller, consumer, output
- 创建
<a href="https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/pipeline.go#L135">https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/pipeline.go#L135</a>
- Output Controller
○ 负责管理 consumer。Consumer 负责从 queue 中获取 batch，然后发送到 workQueue(chan publisher.Batch)。
○ <a href="https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/controller.go#L13">https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/controller.go#L13</a>
- Consumer
○ Consumer 会启动多个 outputWorker。outputWorker 负责从 workQueue 获取 batch，然后调用 output client 的 Publish 方法发送出去。
○ <a href="https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/consumer.go#L43">https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/consumer.go#L43</a>
- Retryer
○ Retry 负责重试发送失败的请求
○ <a href="https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/retry.go#L14">https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/retry.go#L14</a>
- Output(kafka)
○ 创建 <a href="https://github.com/elastic/beats/blob/v6.3.2/libbeat/outputs/kafka/kafka.go#L114">https://github.com/elastic/beats/blob/v6.3.2/libbeat/outputs/kafka/kafka.go#L114</a>
○ Connect
§ <a href="https://github.com/elastic/beats/blob/v6.3.2/libbeat/outputs/kafka/client.go#L68">https://github.com/elastic/beats/blob/v6.3.2/libbeat/outputs/kafka/client.go#L68</a>
§ 调用 sarama 库，创建一个 kafka AsyncProducer。连接时会启动两个循环，处理成功响应和失败响应。
§ msgRef
□ msgRef 注入到发送给 AsyncProducer 的事件中。在处理响应的时候回调。如果成功就调用 batch.ACK()。失败就调用 batch.OnRetry 重试。
□ <a href="https://github.com/elastic/beats/blob/v6.3.2/libbeat/outputs/kafka/client.go#L222">https://github.com/elastic/beats/blob/v6.3.2/libbeat/outputs/kafka/client.go#L222</a>
Queue (memqueue)
真正的 queue 对象时 Broker。创建 broker 时启动事件循环，负责处理 publish 和 consume 等各种请求
- 创建 broker
○ <a href="https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/broker.go#L63">https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/broker.go#L63</a>
- 事件循环
○ <a href="https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/eventloop.go#L30">https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/eventloop.go#L30</a>
- Consumer
○ <a href="https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/consume.go#L12">https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/consume.go#L12</a>
- Producer
○ 真实创建的是 ackProducer
○ <a href="https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/produce.go#L39">https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/produce.go#L39</a></p>

<p>kafka不同
1、filebeat先启动，loggen后启，loggenerror不启动【kafka有数据更新】
2、1步骤中filebeat已经启动，loggen重启，loggenerror不启动【kafka数据有更新】
3、继续步骤2启动loggenerror，loggen数据没有采集完继续采集【kafka数据有更新】
4、loggenerror先重启成功一段时间后（1min），loggen后重启【kafka数据有更新】</p>

<p>kafka修改为相同
1、启动loggen不启动loggenerror【kafka数据有更新】
2、继续步骤1，启动loggenerror，loggen继续产生日志【kafka数据更新】
3、关闭loggen后再次重新启动【有数据更新】</p>

<p>张骞(18030743) 2018-12-17 20:36:47
现在日志采集对象有三种
1.nginx日志（http日志、error日志）
2.jboss日志（中间件日志、app日志）
3.spm日志
这三种日志和云迹以及RSF是什么样的对应关系？谁给解释下？多谢
陈涛(15042021) 2018-12-17 20:37:31
云迹，RSF，SPM是三个日志服务提供方
陈涛(15042021) 2018-12-17 20:38:00
云迹提供1.nginx日志（http日志、error日志）2.jboss日志（中间件日志、app日志） 3.业务日志查看服务
陈涛(15042021) 2018-12-17 20:38:09
RSF提供RSF日志查看服务
陈涛(15042021) 2018-12-17 20:38:26
SPM提供SPM日志查看服务
陈涛(15042021) 2018-12-17 20:38:55
三者只不过巧合的是都是使用云迹用的采集组件</p>

<p>1.filebeat镜像：</p>

<p>打包依赖：基于基础的centos镜像，golang:1.10-alpine</p>

<p>centos版本：centos7.3   1611</p>

<p>探针名：nvidia_gpu_prometheus_exporter</p>

<p>探针版本：1.0.0</p>

<p>探针源码路径：<a href="http://git.cnsuning.com/promes/nvidia_gpu_prometheus_exporter.git">http://git.cnsuning.com/promes/nvidia_gpu_prometheus_exporter.git</a></p>

<p>部署路径：/opt/promes/exporter/nvidia_gpu_prometheus_exporter/</p>

<p>启动命令：/opt/promes/exporter/nvidia_gpu_prometheus_exporter/nvidia_gpu_prometheus_exporter</p>

<p>启动：容器启动时自动启动</p>

<p>暴露端口：9445</p>

<p>[0-9]{4}-[0-9]{2}-[0-9]{2} 按照yyyy-mm-dd时间戳合并
[[0-9]{4}-[0-9]{2}-[0-9]{2} 按照[yyyy-mm-dd时间戳合并
*  不合并</p>

<p>编译</p>

<p>After installing Go, set the GOPATH environment variable to point to your workspace location, and make sure $GOPATH/bin is in your PATH.</p>

<p>mkdir -p ${GOPATH}/src/github.com/elastic
git clone <a href="https://github.com/elastic/beats">https://github.com/elastic/beats</a> ${GOPATH}/src/github.com/elastic/beats
If you have multiple go paths, use ${GOPATH%%:*} instead of ${GOPATH}.</p>

<p>Then you can compile a particular Beat by using the Makefile. For example, for Packetbeat:</p>

<p>cd beats/packetbeat
make
Some of the Beats might have extra development requirements, in which case you’ll find a CONTRIBUTING.md file in the Beat directory.</p>

<p>We use an EditorConfig file in the beats repository to standardise how different editors handle whitespace, line endings, and other coding styles in our files. Most popular editors have a plugin for EditorConfig and we strongly recommend that you install it.</p>

            </div>
            
            <div style="border: 1px dashed #e0e0e0; margin-bottom: 15px; padding: 10px 10px 10px 10px; background-color: #fffeee; background-repeat: no-repeat; background-attachment: scroll; background-position: 1% 50%; -moz-background-size: auto auto; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;">
                <div>
                    <p style="margin-top:0px;">作者：<a target="_blank" href="http://blog.fatedier.com/">kingjcy</a>
                    <br />本文出处：<a target="_blank" href="https://kingjcy.github.io/post/log/collect/filebeat/filebeat/">https://kingjcy.github.io/post/log/collect/filebeat/filebeat/</a>
                    <br />
                    文章版权归本人所有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文链接，否则保留追究法律责任的权利。 </p>
                </div>
            </div>

            <aside>
                
                <ul class="list-inline post-tags">
                    
                    <li>
                        <a href="/tags/filebeat/">
                            <i class="fa fa-tags"></i>
                            filebeat
                        </a>
                    </li>
                    
                    <li>
                        <a href="/tags/log/">
                            <i class="fa fa-tags"></i>
                            log
                        </a>
                    </li>
                    
                    <li>
                        <a href="/tags/collect/">
                            <i class="fa fa-tags"></i>
                            collect
                        </a>
                    </li>
                    
                </ul>

                
                
                <h4 id="real-rels">相关文章</h4>
                <ul class="post-rels" id="real-rels"><li id="li-rels"><a href="/post/product/filebeat_leak/">生产问题排查解决系列---- filebeat resource leak</a>&nbsp;&nbsp;<span class="post-date" style="font-size:14px">&nbsp;(2020年03月02日)</span></li><li id="li-rels"><a href="/post/product/filebeat_optimization/">生产问题排查解决系列---- filebeat resource optimization</a>&nbsp;&nbsp;<span class="post-date" style="font-size:14px">&nbsp;(2020年03月02日)</span></li><li id="li-rels"><a href="/post/log/collect/filebeat/filebeat-principle/">日志采集系列---- Filebeat原理</a>&nbsp;&nbsp;<span class="post-date" style="font-size:14px">&nbsp;(2018年07月08日)</span></li><li id="li-rels"><a href="/post/golang/go-log/">golang使用系列---- Log</a>&nbsp;&nbsp;<span class="post-date" style="font-size:14px">&nbsp;(2017年01月31日)</span></li></ul>
            </aside>
                
            
            <footer>
                <nav>
                    <ul class="pager">

                        
                        <li class="previous"><a href="/post/monitor/prometheus/exporter/mysqld-exporter/"><span aria-hidden="true">&larr;</span> Prev</a></li>
                        

                        <li><a href="/post/">All Posts</a></li>

                        
                        <li class="next"><a href="/post/log/collect/filebeat/filebeat-principle/">Next <span aria-hidden="true">&rarr;</span></a></li>
                        

                    </ul>
                </nav>
            </footer>

        </article>
    </div>
    <div class="col-md-4">
        
<aside>
        <div class="toc panel panel-default hidden-xs hidden-sm affix-top" data-spy="affix" data-offset-top="125" data-offset-bottom="300">
            <div class="panel-heading">
                <h2 class="panel-title">Catalog</h2>
            </div>

            
        </div>
</aside>

    </div>
</div>

</div>
<hr>

<footer class="container copy">
    <p>&copy; 2020  kingjcy blog </p>
	<p>Powered by <a href="https://gohugo.io" target="_blank">Hugo</a></p>
</footer>

<script>hljs.initHighlightingOnLoad();</script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?ace3ec99de96c4080ead1eb8d52db3b3";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-92600390-2', 'auto');
  ga('send', 'pageview');
</script>
</body>
</html>


<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kingjcy blog </title>
    <link>https://kingjcy.github.io/</link>
    <language>en-us</language>
    <author></author>
    <rights>(C) 2020</rights>
    <updated>2020-01-18 19:45:30 &#43;0800 CST</updated>

    
      
        <item>
          <title>日志监控系列---- loki</title>
          <link>https://kingjcy.github.io/post/monitor/log/loki/loki/</link>
          <pubDate>Sat, 18 Jan 2020 19:45:30 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/monitor/log/loki/loki/</guid>
          <description>&lt;p&gt;Loki是 Grafana Labs 团队最新的开源项目，是一个水平可扩展，高可用性，多租户的日志聚合系统。它的设计非常经济高效且易于操作，因为它不会为日志内容编制索引，而是为每个日志流编制一组标签，为 Prometheus和 Kubernetes用户做了相关优化。项目受 Prometheus 启发，类似于 Prometheus 的日志系统。&lt;/p&gt;

&lt;h1 id=&#34;基本概念&#34;&gt;基本概念&lt;/h1&gt;

&lt;h2 id=&#34;使用场景&#34;&gt;使用场景&lt;/h2&gt;

&lt;p&gt;当我们的容器云运行的应用或者某个节点出现问题了，解决思路应该如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/loki/loki&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;一般在容器云中使用prometheus生态来做监控告警，在metrics触发告警的时候，我们就需要查看日志来处理问题，这个时候就需要日志系统来收集日志进行搜索查看。&lt;/p&gt;

&lt;p&gt;现有的很多日志采集的方案都是采用全文检索对日志进行索引（如ELK方案），优点是功能丰富，允许复杂的操作。但是，这些方案往往规模复杂，资源占用高，操作苦难。很多功能往往用不上，大多数查询只关注一定时间范围和一些简单的参数（如host、service等），这个时候就需要一个轻量级的日志系统，这个时候loki就比较合适了。&lt;/p&gt;

&lt;h2 id=&#34;基本组件&#34;&gt;基本组件&lt;/h2&gt;

&lt;p&gt;Loki 整个系统需要三个组件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1、Loki: 相当于 EFK 中的 ElasticSearch，用于存储和查询日志
2、Promtail: 相当于 EFK 中的 Filebeat/Fluentd，用于采集和发送日志
3、Grafana: 相当于 EFK 中的 Kibana，用于 UI 展示
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这些组件以以下的部署在我们的系统中&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/loki/loki1&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以看出&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1、loki: 以 Statefulset 方式部署，可横向扩容
2、promtail: 以 Daemonset 方式部署，采集每个节点上容器日志并发送给 loki
3、grafana: 默认不开启，如果集群中已经有 grafana 就可以不用在部署 grafana，如果没有，部署时可以选择也同时部署 grafana
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不使用容器部署，也大体可以看出对应的部署方式，就是Promtail作为采集组件需要部署在每个一个机器上然后将数据推送到loki中，grafana在loki中拉去数据进行展示。&lt;/p&gt;

&lt;h1 id=&#34;部署使用&#34;&gt;部署使用&lt;/h1&gt;

&lt;h2 id=&#34;k8s部署&#34;&gt;k8s部署&lt;/h2&gt;

&lt;p&gt;新增helm源&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ helm repo add loki https://grafana.github.io/loki/charts
$ helm repo update
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用helm3部署&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;helm install loki loki/loki-stack
# 安装到指定命名空间
# helm install loki loki/loki-stack -n monitoring
# 持久化 loki 的数据，避免 loki 重启后数据丢失
# helm install loki loki/loki-stack --set=&amp;quot;loki.persistence.enabled=ture,loki.persistence.size=100G&amp;quot;
# 部署 grafana
# helm install loki loki/loki-stack --set=&amp;quot;grafana.enabled=true&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们就可以看到对应启动了如下应用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl get all -n monitoring | grep loki
pod/loki-0                                 1/1     Running   1          20h
pod/loki-promtail-8phlp                    1/1     Running   1          20h
service/loki                    NodePort    10.111.208.19    &amp;lt;none&amp;gt;        3100:31278/TCP               20h
service/loki-headless           ClusterIP   None             &amp;lt;none&amp;gt;        3100/TCP                     20h
daemonset.apps/loki-promtail   1         1         1       1            1           &amp;lt;none&amp;gt;                   20h
statefulset.apps/loki                1/1     20h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如上使用了以 Daemonset 方式部署了promtail，使用Statefulset 方式部署loki，然后用service暴露给grafana。&lt;/p&gt;

&lt;h2 id=&#34;配置文件&#34;&gt;配置文件&lt;/h2&gt;

&lt;p&gt;上面启动了对应的应用，我们来看一下默认的启动情况&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ kubectl exec -ti loki-0 -n monitoring -- sh
/ $ ps -ef
PID   USER     TIME  COMMAND
    1 loki      0:01 /usr/bin/loki -config.file=/etc/loki/loki.yaml
   23 loki      0:00 sh
   28 loki      0:00 ps -ef
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看到就是使用二进制文件和配置文件进行启动，所以我们关键看一下配置文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/ $ cat /etc/loki/loki.yaml
auth_enabled: false
chunk_store_config:
  max_look_back_period: 0s
ingester:
  chunk_block_size: 262144
  chunk_idle_period: 3m
  chunk_retain_period: 1m
  lifecycler:
    ring:
      kvstore:
        store: inmemory
      replication_factor: 1
  max_transfer_retries: 0
limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h
schema_config:
  configs:
  - from: &amp;quot;2018-04-15&amp;quot;
    index:
      period: 168h
      prefix: index_
    object_store: filesystem
    schema: v9
    store: boltdb
server:
  http_listen_port: 3100
storage_config:
  boltdb:
    directory: /data/loki/index
  filesystem:
    directory: /data/loki/chunks
table_manager:
  retention_deletes_enabled: false
  retention_period: 0s/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们这边详细说明一下配置文件，配置文件主要有以下几块组成&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1、target：[target: &amp;lt;string&amp;gt; | default = &amp;quot;all&amp;quot;]
2、auth_enabled：[auth_enabled: &amp;lt;boolean&amp;gt; | default = true] 启动验证，默认是启动的，如果需要关闭，需要设置为false
3、server：主要是配置loki的http模块，最常见的就是配置http的地址和端口
    # HTTP server listen host
    [http_listen_address: &amp;lt;string&amp;gt;]

    # HTTP server listen port
    [http_listen_port: &amp;lt;int&amp;gt; | default = 80]

    # gRPC server listen host
    [grpc_listen_address: &amp;lt;string&amp;gt;]

    # gRPC server listen port
    [grpc_listen_port: &amp;lt;int&amp;gt; | default = 9095]

    # Register instrumentation handlers (/metrics, etc.)
    [register_instrumentation: &amp;lt;boolean&amp;gt; | default = true]

    # Timeout for graceful shutdowns
    [graceful_shutdown_timeout: &amp;lt;duration&amp;gt; | default = 30s]

    # Read timeout for HTTP server
    [http_server_read_timeout: &amp;lt;duration&amp;gt; | default = 30s]

    # Write timeout for HTTP server
    [http_server_write_timeout: &amp;lt;duration&amp;gt; | default = 30s]

    # Idle timeout for HTTP server
    [http_server_idle_timeout: &amp;lt;duration&amp;gt; | default = 120s]

    # Max gRPC message size that can be received
    [grpc_server_max_recv_msg_size: &amp;lt;int&amp;gt; | default = 4194304]

    # Max gRPC message size that can be sent
    [grpc_server_max_send_msg_size: &amp;lt;int&amp;gt; | default = 4194304]

    # Limit on the number of concurrent streams for gRPC calls (0 = unlimited)
    [grpc_server_max_concurrent_streams: &amp;lt;int&amp;gt; | default = 100]

    # Log only messages with the given severity or above. Supported values [debug,
    # info, warn, error]
    [log_level: &amp;lt;string&amp;gt; | default = &amp;quot;info&amp;quot;]

    # Base path to server all API routes from (e.g., /v1/).
    [http_path_prefix: &amp;lt;string&amp;gt;]
4、distributor主要是配置loki的分发，目前只有ring轮询
    [ring: &amp;lt;ring_config&amp;gt;]
5、ring_config主要是用来发现和连接Ingesters
    kvstore:
      # The backend storage to use for the ring. Supported values are
      # consul, etcd, inmemory
      store: &amp;lt;string&amp;gt;

      # The prefix for the keys in the store. Should end with a /.
      [prefix: &amp;lt;string&amp;gt; | default = &amp;quot;collectors/&amp;quot;]

      # Configuration for a Consul client. Only applies if store
      # is &amp;quot;consul&amp;quot;
      consul:
        # The hostname and port of Consul.
        [host: &amp;lt;string&amp;gt; | duration = &amp;quot;localhost:8500&amp;quot;]

        # The ACL Token used to interact with Consul.
        [acl_token: &amp;lt;string&amp;gt;]

        # The HTTP timeout when communicating with Consul
        [http_client_timeout: &amp;lt;duration&amp;gt; | default = 20s]

        # Whether or not consistent reads to Consul are enabled.
        [consistent_reads: &amp;lt;boolean&amp;gt; | default = true]

      # Configuration for an ETCD v3 client. Only applies if
      # store is &amp;quot;etcd&amp;quot;
      etcd:
        # The ETCD endpoints to connect to.
        endpoints:
          - &amp;lt;string&amp;gt;

        # The Dial timeout for the ETCD connection.
        [dial_timeout: &amp;lt;duration&amp;gt; | default = 10s]

        # The maximum number of retries to do for failed ops to ETCD.
        [max_retries: &amp;lt;int&amp;gt; | default = 10]

    # The heartbeat timeout after which ingesters are skipped for
    # reading and writing.
    [heartbeat_timeout: &amp;lt;duration&amp;gt; | default = 1m]

    # The number of ingesters to write to and read from. Must be at least
    # 1.
    [replication_factor: &amp;lt;int&amp;gt; | default = 3]
6、querier主要是查询配置
    # Timeout when querying ingesters or storage during the execution of a
    # query request.
    [query_timeout: &amp;lt;duration&amp;gt; | default = 1m]

    # Limit of the duration for which live tailing requests should be
    # served.
    [tail_max_duration: &amp;lt;duration&amp;gt; | default = 1h]

    # Time to wait before sending more than the minimum successful query
    # requests.
    [extra_query_delay: &amp;lt;duration&amp;gt; | default = 0s]

    # Maximum lookback beyond which queries are not sent to ingester.
    # 0 means all queries are sent to ingester.
    [query_ingesters_within: &amp;lt;duration&amp;gt; | default = 0s]

    # Configuration options for the LogQL engine.
    engine:
      # Timeout for query execution
      [timeout: &amp;lt;duration&amp;gt; | default = 3m]

      # The maximum amount of time to look back for log lines. Only
      # applicable for instant log queries.
      [max_look_back_period: &amp;lt;duration&amp;gt; | default = 30s]
7、ingester_client配置ingester的客户端，其实就是distributor连接ingester的配置
    # Configures how connections are pooled
    pool_config:
      # Whether or not to do health checks.
      [health_check_ingesters: &amp;lt;boolean&amp;gt; | default = false]

      # How frequently to clean up clients for servers that have gone away after
      # a health check.
      [client_cleanup_period: &amp;lt;duration&amp;gt; | default = 15s]

      # How quickly a dead client will be removed after it has been detected
      # to disappear. Set this to a value to allow time for a secondary
      # health check to recover the missing client.
      [remotetimeout: &amp;lt;duration&amp;gt;]

    # The remote request timeout on the client side.
    [remote_timeout: &amp;lt;duration&amp;gt; | default = 5s]

    # Configures how the gRPC connection to ingesters work as a
    # client.
    [grpc_client_config: &amp;lt;grpc_client_config&amp;gt;]
8、grpc_client_config上面的client可以使用grpc，这个时候就要对grpc进行配置
    # The maximum size in bytes the client can receive
    [max_recv_msg_size: &amp;lt;int&amp;gt; | default = 104857600]

    # The maximum size in bytes the client can send
    [max_send_msg_size: &amp;lt;int&amp;gt; | default = 16777216]

    # Whether or not messages should be compressed
    [use_gzip_compression: &amp;lt;bool&amp;gt; | default = false]

    # Rate limit for gRPC client. 0 is disabled
    [rate_limit: &amp;lt;float&amp;gt; | default = 0]

    # Rate limit burst for gRPC client.
    [rate_limit_burst: &amp;lt;int&amp;gt; | default = 0]

    # Enable backoff and retry when a rate limit is hit.
    [backoff_on_ratelimits: &amp;lt;bool&amp;gt; | default = false]

    # Configures backoff when enabled.
    backoff_config:
      # Minimum delay when backing off.
      [min_period: &amp;lt;duration&amp;gt; | default = 100ms]

      # The maximum delay when backing off.
      [max_period: &amp;lt;duration&amp;gt; | default = 10s]

      # Number of times to backoff and retry before failing.
      [max_retries: &amp;lt;int&amp;gt; | default = 10]
9、ingester_config配置Ingesters，主要是配置Ingesters的范围
    # Configures how the lifecycle of the ingester will operate
    # and where it will register for discovery.
    [lifecycler: &amp;lt;lifecycler_config&amp;gt;]

    # Number of times to try and transfer chunks when leaving before
    # falling back to flushing to the store. Zero = no transfers are done.
    [max_transfer_retries: &amp;lt;int&amp;gt; | default = 10]

    # How many flushes can happen concurrently from each stream.
    [concurrent_flushes: &amp;lt;int&amp;gt; | default = 16]

    # How often should the ingester see if there are any blocks
    # to flush
    [flush_check_period: &amp;lt;duration&amp;gt; | default = 30s]

    # The timeout before a flush is cancelled
    [flush_op_timeout: &amp;lt;duration&amp;gt; | default = 10s]

    # How long chunks should be retained in-memory after they&#39;ve
    # been flushed.
    [chunk_retain_period: &amp;lt;duration&amp;gt; | default = 15m]

    # How long chunks should sit in-memory with no updates before
    # being flushed if they don&#39;t hit the max block size. This means
    # that half-empty chunks will still be flushed after a certain
    # period as long as they receive no further activity.
    [chunk_idle_period: &amp;lt;duration&amp;gt; | default = 30m]

    # The targeted _uncompressed_ size in bytes of a chunk block
    # When this threshold is exceeded the head block will be cut and compressed inside the chunk
    [chunk_block_size: &amp;lt;int&amp;gt; | default = 262144]

    # A target _compressed_ size in bytes for chunks.
    # This is a desired size not an exact size, chunks may be slightly bigger
    # or significantly smaller if they get flushed for other reasons (e.g. chunk_idle_period)
    # The default value of 0 for this will create chunks with a fixed 10 blocks,
    # A non zero value will create chunks with a variable number of blocks to meet the target size.
    [chunk_target_size: &amp;lt;int&amp;gt; | default = 0]

    # The compression algorithm to use for chunks. (supported: gzip, lz4, snappy)
    # You should choose your algorithm depending on your need:
    # - `gzip` highest compression ratio but also slowest decompression speed. (144 kB per chunk)
    # - `lz4` fastest compression speed (188 kB per chunk)
    # - `snappy` fast and popular compression algorithm (272 kB per chunk)
    [chunk_encoding: &amp;lt;string&amp;gt; | default = gzip]

    # Parameters used to synchronize ingesters to cut chunks at the same moment.
    # Sync period is used to roll over incoming entry to a new chunk. If chunk&#39;s utilization
    # isn&#39;t high enough (eg. less than 50% when sync_min_utilization is set to 0.5), then
    # this chunk rollover doesn&#39;t happen.
    [sync_period: &amp;lt;duration&amp;gt; | default = 0]
    [sync_min_utilization: &amp;lt;float&amp;gt; | Default = 0]

    # The maximum number of errors a stream will report to the user
    # when a push fails. 0 to make unlimited.
    [max_returned_stream_errors: &amp;lt;int&amp;gt; | default = 10]

    # The maximum duration of a timeseries chunk in memory. If a timeseries runs for longer than this the current chunk will be flushed to the store and a new chunk created.
    [max_chunk_age: &amp;lt;duration&amp;gt; | default = 1h]

    # How far in the past an ingester is allowed to query the store for data.
    # This is only useful for running multiple loki binaries with a shared ring with a `filesystem` store which is NOT shared between the binaries
    # When using any &amp;quot;shared&amp;quot; object store like S3 or GCS this value must always be left as 0
    # It is an error to configure this to a non-zero value when using any object store other than `filesystem`
    # Use a value of -1 to allow the ingester to query the store infinitely far back in time.
    [query_store_max_look_back_period: &amp;lt;duration&amp;gt; | default = 0]
10、lifecycler_config主要就是控制
    # Configures the ring the lifecycler connects to
    [ring: &amp;lt;ring_config&amp;gt;]

    # The number of tokens the lifecycler will generate and put into the ring if
    # it joined without transferring tokens from another lifecycler.
    [num_tokens: &amp;lt;int&amp;gt; | default = 128]

    # Period at which to heartbeat to the underlying ring.
    [heartbeat_period: &amp;lt;duration&amp;gt; | default = 5s]

    # How long to wait to claim tokens and chunks from another member when
    # that member is leaving. Will join automatically after the duration expires.
    [join_after: &amp;lt;duration&amp;gt; | default = 0s]

    # Minimum duration to wait before becoming ready. This is to work around race
    # conditions with ingesters exiting and updating the ring.
    [min_ready_duration: &amp;lt;duration&amp;gt; | default = 1m]

    # Name of network interfaces to read addresses from.
    interface_names:
      - [&amp;lt;string&amp;gt; ... | default = [&amp;quot;eth0&amp;quot;, &amp;quot;en0&amp;quot;]]

    # Duration to sleep before exiting to ensure metrics are scraped.
    [final_sleep: &amp;lt;duration&amp;gt; | default = 30s]
11、storage_config主要是存储的配置，可以是本地file，可以是s3等远程存储。这边有很多配置就不一一看了。
12、cache_config就是将数据放到缓存中，比如memche，redis等
13、chunk_store_config是对chunk存储的设置包括多长时间进行存储等
    # The cache configuration for storing chunks
    [chunk_cache_config: &amp;lt;cache_config&amp;gt;]

    # The cache configuration for deduplicating writes
    [write_dedupe_cache_config: &amp;lt;cache_config&amp;gt;]

    # The minimum time between a chunk update and being saved
    # to the store.
    [min_chunk_age: &amp;lt;duration&amp;gt;]

    # Cache index entries older than this period. Default is
    # disabled.
    [cache_lookups_older_than: &amp;lt;duration&amp;gt;]

    # Limit how long back data can be queried. Default is disabled.
    # This should always be set to a value less than or equal to
    # what is set in `table_manager.retention_period`.
    [max_look_back_period: &amp;lt;duration&amp;gt;]
14、schema_config主要是对时间进行设置，格式是period_config
    # The configuration for chunk index schemas.
    configs:
      - [&amp;lt;period_config&amp;gt;]
    # The date of the first day that index buckets should be created. Use
    # a date in the past if this is your only period_config, otherwise
    # use a date when you want the schema to switch over.
    [from: &amp;lt;daytime&amp;gt;]

    # store and object_store below affect which &amp;lt;storage_config&amp;gt; key is
    # used.

    # Which store to use for the index. Either aws, gcp, bigtable, bigtable-hashed,
    # cassandra, or boltdb.
    store: &amp;lt;string&amp;gt;

    # Which store to use for the chunks. Either aws, aws-dynamo, azure, gcp,
    # bigtable, gcs, cassandra, swift or filesystem. If omitted, defaults to the same
    # value as store.
    [object_store: &amp;lt;string&amp;gt;]

    # The schema version to use, current recommended schema is v11.
    schema: &amp;lt;string&amp;gt;

    # Configures how the index is updated and stored.
    index:
      # Table prefix for all period tables.
      prefix: &amp;lt;string&amp;gt;
      # Table period.
      [period: &amp;lt;duration&amp;gt; | default = 168h]
      # A map to be added to all managed tables.
      tags:
        [&amp;lt;string&amp;gt;: &amp;lt;string&amp;gt; ...]

    # Configured how the chunks are updated and stored.
    chunks:
      # Table prefix for all period tables.
      prefix: &amp;lt;string&amp;gt;
      # Table period.
      [period: &amp;lt;duration&amp;gt; | default = 168h]
      # A map to be added to all managed tables.
      tags:
        [&amp;lt;string&amp;gt;: &amp;lt;string&amp;gt; ...]

    # How many shards will be created. Only used if schema is v10 or greater.
    [row_shards: &amp;lt;int&amp;gt; | default = 16]
15、limits_config
    # Whether the ingestion rate limit should be applied individually to each
    # distributor instance (local), or evenly shared across the cluster (global).
    # The ingestion rate strategy cannot be overridden on a per-tenant basis.
    #
    # - local: enforces the limit on a per distributor basis. The actual effective
    #   rate limit will be N times higher, where N is the number of distributor
    #   replicas.
    # - global: enforces the limit globally, configuring a per-distributor local
    #   rate limiter as &amp;quot;ingestion_rate / N&amp;quot;, where N is the number of distributor
    #   replicas (it&#39;s automatically adjusted if the number of replicas change).
    #   The global strategy requires the distributors to form their own ring, which
    #   is used to keep track of the current number of healthy distributor replicas.
    [ingestion_rate_strategy: &amp;lt;string&amp;gt; | default = &amp;quot;local&amp;quot;]

    # Per-user ingestion rate limit in sample size per second. Units in MB.
    [ingestion_rate_mb: &amp;lt;float&amp;gt; | default = 4]

    # Per-user allowed ingestion burst size (in sample size). Units in MB.
    # The burst size refers to the per-distributor local rate limiter even in the
    # case of the &amp;quot;global&amp;quot; strategy, and should be set at least to the maximum logs
    # size expected in a single push request.
    [ingestion_burst_size_mb: &amp;lt;int&amp;gt; | default = 6]

    # Maximum length of a label name.
    [max_label_name_length: &amp;lt;int&amp;gt; | default = 1024]

    # Maximum length of a label value.
    [max_label_value_length: &amp;lt;int&amp;gt; | default = 2048]

    # Maximum number of label names per series.
    [max_label_names_per_series: &amp;lt;int&amp;gt; | default = 30]

    # Whether or not old samples will be rejected.
    [reject_old_samples: &amp;lt;bool&amp;gt; | default = false]

    # Maximum accepted sample age before rejecting.
    [reject_old_samples_max_age: &amp;lt;duration&amp;gt; | default = 336h]

    # Duration for a table to be created/deleted before/after it&#39;s
    # needed. Samples won&#39;t be accepted before this time.
    [creation_grace_period: &amp;lt;duration&amp;gt; | default = 10m]

    # Enforce every sample has a metric name.
    [enforce_metric_name: &amp;lt;boolean&amp;gt; | default = true]

    # Maximum number of active streams per user, per ingester. 0 to disable.
    [max_streams_per_user: &amp;lt;int&amp;gt; | default = 10000]

    # Maximum line size on ingestion path. Example: 256kb.
    # There is no limit when unset.
    [max_line_size: &amp;lt;string&amp;gt; | default = none ]

    # Maximum number of log entries that will be returned for a query. 0 to disable.
    [max_entries_limit: &amp;lt;int&amp;gt; | default = 5000 ]

    # Maximum number of active streams per user, across the cluster. 0 to disable.
    # When the global limit is enabled, each ingester is configured with a dynamic
    # local limit based on the replication factor and the current number of healthy
    # ingesters, and is kept updated whenever the number of ingesters change.
    [max_global_streams_per_user: &amp;lt;int&amp;gt; | default = 0]

    # Maximum number of chunks that can be fetched by a single query.
    [max_chunks_per_query: &amp;lt;int&amp;gt; | default = 2000000]

    # The limit to length of chunk store queries. 0 to disable.
    [max_query_length: &amp;lt;duration&amp;gt; | default = 0]

    # Maximum number of queries that will be scheduled in parallel by the
    # frontend.
    [max_query_parallelism: &amp;lt;int&amp;gt; | default = 14]

    # Cardinality limit for index queries
    [cardinality_limit: &amp;lt;int&amp;gt; | default = 100000]

    # Maximum number of stream matchers per query.
    [max_streams_matchers_per_query: &amp;lt;int&amp;gt; | default = 1000]

    # Feature renamed to &#39;runtime configuration&#39;, flag deprecated in favor of -runtime-config.file (runtime_config.file in YAML)
    [per_tenant_override_config: &amp;lt;string&amp;gt;]

    # Feature renamed to &#39;runtime configuration&#39;, flag deprecated in favor of -runtime-config.reload-period (runtime_config.period in YAML)
    [per_tenant_override_period: &amp;lt;duration&amp;gt; | default = 10s]
16、frontend_worker_config
    # Address of query frontend service, in host:port format.
    # CLI flag: -querier.frontend-address
    [frontend_address: &amp;lt;string&amp;gt; | default = &amp;quot;&amp;quot;]

    # Number of simultaneous queries to process.
    # CLI flag: -querier.worker-parallelism
    [parallelism: &amp;lt;int&amp;gt; | default = 10]

    # How often to query DNS.
    # CLI flag: -querier.dns-lookup-period
    [dns_lookup_duration: &amp;lt;duration&amp;gt; | default = 10s]

    grpc_client_config:
      # gRPC client max receive message size (bytes).
      # CLI flag: -querier.frontend-client.grpc-max-recv-msg-size
      [max_recv_msg_size: &amp;lt;int&amp;gt; | default = 104857600]

      # gRPC client max send message size (bytes).
      # CLI flag: -querier.frontend-client.grpc-max-send-msg-size
      [max_send_msg_size: &amp;lt;int&amp;gt; | default = 16777216]

      # Use compression when sending messages.
      # CLI flag: -querier.frontend-client.grpc-use-gzip-compression
      [use_gzip_compression: &amp;lt;boolean&amp;gt; | default = false]

      # Rate limit for gRPC client; 0 means disabled.
      # CLI flag: -querier.frontend-client.grpc-client-rate-limit
      [rate_limit: &amp;lt;float&amp;gt; | default = 0]

      # Rate limit burst for gRPC client.
      # CLI flag: -querier.frontend-client.grpc-client-rate-limit-burst
      [rate_limit_burst: &amp;lt;int&amp;gt; | default = 0]

      # Enable backoff and retry when we hit ratelimits.
      # CLI flag: -querier.frontend-client.backoff-on-ratelimits
      [backoff_on_ratelimits: &amp;lt;boolean&amp;gt; | default = false]

      backoff_config:
        # Minimum delay when backing off.
        # CLI flag: -querier.frontend-client.backoff-min-period
        [min_period: &amp;lt;duration&amp;gt; | default = 100ms]

        # Maximum delay when backing off.
        # CLI flag: -querier.frontend-client.backoff-max-period
        [max_period: &amp;lt;duration&amp;gt; | default = 10s]

        # Number of times to backoff and retry before failing.
        # CLI flag: -querier.frontend-client.backoff-retries
        [max_retries: &amp;lt;int&amp;gt; | default = 10]
17、table_manager_config，provision_config都是用于DynamoDB。
18、auto_scaling_config用于DynamoDB的自动伸缩
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体可以参考&lt;a href=&#34;https://github.com/grafana/loki/tree/v1.5.0/docs/configuration&#34;&gt;官网&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;loki的配置还是比较复杂的，下面我们再来看一下promtail的配置&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# cat promtail.yaml
client:
  backoff_config:
    max_period: 5s
    max_retries: 20
    min_period: 100ms
  batchsize: 102400
  batchwait: 1s
  external_labels: {}
  timeout: 10s
positions:
  filename: /run/promtail/positions.yaml
server:
  http_listen_port: 3101
target_config:
  sync_period: 10s
scrape_configs:
- job_name: kubernetes-pods-name
  pipeline_stages:
    - docker: {}
  kubernetes_sd_configs:
  - role: pod
  relabel_configs:
  - source_labels:
    - __meta_kubernetes_pod_label_name
    target_label: __service__
  - source_labels:
    - __meta_kubernetes_pod_node_name
    target_label: __host__
  - action: drop
    regex: &#39;&#39;
    source_labels:
    - __service__
  - action: labelmap
    regex: __meta_kubernetes_pod_label_(.+)
  - action: replace
    replacement: $1
    separator: /
    source_labels:
    - __meta_kubernetes_namespace
    - __service__
    target_label: job
  - action: replace
    source_labels:
    - __meta_kubernetes_namespace
    target_label: namespace
  - action: replace
    source_labels:
    - __meta_kubernetes_pod_name
    target_label: pod
  - action: replace
    source_labels:
    - __meta_kubernetes_pod_container_name
    target_label: container
  - replacement: /var/log/pods/*$1/*.log
    separator: /
    source_labels:
    - __meta_kubernetes_pod_uid
    - __meta_kubernetes_pod_container_name
    target_label: __path__
- job_name: kubernetes-pods-app
......
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;promtail的配置和prometheus很像，我们也简单说明一下，promtail的复杂配置分为四个部分。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server_config 配置promtail作为一个服务器。开启一个http端口
client_config 配置promtail怎么连接loki，它作为loki的客户端
position_config 指明promtail的配置文件在什么地方生成，重启的时候会读取一些信息
scrape_config 配置一些常用的抓取策略
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们主要配置的地方，就是scrape_config 。它又分为几种常见的抓取方式，比如&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;journal_config
syslog_config
relabel_config
static_config
file_sd_config
kubernetes_sd_config
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于我们来说，最常使用的就是static_config，比如指定业务的某个日志文件。这部分的描述很长，具体可以参考github文档。&lt;/p&gt;

&lt;p&gt;一个配置文件中，是可以针对不同类型的日志文件同时进行监控的。比如下面的长长的配置文件，就加入了三个抓取策略。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://localhost:3100/loki/api/v1/push

scrape_configs:
  - job_name: journal
    journal:
      max_age: 12h
      labels:
        job: systemd-journal
    relabel_configs:
      - source_labels: [&#39;__journal__systemd_unit&#39;]
        target_label: &#39;unit&#39;
  - job_name: system
    pipeline_stages:
    static_configs:
    - labels:
       job: varlogs
       host: yourhost
       __path__: /var/log/*.log
  - job_name: biz001
    pipeline_stages:
    - match:
       selector: &#39;{app=&amp;quot;test&amp;quot;}&#39;
       stages:
       - regex:
          expression: &#39;.*level=(?P&amp;lt;level&amp;gt;[a-zA-Z]+).*ts=(?P&amp;lt;timestamp&amp;gt;[T\d-:.Z]*).*component=(?P&amp;lt;component&amp;gt;[a-zA-Z]+)&#39;
       - labels:
          level:
          component:
          ts:
          timestrap:
    static_configs:
    - labels:
       job: biz001
       app: test
       node: 001
       host: localhost
       __path__: /alertmgr/dingtalk/nohup.out
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们配置了三个job（概念见普罗米修斯），journal，system和biz001。尤其注意biz001的配置，这代表了我们对一些日志的通用配置方式。&lt;/p&gt;

&lt;p&gt;首先，看一下biz001的日志格式。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;level=info ts=2020-04-30T01:20:38.631Z caller=entry.go:22 component=web http_scheme=http http_proto=HTTP/1.1 http_method=POST remote_addr=[::1]:57710 user_agent=Alertmanager/0.20.0 uri=http://localhost:8060/dingtalk/webhook1/send resp_status=200 resp_bytes_length=2 resp_elapsed_ms=5207.398549 msg=&amp;quot;request complete&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在将日志传送到Loki之前，promtail可以对其进行一系列的操作。比如过滤一些日志，提取一些label，替换一些日志的内容等。&lt;/p&gt;

&lt;p&gt;对于这部分的操作，现有的日志收集工具都搞了一套自己的，而且都很难用。&lt;/p&gt;

&lt;p&gt;比如我们用来解析我们固定格式的nginx日志&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ps -ef | grep promtail
root     14449 14356  0 21:06 pts/0    00:00:00 grep promtail
root     28509     1  0 Jul21 ?        00:23:12 /opt/promes/loki/promtail-linux-amd64 --config.file=/opt/promes/loki/nginx.yaml
[root@promessitweb19 ~]# cat /opt/promes/loki/nginx.yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /opt/promes/loki/positions.yaml

clients:
  - url: http://10.243.51.50:3100/loki/api/v1/push

scrape_configs:
- job_name: nginx
  static_configs:
  - targets:
      - localhost
    labels:
      job: nginxAccess
      __path__: /opt/rsync_log/access_http.log
      ip: &amp;quot;10.243.58.14&amp;quot;
      appId: PROMES
      softType: blackbox
  pipeline_stages:
  - match:
      selector: &#39;{app=&amp;quot;nginx&amp;quot;}&#39;
      stages:
      - regex:
          expression: &#39;^(?P&amp;lt;remote_addr&amp;gt;\\S+)   (?P&amp;lt;http_x_forwarded_for&amp;gt;\\S+)  (?P&amp;lt;http_x_forwarded_for2&amp;gt;\\S+) (?P&amp;lt;http_x_forwarded_for3&amp;gt;\\S+) (?P&amp;lt;time_iso8601&amp;gt;\\S+)  (?P&amp;lt;request_method&amp;gt;\\S+)    &amp;quot;(?P&amp;lt;document_uri&amp;gt;\\S+)&amp;quot;    &amp;quot;(?P&amp;lt;query_string&amp;gt;\\S+)&amp;quot;    (?P&amp;lt;request_http_protocol&amp;gt;\\S+) (?P&amp;lt;status&amp;gt;\\d{3}|-)    (?P&amp;lt;body_bytes_sent&amp;gt;\\d{3}|-)   (?P&amp;lt;request_time&amp;gt;\\S+)  &amp;quot;(?P&amp;lt;http_referer&amp;gt;\\S+)&amp;quot;    &amp;quot;(?P&amp;lt;user_agent&amp;gt;\\S+)&amp;quot;  traceId:(?P&amp;lt;traceId&amp;gt;\\S+),spanId:(?P&amp;lt;spanId&amp;gt;\\S+)   (?P&amp;lt;server_addr&amp;gt;\\S+)   (?P&amp;lt;hostname&amp;gt;\\S+)  (?P&amp;lt;host&amp;gt;\\S+)  (?P&amp;lt;remote_port&amp;gt;\\S+)   (?P&amp;lt;server_port&amp;gt;\\S+)   &amp;quot;(?P&amp;lt;upstream_addr&amp;gt;\\S+)&amp;quot;   &amp;quot;(?P&amp;lt;upstream_status&amp;gt;\\S+)&amp;quot; &amp;quot;(?P&amp;lt;upstream_response_time&amp;gt;\\S+)&amp;quot;  (?P&amp;lt;version&amp;gt;\\S+)?$&#39;
      - labels:
          remote_addr:
          http_x_forwarded_for:
          http_x_forwarded_for2:
          http_x_forwarded_for3:
          timestamp:
          request_method:
          document_uri:
          query_string:
          request_http_protocol:
          status:
          body_bytes_sent:
          request_time:
          http_referer:
          user_agent:
          traceId:
          spanId:
          server_addr:
          hostname:
          host:
          remote_port:
          server_port:
          upstream_addr:
          upstream_status:
          upstream_response_time:
          version:
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;物理部署&#34;&gt;物理部署&lt;/h2&gt;

&lt;p&gt;物理部署很简单，可以直接下载二进制文件，官方还提供来repo，我们还可以编译&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/grafana/loki $GOPATH/src/github.com/grafana/loki
$ cd $GOPATH/src/github.com/grafana/loki
$ make loki
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后直接用二进制文件加配置文件进行启动就可以了，配置文件在/etc/loki/promtail.yaml and /etc/loki/loki.yaml。&lt;/p&gt;

&lt;h2 id=&#34;基本使用&#34;&gt;基本使用&lt;/h2&gt;

&lt;p&gt;下面我们就可以到grafana界面进行操作了，进入 grafana 界面，添加 loki 作为数据源，grafana原生就是支持loki的，所以直接添加loki 在集群中的地址，比如: &lt;a href=&#34;http://loki.monitoring.svc.cluster.local:3100&#34;&gt;http://loki.monitoring.svc.cluster.local:3100&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/loki/loki2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;数据源添加好了，我们就可以开始查询分析日志了，点击 Explore，下拉选择 loki 作为数据源，切到 Logs 模式(不用 Metrics 模式)，在 Log labels 按钮那里就能通过 label 筛选日志了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/loki/loki3&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;选择器&#34;&gt;选择器&lt;/h2&gt;

&lt;p&gt;对于查询表达式的标签部分，将其包装在花括号中{}，然后使用键值对的语法来选择标签，多个标签表达式用逗号分隔，比如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{app=&amp;quot;mysql&amp;quot;,name=&amp;quot;mysql-backup&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;目前支持以下标签匹配运算符：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;=等于
!=不相等
=~正则表达式匹配
!~不匹配正则表达式
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;比如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{name=~&amp;quot;mysql.+&amp;quot;}
{name!~&amp;quot;mysql.+&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;适用于Prometheus标签选择器规则同样也适用于Loki日志流选择器,可以查看官网的&lt;a href=&#34;https://github.com/grafana/loki/blob/v1.5.0/docs/logql.md&#34;&gt;logQL&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;基本原理&#34;&gt;基本原理&lt;/h1&gt;

&lt;h2 id=&#34;promtail&#34;&gt;Promtail&lt;/h2&gt;

&lt;p&gt;promtail 可以理解为采集日志的 “Prometheus”. 它最巧妙的设计是完全复用了 Prometheus 的服务发现机制与 label 机制.&lt;/p&gt;

&lt;p&gt;以 Kubernetes 服务发现为例, Prometheus 可以通过 Pod 的 Annotations 与 Labels 等信息来确定 Pod 是否需要抓取指标, 假如要的话 Pod 的指标暴露在哪个端口上, 以及这个 Pod 本身有哪些 label, 即 target label.&lt;/p&gt;

&lt;p&gt;确定了这些信息之后, Prometheus 就可以去拉应用的指标了. 同时, 这些指标都会被打上 target label, 用于标注指标的来源. 等到在查询的时候, 我们就可以通过 target label, 比方说 pod_name=foo-123512 或 service=user-service 来获取特定的一个或一组 Pod 上的指标信息.&lt;/p&gt;

&lt;p&gt;promtail 是一样的道理. 它也是通过 Pod 的一些元信息来确定该 Pod 的日志文件位置, 同时为日志打上特定的 target label. 但要注意, 这个 label 不是标注在每一行日志事件上的, 而是被标注在”整个日志”上的. 这里”整个日志”在 loki 中抽象为 stream(日志流). 这就是 loki 文档中所说的”不索引日志, 只索引日志流”. 最终在查询端, 我们通过这些 label 就可以快速查询一个或一组特定的 stream.&lt;/p&gt;

&lt;p&gt;服务发现部分的代码非常直白, 可以去 pkg/promtail/targetmanager.go 中自己看一下, 提两个实现细节:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;promtail 要求所有 target 都跟自己属于同一个 node, 处于其它 node 上的 target 会被忽略;
promtail 使用 target 的 __path__ label 来确定日志路径;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过服务发现确定要收集的应用以及应用的日志路径后, promtail 就开始了真正的日志收集过程. 这里分三步:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1、用 fsnotify 监听对应目录下的文件创建与删除(处理 log rolling)
2、对每个活跃的日志文件起一个 goroutine 进行类似 tail -f 的读取, 读取到的内容发送给 channel
3、一个单独的 goroutine 会解析 channel 中的日志行, 分批发送给 loki 的 backend
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;监听&#34;&gt;监听&lt;/h3&gt;

&lt;p&gt;fsnotify负责监听&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for {
    select {
    case event := &amp;lt;-t.watcher.Events:
        switch event.Op {
        case fsnotify.Create:
            // protect against double Creates.
            if _, ok := t.tails[event.Name]; ok {
                level.Info(t.logger).Log(&amp;quot;msg&amp;quot;, &amp;quot;got &#39;create&#39; for existing file&amp;quot;, &amp;quot;filename&amp;quot;, event.Name)
                continue
            }

            // newTailer 中会启动一个 goroutine 来读目标文件
            tailer := newTailer(t.logger, t.handler, t.positions, t.path, event.Name)
            t.tails[event.Name] = tailer

        case fsnotify.Remove:
            tailer, ok := t.tails[event.Name]
            if ok {
                // 关闭 tailer
                helpers.LogError(&amp;quot;stopping tailer&amp;quot;, tailer.stop)
                delete(t.tails, event.Name)
            }
        }
    case err := &amp;lt;-t.watcher.Errors:
        level.Error(t.logger).Log(&amp;quot;msg&amp;quot;, &amp;quot;error from fswatch&amp;quot;, &amp;quot;error&amp;quot;, err)
    case &amp;lt;-t.quit:
        return
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一个for循环，一直来处理对应目录下的文件创建与删除的事件。&lt;/p&gt;

&lt;h3 id=&#34;tail日志&#34;&gt;tail日志&lt;/h3&gt;

&lt;p&gt;newTailer() 这个方法中启动的日志文件读取逻辑&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;unc newTailer() {
    tail := tail.TailFile(path, tail.Config{
        Follow: true,
        Location: &amp;amp;tail.SeekInfo{
            Offset: positions.Get(path),
            Whence: 0,
        },
    })

    tailer := ...
    go tailer.run()
}

func (t *tailer) run() {
    for {
        select {
        case &amp;lt;-positionWait.C:
            // 定时同步当前读取位置
            pos := t.tail.Tell()
            t.positions.Put(t.path, pos)

        case line, ok := &amp;lt;-t.tail.Lines:
            // handler.Handle() 中是一些日志行的预处理逻辑, 最后将日志行转化为 `Entry` 对象扔进 channel
            if err := t.handler.Handle(model.LabelSet{}, line.Time, line.Text); err != nil {
                level.Error(t.logger).Log(&amp;quot;msg&amp;quot;, &amp;quot;error handling line&amp;quot;, &amp;quot;error&amp;quot;, err)
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里直接调用了 hpcloud/tail 这个包来完成文件的 tail 操作. hpcloud/tail 的内部实现中, 在读到 EOF 之后, 同样调用了 fsnotify 来获取新内容写入的通知. fsnotify 这个包内部则是依赖了 inotify_init 和 inotify_add_watch 这两个系统调用。&lt;/p&gt;

&lt;h3 id=&#34;日志channel&#34;&gt;日志channel&lt;/h3&gt;

&lt;p&gt;这里有一个单独的 goroutine 会读取所有 tailer 通过 channel 传过来的日志(Entry对象), 然后按批发送给 loki&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for {
    // 每次发送之后要重置计时器
    maxWait.Reset(c.cfg.BatchWait)
    select {
    case &amp;lt;-c.quit:
        return
    case e := &amp;lt;-c.entries:
        // Batch 足够大之后, 执行发送逻辑
        if batchSize+len(e.Line) &amp;gt; c.cfg.BatchSize {
            c.send(batch)
            // 重置 Batch
            batchSize = 0
            batch = map[model.Fingerprint]*logproto.Stream{}
        }

        // 收到 Entry, 先写进 Batch 当中
        batchSize += len(e.Line)

        // 每个 entry 要根据 label 放进对应的日志流(Stream)中
        fp := e.labels.FastFingerprint()
        stream, ok := batch[fp]
        if !ok {
            stream = &amp;amp;logproto.Stream{
                Labels: e.labels.String(),
            }
            batch[fp] = stream
        }
        stream.Entries = append(stream.Entries, e.Entry)

    case &amp;lt;-maxWait.C:
        // 到达每个批次的最大等待时间, 同样执行发送
        if len(batch) &amp;gt; 0 {
            c.send(batch);
            batchSize = 0
            batch = map[model.Fingerprint]*logproto.Stream{}
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用 channel + select 写 batch 逻辑真的挺优雅, 简单易读.&lt;/p&gt;

&lt;h2 id=&#34;loki&#34;&gt;loki&lt;/h2&gt;

&lt;p&gt;loki的基本架构&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/loki/loki4&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;distributor&#34;&gt;Distributor&lt;/h3&gt;

&lt;p&gt;我们都知道promtail封装后label后的log数据发生到loki，Distributor就是第一个接收日志的组件。由于日志的写入量可能很大，所以不能在它们传入时将它们写入数据库。这会毁掉数据库。我们需要批处理和压缩数据。&lt;/p&gt;

&lt;p&gt;Loki通过构建压缩数据块来实现这一点，方法是在日志进入时对其进行gzip操作，组件ingester是一个有状态的组件，负责构建和刷新chunck，当chunk达到一定的数量或者时间后，刷新到存储中去。每个流的日志对应一个ingester,当日志到达Distributor后，根据元数据和hash算法计算出应该到哪个ingester上面。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/loki/loki8&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我们具体看一下promtail 的日志写入请求, 请求体由 protobuf 编码, 格式如下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 一次写入请求, 包含多段日志流
type PushRequest struct {
    Streams []*Stream `protobuf:&amp;quot;bytes,1,rep,name=streams&amp;quot; json:&amp;quot;streams,omitempty&amp;quot;`
}
// 一段日志流, 包含它的 label, 以及这段日志流当中的每个日志事件: Entry
type Stream struct {
    Labels  string  `protobuf:&amp;quot;bytes,1,opt,name=labels,proto3&amp;quot; json:&amp;quot;labels,omitempty&amp;quot;`
    Entries []Entry `protobuf:&amp;quot;bytes,2,rep,name=entries&amp;quot; json:&amp;quot;entries&amp;quot;`
}
// 一个日志事件, 包含时间戳与内容
type Entry struct {
    Timestamp time.Time `protobuf:&amp;quot;bytes,1,opt,name=timestamp,stdtime&amp;quot; json:&amp;quot;timestamp&amp;quot;`
    Line      string    `protobuf:&amp;quot;bytes,2,opt,name=line,proto3&amp;quot; json:&amp;quot;line,omitempty&amp;quot;`
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;distributor 收到请求后, 会将一个 PushRequest 中的 Stream 根据 labels 拆分成多个 PushRequest, 这个过程使用一致性哈希:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;streams := make([]streamTracker, len(req.Streams))
keys := make([]uint32, 0, len(req.Streams))
for i, stream := range req.Streams {
    // 获取每个 stream 的 label hash
    keys = append(keys, tokenFor(userID, stream.Labels))
    streams[i].stream = stream
}

// 根据 label hash 到 hash ring 上获取对应的 ingester 节点
// 这里的节点指 hash ring 上的节点, 一个节点可能有多个对等的 ingester 副本来做 HA
replicationSets := d.ring.BatchGet(keys, ring.Write)

// 将 Stream 按对应的 ingester 节点进行分组
samplesByIngester := map[string][]*streamTracker{}
ingesterDescs := map[string]ring.IngesterDesc{}
for i, replicationSet := range replicationSets {
    for _, ingester := range replicationSet.Ingesters {
        samplesByIngester[ingester.Addr] = append(samplesByIngester[ingester.Addr], &amp;amp;streams[i])
        ingesterDescs[ingester.Addr] = ingester
    }
}

for ingester, samples := range samplesByIngester {
    // 每组 Stream[] 又作为一个 PushRequest, 下发给对应的 ingester 节点
    d.sendSamples(localCtx, ingester, samples, &amp;amp;tracker)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 All in One 的运行模式中, hash ring 直接存储在内存中. 在生产环境, 由于要起多个 distributor 节点做高可用, 这个 hash ring 会存储到外部的 Consul 集群中.&lt;/p&gt;

&lt;h3 id=&#34;ingester&#34;&gt;Ingester&lt;/h3&gt;

&lt;p&gt;ingester接收到日志并开始构建chunk:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/loki/loki5&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;基本上就是将日志进行压缩并附加到chunk上面。一旦chunk“填满”（数据达到一定数量或者过了一定期限），ingester将其刷新到数据库。我们对块和索引使用单独的数据库，因为它们存储的数据类型不同。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/loki/loki6&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;刷新一个chunk之后，ingester然后创建一个新的空chunk并将新条目添加到该chunk中。&lt;/p&gt;

&lt;p&gt;我们再重代码层来分析一下，ingester 接收 distributor 下发的 PushRequest, 也就是多段日志流([]Entry). 在 ingester 内部会先将收到的 []Entry Append 到内存中的 Chunk 流([]Chunk). 同时会有一组 goroutine 异步将 Chunk 流存储到对象存储当中:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/loki/loki9&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;第一个 Append 过程很关键&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (i *instance) Push(ctx context.Context, req *logproto.PushRequest) error {
    for _, s := range req.Streams {
        // 将收到的日志流 Append 到内存中的日志流上, 同样地, 日志流按 label hash 索引
        fp := client.FastFingerprint(req.labels)
        stream, ok := i.streams[fp]
        if !ok {
            stream = newStream(fp, req.labels)
            // 这个过程中, 还会维护日志流的倒排索引(label -&amp;gt; stream)
            i.index.Add(labels, fp)
            i.streams[fp] = stream
        }
        stream.Push(ctx, s.Entries)
    }
    return nil
}

func (s *stream) Push(_ context.Context, entries []logproto.Entry) error {
    for i := range entries {
        // 假如当前 Chunk 已经关闭或者已经到达设定的最大 Chunk 大小, 则再创建一个新的 Chunk
        if s.chunks[0].closed || !s.chunks[0].chunk.SpaceFor(&amp;amp;entries[i]) {
            s.chunks = append(s.chunks, chunkDesc{
                chunk: chunkenc.NewMemChunk(chunkenc.EncGZIP),
            })
        }
        s.chunks[len(s.chunks)-1].chunk.Append(&amp;amp;entries[i])
    }
    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Chunk 其实就是多条日志构成的压缩包. 将日志压成 Chunk 的意义是可以直接存入对象存储, 而对象存储是最便宜的(便宜是 loki 的核心目标之一). 在 一个 Chunk 到达指定大小之前它就是 open 的, 会不断 Append 新的日志(Entry) 到里面. 而在达到大小之后, Chunk 就会关闭等待持久化(强制持久化也会关闭 Chunk, 比如关闭 ingester 实例时就会关闭所有的 Chunk并持久化).&lt;/p&gt;

&lt;p&gt;对 Chunk 的大小控制是一个调优要点:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;假如 Chunk 容量过小: 首先是导致压缩效率不高. 同时也会增加整体的 Chunk 数量, 导致倒排索引过大. 最后, 对象存储的操作次数也会变多, 带来额外的性能开销;
假如 Chunk 过大: 一个 Chunk 的 open 时间会更长, 占用额外的内存空间, 同时, 也增加了丢数据的风险. 最后, Chunk 过大也会导致查询读放大, 比方说查一小时的数据却要下载整天的 Chunk;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;丢数据问题: 所有 Chunk 要在 close 之后才会进行存储. 因此假如 ingester 异常宕机, 处于 open 状态的 Chunk, 以及 close 了但还没有来得及持久化的 Chunk 数据都会丢失. 从这个角度来说, ingester 其实也是 stateful 的, 在生产中可以通过给 ingester 跑多个副本来解决这个问题. 另外, ingester 里似乎还没有写 WAL, 这感觉是一个 PR 机会, 可以练习一下写存储的基本功.&lt;/p&gt;

&lt;p&gt;异步存储过程就很简单了, 是一个一对多的生产者消费者模型:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 一个 goroutine 将所有的待存储的 chunks enqueue
func (i *Ingester) sweepStream(instance *instance, stream *stream, immediate bool) {

    // 有一组待存储的队列(默认16个), 取模找一个队列把要存储的 chunk 的引用塞进去
    flushQueueIndex := int(uint64(stream.fp) % uint64(i.cfg.ConcurrentFlushes))
    firstTime, _ := stream.chunks[0].chunk.Bounds()
    i.flushQueues[flushQueueIndex].Enqueue(&amp;amp;flushOp{
        model.TimeFromUnixNano(firstTime.UnixNano()), instance.instanceID,
        stream.fp, immediate,
    })
}

// 每个队列都有一个 goroutine 作为消费者在 dequeue
func (i *Ingester) flushLoop(j int) {
    for {
        op := i.flushQueues[j].Dequeue()
        // 实际的存储操作在这个方法中, 存储完成后, Chunk 会被清理掉
        i.flushUserSeries(op.userID, op.fp, op.immediate)

        // 存储失败的 chunk 会重新塞回队列中
        if op.immediate &amp;amp;&amp;amp; err != nil {
            op.from = op.from.Add(flushBackoff)
            i.flushQueues[j].Enqueue(op)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后是清理过程, 同样是一个单独的 goroutine 定时在跑. ingester 里的所有 Chunk 会在持久化之后隔一小段时间才被清理掉. 这个”一小段时间”由 chunk-retain-time 参数进行控制(默认 15 分钟). 这么做是为了加速热点数据的读取(真正被人看的日志中, 有99%都是生成后的一小段时间内被查看的).&lt;/p&gt;

&lt;h3 id=&#34;querier&#34;&gt;Querier&lt;/h3&gt;

&lt;p&gt;读取就非常简单了，由Querier负责给定一个时间范围和标签选择器，Querier查看索引以确定哪些块匹配，并通过greps将结果显示出来。它还从Ingester获取尚未刷新的最新数据，合并后返回。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/loki/loki7&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;合并返回日志的时候，loki 里用了堆, 时间正序就用最小堆, 时间逆序就用最大堆:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 这部分代码实现了一个简单的二叉堆, MinHeap 和 MaxHeap 实现了相反的 `Less()` 方法
type iteratorHeap []EntryIterator
func (h iteratorHeap) Len() int            { return len(h) }
func (h iteratorHeap) Swap(i, j int)       { h[i], h[j] = h[j], h[i] }
func (h iteratorHeap) Peek() EntryIterator { return h[0] }
func (h *iteratorHeap) Push(x interface{}) {
    *h = append(*h, x.(EntryIterator))
}
func (h *iteratorHeap) Pop() interface{} {
    old := *h
    n := len(old)
    x := old[n-1]
    *h = old[0 : n-1]
    return x
}
type iteratorMinHeap struct {
    iteratorHeap
}
func (h iteratorMinHeap) Less(i, j int) bool {
    return h.iteratorHeap[i].Entry().Timestamp.Before(h.iteratorHeap[j].Entry().Timestamp)
}
type iteratorMaxHeap struct {
    iteratorHeap
}
func (h iteratorMaxHeap) Less(i, j int) bool {
    return h.iteratorHeap[i].Entry().Timestamp.After(h.iteratorHeap[j].Entry().Timestamp)
}

// 将一组 Stream 的 iterator 合并成一个 HeapIterator
func NewHeapIterator(is []EntryIterator, direction logproto.Direction) EntryIterator {
    result := &amp;amp;heapIterator{}
    switch direction {
    case logproto.BACKWARD:
        result.heap = &amp;amp;iteratorMaxHeap{}
    case logproto.FORWARD:
        result.heap = &amp;amp;iteratorMinHeap{}
    default:
        panic(&amp;quot;bad direction&amp;quot;)
    }
    // pre-next each iterator, drop empty.
    for _, i := range is {
        result.requeue(i)
    }
    return result
}

func (i *heapIterator) requeue(ei EntryIterator) {
    if ei.Next() {
        heap.Push(i.heap, ei)
        return
    }
    if err := ei.Error(); err != nil {
        i.errs = append(i.errs, err)
    }
    helpers.LogError(&amp;quot;closing iterator&amp;quot;, ei.Close)
}

func (i *heapIterator) Next() bool {
    if i.curr != nil {
        i.requeue(i.curr)
    }
    if i.heap.Len() == 0 {
        return false
    }
    i.curr = heap.Pop(i.heap).(EntryIterator)
    currEntry := i.curr.Entry()
    // keep popping entries off if they match, to dedupe
    for i.heap.Len() &amp;gt; 0 {
        next := i.heap.Peek()
        nextEntry := next.Entry()
        if !currEntry.Equal(nextEntry) {
            break
        }

        next = heap.Pop(i.heap).(EntryIterator)
        i.requeue(next)
    }
    return true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;扩展&#34;&gt;扩展&lt;/h1&gt;

&lt;p&gt;1、Loki的索引存储可以是cassandra/bigtable/dynamodb来进行扩展，chuncks可以是各种对象存储，放入对象存储中进行扩展。&lt;/p&gt;

&lt;p&gt;2、Querier和Distributor都是无状态的组件，可以水平扩展，可以使用负载均衡。&lt;/p&gt;

&lt;p&gt;3、对于ingester他虽然是有状态的但是，当新的节点加入或者减少，整节点间的chunk会重新分配，已适应新的散列环。这些信息需要存储到etcd或者consul等第三方工具中。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;2020.5.20&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;loki今天发布了1.5.0版本！引入了名为boltdb-shipper的新索引选项，这个新索引允许您仅使用对象存储（S3，GCS，文件系统等）来运行Loki。您不再需要单独的专用索引存储（DynamoDB，Bigtable，Cassandra等）！&lt;/p&gt;

&lt;p&gt;该boltdb-shipper索引使用内存中的boltdb索引，但会定期将快照发送到对象存储。这允许通过对象存储共享索引信息。&lt;/p&gt;

&lt;p&gt;将来可扩展可以通过boltdb-shipper索引和memberlist的gossip来完成集群功能。&lt;/p&gt;

&lt;p&gt;在云存储上，ring的信息可以通过gossip协议来进行同步。可以看一下下面的这个配置，基于s3和memberlist的可扩展模式&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;auth_enabled: false

server:
  http_listen_port: 3100

distributor:
  ring:
    store: memberlist

ingester:
  lifecycler:
    ring:
      kvstore:
        store: memberlist
      replication_factor: 1
    final_sleep: 0s
  chunk_idle_period: 5m
  chunk_retain_period: 30s

memberlist:
  abort_if_cluster_join_fails: false

  # Expose this port on all distributor, ingester
  # and querier replicas.
  bind_port: 7946

  # You can use a headless k8s service for all distributor,
  # ingester and querier components.
  join_members:
  - loki-gossip-ring.loki.svc.cluster.local:7946

  max_join_backoff: 1m
  max_join_retries: 10
  min_join_backoff: 1s

schema_config:
  configs:
  - from: 2020-05-15
    store: boltdb-shipper
    object_store: s3
    schema: v11
    index:
      prefix: index_
      period: 168h

storage_config:
 boltdb_shipper:
   active_index_directory: /loki/index
   cache_location: /loki/index_cache
   resync_interval: 5s
   shared_store: s3

 aws:
   s3: s3://access_key:secret_access_key@custom_endpoint/bucket_name
   s3forcepathstyle: true

limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>监控metrics系列----VictoriaMetrics</title>
          <link>https://kingjcy.github.io/post/monitor/metrics/prometheus/cluster/victoriametrics/</link>
          <pubDate>Thu, 13 Jun 2019 16:19:46 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/monitor/metrics/prometheus/cluster/victoriametrics/</guid>
          <description>&lt;p&gt;VictoriaMetrics是一个高性能的，长期存储的prometheus的远程解决方案，实现集群使用的federation的方式，只不过性能很优秀，包括write和query，聚合数据也解决了查询问题。&lt;/p&gt;

&lt;h1 id=&#34;优势&#34;&gt;优势&lt;/h1&gt;

&lt;p&gt;VictoriaMetrics不仅仅是时序数据库,它的优势主要体现在一下几点:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;对外支持Prometheus相关的API，所以它可以直接用于Grafana作为Prometheus数据源使用, 同时扩展了PromQL, 详细使用可参考&lt;a href=&#34;https://github.com/VictoriaMetrics/VictoriaMetrics/wiki/ExtendedPromQL&#34;&gt;https://github.com/VictoriaMetrics/VictoriaMetrics/wiki/ExtendedPromQL&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;针对Prometheus的Metrics插入查询具备高性能和良好的扩展性。甚至性能比InfluxDB和TimescaleDB高出20x&lt;/li&gt;
&lt;li&gt;内存占用方面也做出了优化, 比InfluxDB少10x&lt;/li&gt;
&lt;li&gt;高性能的数据压缩方式,使存入存储的数据量比TimescaleDB多达70x&lt;/li&gt;
&lt;li&gt;优化了高延迟IO和低iops的存储&lt;/li&gt;
&lt;li&gt;操作简单&lt;/li&gt;
&lt;li&gt;支持从第三方时序数据库获取数据源&lt;/li&gt;
&lt;li&gt;异常关闭情况下可以保护存储数据损坏&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;部署&#34;&gt;部署&lt;/h1&gt;

&lt;h2 id=&#34;单点&#34;&gt;单点&lt;/h2&gt;

&lt;h3 id=&#34;编译&#34;&gt;编译&lt;/h3&gt;

&lt;p&gt;1、二进制&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;make victoria-metrics
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2、docker&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;make victoria-metrics-prod
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;启动&#34;&gt;启动&lt;/h3&gt;

&lt;p&gt;直接使用二进制文件进行启动&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nohup /opt/victoria-metrics/victoria-metrics-prod -storageDataPath=&amp;quot;/data/victoria&amp;quot; -retentionPeriod=2  &amp;gt;&amp;gt;/opt/promes/victoria-metrics/logs/start.log 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;-storageDataPath - path to data directory. VictoriaMetrics stores all the data in this directory.&lt;/li&gt;
&lt;li&gt;-retentionPeriod - retention period in months for the data. Older data is automatically deleted.&lt;/li&gt;
&lt;li&gt;-httpListenAddr - TCP address to listen to for http requests. By default it listens port 8428 on all the network interfaces.&lt;/li&gt;
&lt;li&gt;-graphiteListenAddr - TCP and UDP address to listen to for Graphite data. By default it is disabled.&lt;/li&gt;
&lt;li&gt;-opentsdbListenAddr - TCP and UDP address to listen to for OpenTSDB data. By default it is disabled.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可见他也是一个时序数据库，支持将prometheus，influxdb，graphite，opentsdb的数据的写入，比如使用的是prometheus，只使用了http的端口，在我们对应的prometheus文件中配置远程写入，将数据写入到victoria-metrics中去，配置如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;remote_write:
  - url: http://&amp;lt;victoriametrics-addr&amp;gt;:8428/api/v1/write
    queue_config:
      max_samples_per_send: 10000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;数据存储到victoria-metrics，我们还是通过8428端口来读取，我们在grafana中配置datasource：&lt;a href=&#34;http://victoriametrics-addr-ip:8428&#34;&gt;http://victoriametrics-addr-ip:8428&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;停止&#34;&gt;停止&lt;/h3&gt;

&lt;p&gt;发送SIGINT给进程&lt;/p&gt;

&lt;h3 id=&#34;高可用&#34;&gt;高可用&lt;/h3&gt;

&lt;p&gt;启动多个实例，将prometheus的数据分别写入到这些节点中，加一层负载均衡，就可以实现高可用，解决单点问题，prometheus配置如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;remote_write:
  - url: http://&amp;lt;victoriametrics-addr-1&amp;gt;:8428/api/v1/write
    queue_config:
      max_samples_per_send: 10000
  # ...
  - url: http://&amp;lt;victoriametrics-addr-N&amp;gt;:8428/api/v1/write
    queue_config:
      max_samples_per_send: 10000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边讲一下高可用和水平扩展&lt;/p&gt;

&lt;p&gt;高可用是指多活，解决单点故障，正常就是多个相同的服务同时提供服务，来确保一个节点挂了，就能转移到其他的节点上，不影响外部整体的使用，比如redis的主备切换，sentinel机制，还有上面的virtoria-metrics的方式&lt;/p&gt;

&lt;p&gt;水平扩展是一种分布式的能力，一个节点不能处理，就多个节点一起处理，这样分担一下，整体的量就上去了，比如redis的cluster集群，理论上只要加节点，就可以存储月来越多的数据，实际集群内部交互还是有瓶颈的&lt;/p&gt;

&lt;p&gt;正常的服务，可以说在集群同时解决高可用和水平扩展是很困难的，正常的一个集群的作用&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;集群内主节点都获取全部数据，然后其他节点都重主节点复制数据，对外一直提供主节点查询，当主节点出现问题的时候，主备切换，这样实现了高可用，但是有单节点数量瓶颈，不能水平扩展。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;集群内每个节点获取一部分数据，然后集群内节点相互复制，实现最终一致性，每个节点都保存完整的数据，这个时候一个节点挂了，会出问题，单个节点也会有瓶颈，所以在这个基础上收取前加一层负载均衡，这样当一个节点挂了之后，负载均衡会分配到其他节点上，这样实现了高可用，也实现了水平扩展，但是这个很难实现，而且还是有单节点瓶颈，一般是适用这种数据量很小的需要一致性的服务发现。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;集群内每个节点获取一部分数据，并且只存储这一部分数据，然后集群内使用一些数据库或者自身实现关系映射，然后对外查询会路由到对应的节点上去查询数据。这种模式就是支持水平扩展的，但是有一个节点
出问题，查询就会出问题，没有实现高可用，所以在这个基础上实现高可用&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每个单节点的设置主从复制，相互切换&lt;/li&gt;
&lt;li&gt;完成集群间的复制&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最后可以说是目前比较好的解决方式。&lt;/p&gt;

&lt;h3 id=&#34;其他操作&#34;&gt;其他操作&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;可以删除数据&lt;/li&gt;
&lt;li&gt;可以导出数据&lt;/li&gt;
&lt;li&gt;目前不支持Downsampling，但是victoria-metrics的压缩率和查询效率足以使用&lt;/li&gt;
&lt;li&gt;单节点不支持水平扩展，但是单节点足以媲美thanos和M3，timescaleDB的性能，如果还是觉得不够用，可以尝试集群版本&lt;/li&gt;
&lt;li&gt;virtoria-metrics的参数基本不用调整，都是优化后的合理设计，自身也支持prometheus监控&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;测试&#34;&gt;测试&lt;/h3&gt;

&lt;p&gt;启动脚本&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@test victoria-metrics]# cat start.sh
nohup /opt/victoria-metrics/victoria-metrics-prod -storageDataPath=&amp;quot;/data/victoria&amp;quot; -retentionPeriod=2  &amp;gt;&amp;gt;/opt/victoria-metrics/logs/start.log 2&amp;gt;&amp;amp;1 &amp;amp;


-storageDataPath=&amp;quot;/data/victoria&amp;quot;：数据存储目录

-retentionPeriod=2：数据存储时间，两个月
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;11天的数据量&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@test victoria-metrics]# du -sh /data/victoria
20G /data/victoria
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;cpu和内存消耗&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
21899 root      20   0 42.9g  26g 6280 S 188.5 20.8  13486:10 victoria-metric
 4560 root      20   0  159g  26g 365m S 1110.1 20.8   9846:56 prometheus
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;集群&#34;&gt;集群&lt;/h2&gt;

&lt;p&gt;集群模式是采用的分布式部署，将数据分别存储在不同的节点上，实现了水平扩展，目前还没有relaese版本，需要自己编译，但是解决了数据量的问题，同时在性能方面并没有发生太大的影响。&lt;/p&gt;

&lt;h3 id=&#34;编译-1&#34;&gt;编译&lt;/h3&gt;

&lt;p&gt;直接make就会在bin目录下生成可执行文件vmstorage, vmselect and vminsert。&lt;/p&gt;

&lt;h3 id=&#34;架构原理图&#34;&gt;架构原理图&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/monitor/prometheus/cluster/vm/vm.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;组件&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;vmstorage - stores the data&lt;/p&gt;

&lt;p&gt;vmstore其实就是我们数据存在的地方，需要先启动，否则insert会找不到插入的节点，导致数据丢失。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;vminsert - proxies the ingested data to vmstorage shards using consistent hashing&lt;/p&gt;

&lt;p&gt;vminsert对采集的提供的代理接口，同时选择将数据插入到我们指定的store节点，可以是单节点，也可以是集群上所有的机器都部署，通过nginx来负载均衡，可以减少节点压力，但是并不能解决单点问题。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;vmselect - performs incoming queries using the data from vmstorage&lt;/p&gt;

&lt;p&gt;vmselect是给外部进行查询的接口，同时也负责查询数据的聚合功能。负载均衡和vmisert一样，使用nginx。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;http-api&#34;&gt;HTTP api&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;insert&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;http://&amp;lt;vminsert-ip&amp;gt;:8480/insert/&amp;lt;accountID&amp;gt;/&amp;lt;suffix&amp;gt;:

&amp;lt;accountID&amp;gt; is an arbitrary number identifying namespace for data ingestion (aka tenant)
&amp;lt;suffix&amp;gt; may have the following values:

    1.prometheus - for inserting data with Prometheus remote write API
    2.influx/write or influx/api/v2/write - for inserting data with Influx line protocol
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;querying&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;http://&amp;lt;vmselect-ip&amp;gt;:8481/select/&amp;lt;accountID&amp;gt;/prometheus/&amp;lt;suffix&amp;gt;:

&amp;lt;accountID&amp;gt; is an arbitrary number identifying data namespace for the query (aka tenant)
&amp;lt;suffix&amp;gt; may have the following values:

    1.api/v1/query - performs PromQL instant query
    2.api/v1/query_range - performs PromQL range query
    3.api/v1/series - performs series query
    4.api/v1/labels - returns a list of label names
    5.api/v1/label/&amp;lt;label_name&amp;gt;/values - returns values for the given &amp;lt;label_name&amp;gt; according to API
    6.federate - returns federated metrics
    7.api/v1/export - exports raw data. See this article for details
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;delete&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;http://&amp;lt;vmselect-ip&amp;gt;:8481/delete/&amp;lt;accountID&amp;gt;/prometheus/api/v1/admin/tsdb/delete_series?match[]=&amp;lt;timeseries_selector_for_delete&amp;gt;.
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;vmstorage&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;vmstore保留了8482端口，提供一下URL：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/snapshot/create - create instant snapshot, which can be used for backups in background. Snapshots are created in &amp;lt;storageDataPath&amp;gt;/snapshots folder, where &amp;lt;storageDataPath&amp;gt; is the corresponding command-line flag value.
/snapshot/list - list available snasphots.
/snapshot/delete?snapshot=&amp;lt;id&amp;gt; - delete the given snapshot.
/snapshot/delete_all - delete all the snapshots.
Snapshots may be created independently on each vmstorage node. There is no need in synchronizing snapshots&#39; creation across vmstorage nodes.
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;扩展&#34;&gt;扩展&lt;/h3&gt;

&lt;p&gt;1、vminsert and vmselect是可扩展的，无状态的，可以随时扩展或者缩容，并不影响，只是需要在负载均衡中将相关节点处理一下&lt;/p&gt;

&lt;p&gt;2、vmstore是有状态的，因为是分布式存储数据的，所以新增节点需要如下步骤&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start new vmstorage node with the same -retentionPeriod as existing nodes in the cluster.&lt;/li&gt;
&lt;li&gt;Gradually restart all the vmselect nodes with new -storageNode arg containing &lt;new_vmstorage_host&gt;:8401.&lt;/li&gt;
&lt;li&gt;Gradually restart all the vminsert nodes with new -storageNode arg containing &lt;new_vmstorage_host&gt;:8400.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;备份和恢复&#34;&gt;备份和恢复&lt;/h3&gt;

&lt;p&gt;1、主要使用vmstore的url来进行备份&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Create an instant snapshot by navigating to /snapshot/create HTTP handler. It will create snapshot and return its name.
Archive the created snapshot from &amp;lt;-storageDataPath&amp;gt;/snapshots/&amp;lt;snapshot_name&amp;gt; folder using any suitable tool that follows symlinks. For instance, cp -L, rsync -L or scp -r. The archival process doesn&#39;t interfere with vmstorage work, so it may be performed at any suitable time. Incremental backups are possible with rsync --delete, which should remove extraneous files from backup dir.
Delete unused snapshots via /snapshot/delete?snapshot=&amp;lt;snapshot_name&amp;gt; or /snapshot/delete_all in order to free up occupied storage space.
There is no need in synchronizing backups among all the vmstorage nodes.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2、恢复&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Stop vmstorage node with kill -INT.&lt;/li&gt;
&lt;li&gt;Delete all the contents of the directory pointed by -storageDataPath command-line flag.&lt;/li&gt;
&lt;li&gt;Copy all the contents of the backup directory to -storageDataPath directory.&lt;/li&gt;
&lt;li&gt;Start vmstorage node.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;实现原理&#34;&gt;实现原理&lt;/h1&gt;

&lt;h2 id=&#34;vminsert&#34;&gt;vminsert&lt;/h2&gt;

&lt;p&gt;插入数据就比较简单了，使用了prometheus差不多的数据结构体来存储数据，只要将数据转化为对应的结构体直接存入数据就可以。对于其他的时序数据库比如influxdb都是差不多的数据结构，只要稍微进行转换，就可以将数据存储到存储节点去。&lt;/p&gt;

&lt;h2 id=&#34;vmstore&#34;&gt;vmstore&lt;/h2&gt;

&lt;p&gt;存储数据可以比常规的节省10倍的内存&lt;/p&gt;

&lt;h2 id=&#34;vmselect&#34;&gt;vmselect&lt;/h2&gt;

&lt;p&gt;查询数据很快&lt;/p&gt;

&lt;h2 id=&#34;mergetree&#34;&gt;MergeTree&lt;/h2&gt;

&lt;p&gt;VictoriaMetrics将数据存储在相似于ClickHouse的 MergeTree表 数据结构中。它是用于剖析数据和其余事件流的最快的数据库。在典型的剖析查问上，它的性能要比PostgreSQL和MySQL等传统数据库高10到1000倍。&lt;/p&gt;

&lt;h1 id=&#34;特性&#34;&gt;特性&lt;/h1&gt;

&lt;h2 id=&#34;扩展了promeql&#34;&gt;扩展了promeql&lt;/h2&gt;

&lt;p&gt;1 、模版&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;((node_memory_MemTotal_bytes{instance=~&amp;quot;$node:$port&amp;quot;, job=~&amp;quot;$job&amp;quot;} - node_memory_MemFree_bytes{instance=~&amp;quot;$node:$port&amp;quot;, job=~&amp;quot;$job&amp;quot;}) /
node_memory_MemTotal_bytes{instance=~&amp;quot;$node:$port&amp;quot;, job=~&amp;quot;$job&amp;quot;}) * 100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用模版&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;WITH (
    commonFilters = {instance=~&amp;quot;$node:$port&amp;quot;,job=~&amp;quot;$job&amp;quot;}
)
(node_memory_MemTotal_bytes{commonFilters} - node_memory_MemFree_bytes{commonFilters}) /
    node_memory_MemTotal_bytes{commonFilters} * 100
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;发展&#34;&gt;发展&lt;/h1&gt;

&lt;h2 id=&#34;vmagent&#34;&gt;vmagent&lt;/h2&gt;

&lt;p&gt;vmagent是一个很小巧但优秀的代理，它可以帮助您从各种来源收集指标并将其存储到VictoriaMetrics或任何其他支持remote_write协议的与Prometheus兼容的存储系统。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/monitor/prometheus/cluster/vm/vm2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;可以用作Prometheus的直接替代品，用于抓取目标（例如node_exporter）。&lt;/li&gt;
&lt;li&gt;可以像Prometheus那样，重新添加，删除和修改标签。可以在将数据发送到远程存储之前对其进行过滤。&lt;/li&gt;
&lt;li&gt;支持多种VictoriaMetrics支持的数据格式，比如Influx，OpenTSDB，Graphite，Prometheus等。&lt;/li&gt;
&lt;li&gt;可以将收集的指标同时复制到多个远程存储系统。在与远程存储连接不稳定的环境中工作。如果远程存储不可用，则将收集的指标缓存在-remoteWrite.tmpDataPath中。一旦恢复远程存储的连接，缓冲的metrcis即发送到远程存储。可以通过-remoteWrite.maxDiskUsagePerURL限制缓冲区的最大磁盘使用量。&lt;/li&gt;
&lt;li&gt;与Prometheus相比，使用较少的RAM，CPU，磁盘IO和网络带宽。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;目前来讲，Prometheus依旧不可或缺。vmagent 还处于开发阶段。但是vmagent有取代prometheus的想法是可以看出来的。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>监控metrics系列---- Cortex</title>
          <link>https://kingjcy.github.io/post/monitor/metrics/prometheus/cluster/remotestore/cortex/</link>
          <pubDate>Thu, 13 Jun 2019 14:28:39 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/monitor/metrics/prometheus/cluster/remotestore/cortex/</guid>
          <description>&lt;p&gt;crotex是一个为了支持prometheus扩展的服务，支持水平扩展，高可用，多租户，长期存储。主要开发者也是promehteus的开发者&lt;/p&gt;

&lt;h1 id=&#34;架构&#34;&gt;架构&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/monitor/prometheus/cluster/cortex/architecture.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;组件&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Distributor&lt;/p&gt;

&lt;p&gt;Distributor就是负责接收promtheus发送过来的数据，然后将数据分发给lngester。&lt;/p&gt;

&lt;p&gt;Distributor只要和lngester进行交互，使用的是grpc&lt;/p&gt;

&lt;p&gt;Distributor使用一致性hash来将数据分发给哪个lngester实例，consistent hash ring is stored in Consul&lt;/p&gt;

&lt;p&gt;建议使用负载均衡来运行多个distributors实例。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;lngester&lt;/p&gt;

&lt;p&gt;lngester组件主要是接受Distributor发来的数据，然后发送到后段的数据库存储&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ruler&lt;/p&gt;

&lt;p&gt;ruler组件主要是负责处理alertmanager产生的告警&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Query frontend&lt;/p&gt;

&lt;p&gt;Query frontend组件主要是接受http请求，把他们按着tenant ID排列，并且重试一些返回错误的请求，比如large query&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Querier&lt;/p&gt;

&lt;p&gt;Querier组件主要是处理promql&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Chunk store&lt;/p&gt;

&lt;p&gt;Chunk store组件就是长期存储&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;原理&#34;&gt;原理&lt;/h1&gt;

&lt;p&gt;就是我们常用的集群架构：聚合，将所有数据都发送到一个节点，用于存储+查询&lt;/p&gt;

&lt;h1 id=&#34;安装使用&#34;&gt;安装使用&lt;/h1&gt;

&lt;p&gt;编译启动&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go build ./cmd/cortex
$ ./cortex -config.file=./docs/single-process-config.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置prometheus的远程写，将prometheus数据写入到cortex中去&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;remote_write:
- url: http://localhost:9009/api/prom/push
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动脚本&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nohup /opt/promes/cortex/cortex -config.file=/opt/promes/cortex/config/single-process-config.yaml -distributor.ingestion-rate-limit=100000 -ring.store=consul -consul.hostname=10.47.182.224:9996 -distributor.replication-factor=2 &amp;gt;&amp;gt;/opt/promes/cortex/logs/start.log 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;-distributor.ingestion-rate-limit=100000：限制数据量为100000，其实达不到这个量，prometheus默认remote_write的10000个并发，每个包含100个数据，这个时候会大量出错，所以在写入性能上达不到这个量，测试最大每个包含25个数据可以处理，同样的机器上victoria-metrics可以达到10000个数据而不出错。&lt;/li&gt;
&lt;li&gt;-ring.store=consul -consul.hostname=10.47.182.224:9996：一个令牌存储在consul上，用我们现有的consul&lt;/li&gt;
&lt;li&gt;-distributor.replication-factor=2：集群节点的数量，这边主要是高可用，两个节点互相复制，完成一致性哈希&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;目前没有看到cortex的可扩展的优秀的方面，可能是社区开发还没有完成，等release。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>监控metrics系列---- M3db</title>
          <link>https://kingjcy.github.io/post/monitor/metrics/prometheus/cluster/remotestore/m3db/</link>
          <pubDate>Wed, 13 Mar 2019 17:13:10 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/monitor/metrics/prometheus/cluster/remotestore/m3db/</guid>
          <description>&lt;p&gt;Uber开发了指标平台M3和分布式时间序列数据库M3DB。来解决Uber在发展过程当中遇到的问题：使用开源软件后，因为可靠性，成本等问题，在操做密集型方面没法大规模使用这些开源软件。因此Uber逐步构建了本身的指标平台。咱们利用经验来帮助咱们构建本地分布式时间序列数据库，高度动态和高性能的聚合服务，查询引擎以及其余支持基础架构。&lt;/p&gt;

&lt;h1 id=&#34;架构&#34;&gt;架构&lt;/h1&gt;

&lt;p&gt;M3包括了以下的组件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;M3DB &amp;ndash; M3db是一个使用TSDB（时间数据库），保存全部Prometheus指标，M3db是分布式，高可用性和复制的数据库，它使用Etcd做为共识算法。&lt;/li&gt;
&lt;li&gt;M3Coordinator &amp;ndash; 是Prometheus实例与M3db之间的适配器，它公开了Prometheus用来从数据库中推送和提取数据的读/写端点。&lt;/li&gt;
&lt;li&gt;M3Query &amp;ndash; 众所周知，Prometheus努力处理显示大量数据的查询，而不是从Prometheus提取数据，M3Query实现了相同的PromQL并能够响应此类请求。&lt;/li&gt;
&lt;li&gt;M3Aggregator &amp;ndash; 可选但很重要，此服务将下降指标的采样率，为长期存储作好准备。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总体架构图以下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/monitor/prometheus/cluster/m3/m3&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;关于M3，咱们目前积累了一些生产实践。目前的问题是，社区不够活跃，文档也不够丰富。不少时候遇到问题，只能去研究代码。M3query对PromSql支持的不够，因此M3query并不能生产环境使用。&lt;/p&gt;

&lt;h1 id=&#34;调研&#34;&gt;调研&lt;/h1&gt;

&lt;p&gt;首先，我们想把大量的数据存储到m3中，给prometheus进行查询告警。但是数据量很大，m3db数据插入性能是有必要进行保证的。&lt;/p&gt;

&lt;p&gt;之前写过一个adapter，将数据转化为json调用json api将数据已经插入了m3db中，当时对数据性能没有要求，这次使用json api进行压测的时候，发现性能很差，而且在数据并发达到100个goroutine，一个goroutine发送100条数据，m3db就崩溃了，不接受连接。然后简单的测试了一下得到以下的数据&lt;/p&gt;

&lt;p&gt;这个远远达不到要求啊，于是看看有没有批量操作的接口，官方文档说明，有两种方式插入数据&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Test RPC
To test out some of the functionality of M3DB there are some user friendly HTTP JSON APIs that you can use. These use the DB node cluster service endpoints.

Note: performance sensitive users are expected to use the more performant endpoints via either the Go src/dbnode/client/Session API, or the GRPC endpoints exposed via src/coordinator.
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;go api（src/dbnode/client/Session），session看代码使用的是apache的thrift rpc。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;GRPC（src/coordinator）&lt;/p&gt;

&lt;p&gt;官方提供了benchmark（src/query/benchmark），于是去编译进行测试，但是m3开源的太差了，很多第三方库都是使用的老版本，兼容性很差，各种api对不上，也不把自己的vendor包一同开源，踩了许多坑：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;github.com/thrift &amp;mdash;0.10.0&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;github.com/uber-go/tally&amp;mdash;3.3.7&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;client_golang&amp;mdash;0.8.0&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;github.com/coreos/etcd&amp;mdash;&amp;ndash;3.2.0，还是缺少参数，坑&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;google.golang.org/grpc&amp;ndash;laster&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;golang.org/x/text&amp;mdash;&amp;mdash;laster&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;github.com/satori/go.uuid&amp;mdash;-1.2.0&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;github.com/couchbase/vellum&amp;mdash;&amp;ndash;master&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;github.com/pilosa/pilosa-最新班都缺少参数&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;还是没有编译完成，后续持续跟进，看看官方有没有继续开源和改进。&lt;/p&gt;

&lt;p&gt;目前得到以下结论&lt;/p&gt;

&lt;p&gt;m3db目前没有发现批量处理的方式&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Coordinator的方式最后还是一条一条的发送（通过查看代码，未能运行）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;session方式，其中一个包github.com/pilosa/pilosa/roaring目前最新版本都没有m3中使用的参数，最终无法编译使用。网上使用session运行成功的，我未能找到他使用了什么版本的github.com/pilosa/pilosa/roaring包。但是通过他运行的结果来看（结合代码api），也是一条一条发送的。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;m3中很多都是老版本的库，兼容性很差，api很多不兼容，官方也未推出他使用了什么库，如果继续，应该需要大量的时间去校验和编译&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
        </item>
      
    
      
        <item>
          <title>数据库系列---- Elasticsearch</title>
          <link>https://kingjcy.github.io/post/database/elasticsearch/</link>
          <pubDate>Thu, 21 Feb 2019 19:28:32 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/database/elasticsearch/</guid>
          <description>&lt;p&gt;开源的 Elasticsearch （以下简称 Elastic）是目前全文搜索引擎的首选。它可以快速地储存、搜索和分析海量数据。并且支持分布式，解决Lucene（支持全文索引的数据库系统）单机问题，目前维基百科、Stack Overflow、Github 都采用它。&lt;/p&gt;

&lt;h1 id=&#34;基本概念&#34;&gt;基本概念&lt;/h1&gt;

&lt;h2 id=&#34;存储结构&#34;&gt;存储结构&lt;/h2&gt;

&lt;p&gt;在ES中，存储结构主要有四种，与传统的关系型数据库对比如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;index（Indices）相当于一个database&lt;/li&gt;
&lt;li&gt;type相当于一个table&lt;/li&gt;
&lt;li&gt;document相当于一个row&lt;/li&gt;
&lt;li&gt;properties（Fields）相当于一个column&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们可以如下对比&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Relational DB -&amp;gt; Databases -&amp;gt; Tables -&amp;gt; Rows -&amp;gt; Columns
Elasticsearch -&amp;gt; Indices -&amp;gt; Types -&amp;gt; Documents -&amp;gt; Fields
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Node 与 Cluster&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Elastic 本质上是一个分布式数据库，允许多台服务器协同工作，每台服务器可以运行多个 Elastic 实例。&lt;/p&gt;

&lt;p&gt;单个 Elastic 实例称为一个节点（node）。一组节点构成一个集群（cluster）。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Index&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Elastic 会索引所有字段，经过处理后写入一个反向索引（Inverted Index）。查找数据的时候，直接查找该索引。&lt;/p&gt;

&lt;p&gt;所以，Elastic 数据管理的顶层单位就叫做 Index（索引）。它是单个数据库的同义词。每个 Index （即数据库）的名字必须是小写。&lt;/p&gt;

&lt;p&gt;下面的命令可以查看当前节点的所有 Index。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -X GET &#39;http://localhost:9200/_cat/indices?v&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Document&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Index 里面单条的记录称为 Document（文档）。许多条 Document 构成了一个 Index。&lt;/p&gt;

&lt;p&gt;Document 使用 JSON 格式表示，下面是一个例子。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;user&amp;quot;: &amp;quot;张三&amp;quot;,
  &amp;quot;title&amp;quot;: &amp;quot;工程师&amp;quot;,
  &amp;quot;desc&amp;quot;: &amp;quot;数据库管理&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同一个 Index 里面的 Document，不要求有相同的结构（scheme），但是最好保持相同，这样有利于提高搜索效率。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Type&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Document 可以分组，比如weather这个 Index 里面，可以按城市分组（北京和上海），也可以按气候分组（晴天和雨天）。这种分组就叫做 Type，它是虚拟的逻辑分组，用来过滤 Document。&lt;/p&gt;

&lt;p&gt;不同的 Type 应该有相似的结构（schema），举例来说，id字段不能在这个组是字符串，在另一个组是数值。这是与关系型数据库的表的一个区别。性质完全不同的数据（比如products和logs）应该存成两个 Index，而不是一个 Index 里面的两个 Type（虽然可以做到）。&lt;/p&gt;

&lt;p&gt;下面的命令可以列出每个 Index 所包含的 Type。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/_mapping?pretty=true&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;根据规划，Elastic 6.x 版只允许每个 Index 包含一个 Type，7.x 版将会彻底移除 Type。&lt;/p&gt;

&lt;h1 id=&#34;基本操作&#34;&gt;基本操作&lt;/h1&gt;

&lt;h2 id=&#34;新建和删除-index&#34;&gt;新建和删除 Index&lt;/h2&gt;

&lt;p&gt;新建 Index，可以直接向 Elastic 服务器发出 PUT 请求。下面的例子是新建一个名叫weather的 Index。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -X PUT &#39;localhost:9200/weather&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;服务器返回一个 JSON 对象，里面的acknowledged字段表示操作成功。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;acknowledged&amp;quot;:true,
  &amp;quot;shards_acknowledged&amp;quot;:true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后，我们发出 DELETE 请求，删除这个 Index。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -X DELETE &#39;localhost:9200/weather&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;中文分词设置&#34;&gt;中文分词设置&lt;/h2&gt;

&lt;p&gt;首先，安装中文分词插件。这里使用的是 ik，也可以考虑其他插件（比如 smartcn）。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v5.5.1/elasticsearch-analysis-ik-5.5.1.zip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面代码安装的是5.5.1版的插件，与 Elastic 5.5.1 配合使用。&lt;/p&gt;

&lt;p&gt;接着，重新启动 Elastic，就会自动加载这个新安装的插件。&lt;/p&gt;

&lt;p&gt;然后，新建一个 Index，指定需要分词的字段。这一步根据数据结构而异，下面的命令只针对本文。基本上，凡是需要搜索的中文字段，都要单独设置一下。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -X PUT &#39;localhost:9200/accounts&#39; -d &#39;
{
  &amp;quot;mappings&amp;quot;: {
    &amp;quot;person&amp;quot;: {
      &amp;quot;properties&amp;quot;: {
        &amp;quot;user&amp;quot;: {
          &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
          &amp;quot;analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;,
          &amp;quot;search_analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;
        },
        &amp;quot;title&amp;quot;: {
          &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
          &amp;quot;analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;,
          &amp;quot;search_analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;
        },
        &amp;quot;desc&amp;quot;: {
          &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
          &amp;quot;analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;,
          &amp;quot;search_analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;
        }
      }
    }
  }
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面代码中，首先新建一个名称为accounts的 Index，里面有一个名称为person的 Type。person有三个字段。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;user
title
desc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这三个字段都是中文，而且类型都是文本（text），所以需要指定中文分词器，不能使用默认的英文分词器。&lt;/p&gt;

&lt;p&gt;Elastic 的分词器称为 analyzer。我们对每个字段指定分词器。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;user&amp;quot;: {
  &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
  &amp;quot;analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;,
  &amp;quot;search_analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面代码中，analyzer是字段文本的分词器，search_analyzer是搜索词的分词器。ik_max_word分词器是插件ik提供的，可以对文本进行最大数量的分词。&lt;/p&gt;

&lt;h2 id=&#34;新增记录&#34;&gt;新增记录&lt;/h2&gt;

&lt;p&gt;向指定的 /Index/Type 发送 PUT 请求，就可以在 Index 里面新增一条记录。比如，向/accounts/person发送请求，就可以新增一条人员记录。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -X PUT &#39;localhost:9200/accounts/person/1&#39; -d &#39;
{
  &amp;quot;user&amp;quot;: &amp;quot;张三&amp;quot;,
  &amp;quot;title&amp;quot;: &amp;quot;工程师&amp;quot;,
  &amp;quot;desc&amp;quot;: &amp;quot;数据库管理&amp;quot;
}&#39; 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;服务器返回的 JSON 对象，会给出 Index、Type、Id、Version 等信息。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;_index&amp;quot;:&amp;quot;accounts&amp;quot;,
  &amp;quot;_type&amp;quot;:&amp;quot;person&amp;quot;,
  &amp;quot;_id&amp;quot;:&amp;quot;1&amp;quot;,
  &amp;quot;_version&amp;quot;:1,
  &amp;quot;result&amp;quot;:&amp;quot;created&amp;quot;,
  &amp;quot;_shards&amp;quot;:{&amp;quot;total&amp;quot;:2,&amp;quot;successful&amp;quot;:1,&amp;quot;failed&amp;quot;:0},
  &amp;quot;created&amp;quot;:true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你仔细看，会发现请求路径是/accounts/person/1，最后的1是该条记录的 Id。它不一定是数字，任意字符串（比如abc）都可以。&lt;/p&gt;

&lt;p&gt;新增记录的时候，也可以不指定 Id，这时要改成 POST 请求。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -X POST &#39;localhost:9200/accounts/person&#39; -d &#39;
{
  &amp;quot;user&amp;quot;: &amp;quot;李四&amp;quot;,
  &amp;quot;title&amp;quot;: &amp;quot;工程师&amp;quot;,
  &amp;quot;desc&amp;quot;: &amp;quot;系统管理&amp;quot;
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面代码中，向/accounts/person发出一个 POST 请求，添加一个记录。这时，服务器返回的 JSON 对象里面，_id字段就是一个随机字符串。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;_index&amp;quot;:&amp;quot;accounts&amp;quot;,
  &amp;quot;_type&amp;quot;:&amp;quot;person&amp;quot;,
  &amp;quot;_id&amp;quot;:&amp;quot;AV3qGfrC6jMbsbXb6k1p&amp;quot;,
  &amp;quot;_version&amp;quot;:1,
  &amp;quot;result&amp;quot;:&amp;quot;created&amp;quot;,
  &amp;quot;_shards&amp;quot;:{&amp;quot;total&amp;quot;:2,&amp;quot;successful&amp;quot;:1,&amp;quot;failed&amp;quot;:0},
  &amp;quot;created&amp;quot;:true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意，如果没有先创建 Index（这个例子是accounts），直接执行上面的命令，Elastic 也不会报错，而是直接生成指定的 Index。所以，打字的时候要小心，不要写错 Index 的名称。&lt;/p&gt;

&lt;h2 id=&#34;查看记录&#34;&gt;查看记录&lt;/h2&gt;

&lt;p&gt;向/Index/Type/Id发出 GET 请求，就可以查看这条记录。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/accounts/person/1?pretty=true&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面代码请求查看/accounts/person/1这条记录，URL 的参数pretty=true表示以易读的格式返回。&lt;/p&gt;

&lt;p&gt;返回的数据中，found字段表示查询成功，_source字段返回原始记录。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;_index&amp;quot; : &amp;quot;accounts&amp;quot;,
  &amp;quot;_type&amp;quot; : &amp;quot;person&amp;quot;,
  &amp;quot;_id&amp;quot; : &amp;quot;1&amp;quot;,
  &amp;quot;_version&amp;quot; : 1,
  &amp;quot;found&amp;quot; : true,
  &amp;quot;_source&amp;quot; : {
    &amp;quot;user&amp;quot; : &amp;quot;张三&amp;quot;,
    &amp;quot;title&amp;quot; : &amp;quot;工程师&amp;quot;,
    &amp;quot;desc&amp;quot; : &amp;quot;数据库管理&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果 Id 不正确，就查不到数据，found字段就是false。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/weather/beijing/abc?pretty=true&#39;

{
  &amp;quot;_index&amp;quot; : &amp;quot;accounts&amp;quot;,
  &amp;quot;_type&amp;quot; : &amp;quot;person&amp;quot;,
  &amp;quot;_id&amp;quot; : &amp;quot;abc&amp;quot;,
  &amp;quot;found&amp;quot; : false
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;删除记录&#34;&gt;删除记录&lt;/h2&gt;

&lt;p&gt;删除记录就是发出 DELETE 请求。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -X DELETE &#39;localhost:9200/accounts/person/1&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里先不要删除这条记录，后面还要用到。&lt;/p&gt;

&lt;h2 id=&#34;更新记录&#34;&gt;更新记录&lt;/h2&gt;

&lt;p&gt;更新记录就是使用 PUT 请求，重新发送一次数据。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -X PUT &#39;localhost:9200/accounts/person/1&#39; -d &#39;
{
    &amp;quot;user&amp;quot; : &amp;quot;张三&amp;quot;,
    &amp;quot;title&amp;quot; : &amp;quot;工程师&amp;quot;,
    &amp;quot;desc&amp;quot; : &amp;quot;数据库管理，软件开发&amp;quot;
}&#39; 

{
  &amp;quot;_index&amp;quot;:&amp;quot;accounts&amp;quot;,
  &amp;quot;_type&amp;quot;:&amp;quot;person&amp;quot;,
  &amp;quot;_id&amp;quot;:&amp;quot;1&amp;quot;,
  &amp;quot;_version&amp;quot;:2,
  &amp;quot;result&amp;quot;:&amp;quot;updated&amp;quot;,
  &amp;quot;_shards&amp;quot;:{&amp;quot;total&amp;quot;:2,&amp;quot;successful&amp;quot;:1,&amp;quot;failed&amp;quot;:0},
  &amp;quot;created&amp;quot;:false
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面代码中，我们将原始数据从&amp;rdquo;数据库管理&amp;rdquo;改成&amp;rdquo;数据库管理，软件开发&amp;rdquo;。 返回结果里面，有几个字段发生了变化。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;_version&amp;quot; : 2,
&amp;quot;result&amp;quot; : &amp;quot;updated&amp;quot;,
&amp;quot;created&amp;quot; : false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，记录的 Id 没变，但是版本（version）从1变成2，操作类型（result）从created变成updated，created字段变成false，因为这次不是新建记录。&lt;/p&gt;

&lt;h2 id=&#34;数据查询&#34;&gt;数据查询&lt;/h2&gt;

&lt;p&gt;返回所有记录&lt;/p&gt;

&lt;p&gt;使用 GET 方法，直接请求/Index/Type/_search，就会返回所有记录。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/accounts/person/_search&#39;

{
  &amp;quot;took&amp;quot;:2,
  &amp;quot;timed_out&amp;quot;:false,
  &amp;quot;_shards&amp;quot;:{&amp;quot;total&amp;quot;:5,&amp;quot;successful&amp;quot;:5,&amp;quot;failed&amp;quot;:0},
  &amp;quot;hits&amp;quot;:{
    &amp;quot;total&amp;quot;:2,
    &amp;quot;max_score&amp;quot;:1.0,
    &amp;quot;hits&amp;quot;:[
      {
        &amp;quot;_index&amp;quot;:&amp;quot;accounts&amp;quot;,
        &amp;quot;_type&amp;quot;:&amp;quot;person&amp;quot;,
        &amp;quot;_id&amp;quot;:&amp;quot;AV3qGfrC6jMbsbXb6k1p&amp;quot;,
        &amp;quot;_score&amp;quot;:1.0,
        &amp;quot;_source&amp;quot;: {
          &amp;quot;user&amp;quot;: &amp;quot;李四&amp;quot;,
          &amp;quot;title&amp;quot;: &amp;quot;工程师&amp;quot;,
          &amp;quot;desc&amp;quot;: &amp;quot;系统管理&amp;quot;
        }
      },
      {
        &amp;quot;_index&amp;quot;:&amp;quot;accounts&amp;quot;,
        &amp;quot;_type&amp;quot;:&amp;quot;person&amp;quot;,
        &amp;quot;_id&amp;quot;:&amp;quot;1&amp;quot;,
        &amp;quot;_score&amp;quot;:1.0,
        &amp;quot;_source&amp;quot;: {
          &amp;quot;user&amp;quot; : &amp;quot;张三&amp;quot;,
          &amp;quot;title&amp;quot; : &amp;quot;工程师&amp;quot;,
          &amp;quot;desc&amp;quot; : &amp;quot;数据库管理，软件开发&amp;quot;
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面代码中，返回结果的 took字段表示该操作的耗时（单位为毫秒），timed_out字段表示是否超时，hits字段表示命中的记录，里面子字段的含义如下。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;total：返回记录数，本例是2条。
max_score：最高的匹配程度，本例是1.0。
hits：返回的记录组成的数组。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;返回的记录中，每条记录都有一个_score字段，表示匹配的程序，默认是按照这个字段降序排列。&lt;/p&gt;

&lt;h2 id=&#34;全文搜索&#34;&gt;全文搜索&lt;/h2&gt;

&lt;p&gt;Elastic 的查询非常特别，使用自己的查询语法，要求 GET 请求带有数据体。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/accounts/person/_search&#39;  -d &#39;
{
  &amp;quot;query&amp;quot; : { &amp;quot;match&amp;quot; : { &amp;quot;desc&amp;quot; : &amp;quot;软件&amp;quot; }}
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面代码使用 Match 查询，指定的匹配条件是desc字段里面包含&amp;rdquo;软件&amp;rdquo;这个词。返回结果如下。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;took&amp;quot;:3,
  &amp;quot;timed_out&amp;quot;:false,
  &amp;quot;_shards&amp;quot;:{&amp;quot;total&amp;quot;:5,&amp;quot;successful&amp;quot;:5,&amp;quot;failed&amp;quot;:0},
  &amp;quot;hits&amp;quot;:{
    &amp;quot;total&amp;quot;:1,
    &amp;quot;max_score&amp;quot;:0.28582606,
    &amp;quot;hits&amp;quot;:[
      {
        &amp;quot;_index&amp;quot;:&amp;quot;accounts&amp;quot;,
        &amp;quot;_type&amp;quot;:&amp;quot;person&amp;quot;,
        &amp;quot;_id&amp;quot;:&amp;quot;1&amp;quot;,
        &amp;quot;_score&amp;quot;:0.28582606,
        &amp;quot;_source&amp;quot;: {
          &amp;quot;user&amp;quot; : &amp;quot;张三&amp;quot;,
          &amp;quot;title&amp;quot; : &amp;quot;工程师&amp;quot;,
          &amp;quot;desc&amp;quot; : &amp;quot;数据库管理，软件开发&amp;quot;
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Elastic 默认一次返回10条结果，可以通过size字段改变这个设置。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/accounts/person/_search&#39;  -d &#39;
{
  &amp;quot;query&amp;quot; : { &amp;quot;match&amp;quot; : { &amp;quot;desc&amp;quot; : &amp;quot;管理&amp;quot; }},
  &amp;quot;size&amp;quot;: 1
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面代码指定，每次只返回一条结果。&lt;/p&gt;

&lt;p&gt;还可以通过from字段，指定位移。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/accounts/person/_search&#39;  -d &#39;
{
  &amp;quot;query&amp;quot; : { &amp;quot;match&amp;quot; : { &amp;quot;desc&amp;quot; : &amp;quot;管理&amp;quot; }},
  &amp;quot;from&amp;quot;: 1,
  &amp;quot;size&amp;quot;: 1
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面代码指定，从位置1开始（默认是从位置0开始），只返回一条结果。&lt;/p&gt;

&lt;h2 id=&#34;逻辑运算&#34;&gt;逻辑运算&lt;/h2&gt;

&lt;p&gt;如果有多个搜索关键字， Elastic 认为它们是or关系。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/accounts/person/_search&#39;  -d &#39;
{
  &amp;quot;query&amp;quot; : { &amp;quot;match&amp;quot; : { &amp;quot;desc&amp;quot; : &amp;quot;软件 系统&amp;quot; }}
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面代码搜索的是软件 or 系统。&lt;/p&gt;

&lt;p&gt;如果要执行多个关键词的and搜索，必须使用布尔查询。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &#39;localhost:9200/accounts/person/_search&#39;  -d &#39;
{
  &amp;quot;query&amp;quot;: {
    &amp;quot;bool&amp;quot;: {
      &amp;quot;must&amp;quot;: [
        { &amp;quot;match&amp;quot;: { &amp;quot;desc&amp;quot;: &amp;quot;软件&amp;quot; } },
        { &amp;quot;match&amp;quot;: { &amp;quot;desc&amp;quot;: &amp;quot;系统&amp;quot; } }
      ]
    }
  }
}&#39;
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>Golang使用系列---- Bufio</title>
          <link>https://kingjcy.github.io/post/golang/go-bufio/</link>
          <pubDate>Tue, 25 Dec 2018 14:27:45 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/golang/go-bufio/</guid>
          <description>&lt;p&gt;bufio 包实现了缓存IO。它包装了 io.Reader 和 io.Writer 对象，创建了另外的Reader和Writer对象，它们也实现了 io.Reader 和 io.Writer 接口，不过它们是有缓存的。该包同时为文本I/O提供了一些便利操作。&lt;/p&gt;

&lt;h1 id=&#34;类型和方法&#34;&gt;类型和方法&lt;/h1&gt;

&lt;h2 id=&#34;reader-类型和方法&#34;&gt;Reader 类型和方法&lt;/h2&gt;

&lt;h3 id=&#34;类型&#34;&gt;类型&lt;/h3&gt;

&lt;p&gt;bufio.Reader 结构包装了一个 io.Reader 对象，提供缓存功能，同时实现了 io.Reader 接口。&lt;/p&gt;

&lt;p&gt;Reader 结构没有任何导出的字段，结构定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Reader struct {
    buf          []byte        // 缓存
    rd           io.Reader    // 底层的io.Reader
    // r:从buf中读走的字节（偏移）；w:buf中填充内容的偏移；
    // w - r 是buf中可被读的长度（缓存数据的大小），也是Buffered()方法的返回值
    r, w         int
    err          error        // 读过程中遇到的错误
    lastByte     int        // 最后一次读到的字节（ReadByte/UnreadByte)
    lastRuneSize int        // 最后一次读到的Rune的大小 (ReadRune/UnreadRune)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;实例化&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;bufio 包提供了两个实例化 bufio.Reader 对象的函数：NewReader 和 NewReaderSize。其中，NewReader 函数是调用 NewReaderSize 函数实现的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewReader(rd io.Reader) *Reader {
    // 默认缓存大小：defaultBufSize=4096
    return NewReaderSize(rd, defaultBufSize)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们看一下NewReaderSize的源码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewReaderSize(rd io.Reader, size int) *Reader {
    // 已经是bufio.Reader类型，且缓存大小不小于 size，则直接返回
    b, ok := rd.(*Reader)
    if ok &amp;amp;&amp;amp; len(b.buf) &amp;gt;= size {
        return b
    }
    // 缓存大小不会小于 minReadBufferSize （16字节）
    if size &amp;lt; minReadBufferSize {
        size = minReadBufferSize
    }
    // 构造一个bufio.Reader实例
    return &amp;amp;Reader{
        buf:          make([]byte, size),
        rd:           rd,
        lastByte:     -1,
        lastRuneSize: -1,
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见需要一个id.reader的实例来进行初始化，一般我们都是使用string或者[]byte的reader类型来创建。&lt;/p&gt;

&lt;h3 id=&#34;方法&#34;&gt;方法&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;ReadSlice、ReadBytes、ReadString 和 ReadLine 方法&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;之所以将这几个方法放在一起，是因为他们有着类似的行为。事实上，后三个方法最终都是调用ReadSlice来实现的。所以，我们先来看看ReadSlice方法(感觉这一段直接看源码较好)。&lt;/p&gt;

&lt;p&gt;1.ReadSlice方法签名如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b *Reader) ReadSlice(delim byte) (line []byte, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ReadSlice 从输入中读取，直到遇到第一个界定符（delim）为止，返回一个指向缓存中字节的 slice，在下次调用读操作（read）时，这些字节会无效。举例说明：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;reader := bufio.NewReader(strings.NewReader(&amp;quot;http://studygolang.com. \nIt is the home of gophers&amp;quot;))
line, _ := reader.ReadSlice(&#39;\n&#39;)
fmt.Printf(&amp;quot;the line:%s\n&amp;quot;, line)
// 这里可以换上任意的 bufio 的 Read/Write 操作
n, _ := reader.ReadSlice(&#39;\n&#39;)
fmt.Printf(&amp;quot;the line:%s\n&amp;quot;, line)
fmt.Println(string(n))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;the line:http://studygolang.com.

the line:It is the home of gophers
It is the home of gophers
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从结果可以看出，第一次ReadSlice的结果（line），在第二次调用读操作后，内容发生了变化。也就是说，ReadSlice 返回的 []byte 是指向 Reader 中的 buffer ，而不是 copy 一份返回。正因为ReadSlice 返回的数据会被下次的 I/O 操作重写，因此许多的客户端会选择使用 ReadBytes 或者 ReadString 来代替。读者可以将上面代码中的 ReadSlice 改为 ReadBytes 或 ReadString ，看看结果有什么不同。&lt;/p&gt;

&lt;p&gt;注意，这里的界定符可以是任意的字符，可以将上面代码中的&amp;rsquo;\n&amp;rsquo;改为&amp;rsquo;m&amp;rsquo;试试。同时，返回的结果是包含界定符本身的，上例中，输出结果有一空行就是&amp;rsquo;\n&amp;rsquo;本身(line携带一个&amp;rsquo;\n&amp;rsquo;,printf又追加了一个&amp;rsquo;\n&amp;rsquo;)。&lt;/p&gt;

&lt;p&gt;如果 ReadSlice 在找到界定符之前遇到了 error ，它就会返回缓存中所有的数据和错误本身（经常是 io.EOF）。如果在找到界定符之前缓存已经满了，ReadSlice 会返回 bufio.ErrBufferFull 错误。当且仅当返回的结果（line）没有以界定符结束的时候，ReadSlice 返回err != nil，也就是说，如果ReadSlice 返回的结果 line 不是以界定符 delim 结尾，那么返回的 er r也一定不等于 nil（可能是bufio.ErrBufferFull或io.EOF）。 例子代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;reader := bufio.NewReaderSize(strings.NewReader(&amp;quot;http://studygolang.com&amp;quot;),16)
line, err := reader.ReadSlice(&#39;\n&#39;)
fmt.Printf(&amp;quot;line:%s\terror:%s\n&amp;quot;, line, err)
line, err = reader.ReadSlice(&#39;\n&#39;)
fmt.Printf(&amp;quot;line:%s\terror:%s\n&amp;quot;, line, err)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;line:http://studygola    error:bufio: buffer full
line:ng.com    error:EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.ReadBytes方法签名如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b *Reader) ReadBytes(delim byte) (line []byte, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该方法的参数和返回值类型与 ReadSlice 都一样。 ReadBytes 从输入中读取直到遇到界定符（delim）为止，返回的 slice 包含了从当前到界定符的内容 （包括界定符）。如果 ReadBytes 在遇到界定符之前就捕获到一个错误，它会返回遇到错误之前已经读取的数据，和这个捕获到的错误（经常是 io.EOF）。跟 ReadSlice 一样，如果 ReadBytes 返回的结果 line 不是以界定符 delim 结尾，那么返回的 err 也一定不等于 nil（可能是bufio.ErrBufferFull 或 io.EOF）。&lt;/p&gt;

&lt;p&gt;从这个说明可以看出，ReadBytes和ReadSlice功能和用法都很像，那他们有什么不同呢？&lt;/p&gt;

&lt;p&gt;在讲解ReadSlice时说到，它返回的 []byte 是指向 Reader 中的 buffer，而不是 copy 一份返回，也正因为如此，通常我们会使用 ReadBytes 或 ReadString。很显然，ReadBytes 返回的 []byte 不会是指向 Reader 中的 buffer，通过查看源码可以证实这一点。&lt;/p&gt;

&lt;p&gt;还是上面的例子，我们将 ReadSlice 改为 ReadBytes：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;reader := bufio.NewReader(strings.NewReader(&amp;quot;http://studygolang.com. \nIt is the home of gophers&amp;quot;))
line, _ := reader.ReadBytes(&#39;\n&#39;)
fmt.Printf(&amp;quot;the line:%s\n&amp;quot;, line)
// 这里可以换上任意的 bufio 的 Read/Write 操作
n, _ := reader.ReadBytes(&#39;\n&#39;)
fmt.Printf(&amp;quot;the line:%s\n&amp;quot;, line)
fmt.Println(string(n))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;the line:http://studygolang.com.

the line:http://studygolang.com.

It is the home of gophers
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.ReadString方法&lt;/p&gt;

&lt;p&gt;看一下该方法的源码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b *Reader) ReadString(delim byte) (line string, err error) {
    bytes, err := b.ReadBytes(delim)
    return string(bytes), err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;它调用了 ReadBytes 方法，并将结果的 []byte 转为 string 类型。&lt;/p&gt;

&lt;p&gt;4.ReadLine方法签名如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b *Reader) ReadLine() (line []byte, isPrefix bool, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ReadLine 是一个底层的原始行读取命令。许多调用者或许会使用 ReadBytes(&amp;rsquo;\n&amp;rsquo;) 或者 ReadString(&amp;rsquo;\n&amp;rsquo;) 来代替这个方法。&lt;/p&gt;

&lt;p&gt;ReadLine 尝试返回单独的行，不包括行尾的换行符。如果一行大于缓存，isPrefix 会被设置为 true，同时返回该行的开始部分（等于缓存大小的部分）。该行剩余的部分就会在下次调用的时候返回。当下次调用返回该行剩余部分时，isPrefix 将会是 false 。跟 ReadSlice 一样，返回的 line 只是 buffer 的引用，在下次执行IO操作时，line 会无效。可以将 ReadSlice 中的例子该为 ReadLine 试试。&lt;/p&gt;

&lt;p&gt;注意，返回值中，要么 line 不是 nil，要么 err 非 nil，两者不会同时非 nil。ReadLine 返回的文本不会包含行结尾（&amp;rdquo;\r\n&amp;rdquo;或者&amp;rdquo;\n&amp;rdquo;）。如果输入中没有行尾标识符，不会返回任何指示或者错误。&lt;/p&gt;

&lt;p&gt;个人建议可以这么实现读取一行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;line, err := reader.ReadBytes(&#39;\n&#39;)
line = bytes.TrimRight(line, &amp;quot;\r\n&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样既读取了一行，也去掉了行尾结束符（当然，如果你希望留下行尾结束符，只用ReadBytes即可）。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Peek 方法&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;从方法的名称可以猜到，该方法只是“窥探”一下 Reader 中没有读取的 n 个字节。好比栈数据结构中的取栈顶元素，但不出栈。&lt;/p&gt;

&lt;p&gt;方法的签名如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b *Reader) Peek(n int) ([]byte, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同上面介绍的 ReadSlice一样，返回的 []byte 只是 buffer 中的引用，在下次IO操作后会无效，可见该方法（以及ReadSlice这样的，返回buffer引用的方法）对多 goroutine 是不安全的，也就是在多并发环境下，不能依赖其结果。&lt;/p&gt;

&lt;p&gt;我们通过例子来证明一下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
    &amp;quot;bufio&amp;quot;
    &amp;quot;fmt&amp;quot;
    &amp;quot;strings&amp;quot;
    &amp;quot;time&amp;quot;
)

func main() {
    reader := bufio.NewReaderSize(strings.NewReader(&amp;quot;http://studygolang.com.\t It is the home of gophers&amp;quot;), 14)
    go Peek(reader)
    go reader.ReadBytes(&#39;\t&#39;)
    time.Sleep(1e8)
}

func Peek(reader *bufio.Reader) {
    line, _ := reader.Peek(14)
    fmt.Printf(&amp;quot;%s\n&amp;quot;, line)
    // time.Sleep(1)
    fmt.Printf(&amp;quot;%s\n&amp;quot;, line)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://studygo
http://studygo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果和预期的一致。然而，这是由于目前的 goroutine 调度方式导致的结果。如果我们将例子中注释掉的 time.Sleep(1) 取消注释（这样调度其他 goroutine 执行），再次运行，得到的结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://studygo
ng.com.     It is
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外，Reader 的 Peek 方法如果返回的 []byte 长度小于 n，这时返回的 err != nil ，用于解释为啥会小于 n。如果 n 大于 reader 的 buffer 长度，err 会是 ErrBufferFull。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;其他方法&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Reader 的其他方法都是实现了 io 包中的接口，它们的使用方法在io包中都有介绍，在此不赘述。&lt;/p&gt;

&lt;p&gt;这些方法包括：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b *Reader) Read(p []byte) (n int, err error)
func (b *Reader) ReadByte() (c byte, err error)
func (b *Reader) ReadRune() (r rune, size int, err error)
func (b *Reader) UnreadByte() error
func (b *Reader) UnreadRune() error
func (b *Reader) WriteTo(w io.Writer) (n int64, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;你应该知道它们都是哪个接口的方法吧。&lt;/p&gt;

&lt;h2 id=&#34;scanner-类型和方法&#34;&gt;Scanner 类型和方法&lt;/h2&gt;

&lt;h3 id=&#34;类型-1&#34;&gt;类型&lt;/h3&gt;

&lt;p&gt;对于简单的读取一行，在 Reader 类型中，感觉没有让人特别满意的方法。于是，Go1.1增加了一个类型：Scanner。官方关于Go1.1增加该类型的说明如下：&lt;/p&gt;

&lt;p&gt;在 bufio 包中有多种方式获取文本输入，ReadBytes、ReadString 和独特的 ReadLine，对于简单的目的这些都有些过于复杂了。在 Go 1.1 中，添加了一个新类型，Scanner，以便更容易的处理如按行读取输入序列或空格分隔单词等，这类简单的任务。它终结了如输入一个很长的有问题的行这样的输入错误，并且提供了简单的默认行为：基于行的输入，每行都剔除分隔标识。这里的代码展示一次输入一行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scanner := bufio.NewScanner(os.Stdin)
for scanner.Scan() {
    fmt.Println(scanner.Text()) // Println will add back the final &#39;\n&#39;
}
if err := scanner.Err(); err != nil {
    fmt.Fprintln(os.Stderr, &amp;quot;reading standard input:&amp;quot;, err)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输入的行为可以通过一个函数控制，来控制输入的每个部分（参阅 SplitFunc 的文档），但是对于复杂的问题或持续传递错误的，可能还是需要原有接口。&lt;/p&gt;

&lt;p&gt;Scanner 类型和 Reader 类型一样，没有任何导出的字段，同时它也包装了一个 io.Reader 对象，但它没有实现 io.Reader 接口。&lt;/p&gt;

&lt;p&gt;Scanner 的结构定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Scanner struct {
    r            io.Reader // The reader provided by the client.
    split        SplitFunc // The function to split the tokens.
    maxTokenSize int       // Maximum size of a token; modified by tests.
    token        []byte    // Last token returned by split.
    buf          []byte    // Buffer used as argument to split.
    start        int       // First non-processed byte in buf.
    end          int       // End of data in buf.
    err          error     // Sticky error.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里 split、maxTokenSize 和 token 需要讲解一下。&lt;/p&gt;

&lt;h4 id=&#34;split&#34;&gt;split&lt;/h4&gt;

&lt;p&gt;split对应的类型是SplitFunc ，我们需要了解一下SplitFunc类型，定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type SplitFunc func(data []byte, atEOF bool) (advance int, token []byte, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SplitFunc 定义了 用于对输入进行分词的 split 函数的签名。参数 data 是还未处理的数据，atEOF 标识 Reader 是否还有更多数据（是否到了EOF）。返回值 advance 表示从输入中读取的字节数，token 表示下一个结果数据，err 则代表可能的错误。&lt;/p&gt;

&lt;p&gt;举例说明一下这里的 token 代表的意思：&lt;/p&gt;

&lt;p&gt;有数据 &amp;ldquo;studygolang\tpolaris\tgolangchina&amp;rdquo;，通过&amp;rdquo;\t&amp;rdquo;进行分词，那么会得到三个token，它们的内容分别是：studygolang、polaris 和 golangchina。而 SplitFunc 的功能是：进行分词，并返回未处理的数据中第一个 token。对于这个数据，就是返回 studygolang。
如果 data 中没有一个完整的 token，例如，在扫描行（scanning lines）时没有换行符，SplitFunc 会返回(0,nil,nil)通知 Scanner 读取更多数据到 slice 中。&lt;/p&gt;

&lt;p&gt;如果 err != nil，扫描停止，同时该错误会返回。&lt;/p&gt;

&lt;p&gt;如果参数 data 为空的 slice，除非 atEOF 为 true，否则该函数永远不会被调用。如果 atEOF 为 true，这时 data 可以非空，这时的数据是没有处理的。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;SplitFunc 的实例&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在 bufio 包中预定义了一些 split 函数，也就是说，在 Scanner 结构中的 split 字段，可以通过这些预定义的 split 赋值，同时 Scanner 类型的 Split 方法也可以接收这些预定义函数作为参数。所以，我们可以说，这些预定义 split 函数都是 SplitFunc 类型的实例。这些函数包括：ScanBytes、ScanRunes、ScanWords 和 ScanLines。（由于都是 SplitFunc 的实例，自然这些函数的签名都和 SplitFunc 一样）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ScanBytes 返回单个字节作为一个 token。&lt;/li&gt;
&lt;li&gt;ScanRunes 返回单个 UTF-8 编码的 rune 作为一个 token。返回的 rune 序列（token）和 range string类型 返回的序列是等价的，也就是说，对于无效的 UTF-8 编码会解释为 U+FFFD = &amp;ldquo;\xef\xbf\xbd&amp;rdquo;。&lt;/li&gt;
&lt;li&gt;ScanWords 返回通过“空格”分词的单词。如：study golang，调用会返回study。注意，这里的“空格”是 unicode.IsSpace()，即包括：&amp;rsquo;\t&amp;rsquo;, &amp;lsquo;\n&amp;rsquo;, &amp;lsquo;\v&amp;rsquo;, &amp;lsquo;\f&amp;rsquo;, &amp;lsquo;\r&amp;rsquo;, &amp;lsquo; &amp;lsquo;, U+0085 (NEL), U+00A0 (NBSP)。&lt;/li&gt;
&lt;li&gt;ScanLines 返回一行文本，不包括行尾的换行符。这里的换行包括了Windows下的&amp;rdquo;\r\n&amp;rdquo;和Unix下的&amp;rdquo;\n&amp;rdquo;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一般地，我们不会单独使用这些函数，而是提供给 Scanner 实例使用。&lt;/p&gt;

&lt;h4 id=&#34;maxtokensize&#34;&gt;maxTokenSize&lt;/h4&gt;

&lt;p&gt;maxTokenSize 字段 表示通过 split 分词后的一个 token 允许的最大长度。在该包中定义了一个常量 MaxScanTokenSize = 64 * 1024，这是允许的最大 token 长度（64k）。&lt;/p&gt;

&lt;h3 id=&#34;方法-1&#34;&gt;方法&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;实例化&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Scanner 没有导出任何字段，而它需要有外部的 io.Reader 对象，因此，我们不能直接实例化 Scanner 对象，必须通过 bufio 包提供的实例化函数来实例化。实例化函数签名以及内部实现：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewScanner(r io.Reader) *Scanner {
    return &amp;amp;Scanner{
        r:            r,
        split:        ScanLines,
        maxTokenSize: MaxScanTokenSize,
        buf:          make([]byte, 4096), // Plausible starting size; needn&#39;t be large.
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见，返回的 Scanner 实例默认的 split 函数是 ScanLines。这边实例化也是需要一个id.reader的实例，所以我们一般也是使用string或者[]byte的实例来做创建参数使用。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Split 方法&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;前面我们提到过可以通过 Split 方法为 Scanner 实例设置分词行为。由于 Scanner 实例的默认 split 总是 ScanLines，如果我们想要用其他的 split，可以通过 Split 方法做到。&lt;/p&gt;

&lt;p&gt;比如，我们想要统计一段英文有多少个单词（不排除重复），我们可以这么做：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const input = &amp;quot;This is The Golang Standard Library.\nWelcome you!&amp;quot;
scanner := bufio.NewScanner(strings.NewReader(input))
scanner.Split(bufio.ScanWords)
count := 0
for scanner.Scan() {
    count++
}
if err := scanner.Err(); err != nil {
    fmt.Fprintln(os.Stderr, &amp;quot;reading input:&amp;quot;, err)
}
fmt.Println(count)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们实例化 Scanner 后，通过调用 scanner.Split(bufio.ScanWords) 来更改 split 函数。注意，我们应该在调用 Scan 方法之前调用 Split 方法。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Scan 方法&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;该方法好比 iterator 中的 Next 方法，它用于将 Scanner 获取下一个 token，以便 Bytes 和 Text 方法可用。当扫描停止时，它返回false，这时候，要么是到了输入的末尾要么是遇到了一个错误。注意，当 Scan 返回 false 时，通过 Err 方法可以获取第一个遇到的错误（但如果错误是 io.EOF，Err 方法会返回 nil）。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Bytes 和 Text 方法&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这两个方法的行为一致，都是返回最近的 token，无非 Bytes 返回的是 []byte，Text 返回的是 string。该方法应该在 Scan 调用后调用，而且，下次调用 Scan 会覆盖这次的 token。比如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scanner := bufio.NewScanner(strings.NewReader(&amp;quot;http://studygolang.com. \nIt is the home of gophers&amp;quot;))
if scanner.Scan() {
    scanner.Scan()
    fmt.Printf(&amp;quot;%s&amp;quot;, scanner.Text())
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;返回的是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;It is the home of gophers
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;而不是&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://studygolang.com.
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Err 方法&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;前面已经提到，通过 Err 方法可以获取第一个遇到的错误（但如果错误是 io.EOF，Err 方法会返回 nil）。&lt;/p&gt;

&lt;h3 id=&#34;完整实例&#34;&gt;完整实例&lt;/h3&gt;

&lt;p&gt;我们经常会有这样的需求：读取文件中的数据，一次读取一行。在学习了 Reader 类型，我们可以使用它的 ReadBytes 或 ReadString来实现，甚至使用 ReadLine 来实现。然而，在 Go1.1 中，我们可以使用 Scanner 来做这件事，而且更简单好用。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;file, err := os.Create(&amp;quot;scanner.txt&amp;quot;)
if err != nil {
    panic(err)
}
defer file.Close()
file.WriteString(&amp;quot;http://studygolang.com.\nIt is the home of gophers.\nIf you are studying golang, welcome you!&amp;quot;)
// 将文件 offset 设置到文件开头
file.Seek(0, os.SEEK_SET)
scanner := bufio.NewScanner(file)
for scanner.Scan() {
    fmt.Println(scanner.Text())
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://studygolang.com.
It is the home of gophers.
If you are studying golang, welcome you!
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;writer-类型和方法&#34;&gt;Writer 类型和方法&lt;/h2&gt;

&lt;h3 id=&#34;类型-2&#34;&gt;类型&lt;/h3&gt;

&lt;p&gt;bufio.Writer 结构包装了一个 io.Writer 对象，提供缓存功能，同时实现了 io.Writer 接口。&lt;/p&gt;

&lt;p&gt;Writer 结构没有任何导出的字段，结构定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Writer struct {
    err error        // 写过程中遇到的错误
    buf []byte        // 缓存
    n   int            // 当前缓存中的字节数
    wr  io.Writer    // 底层的 io.Writer 对象
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相比 bufio.Reader, bufio.Writer 结构定义简单很多。&lt;/p&gt;

&lt;p&gt;注意：如果在写数据到 Writer 的时候出现了一个错误，不会再允许有数据被写进来了，并且所有随后的写操作都会返回该错误。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;实例化&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;和 Reader 类型一样，bufio 包提供了两个实例化 bufio.Writer 对象的函数：NewWriter 和 NewWriterSize。其中，NewWriter 函数是调用 NewWriterSize 函数实现的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewWriter(wr io.Writer) *Writer {
    // 默认缓存大小：defaultBufSize=4096
    return NewWriterSize(wr, defaultBufSize)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们看一下 NewWriterSize 的源码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewWriterSize(wr io.Writer, size int) *Writer {
    // 已经是 bufio.Writer 类型，且缓存大小不小于 size，则直接返回
    b, ok := wr.(*Writer)
    if ok &amp;amp;&amp;amp; len(b.buf) &amp;gt;= size {
        return b
    }
    if size &amp;lt;= 0 {
        size = defaultBufSize
    }
    return &amp;amp;Writer{
        buf: make([]byte, size),
        wr:  w,
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;方法-2&#34;&gt;方法&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;Available 和 Buffered 方法&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Available 方法获取缓存中还未使用的字节数（缓存大小 - 字段 n 的值）；&lt;/p&gt;

&lt;p&gt;Buffered 方法获取写入当前缓存中的字节数（字段 n 的值）&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Flush 方法&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;该方法将缓存中的所有数据写入底层的 io.Writer 对象中。使用 bufio.Writer 时，在所有的 Write 操作完成之后，应该调用 Flush 方法使得缓存都写入 io.Writer 对象中。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;其他方法&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Writer 类型其他方法是一些实际的写方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 实现了 io.ReaderFrom 接口
func (b *Writer) ReadFrom(r io.Reader) (n int64, err error)

// 实现了 io.Writer 接口
func (b *Writer) Write(p []byte) (nn int, err error)

// 实现了 io.ByteWriter 接口
func (b *Writer) WriteByte(c byte) error

// io 中没有该方法的接口，它用于写入单个 Unicode 码点，返回写入的字节数（码点占用的字节），内部实现会根据当前 rune 的范围调用 WriteByte 或 WriteString
func (b *Writer) WriteRune(r rune) (size int, err error)

// 写入字符串，如果返回写入的字节数比 len(s) 小，返回的error会解释原因
func (b *Writer) WriteString(s string) (int, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这些写方法在缓存满了时会调用 Flush 方法。另外，这些写方法源码开始处，有这样的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if b.err != nil {
    return b.err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是说，只要写的过程中遇到了错误，再次调用写操作会直接返回该错误。&lt;/p&gt;

&lt;h2 id=&#34;readwriter-类型和实例化&#34;&gt;ReadWriter 类型和实例化&lt;/h2&gt;

&lt;h3 id=&#34;类型-3&#34;&gt;类型&lt;/h3&gt;

&lt;p&gt;ReadWriter 结构存储了 bufio.Reader 和 bufio.Writer 类型的指针（内嵌），它实现了 io.ReadWriter 结构。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type ReadWriter struct {
    *Reader
    *Writer
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;实例&#34;&gt;实例&lt;/h3&gt;

&lt;p&gt;ReadWriter 的实例化可以跟普通结构类型一样，也可以通过调用 bufio.NewReadWriter 函数来实现：只是简单的实例化 ReadWriter&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewReadWriter(r *Reader, w *Writer) *ReadWriter {
    return &amp;amp;ReadWriter{r, w}
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>监控系列---- log</title>
          <link>https://kingjcy.github.io/post/monitor/log/log-scheme/</link>
          <pubDate>Mon, 13 Aug 2018 11:16:45 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/monitor/log/log-scheme/</guid>
          <description>&lt;p&gt;日志是设备或者程序对自身状态和运作行为的记录，日志监控平台是包括日志采集，存储，分析，索引查询，告警以及各种流程管理的一站式日志服务，日志监控是监控体系中核心的建设，而且可以说是量最大的一项监控。&lt;/p&gt;

&lt;h1 id=&#34;日志&#34;&gt;日志&lt;/h1&gt;

&lt;p&gt;日志是设备或者程序对自身状态和运作行为的记录。日志记录了事件，通过日志就可以看到设备和程序运行的历史信息，通过这些信息，可以了解设备和程序运行情况的变化，以更好的对于设备和程序进行维护。主要是在系统出现问题的时候，通过对于运行过程中发生的历史事件，可以查找问题出现的原因。&lt;/p&gt;

&lt;p&gt;我们可以通过下图来对日志有一个直观的概念&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/monitor/log/log&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;日志平台&#34;&gt;日志平台&lt;/h1&gt;

&lt;p&gt;业内最常见的日志采集方案就是 ELK，在 ELK 出来之前，日志管理基本上都是通过登陆日志所在机器然后使用 Linux 命令或人为查看和统计 ，这样是非常没有效率的。&lt;/p&gt;

&lt;h2 id=&#34;架构&#34;&gt;架构&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/monitor/log/log1&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这是一个最简化版的日志收集架构，很多基于ELK的日志架构是从它演化而来，比如中加上kafka等队列缓存，核心的问题就是日志数据都保存到ElasticSearch中。其实核心的是四大模块&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;数据采集模块：负责从各节点上实时采集数据，建议选用filebeat来实现。&lt;/li&gt;
&lt;li&gt;数据接入模块：由于采集数据的速度和数据处理的速度不一定同步，因此添加一个消息中间件来作为缓冲，建议选用Kafka来实现。&lt;/li&gt;
&lt;li&gt;存储计算模块：对采集到的数据进行实时存储分析，建议选用ES来实现。&lt;/li&gt;
&lt;li&gt;数据输出模块：对分析后的结果展示，一般使用kibana。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;采集&#34;&gt;采集&lt;/h2&gt;

&lt;p&gt;在日志采集方面，可以说是有很多项目的支持，从以一开始的logstash，Rsyslog到后来Flume，Fluentd，Filebeat等。采集越来越倾向于轻量级，性能越来越高。容器日志采集和寻常的采集也不一样，&lt;a href=&#34;https://kingjcy.github.io/post/monitor/log/collect/collect-scheme/&#34;&gt;不同的方案&lt;/a&gt;有不同的适用场景。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;2020.02.20&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;今天调研了grafana推出的loki也是处理日志,这边采集是promtail，具体可以查看&lt;a href=&#34;https://kingjcy.github.io/post/monitor/log/loki/loki/&#34;&gt;loki调研&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;存储&#34;&gt;存储&lt;/h2&gt;

&lt;p&gt;在日志存储索引查询方面，目前只有&lt;a href=&#34;https://kingjcy.github.io/post/database/elasticsearch/&#34;&gt;ES&lt;/a&gt;一个核心技术站，并没有过多的选择。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;2020.02.20&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;今天调研了grafana推出的loki也是处理日志，借鉴了prometheus的label和metrics理念，通过label完成检索，具体可以查看&lt;a href=&#34;https://kingjcy.github.io/post/monitor/log/loki/loki/&#34;&gt;loki调研&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;展示&#34;&gt;展示&lt;/h2&gt;

&lt;p&gt;在数据展示报表方面，目前对日志也没有什么选择，只有kibana。Kibana主要负责读取ElasticSearch中的数据，并进行可视化展示。并且，它还自带Tool，可以方便调用ElasticSearch的Rest API。在日志平台中，我们通过Kibana查看日志。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>监控系统---- Thanos</title>
          <link>https://kingjcy.github.io/post/monitor/metrics/prometheus/cluster/thanos/</link>
          <pubDate>Fri, 13 Jul 2018 17:14:15 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/monitor/metrics/prometheus/cluster/thanos/</guid>
          <description>&lt;p&gt;Thanos，一组通过跨集群联合、跨集群无限存储和全局查询为Prometheus 增加高可用性的组件。&lt;/p&gt;

&lt;h1 id=&#34;基本功能&#34;&gt;基本功能&lt;/h1&gt;

&lt;p&gt;prometheus单点能够支持百万的metrics，但是在规模越来越大的系统中，已经不能满足要求，需要集群的功能来处理更加庞大的数据，基于这个情况，thanos诞生了，thanos的主要功能：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;去重，单点问题，可以让prometheus高可用，实现多采集情况下的数据查询，query是无状态的，可以使用负载均衡&lt;/li&gt;
&lt;li&gt;聚合，实现不同prometheus的数据的聚合，匹配prometheus的hashmode功能，实现集群的方式&lt;/li&gt;
&lt;li&gt;数据备份，主要是基于s3的，相当于远程存储，我们没有使用，直接将数据写入到了kafka&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;基本组件&#34;&gt;基本组件&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Sidecar&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Sidecar作为一个单独的进程和已有的Prometheus实例运行在一个server上，互不影响。Sidecar可以视为一个Proxy组件，所有对Prometheus的访问都通过Sidecar来代理进行。通过Sidecar还可以将采集到的数据直接备份到云端对象存储服务器。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Querier&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;所有的Sidecar与Querier直连，同时Querier实现了一套Prometheus官方的HTTP API从而保证对外提供与Prometheus一致的数据源接口，Grafana可以通过同一个查询接口请求不同集群的数据，Querier负责找到对应的集群并通过Sidecar获取数据。Querier本身无状态的也是水平可扩展的，因而可以实现高可部署，而且Querier可以实现对高可部署的Prometheus的数据进行合并从而保证多次查询结果的一致性，从而解决全局视图和高可用的问题。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Store&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Store实现了一套和Sidecar完全一致的API提供给Querier用于查询Sidecar备份到云端对象存储的数据。因为Sidecar在完成数据备份后，Prometheus会清理掉本地数据保证本地空间可用。所以当监控人员需要调取历史数据时只能去对象存储空间获取，而Store就提供了这样一个接口。Store Gateway只会缓存对象存储的基本信息，例如存储块的索引，从而保证实现快速查询的同时占用较少本地空间。&lt;/p&gt;

&lt;p&gt;store和sidecar都提供了相同gprc的api，给外部client进行查询，其实是一回事。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Comactor&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Compactor主要用于对采集到的数据进行压缩，实现将数据存储至对象存储时节省空间。单独使用，和集群没有什么关系。主要是将对象存储 Bucket 中的多个小 的相同的Block 合并成 大 Block&lt;/p&gt;

&lt;h1 id=&#34;基本使用&#34;&gt;基本使用&lt;/h1&gt;

&lt;h2 id=&#34;sidecar&#34;&gt;sidecar&lt;/h2&gt;

&lt;p&gt;sidecar部署在prometheus机器上,直接使用二进制文件配置不同的启动参数来启动&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/opt/promes/thanos-sidecar/thanos sidecar --log.level=debug --tsdb.path=/data --prometheus.url=http://localhost:9099
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;query&#34;&gt;query&lt;/h2&gt;

&lt;p&gt;query用于查询，单独部署，然后和prometheus一样使用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/opt/promes/thanos-query/thanos query --query.timeout=15s --store.response-timeout=15s --log.level=debug --store=10.243.53.96:19091 --store=10.243.53.100:19091 --store=10.243.53.101:19091 --store=10.243.53.186:19091
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;sd&#34;&gt;sd&lt;/h2&gt;

&lt;p&gt;thanos有三种sd的方式&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Static Flags&lt;/p&gt;

&lt;p&gt;最简单的就是在参数中配置列表，就是我们上面使用的方式&lt;/p&gt;

&lt;p&gt;&amp;ndash;store参数指定的是每个sidecar的grpc端口，query会根据&amp;ndash;store参数列表找到对应的prometheus进行查询，所有组件的端口都是有默认值的，如果需要修改则指定参数&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Component&lt;/th&gt;
&lt;th&gt;Interface&lt;/th&gt;
&lt;th&gt;Port&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Sidecar&lt;/td&gt;
&lt;td&gt;gRPC&lt;/td&gt;
&lt;td&gt;10901&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Sidecar&lt;/td&gt;
&lt;td&gt;HTTP&lt;/td&gt;
&lt;td&gt;10902&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Query&lt;/td&gt;
&lt;td&gt;gRPC&lt;/td&gt;
&lt;td&gt;10903&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Query&lt;/td&gt;
&lt;td&gt;HTTP&lt;/td&gt;
&lt;td&gt;10904&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Store&lt;/td&gt;
&lt;td&gt;gRPC&lt;/td&gt;
&lt;td&gt;10905&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Store&lt;/td&gt;
&lt;td&gt;HTTP&lt;/td&gt;
&lt;td&gt;10906&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Receive&lt;/td&gt;
&lt;td&gt;gRPC (store API)&lt;/td&gt;
&lt;td&gt;10907&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Receive&lt;/td&gt;
&lt;td&gt;HTTP (remote write API)&lt;/td&gt;
&lt;td&gt;10908&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Receive&lt;/td&gt;
&lt;td&gt;HTTP&lt;/td&gt;
&lt;td&gt;10909&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Rule&lt;/td&gt;
&lt;td&gt;gRPC&lt;/td&gt;
&lt;td&gt;10910&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Rule&lt;/td&gt;
&lt;td&gt;HTTP&lt;/td&gt;
&lt;td&gt;10911&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Compact&lt;/td&gt;
&lt;td&gt;HTTP&lt;/td&gt;
&lt;td&gt;10912&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;File SD&lt;/p&gt;

&lt;p&gt;&amp;ndash;store.sd-files=&lt;path&gt;和 &amp;ndash;store.sd-interval=&lt;5m&gt;来获取对应的prometheus列表&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;DNS SD&lt;/p&gt;

&lt;p&gt;&amp;ndash;store=dns+stores.thanos.mycompany.org:9090
&amp;ndash;store=dnssrv+_thanosstores._tcp.mycompany.org
&amp;ndash;store=dnssrvnoa+_thanosstores._tcp.mycompany.org&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;基本原理&#34;&gt;基本原理&lt;/h1&gt;

&lt;p&gt;Thanos 在每一台 Prometheus 服务器上运行一个sidecar组件，并提供了一个用于处理 PromQL 查询的中央 Querier 组件，因而在所有服务器之间引入了一个中央查询层。这些组件构成了一个 Thanos 部署，并基于 memberlist gossip 协议实现组件间通信。Querier 可以水平扩展，因为它是无状态的，并且可充当智能逆向代理，将请求转发给sidecar，汇总它们的响应，并对 PromQL 查询进行评估。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;实现细节&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
&lt;li&gt;Thanos 通过使用后端的对象存储来解决数据保留问题。Prometheus 在将数据写入磁盘时，sidecar的 StoreAPI 组件会检测到，并将数据上传到对象存储器中。Store 组件还可以作为一个基于 gossip 协议的检索代理，让 Querier 组件与它进行通信以获取数据。&lt;/li&gt;
&lt;li&gt;我们使用基本的过滤器（基于时间范围和外部标签）过滤掉不会提供所需数据的 StoreAPI（叶子），然后执行剩余的查询。然后将来自不同来源的数据按照时间顺序追加的方式合并在一起。&lt;/li&gt;
&lt;li&gt;Querier 组件可以基于用户规模自动调整密度（例如 5 分钟、1 小时或 24 小时）&lt;/li&gt;
&lt;li&gt;StoreAPI 组件了解 Prometheus 的数据格式，因此它可以优化查询执行计划，并缓存数据块的特定索引，以对用户查询做出足够快的响应，避免了缓存大量数据的必要。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;我们通过为所有 Prometheus+ sidecar实例提供唯一的外部标签来解决多个边车试图将相同的数据块上传到对象存储的问题，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;First:

&amp;quot;cluster&amp;quot;: &amp;quot;prod1&amp;quot;

&amp;quot;replica&amp;quot;: &amp;quot;0&amp;quot;

Second:

&amp;quot;cluster&amp;quot;:&amp;quot;prod1&amp;quot;

&amp;quot;replica&amp;quot;: &amp;quot;1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由于标签集是唯一的，所以不会有什么问题。不过，如果指定了副本，查询层可以在运行时通过“replica”标签进行除重操作。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Thanos 还提供了时间序列数据的压缩和降采样（downsample）存储。Prometheus 提供了一个内置的压缩​​模型，现有较小的数据块被重写为较大的数据块，并进行结构重组以提高查询性能。Thanos 在Compactor 组件（作为批次作业运行）中使用了相同的机制，并压缩对象存储数据。Płotka 说，Compactor 也对数据进行降采样，“目前降采样时间间隔不可配置，不过我们选择了一些合理的时间间隔——5 分钟和1 小时”。压缩也是其他时间序列数据库（如 InfluxDB 和 OpenTSDB ）的常见功能。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;遇到的问题&#34;&gt;遇到的问题&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;查询速度较慢，在数据量基本特别大的时候，查询会超时。&lt;/li&gt;
&lt;li&gt;thanos 目前还不能支持默认查询lookback时间，promehteus可以设置默认查询时间，thanos默认是根据规模自动调整的，目前发现有10m，20m等，这边可以暂时表达式加时间处理这个问题。&lt;/li&gt;
&lt;li&gt;sidecar的启动参数&amp;ndash;cluster-peers是什么作用&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;扩展&#34;&gt;扩展&lt;/h1&gt;

&lt;p&gt;在prometheus的聚合和集群发展中，出现了很多的相同的项目，大部分都是使用了远程存储的概念，比如&lt;a href=&#34;https://kingjcy.github.io/post/monitor/metrics/prometheus/cluster/remotestore/cortex/&#34;&gt;cortex&lt;/a&gt;，&lt;a href=&#34;https://kingjcy.github.io/post/monitor/metrics/prometheus/cluster/remotestore/m3db/&#34;&gt;M3DB&lt;/a&gt;，&lt;a href=&#34;https://kingjcy.github.io/post/monitor/metrics/prometheus/cluster/victoriametrics/&#34;&gt;victoriametrics&lt;/a&gt;，thanos在调研落地的过程中，各方面还是相对做到比较好的，适合做为prometheus的扩展和聚合方案。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/monitor/prometheus/cluster/thanos/thanos&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;2019.9.9&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;https://kingjcy.github.io/post/monitor/metrics/prometheus/cluster/victoriametrics/&#34;&gt;victoriametrics&lt;/a&gt;在存储和查询上更加的优秀，目前比较推荐victoriametrics。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>日志系列---- 容器日志采集方案</title>
          <link>https://kingjcy.github.io/post/monitor/log/collect/collect-scheme/</link>
          <pubDate>Sun, 08 Jul 2018 19:45:30 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/monitor/log/collect/collect-scheme/</guid>
          <description>&lt;p&gt;容器由于其特殊性，在日志采集上有着不同的解决方案，目前主要还是以探针采集为主。&lt;/p&gt;

&lt;h1 id=&#34;日志采集演进&#34;&gt;日志采集演进&lt;/h1&gt;

&lt;p&gt;容器日志采集方案一直不断的演进，纵览当前容器日志收集的场景，无非就是两种方式：一是直接采集Docker标准输出，容器内的服务将日志信息写到标准输出，这样通过Docker的log driver可以发送到相应的收集程序中；二是延续传统的日志写入方式，容器内的服务将日志直接写到普通文件中，通过Docker volume将日志文件映射到Host上，日志采集程序就可以收集它。&lt;/p&gt;

&lt;h2 id=&#34;docker-log-driver&#34;&gt;docker log driver&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;docker logs&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;docker logs edc-k8s-demo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;默认情况下，Docker的日志会发送到容器的标准输出设备（STDOUT）和标准错误设备（STDERR），其中STDOUT和STDERR实际上就是容器的控制台终端。如果想要持续看到新打印出的日志信息，那么可以加上 -f 参数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker logs -f edc-k8s-demo
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Docker logging driver&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Docker还提供了其他的一些机制允许我们从运行的容器中提取日志，这些机制统称为 logging driver。&lt;/p&gt;

&lt;p&gt;对Docker而言，其默认的logging driver是json-file，如果在启动时没有特别指定，都会使用这个默认的logging driver。json-file会将我们在控制台通过docker logs命名看到的日志都保存在一个json文件中，我们可以在服务器Host上的容器目录中找到这个json文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;容器日志路径：/var/lib/docker/containers/&amp;lt;container-id&amp;gt;/&amp;lt;container-id&amp;gt;-json.log
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;除了json-file，Docker还支持以下多种logging dirver&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;none  No logs are available for the container and docker logs does not return any output.&lt;/li&gt;
&lt;li&gt;local Logs are stored in a custom format designed for minimal overhead.&lt;/li&gt;
&lt;li&gt;json-file The logs are formatted as JSON. The default logging driver for Docker.&lt;/li&gt;
&lt;li&gt;syslog    Writes logging messages to the syslog facility. The syslog daemon must be running on the host machine.&lt;/li&gt;
&lt;li&gt;journald  Writes log messages to journald. The journald daemon must be running on the host machine.&lt;/li&gt;
&lt;li&gt;gelf  Writes log messages to a Graylog Extended Log Format (GELF) endpoint such as Graylog or Logstash.&lt;/li&gt;
&lt;li&gt;fluentd   Writes log messages to fluentd (forward input). The fluentd daemon must be running on the host machine.&lt;/li&gt;
&lt;li&gt;awslogs   Writes log messages to Amazon CloudWatch Logs.&lt;/li&gt;
&lt;li&gt;splunk    Writes log messages to splunk using the HTTP Event Collector.&lt;/li&gt;
&lt;li&gt;etwlogs   Writes log messages as Event Tracing for Windows (ETW) events. Only available on Windows platforms.&lt;/li&gt;
&lt;li&gt;gcplogs   Writes log messages to Google Cloud Platform (GCP) Logging.&lt;/li&gt;
&lt;li&gt;logentries    Writes log messages to Rapid7 Logentries.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们可以在容器启动时通过加上 &amp;ndash;log-driver 来指定使用哪个具体的 logging driver，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -d --log-driver=syslog ......
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果想要设置默认的logging driver，那么则需要修改Docker daemon的启动脚本，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;log-driver&amp;quot;: &amp;quot;json-file&amp;quot;,
  &amp;quot;log-opts&amp;quot;: {
    &amp;quot;labels&amp;quot;: &amp;quot;production_status&amp;quot;,
    &amp;quot;env&amp;quot;: &amp;quot;os,customer&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;每个logging driver都有一些自己特定的log-opt，使用时可以参考具体官方文档。&lt;/p&gt;

&lt;p&gt;可见，第一种方式足够简单，直接配置相关的Log Driver就可以，但是这种方式也有些劣势：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当主机的容器密度比较高的时候，对Docker Engine的压力比较大，毕竟容器标准输出都要通过Docker Engine来处理。&lt;/li&gt;
&lt;li&gt;尽管原则上，我们希望遵循一容器部署一个服务的原则，但是有时候特殊情况不可避免容器内有多个业务服务，这时候很难做到所有服务都向标准输出写日志，这就需要用到前面所说的第二种场景模式。&lt;/li&gt;
&lt;li&gt;虽然我们可以先选择很多种Log Driver，但是有些Log Driver会破坏Docker原生的体验，比如docker logs无法直接看到容器日志。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;docker-volume&#34;&gt;docker volume&lt;/h2&gt;

&lt;p&gt;通过对第一种方案的摸索，存在着很多的问题与不方便，所以目前我们大多数采集还是使用第二种方案，文件采集的方式。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;第三方采集方案&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;上面都是将日志文件落到STDOUT和STDERR，我们采集都是基于这个，其实在我们应用编程的时候，完全可以将日志文件落到容器的对应的目录下，落盘然后使用第三方采集组件比如filebeat、fluentd等采集，统一管理。&lt;/p&gt;

&lt;h1 id=&#34;容器日志采集方案&#34;&gt;容器日志采集方案&lt;/h1&gt;

&lt;p&gt;根据上面的基本描述，容器日志采集有很多种方式，每种方式都用不同实现方案，适用于不同的场景。&lt;/p&gt;

&lt;h2 id=&#34;logdriver&#34;&gt;LogDriver&lt;/h2&gt;

&lt;p&gt;DockerEngine 本身具有 LogDriver 功能，可通过配置不同的 LogDriver 将容器的 stdout 通过 DockerEngine 写入到远端存储，以此达到日志采集的目的。这种方式的可定制化、灵活性、资源隔离性都很低，一般不建议在生产环境中使用，上面我们已经说明不使用的原因。&lt;/p&gt;

&lt;h2 id=&#34;http&#34;&gt;http&lt;/h2&gt;

&lt;p&gt;业务直写是在应用中集成日志采集的 SDK，通过 SDK 直接将日志发送到服务端。这种方式省去了落盘采集的逻辑，也不需要额外部署 Agent，对于系统的资源消耗最低，但由于业务和日志 SDK 强绑定，整体灵活性很低，一般只有日志量极大的场景中使用，这是一种特殊的场景，我们会在特殊情况下使用。&lt;/p&gt;

&lt;h2 id=&#34;deamonset模式&#34;&gt;deamonset模式&lt;/h2&gt;

&lt;p&gt;DaemonSet 方式在每个 node 节点上只运行一个日志 agent(&lt;a href=&#34;https://kingjcy.github.io/post/monitor/log/collect/filebeat/filebeat/&#34;&gt;filebeat&lt;/a&gt;,fluentd,flume,fluentbit)，采集这个节点上所有的日志。DaemonSet 相对资源占用要小很多，但扩展性、租户隔离性受限，比较适用于功能单一或业务不是很多的集群；&lt;/p&gt;

&lt;p&gt;正常规模的采集可以适应，日志分类明确、功能较单一的集群，大规模的集群采集速度就跟不上了，而且没有办法做到垂直扩展无上限。&lt;/p&gt;

&lt;p&gt;当然完整的方案还是有很多需要做的工作，比如如何做发现，如何动态变更，这就是一个完成的平台建设了，这些每个公司都有自己的建设，就不太好说了。&lt;/p&gt;

&lt;h2 id=&#34;sidecar模式&#34;&gt;sidecar模式&lt;/h2&gt;

&lt;p&gt;Sidecar 方式为每个 POD 单独部署日志 agent，这个 agent 只负责一个业务应用的日志采集。Sidecar 相对资源占用较多，但灵活性以及多租户隔离性较强，建议大型的 K8s 集群或作为 PaaS 平台为多个业务方服务的集群使用该方式。&lt;/p&gt;

&lt;p&gt;适用于大型、混合型、PAAS型集群的日志采集，是一种水平扩展消耗更多资源来增加采集速度的方案，但是方案就比较复杂。&lt;/p&gt;

&lt;p&gt;当然完整的方案还是有很多需要做的工作，比如如何做发现，如何动态变更，这就是一个完成的平台建设了，这些每个公司都有自己的建设，也就不太好说了。&lt;/p&gt;

&lt;h1 id=&#34;网络采集性能数据&#34;&gt;网络采集性能数据&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;有赞&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;重flume发展到自研rsyslog-hub和http服务&lt;/p&gt;

&lt;p&gt;17年平均每秒产生日志1.1万条，峰值1.5万条，每天的日志量约9亿条，占用空间2.4T左右&lt;/p&gt;

&lt;p&gt;19年每天都会产生百亿级别的日志量（据统计，平均每秒产生 50 万条日志，峰值每秒可达 80 万条）&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;七牛云&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;自研logkit&lt;/p&gt;

&lt;p&gt;17年现在日均数据流入量超 250 TB，3650 亿条，其中最大的客户日均数据流入量超过 45 TB。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;b站&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;17年目前集群规模20台机器，接入业务200+，单日日志量10T+。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;阿里云&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;自研logtail（重内核都得到的优化和充分利用）&lt;/p&gt;

&lt;p&gt;速度达到160M/s&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>监控日志系列---- Filebeat</title>
          <link>https://kingjcy.github.io/post/monitor/log/collect/filebeat/filebeat/</link>
          <pubDate>Sun, 08 Jul 2018 19:45:30 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/monitor/log/collect/filebeat/filebeat/</guid>
          <description>&lt;p&gt;Filebeat 是使用 Golang 实现的轻量型日志采集器，是基于原先 logstash-forwarder 的源码改造出来的，没有任何依赖，可以单独存在的搞性能采集工具。&lt;/p&gt;

&lt;h1 id=&#34;认识beats&#34;&gt;认识beats&lt;/h1&gt;

&lt;p&gt;Beats是轻量级（资源高效，无依赖性，小型）采集程序的集合。这些可以是日志文件（Filebeat），网络数据（Packetbeat），服务器指标（Metricbeat）等，Beats建立在名为libbeat的Go框架之上，该框架主要用于数据转发，Elastic和社区开发的越来越多的Beats可以收集的任何其他类型的数据，收集后，数据将直接发送到Elasticsearch或Logstash中进行其他处理。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Filebeat&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;顾名思义，Filebeat用于收集和传送日志文件，它也是最常用的Beat。 Filebeat如此高效的事实之一就是它处理背压的方式，如果Logstash繁忙，Filebeat会减慢其读取速率，并在减速结束后加快节奏。
Filebeat几乎可以安装在任何操作系统上，包括作为Docker容器安装，还随附用于特定平台（例如Apache，MySQL，Docker等）的内部模块，其中包含这些平台的默认配置和Kibana对象。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Packetbeat&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;网络数据包分析器Packetbeat是第一个引入的beat。 Packetbeat捕获服务器之间的网络流量，因此可用于应用程序和性能监视。
Packetbeat可以安装在受监视的服务器上，也可以安装在其专用服务器上。 Packetbeat跟踪网络流量，解码协议并记录每笔交易的数据。 Packetbeat支持的协议包括：DNS，HTTP，ICMP，Redis，MySQL，MongoDB，Cassandra等。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Metricbeat&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Metricbeat是一种非常受欢迎的beat，它收集并报告各种系统和平台的各种系统级度量。 Metricbeat还支持用于从特定平台收集统计信息的内部模块。您可以使用这些模块和称为指标集的metricsets来配置Metricbeat收集指标的频率以及要收集哪些特定指标。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Heartbeat&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Heartbeat是用于“uptime monitoring”的。本质上，Heartbeat是探测服务以检查它们是否可访问的功能，例如，它可以用来验证服务的正常运行时间是否符合您的SLA。 您要做的就是为Heartbeat提供URL和正常运行时间指标的列表。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Auditbeat&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Auditbeat可用于操作Linux服务器上的用户和进程活动。 与其他传统的系统工具（systemd，auditd）类似，Auditbeat可用于识别安全漏洞-文件更改，配置更改，恶意行为等。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Winlogbeat&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Winlogbeat仅会引起Windows系统管理员或工程师的兴趣，因为它是专门为收集Windows事件日志而设计的。 它可用于分析安全事件，已安装的更新等。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Functionbeat&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Functionbeat主要是为“serverless”而设计，可以将其部署为收集数据并将其发送到ELK堆栈的功能。 Functionbeat专为监视云环境而设计，目前已针对Amazon设置量身定制，可以部署为Amazon Lambda函数，以从Amazon CloudWatch，Kinesis和SQS收集数据。&lt;/p&gt;

&lt;h1 id=&#34;filebeat&#34;&gt;filebeat&lt;/h1&gt;

&lt;p&gt;为什么选择filebeat&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;性能好&lt;/li&gt;
&lt;li&gt;基于golang的技术站，对于容器生态友好&lt;/li&gt;
&lt;li&gt;使用部署方便，功能齐全&lt;/li&gt;
&lt;li&gt;其他技术方案，主要是社区的fluentd，使用的ruby+c，使用起来很复杂，各种功能都需要写插件来完成。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;基本使用&#34;&gt;基本使用&lt;/h2&gt;

&lt;h3 id=&#34;下载&#34;&gt;下载&lt;/h3&gt;

&lt;p&gt;直接去github上可以下载二进制文件，可以直接运行&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.10.2-linux-x86_64.tar.gz
tar xzvf filebeat-7.10.2-linux-x86_64.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也可以使用源码编译&lt;/p&gt;

&lt;p&gt;After installing Go, set the GOPATH environment variable to point to your workspace location, and make sure $GOPATH/bin is in your PATH.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p ${GOPATH}/src/github.com/elastic
git clone https://github.com/elastic/beats ${GOPATH}/src/github.com/elastic/beats
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you have multiple go paths, use ${GOPATH%%:*} instead of ${GOPATH}.&lt;/p&gt;

&lt;p&gt;Then you can compile a particular Beat by using the Makefile. For example, for Packetbeat:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd beats/packetbeat
make
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Some of the Beats might have extra development requirements, in which case you’ll find a CONTRIBUTING.md file in the Beat directory.&lt;/p&gt;

&lt;p&gt;We use an EditorConfig file in the beats repository to standardise how different editors handle whitespace, line endings, and other coding styles in our files. Most popular editors have a plugin for EditorConfig and we strongly recommend that you install it.&lt;/p&gt;

&lt;h3 id=&#34;配置文件&#34;&gt;配置文件&lt;/h3&gt;

&lt;p&gt;FileBeat 的配置文件定义了在读取文件的位置，输出流的位置以及相应的性能参数，本实例是以 Kafka 消息中间件作为缓冲，所有的日志收集器都向 Kafka 输送日志流，相应的最简单的配置项如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vim fileat.yml

filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /wls/applogs/rtlog/app.log
  fields:
    log_topic: appName
  multiline:
        # pattern for error log, if start with space or cause by
        pattern: &#39;^[[:space:]]+(at|\.{3})\b|^Caused by:&#39;
        negate:  false
        match:   after

output.kafka:
   enabled: true
   hosts: [&amp;quot;kafka-1:9092&amp;quot;,&amp;quot;kafka-2:9092&amp;quot;]
   topic: applog
   version: &amp;quot;0.10.2.0&amp;quot;
   compression: gzip

processors:
- drop_fields:
   fields: [&amp;quot;beat&amp;quot;, &amp;quot;input&amp;quot;, &amp;quot;source&amp;quot;, &amp;quot;offset&amp;quot;]

logging.level: error
name: app-server-ip
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;paths:定义了日志文件路径，可以采用模糊匹配模式，如*.log&lt;/li&gt;
&lt;li&gt;fields：topic 对应的消息字段或自定义增加的字段。&lt;/li&gt;
&lt;li&gt;output.kafka：filebeat 支持多种输出，支持向 kafka，logstash，elasticsearch 输出数据，此处设置数据输出到 kafka。&lt;/li&gt;
&lt;li&gt;enabled：这个启动这个模块。&lt;/li&gt;
&lt;li&gt;topic：指定要发送数据给 kafka 集群的哪个 topic，若指定的 topic 不存在，则会自动创建此 topic。&lt;/li&gt;
&lt;li&gt;version：指定 kafka 的版本。&lt;/li&gt;
&lt;li&gt;drop_fields：舍弃字段，filebeat 会 json 日志信息，适当舍弃无用字段节省空间资源。&lt;/li&gt;
&lt;li&gt;name：收集日志中对应主机的名字，建议 name 这里设置为 IP，便于区分多台主机的日志信息。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;每一个不同的输出都用不同的配置项，还有很多功能性能的配置项，比如&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;合并规则&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;multiline:
        pattern: &#39;^[[:space:]]+(at|\.{3})\b|^Caused by:&#39;
        negate:  false
        match:   after
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;常用的合并规则&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[0-9]{4}-[0-9]{2}-[0-9]{2} 按照yyyy-mm-dd时间戳合并，日志不是以这个时间戳开头的都合并
[[0-9]{4}-[0-9]{2}-[0-9]{2} 按照[yyyy-mm-dd时间戳合并，日志不是以这个时间戳开头的都合并
* 不合并----不合并最后处理出来的结果就是没有这一段的配置
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;过滤规则&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;include_lines: [&amp;quot;FATAL&amp;quot;,&amp;quot;ERROR&amp;quot;,&amp;quot;WARN&amp;quot;,&amp;quot;INFO&amp;quot;,&amp;quot;fatal&amp;quot;,&amp;quot;error&amp;quot;,&amp;quot;warn&amp;quot;,&amp;quot;info&amp;quot;,&amp;quot;Fatal&amp;quot;,&amp;quot;Error&amp;quot;,&amp;quot;Warn&amp;quot;,&amp;quot;Info&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正常用于日志级别的选择，比如上面只是采集包含这些字段的日志，其实也就是INFO级别的日志的采集。当然还是使用exclude_lines，不包含，和白名单黑名单一样的概念。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;资源限制&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;logging.level: debug    日志级别
max_procs: 2            cpu核数限制

queue:
      mem:
        events: 32768               pipeline队列长度
        flush.min_events: 1024
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;采集配置&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;close_eof: false
close_inactive: 5m（5分钟没有活跃，就会停止采集）
close_removed: false
close_renamed: false
ignore_older: 48h（即将开启的采集文件如果大于48H，就不要采集了）
# State options
clean_removed: true
clean_inactive: 72h（如果文件72h没有活跃就删除采集记录）
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;输出配置&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;output.kafka:
      topic: &amp;quot;%{[topic]}&amp;quot;
      version: &amp;quot;0.8.2.2&amp;quot;
      codec.format:
        ignoreNotFound: true
        string: &#39;%{[message]}&#39;
      metadata:
        retry.max: 2
        full: true
      worker: 10（The number of concurrent load-balanced Kafka output workers.）
      channel_buffer_size: 30000（每一个连接可以缓存消息的长度，默认是256）
      ##bulk_max_size: 20480（一次发送kafka请求最多的事件数量，默认是2048）
      #keep_alive: 0（是否保持连接，默认0，不保持）
      ##required_acks: 0（代表kafka是否需要等待回复，有1，0，-1，默认是1，需要等待主节点回复）
      compression: none（代表压缩级别，none代表不压缩，默认压缩是gzip）
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;更多详细的配置可以去查看完整的配置文件说明。&lt;/p&gt;

&lt;h3 id=&#34;启动&#34;&gt;启动&lt;/h3&gt;

&lt;p&gt;调试模式下采用：终端启动（退出终端或 ctrl+c 会退出运行）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./filebeat -e -c filebeat.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;线上环境配合 error 级别使用：以后台守护进程启动启动 filebeats&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nohup ./filebeat -e -c filebeat.yml &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;零输出启动（不推荐）：将所有标准输出及标准错误输出到/dev/null空设备，即没有任何输出信息。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nohup ./filebeat -e -c filebeat.yml &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;停止运行 FileBeat 进程&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ps -ef | grep filebeat
Kill -9 线程号
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;特性&#34;&gt;特性&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;采集路径可以使用正则表达式，来采集当前目录下所有的文件，包括子目录下，比如/k8s_log/*&lt;em&gt;/&lt;/em&gt;.log*&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;可以动态加载，可以在配置文件中配置reload的时间，filebeat本身自动加载，但是这个加载不能更新output&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;filebeat本身日志支持备份切换，默认一个文件10M，保留8个文件。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;filebaet支持句柄保持和checkpoint功能。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;filebeat输出到kafka可以不支持多个kafka集群，可以改造多pipeline来发送到不同的Kafka集群。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;原理&#34;&gt;原理&lt;/h2&gt;

&lt;h3 id=&#34;filebeat创建一个beater&#34;&gt;filebeat创建一个beater&lt;/h3&gt;

&lt;p&gt;filebaet创建了一个beater实例启动&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.启动了一个Crawler，用于

&lt;ul&gt;
&lt;li&gt;1.启动静态的 input (写在主配置里的)&lt;/li&gt;
&lt;li&gt;2.启动 reloader，动态的 input 由 reloader 管理。&lt;/li&gt;
&lt;li&gt;3.启动Registrar&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2.每个input又启动了Harvester，Harvester就是负责采集日志&lt;/li&gt;
&lt;li&gt;3.Harvester 连接 pipeline 时，调用 outlet factory 创建一个 outleter，Outleter 封装了 pipeline 的 producer，调用 outleter OnEvent 方法发送数据到 pipeline&lt;/li&gt;
&lt;li&gt;4.Registrar 负责 checkpoint 文件的更新&lt;/li&gt;
&lt;li&gt;5.启动Pipeline 模块，Pipeline 是一个大的功能模块，包含 &lt;code&gt;queue&lt;/code&gt;, &lt;code&gt;outputController&lt;/code&gt;, &lt;code&gt;consumer&lt;/code&gt;, &lt;code&gt;output&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;1.Queue (memqueue)
真正的 queue 对象时 Broker。创建 broker 时启动事件循环，负责处理 publish 和 consume 等各种请求

&lt;ul&gt;
&lt;li&gt;创建 broker&lt;/li&gt;
&lt;li&gt;事件循环&lt;/li&gt;
&lt;li&gt;Consumer&lt;/li&gt;
&lt;li&gt;Producer 真实创建的是 ackProducer&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2.Output Controller
负责管理 consumer。Consumer 负责从 queue 中获取 batch，然后发送到 workQueue(chan publisher.Batch)。&lt;/li&gt;
&lt;li&gt;3.Consumer
Consumer 会启动多个 outputWorker。outputWorker 负责从 workQueue 获取 batch，然后调用 output client 的 Publish 方法发送出去。&lt;/li&gt;
&lt;li&gt;4.Retryer
Retry 负责重试发送失败的请求&lt;/li&gt;
&lt;li&gt;5.Output(kafka)
Connect 调用 sarama 库，创建一个 kafka AsyncProducer。连接时会启动两个循环，处理成功响应和失败响应。&lt;/li&gt;
&lt;li&gt;6.msgRef
msgRef 注入到发送给 AsyncProducer 的事件中。在处理响应的时候回调。如果成功就调用 batch.ACK()。失败就调用 batch.OnRetry 重试。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;核心代码模块&#34;&gt;核心代码模块&lt;/h3&gt;

&lt;h4 id=&#34;filebeat-1&#34;&gt;filebeat&lt;/h4&gt;

&lt;p&gt;beater 启动
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/filebeat/beater/filebeat.go#L273&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/filebeat/beater/filebeat.go#L273&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Crawler 启动时加载配置文件中的 inputs。启动 reloader，定期加载动态配置文件目录中的 inputs。启动Registrar，负责checkpoint
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/filebeat/crawler/crawler.go#L33&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/filebeat/crawler/crawler.go#L33&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;启动静态的 input (写在主配置里的)&lt;/li&gt;
&lt;li&gt;启动 reloader，动态的 input 由 reloader 管理&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;InputInput 是一个用来包装 &lt;code&gt;harvester&lt;/code&gt; 的数据结构，对外提供生命周期管理接口。Input 在建立起来时，会调用 pipeline 的 &lt;code&gt;ConnectWith&lt;/code&gt; 方法获取一个 client，用于发送 events。
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/filebeat/input/input.go#L35&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/filebeat/input/input.go#L35&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Harvester
负责采集日志
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/filebeat/input/log/harvester.go#L88&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/filebeat/input/log/harvester.go#L88&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Outleter：
Harvester 连接 pipeline 时，调用 outlet factory 创建一个 outleter
Outleter 封装了 pipeline 的 producer，调用 outleter OnEvent 方法发送数据到 pipeline&lt;/p&gt;

&lt;p&gt;Outleter 创建
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/filebeat/channel/factory.go#L70&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/filebeat/channel/factory.go#L70&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Registrar
负责 checkpoint 文件的更新
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/filebeat/registrar/registrar.go#L19&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/filebeat/registrar/registrar.go#L19&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;libbeat&#34;&gt;Libbeat&lt;/h4&gt;

&lt;p&gt;Pipeline 模块启动
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/module.go#L30&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/module.go#L30&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;加载 output &lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/module.go#L85&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/module.go#L85&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Pipeline
Pipeline 包含 queue, output controller, consumer, output&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/pipeline.go#L135&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/pipeline.go#L135&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Output Controller

&lt;ul&gt;
&lt;li&gt;负责管理 consumer。Consumer 负责从 queue 中获取 batch，然后发送到 workQueue(chan publisher.Batch)。&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/controller.go#L13&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/controller.go#L13&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Consumer

&lt;ul&gt;
&lt;li&gt;Consumer 会启动多个 outputWorker。outputWorker 负责从 workQueue 获取 batch，然后调用 output client 的 Publish 方法发送出去。
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/consumer.go#L43&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/consumer.go#L43&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Retryer

&lt;ul&gt;
&lt;li&gt;Retry 负责重试发送失败的请求
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/retry.go#L14&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/pipeline/retry.go#L14&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Output(kafka)

&lt;ul&gt;
&lt;li&gt;创建 &lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/libbeat/outputs/kafka/kafka.go#L114&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/libbeat/outputs/kafka/kafka.go#L114&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Connect
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/libbeat/outputs/kafka/client.go#L68&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/libbeat/outputs/kafka/client.go#L68&lt;/a&gt;
调用 sarama 库，创建一个 kafka AsyncProducer。连接时会启动两个循环，处理成功响应和失败响应。&lt;/li&gt;
&lt;li&gt;msgRef
msgRef 注入到发送给 AsyncProducer 的事件中。在处理响应的时候回调。如果成功就调用 batch.ACK()。失败就调用 batch.OnRetry 重试。
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/libbeat/outputs/kafka/client.go#L222&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/libbeat/outputs/kafka/client.go#L222&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Queue (memqueue)
真正的 queue 对象时 Broker。创建 broker 时启动事件循环，负责处理 publish 和 consume 等各种请求&lt;/li&gt;
&lt;li&gt;创建 broker
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/broker.go#L63&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/broker.go#L63&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;事件循环
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/eventloop.go#L30&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/eventloop.go#L30&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Consumer
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/consume.go#L12&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/consume.go#L12&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Producer
真实创建的是 ackProducer
&lt;a href=&#34;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/produce.go#L39&#34;&gt;https://github.com/elastic/beats/blob/v6.3.2/libbeat/publisher/queue/memqueue/produce.go#L39&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;工作机制:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;队列容量为 &lt;code&gt;Events&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;当队列中的 events 数量大于 &lt;code&gt;FlushMinEvents&lt;/code&gt; 开始 flush&lt;/li&gt;
&lt;li&gt;当队列中有 events 并且离上一次 flush 过了 &lt;code&gt;FlushTimeout&lt;/code&gt; 时间，开始 flush&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这边简单梳理了filebeat的模块，核心的原理包括一些beats的原理可以看我写的另一篇&lt;a href=&#34;https://kingjcy.github.io/post/monitor/log/collect/filebeat/filebeat-principle/&#34;&gt;filebeat原理&lt;/a&gt;。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>监控日志系列---- Filebeat原理</title>
          <link>https://kingjcy.github.io/post/monitor/log/collect/filebeat/filebeat-principle/</link>
          <pubDate>Sun, 08 Jul 2018 19:45:30 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/monitor/log/collect/filebeat/filebeat-principle/</guid>
          <description>&lt;p&gt;Filebeat 是使用 Golang 实现的轻量型日志采集器，也是 Elasticsearch stack 里面的一员。本质上是一个 agent，可以安装在各个节点上，根据配置读取对应位置的日志，并上报到相应的地方去。&lt;/p&gt;

&lt;p&gt;filebeat源码归属于beats项目，而beats项目的设计初衷是为了采集各类的数据，所以beats抽象出了一个libbeat库，基于libbeat我们可以快速的开发实现一个采集的工具，除了filebeat，还有像metricbeat、packetbeat等官方的项目也是在beats工程中。libbeat已经实现了内存缓存队列memqueue、几种output日志发送客户端，数据的过滤处理processor,配置解析、日志打印、事件处理和发送等通用功能，而filebeat只需要实现日志文件的读取等和日志相关的逻辑即可。&lt;/p&gt;

&lt;h1 id=&#34;beats&#34;&gt;beats&lt;/h1&gt;

&lt;p&gt;对于任一种beats来说，主要逻辑都包含两个部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;收集数据并转换成事件&lt;/li&gt;
&lt;li&gt;发送事件到指定的输出&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中第二点已由libbeat实现，因此各个beats实际只需要关心如何收集数据并生成事件后发送给libbeat的Publisher。&lt;/p&gt;

&lt;h1 id=&#34;filebeat整体架构&#34;&gt;filebeat整体架构&lt;/h1&gt;

&lt;h2 id=&#34;架构图&#34;&gt;架构图&lt;/h2&gt;

&lt;p&gt;下图是 Filebeat 官方提供的架构图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/filebeat.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;下图是看代码的一些模块组合&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/filebeat1.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;其实我个人觉得这一幅图是最形象的说明了filebeat的功能&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/filebeat2.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;模块&#34;&gt;模块&lt;/h2&gt;

&lt;p&gt;除了图中提到的各个模块，整个 filebeat 主要包含以下重要模块：&lt;/p&gt;

&lt;p&gt;1.filebeat主要模块&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Crawler: 负责管理和启动各个Input,管理所有Input收集数据并发送事件到libbeat的Publisher
Input: 负责管理和解析输入源的信息，以及为每个文件启动 Harvester。可由配置文件指定输入源信息。
    Harvester: 负责读取一个文件的数据,对应一个输入源，是收集数据的实际工作者。配置中，一个具体的Input可以包含多个输入源（Harvester）
module: 简化了一些常见程序日志（比如nginx日志）收集、解析、可视化（kibana dashboard）配置项
    fileset: module下具体的一种Input定义（比如nginx包括access和error log），包含：
        1）输入配置；
        2）es ingest node pipeline定义；
        3）事件字段定义；
        4）示例kibana dashboard
Registrar：接收libbeat反馈回来的ACK, 作相应的持久化，管理记录每个文件处理状态，包括偏移量、文件名等信息。当 Filebeat 启动时，会从 Registrar 恢复文件处理状态。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.libbeat主要模块&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Pipeline（publisher）: 负责管理缓存、Harvester 的信息写入以及 Output 的消费等，是 Filebeat 最核心的组件。
    client: 提供Publish接口让filebeat将事件发送到Publisher。在发送到队列之前，内部会先调用processors（包括input 内部的processors和全局processors）进行处理。
    processor: 事件处理器，可对事件按照配置中的条件进行各种处理（比如删除事件、保留指定字段，过滤添加字段，多行合并等）。配置项
    queue: 事件队列，有memqueue（基于内存）和spool（基于磁盘文件）两种实现。配置项
    outputs: 事件的输出端，比如ES、Logstash、kafka等。配置项
    acker: 事件确认回调，在事件发送成功后进行回调
autodiscover：用于自动发现容器并将其作为输入源
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;filebeat 的整个生命周期，几个组件共同协作，完成了日志从采集到上报的整个过程。&lt;/p&gt;

&lt;h1 id=&#34;基本原理-源码解析&#34;&gt;基本原理（源码解析）&lt;/h1&gt;

&lt;h2 id=&#34;文件目录组织&#34;&gt;文件目录组织&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;├── autodiscover        # 包含filebeat的autodiscover适配器（adapter），当autodiscover发现新容器时创建对应类型的输入
├── beater              # 包含与libbeat库交互相关的文件
├── channel             # 包含filebeat输出到pipeline相关的文件
├── config              # 包含filebeat配置结构和解析函数
├── crawler             # 包含Crawler结构和相关函数
├── fileset             # 包含module和fileset相关的结构
├── harvester           # 包含Harvester接口定义、Reader接口及实现等
├── input               # 包含所有输入类型的实现（比如: log, stdin, syslog）
├── inputsource         # 在syslog输入类型中用于读取tcp或udp syslog
├── module              # 包含各module和fileset配置
├── modules.d           # 包含各module对应的日志路径配置文件，用于修改默认路径
├── processor           # 用于从容器日志的事件字段source中提取容器id
├── prospector          # 包含旧版本的输入结构Prospector，现已被Input取代
├── registrar           # 包含Registrar结构和方法
└── util                # 包含beat事件和文件状态的通用结构Data
└── ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在这些目录中还有一些重要的文件&lt;/p&gt;

&lt;p&gt;/beater：包含与libbeat库交互相关的文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;acker.go: 包含在libbeat设置的ack回调函数，事件成功发送后被调用
channels.go: 包含在ack回调函数中被调用的记录者（logger），包括：
    registrarLogger: 将已确认事件写入registrar运行队列
    finishedLogger: 统计已确认事件数量
filebeat.go: 包含实现了beater接口的filebeat结构，接口函数包括：
    New：创建了filebeat实例
    Run：运行filebeat
    Stop: 停止filebeat运行
signalwait.go：基于channel实现的等待函数，在filebeat中用于：
    等待fileebat结束
    等待确认事件被写入registry文件
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;/channel：filebeat输出（到pipeline）相关的文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;factory.go: 包含OutletFactory，用于创建输出器Outleter对象
interface.go: 定义输出接口Outleter
outlet.go: 实现Outleter，封装了libbeat的pipeline client，其在harvester中被调用用于将事件发送给pipeline
util.go: 定义ack回调的参数结构data，包含beat事件和文件状态
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;/input：包含Input接口及各种输入类型的Input和Harvester实现&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Input：对应配置中的一个Input项，同个Input下可包含多个输入源（比如文件）
Harvester：每个输入源对应一个Harvester，负责实际收集数据、并发送事件到pipeline
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;/harvester：包含Harvester接口定义、Reader接口及实现等&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;forwarder.go: Forwarder结构（包含outlet）定义，用于转发事件
harvester.go: Harvester接口定义，具体实现则在/input目录下
registry.go: Registry结构，用于在Input中管理多个Harvester（输入源）的启动和停止
source.go: Source接口定义，表示输入源。目前仅有Pipe一种实现（包含os.File），用在log、stdin和docker输入类型中。btw，这三种输入类型都是用的log input的实现。
/reader目录: Reader接口定义和各种Reader实现
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;重要数据结构&#34;&gt;重要数据结构&lt;/h2&gt;

&lt;p&gt;beats通用事件结构(libbeat/beat/event.go):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Event struct {
    Timestamp time.Time     // 收集日志时记录的时间戳，对应es文档中的@timestamp字段
    Meta      common.MapStr // meta信息，outpus可选的将其作为事件字段输出。比如输出为es且指定了pipeline时，其pipeline id就被包含在此字段中
    Fields    common.MapStr // 默认输出字段定义在field.yml，其他字段可以在通过fields配置项指定
    Private   interface{} // for beats private use
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Crawler(filebeat/crawler/crawler.go):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Crawler 负责抓取日志并发送到libbeat pipeline
type Crawler struct {
    inputs          map[uint64]*input.Runner // 包含所有输入的runner
    inputConfigs    []*common.Config
    out             channel.Factory
    wg              sync.WaitGroup
    InputsFactory   cfgfile.RunnerFactory
    ModulesFactory  cfgfile.RunnerFactory
    modulesReloader *cfgfile.Reloader
    inputReloader   *cfgfile.Reloader
    once            bool
    beatVersion     string
    beatDone        chan struct{}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;log类型Input(filebeat/input/log/input.go)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Input contains the input and its config
type Input struct {
    cfg           *common.Config
    config        config
    states        *file.States
    harvesters    *harvester.Registry   // 包含Input所有Harvester
    outlet        channel.Outleter      // Input共享的Publisher client
    stateOutlet   channel.Outleter
    done          chan struct{}
    numHarvesters atomic.Uint32
    meta          map[string]string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;log类型Harvester(filebeat/input/log/harvester.go):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Harvester struct {
    id     uuid.UUID
    config config
    source harvester.Source // the source being watched

    // shutdown handling
    done     chan struct{}
    stopOnce sync.Once
    stopWg   *sync.WaitGroup
    stopLock sync.Mutex

    // internal harvester state
    state  file.State
    states *file.States
    log    *Log

    // file reader pipeline
    reader          reader.Reader
    encodingFactory encoding.EncodingFactory
    encoding        encoding.Encoding

    // event/state publishing
    outletFactory OutletFactory
    publishState  func(*util.Data) bool

    onTerminate func()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Registrar(filebeat/registrar/registrar.go):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Registrar struct {
    Channel      chan []file.State
    out          successLogger
    done         chan struct{}
    registryFile string      // Path to the Registry File
    fileMode     os.FileMode // Permissions to apply on the Registry File
    wg           sync.WaitGroup

    states               *file.States // Map with all file paths inside and the corresponding state
    gcRequired           bool         // gcRequired is set if registry state needs to be gc&#39;ed before the next write
    gcEnabled            bool         // gcEnabled indictes the registry contains some state that can be gc&#39;ed in the future
    flushTimeout         time.Duration
    bufferedStateUpdates int
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;libbeat Pipeline(libbeat/publisher/pipeline/pipeline.go)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Pipeline struct {
    beatInfo beat.Info

    logger *logp.Logger
    queue  queue.Queue
    output *outputController

    observer observer

    eventer pipelineEventer

    // wait close support
    waitCloseMode    WaitCloseMode
    waitCloseTimeout time.Duration
    waitCloser       *waitCloser

    // pipeline ack
    ackMode    pipelineACKMode
    ackActive  atomic.Bool
    ackDone    chan struct{}
    ackBuilder ackBuilder // pipelineEventsACK
    eventSema  *sema

    processors pipelineProcessors
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;启动&#34;&gt;启动&lt;/h2&gt;

&lt;p&gt;filebeat启动流程图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/f1.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;每个 beat 的构建是独立的。从 filebeat 的入口文件filebeat/main.go可以看到，它向libbeat传递了名字、版本和构造函数来构造自身。跟着走到libbeat/beater/beater.go，我们可以看到程序的启动时的主要工作都是在这里完成的，包括命令行参数的处理、通用配置项的解析，以及最为重要的：调用象征一个beat的生命周期的若干方法&lt;/p&gt;

&lt;p&gt;我们来看filebeat的启动过程。&lt;/p&gt;

&lt;p&gt;1、执行root命令&lt;/p&gt;

&lt;p&gt;在filebeat/main.go文件中，main函数调用了cmd.RootCmd.Execute()，而RootCmd则是在cmd/root.go中被init函数初始化，其中就注册了filebeat.go:New函数以创建实现了beater接口的filebeat实例&lt;/p&gt;

&lt;p&gt;对于任意一个beats来说，都需要有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;实现Beater接口的具体Beater（如Filebeat）;&lt;/li&gt;
&lt;li&gt;创建该具体Beater的(New)函数。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;beater接口定义（beat/beat.go）：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Beater interface {
    // The main event loop. This method should block until signalled to stop by an
    // invocation of the Stop() method.
    Run(b *Beat) error

    // Stop is invoked to signal that the Run method should finish its execution.
    // It will be invoked at most once.
    Stop()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2、初始化和运行Filebeat&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建libbeat/cmd/instance/beat.go:Beat结构&lt;/li&gt;
&lt;li&gt;执行(*Beat).launch方法

&lt;ul&gt;
&lt;li&gt;(*Beat).Init() 初始化Beat：加载beats公共config&lt;/li&gt;
&lt;li&gt;(*Beat).createBeater&lt;/li&gt;
&lt;li&gt;registerTemplateLoading: 当输出为es时，注册加载es模板的回调函数&lt;/li&gt;
&lt;li&gt;pipeline.Load: 创建Pipeline：包含队列、事件处理器、输出等&lt;/li&gt;
&lt;li&gt;setupMetrics: 安装监控&lt;/li&gt;
&lt;li&gt;filebeat.New: 解析配置(其中输入配置包括配置文件中的Input和module Input)等&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;loadDashboards 加载kibana dashboard&lt;/li&gt;
&lt;li&gt;(*Filebeat).Run: 运行filebeat&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;3、Filebeat运行&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;设置加载es pipeline的回调函数&lt;/li&gt;
&lt;li&gt;初始化registrar和crawler&lt;/li&gt;
&lt;li&gt;设置事件完成的回调函数&lt;/li&gt;
&lt;li&gt;启动Registrar、启动Crawler、启动Autodiscover&lt;/li&gt;
&lt;li&gt;等待filebeat运行结束&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们再重代码看一下这个启动过程&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;main.go

    package main
    import (
        &amp;quot;os&amp;quot;
        &amp;quot;github.com/elastic/beats/filebeat/cmd&amp;quot;
    )
    func main() {
        if err := cmd.RootCmd.Execute(); err != nil {
            os.Exit(1)
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入到filebeat/cmd执行&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package cmd

import (
    &amp;quot;flag&amp;quot;

    &amp;quot;github.com/spf13/pflag&amp;quot;

    &amp;quot;github.com/elastic/beats/filebeat/beater&amp;quot;

    cmd &amp;quot;github.com/elastic/beats/libbeat/cmd&amp;quot;
)

// Name of this beat
var Name = &amp;quot;filebeat&amp;quot;

// RootCmd to handle beats cli
var RootCmd *cmd.BeatsRootCmd

func init() {
    var runFlags = pflag.NewFlagSet(Name, pflag.ExitOnError)
    runFlags.AddGoFlag(flag.CommandLine.Lookup(&amp;quot;once&amp;quot;))
    runFlags.AddGoFlag(flag.CommandLine.Lookup(&amp;quot;modules&amp;quot;))

    RootCmd = cmd.GenRootCmdWithRunFlags(Name, &amp;quot;&amp;quot;, beater.New, runFlags)
    RootCmd.PersistentFlags().AddGoFlag(flag.CommandLine.Lookup(&amp;quot;M&amp;quot;))
    RootCmd.TestCmd.Flags().AddGoFlag(flag.CommandLine.Lookup(&amp;quot;modules&amp;quot;))
    RootCmd.SetupCmd.Flags().AddGoFlag(flag.CommandLine.Lookup(&amp;quot;modules&amp;quot;))
    RootCmd.AddCommand(cmd.GenModulesCmd(Name, &amp;quot;&amp;quot;, buildModulesManager))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RootCmd 在这一句初始化&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RootCmd = cmd.GenRootCmdWithRunFlags(Name, &amp;quot;&amp;quot;, beater.New, runFlags)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;beater.New跟进去看到是filebeat.go，这个函数会在后面进行调用，来创建filebeat结构体，传递filebeat相关的配置。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func New(b beat.Beat, rawConfig common.Config) (beat.Beater, error) {...}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在进入GenRootCmdWithRunFlags方法，一路跟进去到GenRootCmdWithSettings，真正的初始化是在这个方法里面。&lt;/p&gt;

&lt;p&gt;忽略前面的一段初始化值方法，看到RunCmd的初始化在：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rootCmd.RunCmd = genRunCmd(settings, beatCreator, runFlags)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入getRunCmd，看到执行代码&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;err := instance.Run(settings, beatCreator)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;跟到\elastic\beats\libbeat\cmd\instance\beat.go的Run方法&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;b, err := NewBeat(name, idxPrefix, version)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里新建了beat结构体，同时将filebeat的New方法也传递了进来，就是参数beatCreator，我们可以看到在beat通过launch函数创建了filebeat结构体类型的beater&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;return b.launch(settings, bt)---&amp;gt;beater, err := b.createBeater(bt)---&amp;gt;beater, err := bt(&amp;amp;b.Beat, sub)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入launch后，还做了很多的事情&lt;/p&gt;

&lt;p&gt;1、还初始化了配置&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;err := b.InitWithSettings(settings)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2、&lt;a href=&#34;#pipeline初始化&#34;&gt;pipeline的初始化&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pipeline, err := pipeline.Load(b.Info,
        pipeline.Monitors{
            Metrics:   reg,
            Telemetry: monitoring.GetNamespace(&amp;quot;state&amp;quot;).GetRegistry(),
            Logger:    logp.L().Named(&amp;quot;publisher&amp;quot;),
        },
        b.Config.Pipeline,
        b.processing,
        b.makeOutputFactory(b.Config.Output),
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在launch的末尾，还调用了beater启动方法，也就是filebeat的run函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;return beater.Run(&amp;amp;b.Beat)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因为启动的是filebeat，我们到filebeat.go的Run方法&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (fb *Filebeat) Run(b *beat.Beat) error {
       var err error
       config := fb.config

       if !fb.moduleRegistry.Empty() {
              err = fb.loadModulesPipelines(b)
              if err != nil {
                     return err
              }
       }

       waitFinished := newSignalWait()
       waitEvents := newSignalWait()

       // count active events for waiting on shutdown
       wgEvents := &amp;amp;eventCounter{
              count: monitoring.NewInt(nil, &amp;quot;filebeat.events.active&amp;quot;),
              added: monitoring.NewUint(nil, &amp;quot;filebeat.events.added&amp;quot;),
              done:  monitoring.NewUint(nil, &amp;quot;filebeat.events.done&amp;quot;),
       }
       finishedLogger := newFinishedLogger(wgEvents)

       // Setup registrar to persist state
       registrar, err := registrar.New(config.RegistryFile, config.RegistryFilePermissions, config.RegistryFlush, finishedLogger)
       if err != nil {
              logp.Err(&amp;quot;Could not init registrar: %v&amp;quot;, err)
              return err
       }

       // Make sure all events that were published in
       registrarChannel := newRegistrarLogger(registrar)

       err = b.Publisher.SetACKHandler(beat.PipelineACKHandler{
              ACKEvents: newEventACKer(finishedLogger, registrarChannel).ackEvents,
       })
       if err != nil {
              logp.Err(&amp;quot;Failed to install the registry with the publisher pipeline: %v&amp;quot;, err)
              return err
       }

       outDone := make(chan struct{}) // outDone closes down all active pipeline connections
       crawler, err := crawler.New(
              channel.NewOutletFactory(outDone, wgEvents).Create,
              config.Inputs,
              b.Info.Version,
              fb.done,
              *once)
       if err != nil {
              logp.Err(&amp;quot;Could not init crawler: %v&amp;quot;, err)
              return err
       }

       // The order of starting and stopping is important. Stopping is inverted to the starting order.
       // The current order is: registrar, publisher, spooler, crawler
       // That means, crawler is stopped first.

       // Start the registrar
       err = registrar.Start()
       if err != nil {
              return fmt.Errorf(&amp;quot;Could not start registrar: %v&amp;quot;, err)
       }

       // Stopping registrar will write last state
       defer registrar.Stop()

       // Stopping publisher (might potentially drop items)
       defer func() {
              // Closes first the registrar logger to make sure not more events arrive at the registrar
              // registrarChannel must be closed first to potentially unblock (pretty unlikely) the publisher
              registrarChannel.Close()
              close(outDone) // finally close all active connections to publisher pipeline
       }()

       // Wait for all events to be processed or timeout
       defer waitEvents.Wait()

       // Create a ES connection factory for dynamic modules pipeline loading
       var pipelineLoaderFactory fileset.PipelineLoaderFactory
       if b.Config.Output.Name() == &amp;quot;elasticsearch&amp;quot; {
              pipelineLoaderFactory = newPipelineLoaderFactory(b.Config.Output.Config())
       } else {
              logp.Warn(pipelinesWarning)
       }

       if config.OverwritePipelines {
              logp.Debug(&amp;quot;modules&amp;quot;, &amp;quot;Existing Ingest pipelines will be updated&amp;quot;)
       }

       err = crawler.Start(b.Publisher, registrar, config.ConfigInput, config.ConfigModules, pipelineLoaderFactory, config.OverwritePipelines)
       if err != nil {
              crawler.Stop()
              return err
       }

       // If run once, add crawler completion check as alternative to done signal
       if *once {
              runOnce := func() {
                     logp.Info(&amp;quot;Running filebeat once. Waiting for completion ...&amp;quot;)
                     crawler.WaitForCompletion()
                     logp.Info(&amp;quot;All data collection completed. Shutting down.&amp;quot;)
              }
              waitFinished.Add(runOnce)
       }

       // Register reloadable list of inputs and modules
       inputs := cfgfile.NewRunnerList(management.DebugK, crawler.InputsFactory, b.Publisher)
       reload.Register.MustRegisterList(&amp;quot;filebeat.inputs&amp;quot;, inputs)

       modules := cfgfile.NewRunnerList(management.DebugK, crawler.ModulesFactory, b.Publisher)
       reload.Register.MustRegisterList(&amp;quot;filebeat.modules&amp;quot;, modules)

       var adiscover *autodiscover.Autodiscover
       if fb.config.Autodiscover != nil {
              adapter := fbautodiscover.NewAutodiscoverAdapter(crawler.InputsFactory, crawler.ModulesFactory)
              adiscover, err = autodiscover.NewAutodiscover(&amp;quot;filebeat&amp;quot;, b.Publisher, adapter, config.Autodiscover)
              if err != nil {
                     return err
              }
       }
       adiscover.Start()

       // Add done channel to wait for shutdown signal
       waitFinished.AddChan(fb.done)
       waitFinished.Wait()

       // Stop reloadable lists, autodiscover -&amp;gt; Stop crawler -&amp;gt; stop inputs -&amp;gt; stop harvesters
       // Note: waiting for crawlers to stop here in order to install wgEvents.Wait
       //       after all events have been enqueued for publishing. Otherwise wgEvents.Wait
       //       or publisher might panic due to concurrent updates.
       inputs.Stop()
       modules.Stop()
       adiscover.Stop()
       crawler.Stop()

       timeout := fb.config.ShutdownTimeout
       // Checks if on shutdown it should wait for all events to be published
       waitPublished := fb.config.ShutdownTimeout &amp;gt; 0 || *once
       if waitPublished {
              // Wait for registrar to finish writing registry
              waitEvents.Add(withLog(wgEvents.Wait,
                     &amp;quot;Continue shutdown: All enqueued events being published.&amp;quot;))
              // Wait for either timeout or all events having been ACKed by outputs.
              if fb.config.ShutdownTimeout &amp;gt; 0 {
                     logp.Info(&amp;quot;Shutdown output timer started. Waiting for max %v.&amp;quot;, timeout)
                     waitEvents.Add(withLog(waitDuration(timeout),
                            &amp;quot;Continue shutdown: Time out waiting for events being published.&amp;quot;))
              } else {
                     waitEvents.AddChan(fb.done)
              }
       }

       return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;构造了&lt;a href=&#34;#registry和ack-机制&#34;&gt;registrar&lt;/a&gt;和crawler，用于监控文件状态变更和数据采集。然后&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;err = crawler.Start(b.Publisher, registrar, config.ConfigInput, config.ConfigModules, pipelineLoaderFactory, config.OverwritePipelines)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;crawler开始启动采集数据&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for _, inputConfig := range c.inputConfigs {
       err := c.startInput(pipeline, inputConfig, r.GetStates())
       if err != nil {
              return err
       }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;crawler的Start方法里面根据每个配置的输入调用一次startInput&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Crawler) startInput(
       pipeline beat.Pipeline,
       config *common.Config,
       states []file.State,
) error {
       if !config.Enabled() {
              return nil
       }

       connector := channel.ConnectTo(pipeline, c.out)
       p, err := input.New(config, connector, c.beatDone, states, nil)
       if err != nil {
              return fmt.Errorf(&amp;quot;Error in initing input: %s&amp;quot;, err)
       }
       p.Once = c.once

       if _, ok := c.inputs[p.ID]; ok {
              return fmt.Errorf(&amp;quot;Input with same ID already exists: %d&amp;quot;, p.ID)
       }

       c.inputs[p.ID] = p

       p.Start()

       return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;根据配置的input，构造log/input&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (p *Input) Run() {
       logp.Debug(&amp;quot;input&amp;quot;, &amp;quot;Start next scan&amp;quot;)

       // TailFiles is like ignore_older = 1ns and only on startup
       if p.config.TailFiles {
              ignoreOlder := p.config.IgnoreOlder

              // Overwrite ignore_older for the first scan
              p.config.IgnoreOlder = 1
              defer func() {
                     // Reset ignore_older after first run
                     p.config.IgnoreOlder = ignoreOlder
                     // Disable tail_files after the first run
                     p.config.TailFiles = false
              }()
       }
       p.scan()

       // It is important that a first scan is run before cleanup to make sure all new states are read first
       if p.config.CleanInactive &amp;gt; 0 || p.config.CleanRemoved {
              beforeCount := p.states.Count()
              cleanedStates, pendingClean := p.states.Cleanup()
              logp.Debug(&amp;quot;input&amp;quot;, &amp;quot;input states cleaned up. Before: %d, After: %d, Pending: %d&amp;quot;,
                     beforeCount, beforeCount-cleanedStates, pendingClean)
       }

       // Marking removed files to be cleaned up. Cleanup happens after next scan to make sure all states are updated first
       if p.config.CleanRemoved {
              for _, state := range p.states.GetStates() {
                     // os.Stat will return an error in case the file does not exist
                     stat, err := os.Stat(state.Source)
                     if err != nil {
                            if os.IsNotExist(err) {
                                   p.removeState(state)
                                   logp.Debug(&amp;quot;input&amp;quot;, &amp;quot;Remove state for file as file removed: %s&amp;quot;, state.Source)
                            } else {
                                   logp.Err(&amp;quot;input state for %s was not removed: %s&amp;quot;, state.Source, err)
                            }
                     } else {
                            // Check if existing source on disk and state are the same. Remove if not the case.
                            newState := file.NewState(stat, state.Source, p.config.Type, p.meta)
                            if !newState.FileStateOS.IsSame(state.FileStateOS) {
                                   p.removeState(state)
                                   logp.Debug(&amp;quot;input&amp;quot;, &amp;quot;Remove state for file as file removed or renamed: %s&amp;quot;, state.Source)
                            }
                     }
              }
       }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;input开始根据配置的输入路径扫描所有符合的文件，并启动harvester&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (p *Input) scan() {
       var sortInfos []FileSortInfo
       var files []string

       paths := p.getFiles()

       var err error

       if p.config.ScanSort != &amp;quot;&amp;quot; {
              sortInfos, err = getSortedFiles(p.config.ScanOrder, p.config.ScanSort, getSortInfos(paths))
              if err != nil {
                     logp.Err(&amp;quot;Failed to sort files during scan due to error %s&amp;quot;, err)
              }
       }

       if sortInfos == nil {
              files = getKeys(paths)
       }

       for i := 0; i &amp;lt; len(paths); i++ {

              var path string
              var info os.FileInfo

              if sortInfos == nil {
                     path = files[i]
                     info = paths[path]
              } else {
                     path = sortInfos[i].path
                     info = sortInfos[i].info
              }

              select {
              case &amp;lt;-p.done:
                     logp.Info(&amp;quot;Scan aborted because input stopped.&amp;quot;)
                     return
              default:
              }

              newState, err := getFileState(path, info, p)
              if err != nil {
                     logp.Err(&amp;quot;Skipping file %s due to error %s&amp;quot;, path, err)
              }

              // Load last state
              lastState := p.states.FindPrevious(newState)

              // Ignores all files which fall under ignore_older
              if p.isIgnoreOlder(newState) {
                     err := p.handleIgnoreOlder(lastState, newState)
                     if err != nil {
                            logp.Err(&amp;quot;Updating ignore_older state error: %s&amp;quot;, err)
                     }
                     continue
              }

              // Decides if previous state exists
              if lastState.IsEmpty() {
                     logp.Debug(&amp;quot;input&amp;quot;, &amp;quot;Start harvester for new file: %s&amp;quot;, newState.Source)
                     err := p.startHarvester(newState, 0)
                     if err == errHarvesterLimit {
                            logp.Debug(&amp;quot;input&amp;quot;, harvesterErrMsg, newState.Source, err)
                            continue
                     }
                     if err != nil {
                            logp.Err(harvesterErrMsg, newState.Source, err)
                     }
              } else {
                     p.harvestExistingFile(newState, lastState)
              }
       }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在harvest的Run看到一个死循环读取message，预处理之后交由forwarder发送到目标输出&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;message, err := h.reader.Next()
h.sendEvent(data, forwarder)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此，整个filebeat的启动到发送数据就理完了&lt;/p&gt;

&lt;h2 id=&#34;配置文件解析&#34;&gt;配置文件解析&lt;/h2&gt;

&lt;p&gt;在libbeat中实现了通用的配置文件解析，在启动的过程中，在每次createbeater时候就会进行config。&lt;/p&gt;

&lt;p&gt;调用 cfgfile.Load方法解析到cfg对象，进入load方法&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Load(path string, beatOverrides *common.Config) (*common.Config, error) {
       var config *common.Config
       var err error

       cfgpath := GetPathConfig()

       if path == &amp;quot;&amp;quot; {
              list := []string{}
              for _, cfg := range configfiles.List() {
                     if !filepath.IsAbs(cfg) {
                            list = append(list, filepath.Join(cfgpath, cfg))
                     } else {
                            list = append(list, cfg)
                     }
              }
              config, err = common.LoadFiles(list...)
       } else {
              if !filepath.IsAbs(path) {
                     path = filepath.Join(cfgpath, path)
              }
              config, err = common.LoadFile(path)
       }
       if err != nil {
              return nil, err
       }

       if beatOverrides != nil {
              config, err = common.MergeConfigs(
                     defaults,
                     beatOverrides,
                     config,
                     overwrites,
              )
              if err != nil {
                     return nil, err
              }
       } else {
              config, err = common.MergeConfigs(
                     defaults,
                     config,
                     overwrites,
              )
       }

       config.PrintDebugf(&amp;quot;Complete configuration loaded:&amp;quot;)
       return config, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果不输入配置文件，使用configfiles定义文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;configfiles = common.StringArrFlag(nil, &amp;quot;c&amp;quot;, &amp;quot;beat.yml&amp;quot;, &amp;quot;Configuration file, relative to path.config&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果输入配置文件进入else分支&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;config, err = common.LoadFile(path)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;根据配置文件构造config对象，使用的是yaml解析库。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c, err := yaml.NewConfigWithFile(path, configOpts...)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pipeline初始化&#34;&gt;pipeline初始化&lt;/h2&gt;

&lt;p&gt;pipeline的初始化是在libbeat的创建对于的filebeat 的结构体的时候进行的在func (b *Beat) createBeater(bt beat.Creator) (beat.Beater, error) {}函数中&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pipeline, err := pipeline.Load(b.Info,
    pipeline.Monitors{
        Metrics:   reg,
        Telemetry: monitoring.GetNamespace(&amp;quot;state&amp;quot;).GetRegistry(),
        Logger:    logp.L().Named(&amp;quot;publisher&amp;quot;),
    },
    b.Config.Pipeline,
    b.processing,
    b.makeOutputFactory(b.Config.Output),
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们来看看load函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Load uses a Config object to create a new complete Pipeline instance with
// configured queue and outputs.
func Load(
    beatInfo beat.Info,
    monitors Monitors,
    config Config,
    processors processing.Supporter,
    makeOutput func(outputs.Observer) (string, outputs.Group, error),
) (*Pipeline, error) {
    log := monitors.Logger
    if log == nil {
        log = logp.L()
    }

    if publishDisabled {
        log.Info(&amp;quot;Dry run mode. All output types except the file based one are disabled.&amp;quot;)
    }

    name := beatInfo.Name
    settings := Settings{
        WaitClose:     0,
        WaitCloseMode: NoWaitOnClose,
        Processors:    processors,
    }

    queueBuilder, err := createQueueBuilder(config.Queue, monitors)
    if err != nil {
        return nil, err
    }

    out, err := loadOutput(monitors, makeOutput)
    if err != nil {
        return nil, err
    }

    p, err := New(beatInfo, monitors, queueBuilder, out, settings)
    if err != nil {
        return nil, err
    }

    log.Infof(&amp;quot;Beat name: %s&amp;quot;, name)
    return p, err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要是初始化queue，output，并创建对应的pipeline。&lt;/p&gt;

&lt;p&gt;1、queue&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;queueBuilder, err := createQueueBuilder(config.Queue, monitors)
    if err != nil {
        return nil, err
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入createQueueBuilder&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func createQueueBuilder(
    config common.ConfigNamespace,
    monitors Monitors,
) (func(queue.Eventer) (queue.Queue, error), error) {
    queueType := defaultQueueType
    if b := config.Name(); b != &amp;quot;&amp;quot; {
        queueType = b
    }

    queueFactory := queue.FindFactory(queueType)
    if queueFactory == nil {
        return nil, fmt.Errorf(&amp;quot;&#39;%v&#39; is no valid queue type&amp;quot;, queueType)
    }

    queueConfig := config.Config()
    if queueConfig == nil {
        queueConfig = common.NewConfig()
    }

    if monitors.Telemetry != nil {
        queueReg := monitors.Telemetry.NewRegistry(&amp;quot;queue&amp;quot;)
        monitoring.NewString(queueReg, &amp;quot;name&amp;quot;).Set(queueType)
    }

    return func(eventer queue.Eventer) (queue.Queue, error) {
        return queueFactory(eventer, monitors.Logger, queueConfig)
    }, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;根据queueType（有默认类型mem）找到创建的方法，一般mem就是&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func init() {
    queue.RegisterType(&amp;quot;mem&amp;quot;, create)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看一下create函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func create(eventer queue.Eventer, logger *logp.Logger, cfg *common.Config) (queue.Queue, error) {
    config := defaultConfig
    if err := cfg.Unpack(&amp;amp;config); err != nil {
        return nil, err
    }

    if logger == nil {
        logger = logp.L()
    }

    return NewBroker(logger, Settings{
        Eventer:        eventer,
        Events:         config.Events,
        FlushMinEvents: config.FlushMinEvents,
        FlushTimeout:   config.FlushTimeout,
    }), nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;创建了一个broker&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// NewBroker creates a new broker based in-memory queue holding up to sz number of events.
// If waitOnClose is set to true, the broker will block on Close, until all internal
// workers handling incoming messages and ACKs have been shut down.
func NewBroker(
    logger logger,
    settings Settings,
) *Broker {
    // define internal channel size for producer/client requests
    // to the broker
    chanSize := 20

    var (
        sz           = settings.Events
        minEvents    = settings.FlushMinEvents
        flushTimeout = settings.FlushTimeout
    )

    if minEvents &amp;lt; 1 {
        minEvents = 1
    }
    if minEvents &amp;gt; 1 &amp;amp;&amp;amp; flushTimeout &amp;lt;= 0 {
        minEvents = 1
        flushTimeout = 0
    }
    if minEvents &amp;gt; sz {
        minEvents = sz
    }

    if logger == nil {
        logger = logp.NewLogger(&amp;quot;memqueue&amp;quot;)
    }

    b := &amp;amp;Broker{
        done:   make(chan struct{}),
        logger: logger,

        // broker API channels
        events:    make(chan pushRequest, chanSize),
        requests:  make(chan getRequest),
        pubCancel: make(chan producerCancelRequest, 5),

        // internal broker and ACK handler channels
        acks:          make(chan int),
        scheduledACKs: make(chan chanList),

        waitOnClose: settings.WaitOnClose,

        eventer: settings.Eventer,
    }

    var eventLoop interface {
        run()
        processACK(chanList, int)
    }

    if minEvents &amp;gt; 1 {
        eventLoop = newBufferingEventLoop(b, sz, minEvents, flushTimeout)
    } else {
        eventLoop = newDirectEventLoop(b, sz)
    }

    b.bufSize = sz
    ack := newACKLoop(b, eventLoop.processACK)

    b.wg.Add(2)
    go func() {
        defer b.wg.Done()
        eventLoop.run()
    }()
    go func() {
        defer b.wg.Done()
        ack.run()
    }()

    return b
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;broker就是我们的queue，同时创建了一个eventLoop（根据是否有缓存创建不同的结构体，根据配置min_event是否大于1创建BufferingEventLoop或者DirectEventLoop，一般默认都是BufferingEventLoop，即带缓冲的队列。）和ack，调用他们的run函数进行监听&lt;/p&gt;

&lt;p&gt;这边特别说明一下eventLoop的new，我们看带缓存的newBufferingEventLoop&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newBufferingEventLoop(b *Broker, size int, minEvents int, flushTimeout time.Duration) *bufferingEventLoop {
    l := &amp;amp;bufferingEventLoop{
        broker:       b,
        maxEvents:    size,
        minEvents:    minEvents,
        flushTimeout: flushTimeout,

        events:    b.events,
        get:       nil,
        pubCancel: b.pubCancel,
        acks:      b.acks,
    }
    l.buf = newBatchBuffer(l.minEvents)

    l.timer = time.NewTimer(flushTimeout)
    if !l.timer.Stop() {
        &amp;lt;-l.timer.C
    }

    return l
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;把broker的值很多都赋给了bufferingEventLoop，不知道为什么这么做。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go func() {
    defer b.wg.Done()
    eventLoop.run()
}()
go func() {
    defer b.wg.Done()
    ack.run()
}()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们看一下有缓存的事件处理&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (l *bufferingEventLoop) run() {
    var (
        broker = l.broker
    )

    for {
        select {
        case &amp;lt;-broker.done:
            return

        case req := &amp;lt;-l.events: // producer pushing new event
            l.handleInsert(&amp;amp;req)

        case req := &amp;lt;-l.pubCancel: // producer cancelling active events
            l.handleCancel(&amp;amp;req)

        case req := &amp;lt;-l.get: // consumer asking for next batch
            l.handleConsumer(&amp;amp;req)

        case l.schedACKS &amp;lt;- l.pendingACKs:
            l.schedACKS = nil
            l.pendingACKs = chanList{}

        case count := &amp;lt;-l.acks:
            l.handleACK(count)

        case &amp;lt;-l.idleC:
            l.idleC = nil
            l.timer.Stop()
            if l.buf.length() &amp;gt; 0 {
                l.flushBuffer()
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这里就可以监听队列中的事件了，BufferingEventLoop是一个实现了Broker、带有各种channel的结构，主要用于将日志发送至consumer消费。 BufferingEventLoop的run方法中，同样是一个无限循环，这里可以认为是一个日志事件的调度中心。&lt;/p&gt;

&lt;p&gt;再来看看ack的调度&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (l *ackLoop) run() {
    var (
        // log = l.broker.logger

        // Buffer up acked event counter in acked. If acked &amp;gt; 0, acks will be set to
        // the broker.acks channel for sending the ACKs while potentially receiving
        // new batches from the broker event loop.
        // This concurrent bidirectionally communication pattern requiring &#39;select&#39;
        // ensures we can not have any deadlock between the event loop and the ack
        // loop, as the ack loop will not block on any channel
        acked int
        acks  chan int
    )

    for {
        select {
        case &amp;lt;-l.broker.done:
            // TODO: handle pending ACKs?
            // TODO: panic on pending batches?
            return

        case acks &amp;lt;- acked:
            acks, acked = nil, 0

        case lst := &amp;lt;-l.broker.scheduledACKs:
            count, events := lst.count()
            l.lst.concat(&amp;amp;lst)

            // log.Debug(&amp;quot;ACK List:&amp;quot;)
            // for current := l.lst.head; current != nil; current = current.next {
            //  log.Debugf(&amp;quot;  ack entry(seq=%v, start=%v, count=%v&amp;quot;,
            //      current.seq, current.start, current.count)
            // }

            l.batchesSched += uint64(count)
            l.totalSched += uint64(events)

        case &amp;lt;-l.sig:
            acked += l.handleBatchSig()
            if acked &amp;gt; 0 {
                acks = l.broker.acks
            }
        }

        // log.Debug(&amp;quot;ackloop INFO&amp;quot;)
        // log.Debug(&amp;quot;ackloop:   total events scheduled = &amp;quot;, l.totalSched)
        // log.Debug(&amp;quot;ackloop:   total events ack = &amp;quot;, l.totalACK)
        // log.Debug(&amp;quot;ackloop:   total batches scheduled = &amp;quot;, l.batchesSched)
        // log.Debug(&amp;quot;ackloop:   total batches ack = &amp;quot;, l.batchesACKed)

        l.sig = l.lst.channel()
        // if l.sig == nil {
        //  log.Debug(&amp;quot;ackloop: no ack scheduled&amp;quot;)
        // } else {
        //  log.Debug(&amp;quot;ackloop: schedule ack: &amp;quot;, l.lst.head.seq)
        // }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果有处理信号就发送给regestry进行记录，关于&lt;a href=&#34;https://kingjcy.github.io/post/monitor/log/collect/filebeat/filebeat-principle/#registry和ack-机制&#34;&gt;registry在下面详细说明&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;2、output&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;out, err := loadOutput(monitors, makeOutput)
if err != nil {
    return nil, err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入loadOutput&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func loadOutput(
    monitors Monitors,
    makeOutput OutputFactory,
) (outputs.Group, error) {
    log := monitors.Logger
    if log == nil {
        log = logp.L()
    }

    if publishDisabled {
        return outputs.Group{}, nil
    }

    if makeOutput == nil {
        return outputs.Group{}, nil
    }

    var (
        metrics  *monitoring.Registry
        outStats outputs.Observer
    )
    if monitors.Metrics != nil {
        metrics = monitors.Metrics.GetRegistry(&amp;quot;output&amp;quot;)
        if metrics != nil {
            metrics.Clear()
        } else {
            metrics = monitors.Metrics.NewRegistry(&amp;quot;output&amp;quot;)
        }
        outStats = outputs.NewStats(metrics)
    }

    outName, out, err := makeOutput(outStats)
    if err != nil {
        return outputs.Fail(err)
    }

    if metrics != nil {
        monitoring.NewString(metrics, &amp;quot;type&amp;quot;).Set(outName)
    }
    if monitors.Telemetry != nil {
        telemetry := monitors.Telemetry.GetRegistry(&amp;quot;output&amp;quot;)
        if telemetry != nil {
            telemetry.Clear()
        } else {
            telemetry = monitors.Telemetry.NewRegistry(&amp;quot;output&amp;quot;)
        }
        monitoring.NewString(telemetry, &amp;quot;name&amp;quot;).Set(outName)
    }

    return out, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边是根据load传进来的makeOutput函数来进行创建的，我们看一下load这个参数。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b *Beat) makeOutputFactory(
    cfg common.ConfigNamespace,
) func(outputs.Observer) (string, outputs.Group, error) {
    return func(outStats outputs.Observer) (string, outputs.Group, error) {
        out, err := b.createOutput(outStats, cfg)
        return cfg.Name(), out, err
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;创建createOutput&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b *Beat) createOutput(stats outputs.Observer, cfg common.ConfigNamespace) (outputs.Group, error) {
    if !cfg.IsSet() {
        return outputs.Group{}, nil
    }

    return outputs.Load(b.IdxSupporter, b.Info, stats, cfg.Name(), cfg.Config())
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再看load&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Load creates and configures a output Group using a configuration object..
func Load(
    im IndexManager,
    info beat.Info,
    stats Observer,
    name string,
    config *common.Config,
) (Group, error) {
    factory := FindFactory(name)
    if factory == nil {
        return Group{}, fmt.Errorf(&amp;quot;output type %v undefined&amp;quot;, name)
    }

    if stats == nil {
        stats = NewNilObserver()
    }
    return factory(im, info, stats, config)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见根据配置文件的配置的output的类型进行创建，比如我们用kafka做为output，我们看一下创建函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func init() {
    sarama.Logger = kafkaLogger{}

    outputs.RegisterType(&amp;quot;kafka&amp;quot;, makeKafka)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就是makeKafka&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func makeKafka(
    _ outputs.IndexManager,
    beat beat.Info,
    observer outputs.Observer,
    cfg *common.Config,
) (outputs.Group, error) {
    debugf(&amp;quot;initialize kafka output&amp;quot;)

    config, err := readConfig(cfg)
    if err != nil {
        return outputs.Fail(err)
    }

    topic, err := outil.BuildSelectorFromConfig(cfg, outil.Settings{
        Key:              &amp;quot;topic&amp;quot;,
        MultiKey:         &amp;quot;topics&amp;quot;,
        EnableSingleOnly: true,
        FailEmpty:        true,
    })
    if err != nil {
        return outputs.Fail(err)
    }

    libCfg, err := newSaramaConfig(config)
    if err != nil {
        return outputs.Fail(err)
    }

    hosts, err := outputs.ReadHostList(cfg)
    if err != nil {
        return outputs.Fail(err)
    }

    codec, err := codec.CreateEncoder(beat, config.Codec)
    if err != nil {
        return outputs.Fail(err)
    }

    client, err := newKafkaClient(observer, hosts, beat.IndexPrefix, config.Key, topic, codec, libCfg)
    if err != nil {
        return outputs.Fail(err)
    }

    retry := 0
    if config.MaxRetries &amp;lt; 0 {
        retry = -1
    }
    return outputs.Success(config.BulkMaxSize, retry, client)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;直接创建了kafka的client给发送的时候使用。&lt;/p&gt;

&lt;p&gt;最后利用上面的两个构建函数来创建我们的pipeline&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;p, err := New(beatInfo, monitors, queueBuilder, out, settings)
if err != nil {
    return nil, err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实上面函数有的调用是在这个new中进行的&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// New create a new Pipeline instance from a queue instance and a set of outputs.
// The new pipeline will take ownership of queue and outputs. On Close, the
// queue and outputs will be closed.
func New(
    beat beat.Info,
    monitors Monitors,
    queueFactory queueFactory,
    out outputs.Group,
    settings Settings,
) (*Pipeline, error) {
    var err error

    if monitors.Logger == nil {
        monitors.Logger = logp.NewLogger(&amp;quot;publish&amp;quot;)
    }

    p := &amp;amp;Pipeline{
        beatInfo:         beat,
        monitors:         monitors,
        observer:         nilObserver,
        waitCloseMode:    settings.WaitCloseMode,
        waitCloseTimeout: settings.WaitClose,
        processors:       settings.Processors,
    }
    p.ackBuilder = &amp;amp;pipelineEmptyACK{p}
    p.ackActive = atomic.MakeBool(true)

    if monitors.Metrics != nil {
        p.observer = newMetricsObserver(monitors.Metrics)
    }
    p.eventer.observer = p.observer
    p.eventer.modifyable = true

    if settings.WaitCloseMode == WaitOnPipelineClose &amp;amp;&amp;amp; settings.WaitClose &amp;gt; 0 {
        p.waitCloser = &amp;amp;waitCloser{}

        // waitCloser decrements counter on queue ACK (not per client)
        p.eventer.waitClose = p.waitCloser
    }

    p.queue, err = queueFactory(&amp;amp;p.eventer)
    if err != nil {
        return nil, err
    }

    if count := p.queue.BufferConfig().Events; count &amp;gt; 0 {
        p.eventSema = newSema(count)
    }

    maxEvents := p.queue.BufferConfig().Events
    if maxEvents &amp;lt;= 0 {
        // Maximum number of events until acker starts blocking.
        // Only active if pipeline can drop events.
        maxEvents = 64000
    }
    p.eventSema = newSema(maxEvents)

    p.output = newOutputController(beat, monitors, p.observer, p.queue)
    p.output.Set(out)

    return p, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;创建一个output的控制器outputController&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newOutputController(
    beat beat.Info,
    monitors Monitors,
    observer outputObserver,
    b queue.Queue,
) *outputController {
    c := &amp;amp;outputController{
        beat:     beat,
        monitors: monitors,
        observer: observer,
        queue:    b,
    }

    ctx := &amp;amp;batchContext{}
    c.consumer = newEventConsumer(monitors.Logger, b, ctx)
    c.retryer = newRetryer(monitors.Logger, observer, nil, c.consumer)
    ctx.observer = observer
    ctx.retryer = c.retryer

    c.consumer.sigContinue()

    return c
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同时初始化了eventConsumer和retryer。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newEventConsumer(
    log *logp.Logger,
    queue queue.Queue,
    ctx *batchContext,
) *eventConsumer {
    c := &amp;amp;eventConsumer{
        logger: log,
        done:   make(chan struct{}),
        sig:    make(chan consumerSignal, 3),
        out:    nil,

        queue:    queue,
        consumer: queue.Consumer(),
        ctx:      ctx,
    }

    c.pause.Store(true)
    go c.loop(c.consumer)
    return c
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在eventConsumer中启动了一个监听程序&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *eventConsumer) loop(consumer queue.Consumer) {
    log := c.logger

    log.Debug(&amp;quot;start pipeline event consumer&amp;quot;)

    var (
        out    workQueue
        batch  *Batch
        paused = true
    )

    handleSignal := func(sig consumerSignal) {
        switch sig.tag {
        case sigConsumerCheck:

        case sigConsumerUpdateOutput:
            c.out = sig.out

        case sigConsumerUpdateInput:
            consumer = sig.consumer
        }

        paused = c.paused()
        if !paused &amp;amp;&amp;amp; c.out != nil &amp;amp;&amp;amp; batch != nil {
            out = c.out.workQueue
        } else {
            out = nil
        }
    }

    for {
        if !paused &amp;amp;&amp;amp; c.out != nil &amp;amp;&amp;amp; consumer != nil &amp;amp;&amp;amp; batch == nil {
            out = c.out.workQueue
            queueBatch, err := consumer.Get(c.out.batchSize)
            if err != nil {
                out = nil
                consumer = nil
                continue
            }
            if queueBatch != nil {
                batch = newBatch(c.ctx, queueBatch, c.out.timeToLive)
            }

            paused = c.paused()
            if paused || batch == nil {
                out = nil
            }
        }

        select {
        case sig := &amp;lt;-c.sig:
            handleSignal(sig)
            continue
        default:
        }

        select {
        case &amp;lt;-c.done:
            log.Debug(&amp;quot;stop pipeline event consumer&amp;quot;)
            return
        case sig := &amp;lt;-c.sig:
            handleSignal(sig)
        case out &amp;lt;- batch:
            batch = nil
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用于消费队列中的事件event，并将其构建成Batch，放到处理队列中。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newBatch(ctx *batchContext, original queue.Batch, ttl int) *Batch {
    if original == nil {
        panic(&amp;quot;empty batch&amp;quot;)
    }

    b := batchPool.Get().(*Batch)
    *b = Batch{
        original: original,
        ctx:      ctx,
        ttl:      ttl,
        events:   original.Events(),
    }
    return b
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再来看看retryer&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newRetryer(
    log *logp.Logger,
    observer outputObserver,
    out workQueue,
    c *eventConsumer,
) *retryer {
    r := &amp;amp;retryer{
        logger:     log,
        observer:   observer,
        done:       make(chan struct{}),
        sig:        make(chan retryerSignal, 3),
        in:         retryQueue(make(chan batchEvent, 3)),
        out:        out,
        consumer:   c,
        doneWaiter: sync.WaitGroup{},
    }
    r.doneWaiter.Add(1)
    go r.loop()
    return r
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同样启动了监听程序，用于重试。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (r *retryer) loop() {
    defer r.doneWaiter.Done()
    var (
        out             workQueue
        consumerBlocked bool

        active     *Batch
        activeSize int
        buffer     []*Batch
        numOutputs int

        log = r.logger
    )

    for {
        select {
        case &amp;lt;-r.done:
            return
        case evt := &amp;lt;-r.in:
            var (
                countFailed  int
                countDropped int
                batch        = evt.batch
                countRetry   = len(batch.events)
            )

            if evt.tag == retryBatch {
                countFailed = len(batch.events)
                r.observer.eventsFailed(countFailed)

                decBatch(batch)

                countRetry = len(batch.events)
                countDropped = countFailed - countRetry
                r.observer.eventsDropped(countDropped)
            }

            if len(batch.events) == 0 {
                log.Info(&amp;quot;Drop batch&amp;quot;)
                batch.Drop()
            } else {
                out = r.out
                buffer = append(buffer, batch)
                out = r.out
                active = buffer[0]
                activeSize = len(active.events)
                if !consumerBlocked {
                    consumerBlocked = blockConsumer(numOutputs, len(buffer))
                    if consumerBlocked {
                        log.Info(&amp;quot;retryer: send wait signal to consumer&amp;quot;)
                        r.consumer.sigWait()
                        log.Info(&amp;quot;  done&amp;quot;)
                    }
                }
            }

        case out &amp;lt;- active:
            r.observer.eventsRetry(activeSize)

            buffer = buffer[1:]
            active, activeSize = nil, 0

            if len(buffer) == 0 {
                out = nil
            } else {
                active = buffer[0]
                activeSize = len(active.events)
            }

            if consumerBlocked {
                consumerBlocked = blockConsumer(numOutputs, len(buffer))
                if !consumerBlocked {
                    log.Info(&amp;quot;retryer: send unwait-signal to consumer&amp;quot;)
                    r.consumer.sigUnWait()
                    log.Info(&amp;quot;  done&amp;quot;)
                }
            }

        case sig := &amp;lt;-r.sig:
            switch sig.tag {
            case sigRetryerUpdateOutput:
                r.out = sig.channel
            case sigRetryerOutputAdded:
                numOutputs++
            case sigRetryerOutputRemoved:
                numOutputs--
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后对out进行了设置&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *outputController) Set(outGrp outputs.Group) {
    // create new outputGroup with shared work queue
    clients := outGrp.Clients
    queue := makeWorkQueue()
    worker := make([]outputWorker, len(clients))
    for i, client := range clients {
        worker[i] = makeClientWorker(c.observer, queue, client)
    }
    grp := &amp;amp;outputGroup{
        workQueue:  queue,
        outputs:    worker,
        timeToLive: outGrp.Retry + 1,
        batchSize:  outGrp.BatchSize,
    }

    // update consumer and retryer
    c.consumer.sigPause()
    if c.out != nil {
        for range c.out.outputs {
            c.retryer.sigOutputRemoved()
        }
    }
    c.retryer.updOutput(queue)
    for range clients {
        c.retryer.sigOutputAdded()
    }
    c.consumer.updOutput(grp)

    // close old group, so events are send to new workQueue via retryer
    if c.out != nil {
        for _, w := range c.out.outputs {
            w.Close()
        }
    }

    c.out = grp

    // restart consumer (potentially blocked by retryer)
    c.consumer.sigContinue()

    c.observer.updateOutputGroup()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边就是对上面创建的kafka的每个client创建一个监控程序makeClientWorker&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func makeClientWorker(observer outputObserver, qu workQueue, client outputs.Client) outputWorker {
    if nc, ok := client.(outputs.NetworkClient); ok {
        c := &amp;amp;netClientWorker{observer: observer, qu: qu, client: nc}
        go c.run()
        return c
    }
    c := &amp;amp;clientWorker{observer: observer, qu: qu, client: client}
    go c.run()
    return c
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就用于监控workQueue的数据，有数据就通过client的push发送到kafka，到这边pipeline的初始化也就结束了。&lt;/p&gt;

&lt;h2 id=&#34;日志收集&#34;&gt;日志收集&lt;/h2&gt;

&lt;p&gt;Filebeat 不仅支持普通文本日志的作为输入源，还内置支持了 redis 的慢查询日志、stdin、tcp 和 udp 等作为输入源。&lt;/p&gt;

&lt;p&gt;本文只分析下普通文本日志的处理方式，对于普通文本日志，可以按照以下配置方式，指定 log 的输入源信息。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/*.log
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 Input 也可以指定多个, 每个 Input 下的 Log 也可以指定多个。&lt;/p&gt;

&lt;p&gt;从收集日志、到发送事件到publisher，其数据流如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/collect.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;filebeat 启动时会开启 Crawler，filebeat抽象出一个Crawler的结构体，对于配置中的每条 Input，Crawler 都会启动一个 Input 进行处理，代码如下所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Crawler) Start(...){
    ...
    for _, inputConfig := range c.inputConfigs {
        err := c.startInput(pipeline, inputConfig, r.GetStates())
        if err != nil {
            return err
        }
    }
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就是创建input，比如我们采集的是log类型的，就是调用log的NewInput来创建，并且启动，定时进行扫描&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;p, err := input.New(config, connector, c.beatDone, states, nil)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会根据采集日志的类型来进行注册调用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// NewInput instantiates a new Log
func NewInput(
    cfg *common.Config,
    outlet channel.Connector,
    context input.Context,
) (input.Input, error) {
    cleanupNeeded := true
    cleanupIfNeeded := func(f func() error) {
        if cleanupNeeded {
            f()
        }
    }

    // Note: underlying output.
    //  The input and harvester do have different requirements
    //  on the timings the outlets must be closed/unblocked.
    //  The outlet generated here is the underlying outlet, only closed
    //  once all workers have been shut down.
    //  For state updates and events, separate sub-outlets will be used.
    out, err := outlet.ConnectWith(cfg, beat.ClientConfig{
        Processing: beat.ProcessingConfig{
            DynamicFields: context.DynamicFields,
        },
    })
    if err != nil {
        return nil, err
    }
    defer cleanupIfNeeded(out.Close)

    // stateOut will only be unblocked if the beat is shut down.
    // otherwise it can block on a full publisher pipeline, so state updates
    // can be forwarded correctly to the registrar.
    stateOut := channel.CloseOnSignal(channel.SubOutlet(out), context.BeatDone)
    defer cleanupIfNeeded(stateOut.Close)

    meta := context.Meta
    if len(meta) == 0 {
        meta = nil
    }

    p := &amp;amp;Input{
        config:      defaultConfig,
        cfg:         cfg,
        harvesters:  harvester.NewRegistry(),
        outlet:      out,
        stateOutlet: stateOut,
        states:      file.NewStates(),
        done:        context.Done,
        meta:        meta,
    }

    if err := cfg.Unpack(&amp;amp;p.config); err != nil {
        return nil, err
    }
    if err := p.config.resolveRecursiveGlobs(); err != nil {
        return nil, fmt.Errorf(&amp;quot;Failed to resolve recursive globs in config: %v&amp;quot;, err)
    }
    if err := p.config.normalizeGlobPatterns(); err != nil {
        return nil, fmt.Errorf(&amp;quot;Failed to normalize globs patterns: %v&amp;quot;, err)
    }

    // Create empty harvester to check if configs are fine
    // TODO: Do config validation instead
    _, err = p.createHarvester(file.State{}, nil)
    if err != nil {
        return nil, err
    }

    if len(p.config.Paths) == 0 {
        return nil, fmt.Errorf(&amp;quot;each input must have at least one path defined&amp;quot;)
    }

    err = p.loadStates(context.States)
    if err != nil {
        return nil, err
    }

    logp.Info(&amp;quot;Configured paths: %v&amp;quot;, p.config.Paths)

    cleanupNeeded = false
    go p.stopWhenDone()

    return p, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后会调用这个结构体的run函数进行扫描，主要是调用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;p.scan()

// Scan starts a scanGlob for each provided path/glob
func (p *Input) scan() {
    var sortInfos []FileSortInfo
    var files []string

    paths := p.getFiles()

    var err error

    if p.config.ScanSort != &amp;quot;&amp;quot; {
        sortInfos, err = getSortedFiles(p.config.ScanOrder, p.config.ScanSort, getSortInfos(paths))
        if err != nil {
            logp.Err(&amp;quot;Failed to sort files during scan due to error %s&amp;quot;, err)
        }
    }

    if sortInfos == nil {
        files = getKeys(paths)
    }

    for i := 0; i &amp;lt; len(paths); i++ {

        var path string
        var info os.FileInfo

        if sortInfos == nil {
            path = files[i]
            info = paths[path]
        } else {
            path = sortInfos[i].path
            info = sortInfos[i].info
        }

        select {
        case &amp;lt;-p.done:
            logp.Info(&amp;quot;Scan aborted because input stopped.&amp;quot;)
            return
        default:
        }

        newState, err := getFileState(path, info, p)
        if err != nil {
            logp.Err(&amp;quot;Skipping file %s due to error %s&amp;quot;, path, err)
        }



        // Load last state
        lastState := p.states.FindPrevious(newState)

        // Ignores all files which fall under ignore_older
        if p.isIgnoreOlder(newState) {
            logp.Debug(&amp;quot;input&amp;quot;,&amp;quot;ignore&amp;quot;)
            err := p.handleIgnoreOlder(lastState, newState)
            if err != nil {
                logp.Err(&amp;quot;Updating ignore_older state error: %s&amp;quot;, err)
            }
            //close(p.done)
            continue
        }

        // Decides if previous state exists
        if lastState.IsEmpty() {
            logp.Debug(&amp;quot;input&amp;quot;, &amp;quot;Start harvester for new file: %s&amp;quot;, newState.Source)
            err := p.startHarvester(newState, 0)
            if err == errHarvesterLimit {
                logp.Debug(&amp;quot;input&amp;quot;, harvesterErrMsg, newState.Source, err)
                continue
            }
            if err != nil {
                logp.Err(harvesterErrMsg, newState.Source, err)
            }
        } else {
            p.harvestExistingFile(newState, lastState)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进行扫描过滤。由于指定的 paths 可以配置多个，而且可以是 Glob 类型，因此 Filebeat 将会匹配到多个配置文件。&lt;/p&gt;

&lt;p&gt;根据配置获取匹配的日志文件，需要注意的是，这里的匹配方式并非正则，而是采用linux glob的规则，和正则还是有一些区别。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;matches, err := filepath.Glob(path)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;获取到了所有匹配的日志文件之后，会经过一些复杂的过滤，例如如果配置了exclude_files则会忽略这类文件，同时还会查询文件的状态，如果文件的最近一次修改时间大于ignore_older的配置，也会不去采集该文件。&lt;/p&gt;

&lt;p&gt;还会对文件进行处理，获取每个文件的状态，构建新的state结构，&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;newState, err := getFileState(path, info, p)
if err != nil {
    logp.Err(&amp;quot;Skipping file %s due to error %s&amp;quot;, path, err)
}

func getFileState(path string, info os.FileInfo, p *Input) (file.State, error) {
    var err error
    var absolutePath string
    absolutePath, err = filepath.Abs(path)
    if err != nil {
        return file.State{}, fmt.Errorf(&amp;quot;could not fetch abs path for file %s: %s&amp;quot;, absolutePath, err)
    }
    logp.Debug(&amp;quot;input&amp;quot;, &amp;quot;Check file for harvesting: %s&amp;quot;, absolutePath)
    // Create new state for comparison
    newState := file.NewState(info, absolutePath, p.config.Type, p.meta, p.cfg.GetField(&amp;quot;brokerlist&amp;quot;), p.cfg.GetField(&amp;quot;topic&amp;quot;))
    return newState, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同时在已经存在的状态中进行对比，如果获取到对于的状态就不重新启动协程进行采集，如果获取一个新的状态就开启新的协程进行采集。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Load last state
lastState := p.states.FindPrevious(newState)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Input对象创建时会从registry读取文件状态(主要是offset)， 对于每个匹配到的文件，都会开启一个 Harvester 进行逐行读取，每个 Harvester 都工作在自己的的 goroutine 中。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;err := p.startHarvester(newState, 0)
if err == errHarvesterLimit {
    logp.Debug(&amp;quot;input&amp;quot;, harvesterErrMsg, newState.Source, err)
    continue
}
if err != nil {
    logp.Err(harvesterErrMsg, newState.Source, err)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们来看看startHarvester&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// startHarvester starts a new harvester with the given offset
// In case the HarvesterLimit is reached, an error is returned
func (p *Input) startHarvester(state file.State, offset int64) error {
    if p.numHarvesters.Inc() &amp;gt; p.config.HarvesterLimit &amp;amp;&amp;amp; p.config.HarvesterLimit &amp;gt; 0 {
        p.numHarvesters.Dec()
        harvesterSkipped.Add(1)
        return errHarvesterLimit
    }
    // Set state to &amp;quot;not&amp;quot; finished to indicate that a harvester is running
    state.Finished = false
    state.Offset = offset

    // Create harvester with state
    h, err := p.createHarvester(state, func() { p.numHarvesters.Dec() })
    if err != nil {
        p.numHarvesters.Dec()
        return err
    }

    err = h.Setup()
    if err != nil {
        p.numHarvesters.Dec()
        return fmt.Errorf(&amp;quot;error setting up harvester: %s&amp;quot;, err)
    }

    // Update state before staring harvester
    // This makes sure the states is set to Finished: false
    // This is synchronous state update as part of the scan
    h.SendStateUpdate()

    if err = p.harvesters.Start(h); err != nil {
        p.numHarvesters.Dec()
    }
    return err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先创建了Harvester&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// createHarvester creates a new harvester instance from the given state
func (p *Input) createHarvester(state file.State, onTerminate func()) (*Harvester, error) {
    // Each wraps the outlet, for closing the outlet individually
    h, err := NewHarvester(
        p.cfg,
        state,
        p.states,
        func(state file.State) bool {
            return p.stateOutlet.OnEvent(beat.Event{Private: state})
        },
        subOutletWrap(p.outlet),
    )
    if err == nil {
        h.onTerminate = onTerminate
    }
    return h, err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;harvester启动时会通过Setup方法创建一系列reader形成读处理链&lt;/p&gt;

&lt;p&gt;关于log类型的reader处理链，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/read.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;opt表示根据配置决定是否创建该reader&lt;/p&gt;

&lt;p&gt;Reader包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Line: 包含os.File，用于从指定offset开始读取日志行。虽然位于处理链的最内部，但其Next函数中实际的处理逻辑（读文件行）却是最新被执行的。&lt;/li&gt;
&lt;li&gt;Encode: 包含Line Reader，将其读取到的行生成Message结构后返回&lt;/li&gt;
&lt;li&gt;JSON, DockerJSON: 将json形式的日志内容decode成字段&lt;/li&gt;
&lt;li&gt;StripNewLine：去除日志行尾部的空白符&lt;/li&gt;
&lt;li&gt;Multiline: 用于读取多行日志&lt;/li&gt;
&lt;li&gt;Limit: 限制单行日志字节数&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;除了Line Reader外，这些reader都实现了Reader接口：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Reader interface {
    Next() (Message, error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reader通过内部包含Reader对象的方式，使Reader形成一个处理链，其实这就是设计模式中的责任链模式。&lt;/p&gt;

&lt;p&gt;各Reader的Next方法的通用形式像是这样：Next方法调用内部Reader对象的Next方法获取Message，然后处理后返回。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (r *SomeReader) Next() (Message, error) {
    message, err := r.reader.Next()
    if err != nil {
        return message, err
    }

    // do some processing...

    return message, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实Harvester 的工作流程非常简单，harvester从registry记录的文件位置开始读取，就是逐行读取文件，并更新该文件暂时在 Input 中的文件偏移量（注意，并不是 Registrar 中的偏移量），读取完成（读到文件的EOF末尾），组装成事件（beat.Event）后发给Publisher。主要是调用了Harvester的run方法，部分如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for {
    select {
    case &amp;lt;-h.done:
        return nil
    default:
    }

    message, err := h.reader.Next()
    if err != nil {
        switch err {
        case ErrFileTruncate:
            logp.Info(&amp;quot;File was truncated. Begin reading file from offset 0: %s&amp;quot;, h.state.Source)
            h.state.Offset = 0
            filesTruncated.Add(1)
        case ErrRemoved:
            logp.Info(&amp;quot;File was removed: %s. Closing because close_removed is enabled.&amp;quot;, h.state.Source)
        case ErrRenamed:
            logp.Info(&amp;quot;File was renamed: %s. Closing because close_renamed is enabled.&amp;quot;, h.state.Source)
        case ErrClosed:
            logp.Info(&amp;quot;Reader was closed: %s. Closing.&amp;quot;, h.state.Source)
        case io.EOF:
            logp.Info(&amp;quot;End of file reached: %s. Closing because close_eof is enabled.&amp;quot;, h.state.Source)
        case ErrInactive:
            logp.Info(&amp;quot;File is inactive: %s. Closing because close_inactive of %v reached.&amp;quot;, h.state.Source, h.config.CloseInactive)
        case reader.ErrLineUnparsable:
            logp.Info(&amp;quot;Skipping unparsable line in file: %v&amp;quot;, h.state.Source)
            //line unparsable, go to next line
            continue
        default:
            logp.Err(&amp;quot;Read line error: %v; File: %v&amp;quot;, err, h.state.Source)
        }
        return nil
    }

    // Get copy of state to work on
    // This is important in case sending is not successful so on shutdown
    // the old offset is reported
    state := h.getState()
    startingOffset := state.Offset
    state.Offset += int64(message.Bytes)

    // Stop harvester in case of an error
    if !h.onMessage(forwarder, state, message, startingOffset) {
        return nil
    }

    // Update state of harvester as successfully sent
    h.state = state
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，reader.Next()方法会不停的读取日志，如果没有返回异常，则发送日志数据到缓存队列中。&lt;/p&gt;

&lt;p&gt;返回的异常有几种类型，除了读取到EOF外，还会有例如文件一段时间不活跃等情况发生会使harvester goroutine退出，不再采集该文件，并关闭文件句柄。 filebeat为了防止占据过多的采集日志文件的文件句柄，默认的close_inactive参数为5min，如果日志文件5min内没有被修改，上面代码会进入ErrInactive的case，之后该harvester goroutine会被关闭。 这种场景下还需要注意的是，如果某个文件日志采集中被移除了，但是由于此时被filebeat保持着文件句柄，文件占据的磁盘空间会被保留直到harvester goroutine结束。&lt;/p&gt;

&lt;p&gt;不同的harvester goroutine采集到的日志数据都会发送至一个全局的队列queue中，queue的实现有两种：基于内存和基于磁盘的队列，目前基于磁盘的队列还是处于alpha阶段，filebeat默认启用的是基于内存的缓存队列。 每当队列中的数据缓存到一定的大小或者超过了定时的时间（默认1s)，会被注册的client从队列中消费，发送至配置的后端。目前可以设置的client有kafka、elasticsearch、redis等。&lt;/p&gt;

&lt;p&gt;同时，我们需要考虑到，日志型的数据其实是在不断增长和变化的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;会有新的日志在不断产生
可能一个日志文件对应的 Harvester 退出后，又再次有了内容更新。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了解决这两个情况，filebeat 采用了 Input 定时扫描的方式。代码如下，可以看出，Input 扫描的频率是由用户指定的 scan_frequency 配置来决定的 (默认 10s 扫描一次)。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (p *Runner) Run() {
    p.input.Run()

    if p.Once {
        return
    }

    for {
        select {
        case &amp;lt;-p.done:
            logp.Info(&amp;quot;input ticker stopped&amp;quot;)
            return
        case &amp;lt;-time.After(p.config.ScanFrequency): // 定时扫描
            logp.Debug(&amp;quot;input&amp;quot;, &amp;quot;Run input&amp;quot;)
            p.input.Run()
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;此外，如果用户启动时指定了 –once 选项，则扫描只会进行一次，就退出了。&lt;/p&gt;

&lt;p&gt;使用一个简单的流程图可以这样表示&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/collect1.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;处理文件重命名，删除，截断&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;获取文件信息时会获取文件的device id + indoe作为文件的唯一标识;&lt;/li&gt;
&lt;li&gt;文件收集进度会被持久化，这样当创建Harvester时，首先会对文件作openFile, 以 device id + inode为key在持久化文件中查看当前文件是否被收集过，收集到了什么位置，然后断点续传&lt;/li&gt;
&lt;li&gt;在读取过程中，如果文件被截断，认为文件已经被同名覆盖，将从头开始读取文件&lt;/li&gt;
&lt;li&gt;如果文件被删除，因为原文件已被打开，不影响继续收集，但如果设置了CloseRemoved， 则不会再继续收集&lt;/li&gt;
&lt;li&gt;如果文件被重命名，因为原文件已被打开，不影响继续收集，但如果设置了CloseRenamed ， 则不会再继续收集&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;pipeline调度&#34;&gt;pipeline调度&lt;/h2&gt;

&lt;p&gt;至此，我们可以清楚的知道，Filebeat 是如何采集日志文件。而日志采集过程，Harvest 会将数据写到 Pipeline 中。我们接下来看下数据是如何写入到 Pipeline 中的。&lt;/p&gt;

&lt;p&gt;Haveseter 会将数据写入缓存中，而另一方面 Output 会从缓存将数据读走。整个生产消费的过程都是由 Pipeline 进行调度的，而整个调度过程也非常复杂。&lt;/p&gt;

&lt;p&gt;不同的harvester goroutine采集到的日志数据都会发送至一个全局的队列queue中，Filebeat 的缓存queue目前分为 memqueue 和 spool。memqueue 顾名思义就是内存缓存，spool 则是将数据缓存到磁盘中。本文将基于 memqueue 讲解整个调度过程。&lt;/p&gt;

&lt;p&gt;在下面的pipeline的写入和消费中，在client.go在(*client) publish方法中我们可以看到，事件是通过调用c.producer.Publish(pubEvent)被实际发送的，而producer则通过具体Queue的Producer方法生成。&lt;/p&gt;

&lt;p&gt;队列对象被包含在pipeline.go:Pipeline结构中，其接口的定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Queue interface {
    io.Closer
    BufferConfig() BufferConfig
    Producer(cfg ProducerConfig) Producer
    Consumer() Consumer
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要的，Producer方法生成Producer对象，用于向队列中push事件；Consumer方法生成Consumer对象，用于从队列中取出事件。Producer和Consumer接口定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Producer interface {
    Publish(event publisher.Event) bool
    TryPublish(event publisher.Event) bool
    Cancel() int
}

type Consumer interface {
    Get(sz int) (Batch, error)
    Close() error
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在配置中没有指定队列配置时，默认使用了memqueue作为队列实现，下面我们来看看memqueue及其对应producer和consumer定义：&lt;/p&gt;

&lt;p&gt;Broker结构(memqueue在代码中实际对应的结构名是Broker)：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Broker struct {
    done chan struct{}

    logger logger

    bufSize int
    // buf         brokerBuffer
    // minEvents   int
    // idleTimeout time.Duration

    // api channels
    events    chan pushRequest
    requests  chan getRequest
    pubCancel chan producerCancelRequest

    // internal channels
    acks          chan int
    scheduledACKs chan chanList

    eventer queue.Eventer

    // wait group for worker shutdown
    wg          sync.WaitGroup
    waitOnClose bool
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;根据是否需要ack分为forgetfullProducer和ackProducer两种producer：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type forgetfullProducer struct {
    broker    *Broker
    openState openState
}

type ackProducer struct {
    broker    *Broker
    cancel    bool
    seq       uint32
    state     produceState
    openState openState
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;consumer结构:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type consumer struct {
    broker *Broker
    resp   chan getResponse

    done   chan struct{}
    closed atomic.Bool
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;queue、producer、consumer三者关系的运作方式如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/queue.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Producer通过Publish或TryPublish事件放入Broker的队列，即结构中的channel对象evetns&lt;/li&gt;
&lt;li&gt;Broker的主事件循环EventLoop将（请求）事件从events channel取出，放入自身结构体对象ringBuffer中。主事件循环有两种类型：

&lt;ul&gt;
&lt;li&gt;直接（不带buffer）事件循环结构directEventLoop：收到事件后尽可能快的转发；&lt;/li&gt;
&lt;li&gt;带buffer事件循环结构bufferingEventLoop：当buffer满或刷新超时时转发。具体使用哪一种取决于memqueue配置项flush.min_events，大于1时使用后者，否则使用前者。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;eventConsumer调用Consumer的Get方法获取事件：

&lt;ul&gt;
&lt;li&gt;首先将获取事件请求（包括请求事件数和用于存放其响应事件的channel resp）放入Broker的请求队列requests中，等待主事件循环EventLoop处理后将事件放入resp；&lt;/li&gt;
&lt;li&gt;获取resp的事件，组装成batch结构后返回&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;eventConsumer将事件放入output对应队列中&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;这部分关于事件在队列中各种channel间的流转，笔者认为是比较消耗性能的，但不清楚设计者这样设计的考量是什么。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;另外值得思考的是，在多个go routine使用队列交互的场景下，libbeat中都使用了go语言channel作为其底层的队列，它是否可以完全替代加锁队列的使用呢？&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;pipeline-的写入&#34;&gt;Pipeline 的写入&lt;/h3&gt;

&lt;p&gt;在Crawler收集日志并转换成事件后，我们继续发送数据，其就会通过调用Publisher对应client的Publish接口将事件送到Publisher，后续的处理流程也都将由libbeat完成，事件的流转如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/event.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我们首先看一下事件处理器processor&lt;/p&gt;

&lt;p&gt;在harvester调用client.Publish接口时，其内部会使用配置中定义的processors对事件进行处理，然后才将事件发送到Publisher队列。&lt;/p&gt;

&lt;p&gt;processor包含两种：在Input内定义作为局部（Input独享）的processor，其只对该Input产生的事件生效；在顶层配置中定义作为全局processor，其对全部事件生效。其对应的代码实现方式是： filebeat在使用libbeat pipeline的ConnectWith接口创建client时（factory.go中(*OutletFactory)Create函数），会将Input内部的定义processor作为参数传递给ConnectWith接口。而在ConnectWith实现中，会将参数中的processor和全局processor（在创建pipeline时生成）合并。从这里读者也可以发现，实际上每个Input都独享一个client，其包含一些Input自身的配置定义逻辑。&lt;/p&gt;

&lt;p&gt;任一Processor都实现了Processor接口：Run函数包含处理逻辑，String返回Processor名。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Processor interface {
    Run(event *beat.Event) (*beat.Event, error)
    String() string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们再看下 Haveseter 是如何将数据写入缓存中的，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/produce-to-pipeline.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Harvester 通过 pipeline 提供的 pipelineClient 将数据写入到 pipeline 中，Haveseter 会将读到的数据会包装成一个 Event 结构体，再递交给 pipeline。&lt;/p&gt;

&lt;p&gt;在 Filebeat 的实现中，pipelineClient 并不直接操作缓存，而是将 event 先写入一个 events channel 中。&lt;/p&gt;

&lt;p&gt;同时，有一个 eventloop 组件，会监听 events channel 的事件到来，等 event 到达时，eventloop 会将其放入缓存中。&lt;/p&gt;

&lt;p&gt;当缓存满的时候，eventloop 直接移除对该 channel 的监听。&lt;/p&gt;

&lt;p&gt;每次 event ACK 或者取消后，缓存不再满了，则 eventloop 会重新监听 events channel。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// onMessage processes a new message read from the reader.
// This results in a state update and possibly an event would be send.
// A state update first updates the in memory state held by the prospector,
// and finally sends the file.State indirectly to the registrar.
// The events Private field is used to forward the file state update.
//
// onMessage returns &#39;false&#39; if it was interrupted in the process of sending the event.
// This normally signals a harvester shutdown.
func (h *Harvester) onMessage(
    forwarder *harvester.Forwarder,
    state file.State,
    message reader.Message,
    messageOffset int64,
) bool {
    if h.source.HasState() {
        h.states.Update(state)
    }

    text := string(message.Content)
    if message.IsEmpty() || !h.shouldExportLine(text) {
        // No data or event is filtered out -&amp;gt; send empty event with state update
        // only. The call can fail on filebeat shutdown.
        // The event will be filtered out, but forwarded to the registry as is.
        err := forwarder.Send(beat.Event{Private: state})
        return err == nil
    }

    fields := common.MapStr{
        &amp;quot;log&amp;quot;: common.MapStr{
            &amp;quot;offset&amp;quot;: messageOffset, // Offset here is the offset before the starting char.
            &amp;quot;file&amp;quot;: common.MapStr{
                &amp;quot;path&amp;quot;: state.Source,
            },
        },
    }
    fields.DeepUpdate(message.Fields)

    // Check if json fields exist
    var jsonFields common.MapStr
    if f, ok := fields[&amp;quot;json&amp;quot;]; ok {
        jsonFields = f.(common.MapStr)
    }

    var meta common.MapStr
    timestamp := message.Ts
    if h.config.JSON != nil &amp;amp;&amp;amp; len(jsonFields) &amp;gt; 0 {
        id, ts := readjson.MergeJSONFields(fields, jsonFields, &amp;amp;text, *h.config.JSON)
        if !ts.IsZero() {
            // there was a `@timestamp` key in the event, so overwrite
            // the resulting timestamp
            timestamp = ts
        }

        if id != &amp;quot;&amp;quot; {
            meta = common.MapStr{
                &amp;quot;id&amp;quot;: id,
            }
        }
    } else if &amp;amp;text != nil {
        if fields == nil {
            fields = common.MapStr{}
        }
        fields[&amp;quot;message&amp;quot;] = text
    }

    err := forwarder.Send(beat.Event{
        Timestamp: timestamp,
        Fields:    fields,
        Meta:      meta,
        Private:   state,
    })
    return err == nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将数据包装成event直接通过send方法将数据发出去&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Send updates the input state and sends the event to the spooler
// All state updates done by the input itself are synchronous to make sure no states are overwritten
func (f *Forwarder) Send(event beat.Event) error {
    ok := f.Outlet.OnEvent(event)
    if !ok {
        logp.Info(&amp;quot;Input outlet closed&amp;quot;)
        return errors.New(&amp;quot;input outlet closed&amp;quot;)
    }

    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调用Outlet.OnEvent发送data&lt;/p&gt;

&lt;p&gt;点进去发现是一个接口&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Outlet interface {
       OnEvent(data *util.Data) bool
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;经过调试观察，elastic\beats\filebeat\channel\outlet.go实现了这个接口&lt;/p&gt;

&lt;p&gt;outlet在Harvester的run一开始就创建了&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;outlet := channel.CloseOnSignal(h.outletFactory(), h.done)
forwarder := harvester.NewForwarder(outlet)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;所以调用的OnEvent&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (o *outlet) OnEvent(event beat.Event) bool {
    if !o.isOpen.Load() {
        return false
    }

    if o.wg != nil {
        o.wg.Add(1)
    }

    o.client.Publish(event)

    // Note: race condition on shutdown:
    //  The underlying beat.Client is asynchronous. Without proper ACK
    //  handler we can not tell if the event made it &#39;through&#39; or the client
    //  close has been completed before sending. In either case,
    //  we report &#39;false&#39; here, indicating the event eventually being dropped.
    //  Returning false here, prevents the harvester from updating the state
    //  to the most recently published events. Therefore, on shutdown the harvester
    //  might report an old/outdated state update to the registry, overwriting the
    //  most recently
    //  published offset in the registry on shutdown.
    return o.isOpen.Load()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过client.Publish发送数据，client也是一个接口&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Client interface {
       Publish(Event)
       PublishAll([]Event)
       Close() error
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调试之后，client使用的是elastic\beats\libbeat\publisher\pipeline\client.go的client对象&lt;/p&gt;

&lt;p&gt;我们来看一下这个client是通过Harvester的参数outletFactory来初始化的，我们来看一下NewHarvester初始化的时候也就是在createHarvester的时候传递的参数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// createHarvester creates a new harvester instance from the given state
func (p *Input) createHarvester(state file.State, onTerminate func()) (*Harvester, error) {
    // Each wraps the outlet, for closing the outlet individually
    h, err := NewHarvester(
        p.cfg,
        state,
        p.states,
        func(state file.State) bool {
            return p.stateOutlet.OnEvent(beat.Event{Private: state})
        },
        subOutletWrap(p.outlet),
    )
    if err == nil {
        h.onTerminate = onTerminate
    }
    return h, err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就是subOutletWrap中的参数p.outlet那就要看以下Input初始化的的时候NewInput传递的参数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// NewInput instantiates a new Log
func NewInput(
    cfg *common.Config,
    outlet channel.Connector,
    context input.Context,
) (input.Input, error) {
    cleanupNeeded := true
    cleanupIfNeeded := func(f func() error) {
        if cleanupNeeded {
            f()
        }
    }

    // Note: underlying output.
    //  The input and harvester do have different requirements
    //  on the timings the outlets must be closed/unblocked.
    //  The outlet generated here is the underlying outlet, only closed
    //  once all workers have been shut down.
    //  For state updates and events, separate sub-outlets will be used.
    out, err := outlet.ConnectWith(cfg, beat.ClientConfig{
        Processing: beat.ProcessingConfig{
            DynamicFields: context.DynamicFields,
        },
    })
    if err != nil {
        return nil, err
    }
    defer cleanupIfNeeded(out.Close)

    // stateOut will only be unblocked if the beat is shut down.
    // otherwise it can block on a full publisher pipeline, so state updates
    // can be forwarded correctly to the registrar.
    stateOut := channel.CloseOnSignal(channel.SubOutlet(out), context.BeatDone)
    defer cleanupIfNeeded(stateOut.Close)

    meta := context.Meta
    if len(meta) == 0 {
        meta = nil
    }

    p := &amp;amp;Input{
        config:      defaultConfig,
        cfg:         cfg,
        harvesters:  harvester.NewRegistry(),
        outlet:      out,
        stateOutlet: stateOut,
        states:      file.NewStates(),
        done:        context.Done,
        meta:        meta,
    }

    if err := cfg.Unpack(&amp;amp;p.config); err != nil {
        return nil, err
    }
    if err := p.config.resolveRecursiveGlobs(); err != nil {
        return nil, fmt.Errorf(&amp;quot;Failed to resolve recursive globs in config: %v&amp;quot;, err)
    }
    if err := p.config.normalizeGlobPatterns(); err != nil {
        return nil, fmt.Errorf(&amp;quot;Failed to normalize globs patterns: %v&amp;quot;, err)
    }

    // Create empty harvester to check if configs are fine
    // TODO: Do config validation instead
    _, err = p.createHarvester(file.State{}, nil)
    if err != nil {
        return nil, err
    }

    if len(p.config.Paths) == 0 {
        return nil, fmt.Errorf(&amp;quot;each input must have at least one path defined&amp;quot;)
    }

    err = p.loadStates(context.States)
    if err != nil {
        return nil, err
    }

    logp.Info(&amp;quot;Configured paths: %v&amp;quot;, p.config.Paths)

    cleanupNeeded = false
    go p.stopWhenDone()

    return p, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要看outlet，这个是在Crawler的startInput的时候进行初始化&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Crawler) startInput(
    pipeline beat.Pipeline,
    config *common.Config,
    states []file.State,
) error {
    if !config.Enabled() {
        return nil
    }

    connector := c.out(pipeline)
    p, err := input.New(config, connector, c.beatDone, states, nil)
    if err != nil {
        return fmt.Errorf(&amp;quot;Error while initializing input: %s&amp;quot;, err)
    }
    p.Once = c.once

    if _, ok := c.inputs[p.ID]; ok {
        return fmt.Errorf(&amp;quot;Input with same ID already exists: %d&amp;quot;, p.ID)
    }

    c.inputs[p.ID] = p

    p.Start()

    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看out就是crawler创建new的时候传递的值&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;crawler, err := crawler.New(
        channel.NewOutletFactory(outDone, wgEvents, b.Info).Create,
        config.Inputs,
        b.Info.Version,
        fb.done,
        *once)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就是create返回的pipelineConnector结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (f *OutletFactory) Create(p beat.Pipeline) Connector {
    return &amp;amp;pipelineConnector{parent: f, pipeline: p}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看pipelineConnector的ConnectWith函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *pipelineConnector) ConnectWith(cfg *common.Config, clientCfg beat.ClientConfig) (Outleter, error) {
    config := inputOutletConfig{}
    if err := cfg.Unpack(&amp;amp;config); err != nil {
        return nil, err
    }

    procs, err := processorsForConfig(c.parent.beatInfo, config, clientCfg)
    if err != nil {
        return nil, err
    }

    setOptional := func(to common.MapStr, key string, value string) {
        if value != &amp;quot;&amp;quot; {
            to.Put(key, value)
        }
    }

    meta := clientCfg.Processing.Meta.Clone()
    fields := clientCfg.Processing.Fields.Clone()

    serviceType := config.ServiceType
    if serviceType == &amp;quot;&amp;quot; {
        serviceType = config.Module
    }

    setOptional(meta, &amp;quot;pipeline&amp;quot;, config.Pipeline)
    setOptional(fields, &amp;quot;fileset.name&amp;quot;, config.Fileset)
    setOptional(fields, &amp;quot;service.type&amp;quot;, serviceType)
    setOptional(fields, &amp;quot;input.type&amp;quot;, config.Type)
    if config.Module != &amp;quot;&amp;quot; {
        event := common.MapStr{&amp;quot;module&amp;quot;: config.Module}
        if config.Fileset != &amp;quot;&amp;quot; {
            event[&amp;quot;dataset&amp;quot;] = config.Module + &amp;quot;.&amp;quot; + config.Fileset
        }
        fields[&amp;quot;event&amp;quot;] = event
    }

    mode := clientCfg.PublishMode
    if mode == beat.DefaultGuarantees {
        mode = beat.GuaranteedSend
    }

    // connect with updated configuration
    clientCfg.PublishMode = mode
    clientCfg.Processing.EventMetadata = config.EventMetadata
    clientCfg.Processing.Meta = meta
    clientCfg.Processing.Fields = fields
    clientCfg.Processing.Processor = procs
    clientCfg.Processing.KeepNull = config.KeepNull
    client, err := c.pipeline.ConnectWith(clientCfg)
    if err != nil {
        return nil, err
    }

    outlet := newOutlet(client, c.parent.wgEvents)
    if c.parent.done != nil {
        return CloseOnSignal(outlet, c.parent.done), nil
    }
    return outlet, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边获取到了pipeline的客户端client&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// ConnectWith create a new Client for publishing events to the pipeline.
// The client behavior on close and ACK handling can be configured by setting
// the appropriate fields in the passed ClientConfig.
// If not set otherwise the defaut publish mode is OutputChooses.
func (p *Pipeline) ConnectWith(cfg beat.ClientConfig) (beat.Client, error) {
    var (
        canDrop      bool
        dropOnCancel bool
        eventFlags   publisher.EventFlags
    )

    err := validateClientConfig(&amp;amp;cfg)
    if err != nil {
        return nil, err
    }

    p.eventer.mutex.Lock()
    p.eventer.modifyable = false
    p.eventer.mutex.Unlock()

    switch cfg.PublishMode {
    case beat.GuaranteedSend:
        eventFlags = publisher.GuaranteedSend
        dropOnCancel = true
    case beat.DropIfFull:
        canDrop = true
    }

    waitClose := cfg.WaitClose
    reportEvents := p.waitCloser != nil

    switch p.waitCloseMode {
    case NoWaitOnClose:

    case WaitOnClientClose:
        if waitClose &amp;lt;= 0 {
            waitClose = p.waitCloseTimeout
        }
    }

    processors, err := p.createEventProcessing(cfg.Processing, publishDisabled)
    if err != nil {
        return nil, err
    }

    client := &amp;amp;client{
        pipeline:     p,
        closeRef:     cfg.CloseRef,
        done:         make(chan struct{}),
        isOpen:       atomic.MakeBool(true),
        eventer:      cfg.Events,
        processors:   processors,
        eventFlags:   eventFlags,
        canDrop:      canDrop,
        reportEvents: reportEvents,
    }

    acker := p.makeACKer(processors != nil, &amp;amp;cfg, waitClose, client.unlink)
    producerCfg := queue.ProducerConfig{
        // Cancel events from queue if acker is configured
        // and no pipeline-wide ACK handler is registered.
        DropOnCancel: dropOnCancel &amp;amp;&amp;amp; acker != nil &amp;amp;&amp;amp; p.eventer.cb == nil,
    }

    if reportEvents || cfg.Events != nil {
        producerCfg.OnDrop = func(event beat.Event) {
            if cfg.Events != nil {
                cfg.Events.DroppedOnPublish(event)
            }
            if reportEvents {
                p.waitCloser.dec(1)
            }
        }
    }

    if acker != nil {
        producerCfg.ACK = acker.ackEvents
    } else {
        acker = newCloseACKer(nilACKer, client.unlink)
    }

    client.acker = acker
    client.producer = p.queue.Producer(producerCfg)

    p.observer.clientConnected()

    if client.closeRef != nil {
        p.registerSignalPropagation(client)
    }

    return client, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调用的就是client的Publish函数来发送数据，publish方法即发送日志的方法，如果需要在发送前改造日志格式，可在这里添加代码，如下面的解析日志代码。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *client) Publish(e beat.Event) {
    c.mutex.Lock()
    defer c.mutex.Unlock()

    c.publish(e)
}

func (c *client) publish(e beat.Event) {
    var (
        event   = &amp;amp;e
        publish = true
        log     = c.pipeline.monitors.Logger
    )

    c.onNewEvent()

    if !c.isOpen.Load() {
        // client is closing down -&amp;gt; report event as dropped and return
        c.onDroppedOnPublish(e)
        return
    }

    if c.processors != nil {
        var err error

        event, err = c.processors.Run(event)
        publish = event != nil
        if err != nil {
            // TODO: introduce dead-letter queue?

            log.Errorf(&amp;quot;Failed to publish event: %v&amp;quot;, err)
        }
    }

    if event != nil {
        e = *event
    }

    open := c.acker.addEvent(e, publish)
    if !open {
        // client is closing down -&amp;gt; report event as dropped and return
        c.onDroppedOnPublish(e)
        return
    }

    if !publish {
        c.onFilteredOut(e)
        return
    }

    e = *event
    pubEvent := publisher.Event{
        Content: e,
        Flags:   c.eventFlags,
    }

    if c.reportEvents {
        c.pipeline.waitCloser.inc()
    }

    var published bool
    if c.canDrop {
        published = c.producer.TryPublish(pubEvent)
    } else {
        published = c.producer.Publish(pubEvent)
    }

    if published {
        c.onPublished()
    } else {
        c.onDroppedOnPublish(e)
        if c.reportEvents {
            c.pipeline.waitCloser.dec(1)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在上面创建clinet的时候，创建了队列的生产者，也就是之前broker的Producer&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b *Broker) Producer(cfg queue.ProducerConfig) queue.Producer {
    return newProducer(b, cfg.ACK, cfg.OnDrop, cfg.DropOnCancel)
}

func newProducer(b *Broker, cb ackHandler, dropCB func(beat.Event), dropOnCancel bool) queue.Producer {
    openState := openState{
        log:    b.logger,
        isOpen: atomic.MakeBool(true),
        done:   make(chan struct{}),
        events: b.events,
    }

    if cb != nil {
        p := &amp;amp;ackProducer{broker: b, seq: 1, cancel: dropOnCancel, openState: openState}
        p.state.cb = cb
        p.state.dropCB = dropCB
        return p
    }
    return &amp;amp;forgetfulProducer{broker: b, openState: openState}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是forgetfulProducer结构体，调用这个的Publish函数来发送数据&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (p *forgetfulProducer) Publish(event publisher.Event) bool {
    return p.openState.publish(p.makeRequest(event))
}

func (st *openState) publish(req pushRequest) bool {
    select {
    case st.events &amp;lt;- req:
        return true
    case &amp;lt;-st.done:
        st.events = nil
        return false
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将数据放到了forgetfulProducer的openState的events中。到此数据就算发送到pipeline中了。&lt;/p&gt;

&lt;p&gt;上文在pipeline的初始化的时候，queue初始化一般默认都是BufferingEventLoop，即带缓冲的队列。BufferingEventLoop是一个实现了Broker、带有各种channel的结构，主要用于将日志发送至consumer消费。 BufferingEventLoop的run方法中，同样是一个无限循环，这里可以认为是一个日志事件的调度中心。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for {
        select {
        case &amp;lt;-broker.done:
            return
        case req := &amp;lt;-l.events: // producer pushing new event
            l.handleInsert(&amp;amp;req)
        case req := &amp;lt;-l.get: // consumer asking for next batch
            l.handleConsumer(&amp;amp;req)
        case count := &amp;lt;-l.acks:
            l.handleACK(count)
        case &amp;lt;-l.idleC:
            l.idleC = nil
            l.timer.Stop()
            if l.buf.length() &amp;gt; 0 {
                l.flushBuffer()
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上文中harvester goroutine每次读取到日志数据之后，最终会被发送至bufferingEventLoop中的events chan pushRequest 的channel中，然后触发上面req := &amp;lt;-l.events的case，handleInsert方法会把数据添加至bufferingEventLoop的buf中，buf即memqueue实际缓存日志数据的队列，如果buf长度超过配置的最大值或者bufferingEventLoop中的timer定时器（默认1S）触发了case &amp;lt;-l.idleC，均会调用flushBuffer()方法。
flushBuffer()又会触发req := &amp;lt;-l.get的case，然后运行handleConsumer方法，该方法中最重要的是这一句代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;req.resp &amp;lt;- getResponse{ackChan, events}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里获取到了consumer消费者的response channel，然后发送数据给这个channel。真正到这，才会触发consumer对memqueue的消费。所以，其实memqueue并非一直不停的在被consumer消费，而是在memqueue通知consumer的时候才被消费，我们可以理解为一种脉冲式的发送&lt;/p&gt;

&lt;p&gt;简单的来说就是，每当队列中的数据缓存到一定的大小或者超过了定时的时间（默认1s)，会被注册的client从队列中消费，发送至配置的后端。&lt;/p&gt;

&lt;p&gt;以上是 Pipeline 的写入过程，此时 event 已被写入到了缓存中。&lt;/p&gt;

&lt;p&gt;但是 Output 是如何从缓存中拿到 event 数据的？&lt;/p&gt;

&lt;h3 id=&#34;pipeline-的消费过程&#34;&gt;Pipeline 的消费过程&lt;/h3&gt;

&lt;p&gt;在上文已经提到过，filebeat初始化的时候，就已经创建了一个eventConsumer并在loop无限循环方法里试图从Broker中其实也就是上面的resp中获取日志数据。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for {
        if !paused &amp;amp;&amp;amp; c.out != nil &amp;amp;&amp;amp; consumer != nil &amp;amp;&amp;amp; batch == nil {
            out = c.out.workQueue
            queueBatch, err := consumer.Get(c.out.batchSize)
            ...
            batch = newBatch(c.ctx, queueBatch, c.out.timeToLive)
        }
        ...
        select {
        case &amp;lt;-c.done:
            return
        case sig := &amp;lt;-c.sig:
            handleSignal(sig)
        case out &amp;lt;- batch:
            batch = nil
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面consumer.Get就是消费者consumer从Broker中获取日志数据，然后发送至out的channel中被output client发送，我们看一下Get方法里的核心代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;select {
    case c.broker.requests &amp;lt;- getRequest{sz: sz, resp: c.resp}:
    case &amp;lt;-c.done:
        return nil, io.EOF
    }

    // if request has been send, we do have to wait for a response
    resp := &amp;lt;-c.resp
    return &amp;amp;batch{
        consumer: c,
        events:   resp.buf,
        ack:      resp.ack,
        state:    batchActive,
    }, nil
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;getRequest的结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type getRequest struct {
    sz   int              // request sz events from the broker
    resp chan getResponse // channel to send response to
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;getResponse的结构：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type getResponse struct {
    ack *ackChan
    buf []publisher.Event
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;getResponse里包含了日志的数据，而getRequest包含了一个发送至消费者的channel。
在上文bufferingEventLoop缓冲队列的handleConsumer方法里接收到的参数为getRequest，里面包含了consumer请求的getResponse channel。
如果handleConsumer不发送数据，consumer.Get方法会一直阻塞在select中，直到flushBuffer，consumer的getResponse channel才会接收到日志数据。&lt;/p&gt;

&lt;p&gt;我们来看看bufferingEventLoop的调度中心&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (l *bufferingEventLoop) run() {
    var (
        broker = l.broker
    )

    for {
        select {
        case &amp;lt;-broker.done:
            return

        case req := &amp;lt;-l.events: // producer pushing new event
            l.handleInsert(&amp;amp;req)

        case req := &amp;lt;-l.pubCancel: // producer cancelling active events
            l.handleCancel(&amp;amp;req)

        case req := &amp;lt;-l.get: // consumer asking for next batch
            l.handleConsumer(&amp;amp;req)

        case l.schedACKS &amp;lt;- l.pendingACKs:
            l.schedACKS = nil
            l.pendingACKs = chanList{}

        case count := &amp;lt;-l.acks:
            l.handleACK(count)

        case &amp;lt;-l.idleC:
            l.idleC = nil
            l.timer.Stop()
            if l.buf.length() &amp;gt; 0 {
                l.flushBuffer()
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当c.broker.requests &amp;lt;- getRequest{sz: sz, resp: c.resp}时候，l.get会得到信息，为什么l.get会得到信息，因为l.get = l.broker.requests&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (l *bufferingEventLoop) flushBuffer() {
    l.buf.flushed = true

    if l.buf.length() == 0 {
        panic(&amp;quot;flushing empty buffer&amp;quot;)
    }

    l.flushList.add(l.buf)
    l.get = l.broker.requests
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再来看看handleConsumer如何处理信息的&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (l *bufferingEventLoop) handleConsumer(req *getRequest) {
    buf := l.flushList.head
    if buf == nil {
        panic(&amp;quot;get from non-flushed buffers&amp;quot;)
    }

    count := buf.length()
    if count == 0 {
        panic(&amp;quot;empty buffer in flush list&amp;quot;)
    }

    if sz := req.sz; sz &amp;gt; 0 {
        if sz &amp;lt; count {
            count = sz
        }
    }

    if count == 0 {
        panic(&amp;quot;empty batch returned&amp;quot;)
    }

    events := buf.events[:count]
    clients := buf.clients[:count]
    ackChan := newACKChan(l.ackSeq, 0, count, clients)
    l.ackSeq++

    req.resp &amp;lt;- getResponse{ackChan, events}
    l.pendingACKs.append(ackChan)
    l.schedACKS = l.broker.scheduledACKs

    buf.events = buf.events[count:]
    buf.clients = buf.clients[count:]
    if buf.length() == 0 {
        l.advanceFlushList()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;处理req，并且将数据发送给req的resp，在发送的时候c.broker.requests &amp;lt;- getRequest{sz: sz, resp: c.resp}:就将c.resp赋值给了req的resp。所以可以获得返回值getResponse，组装成batch发送出去，其实就是放到type workQueue chan *Batch这个barch类型的channel中。&lt;/p&gt;

&lt;p&gt;看一下getResponse&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type getResponse struct {
    ack *ackChan
    buf []publisher.Event
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见ack就是channel，buf就是发送的日志。&lt;/p&gt;

&lt;p&gt;整个消费的过程非常复杂，数据会在多个 channel 之间传递流转，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/consume-from-pipeline.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;首先再介绍两个角色：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;consumer： pipeline 在创建的时候，会同时创建一个 consumer。consumer 负责从缓存中取数据
client worker：负责接收 consumer 传来的数据，并调用 Output 的 Publish 函数进行上报。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;与 producer 类似，consumer 也不直接操作缓存，而是会向 get channel 中写入消费请求。&lt;/p&gt;

&lt;p&gt;consumer 本身是个后台 loop 的过程，这个消费请求会不断进行。&lt;/p&gt;

&lt;p&gt;eventloop 监听 get channel, 拿到之后会从缓存中取数据。并将数据写入到 resp channel 中。&lt;/p&gt;

&lt;p&gt;consumer 从 resp channel 中拿到 event 数据后，又会将其写入到 workQueue。&lt;/p&gt;

&lt;p&gt;workQueue 也是个 channel。client worker 会监听该 channel 上的数据到来，将数据交给 Output client 进行 Publish 上报。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type workQueue chan *Batch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;而且，Output 收到的是 Batch Events，即会一次收到一批 Events。BatchSize 由各个 Output 自行决定。&lt;/p&gt;

&lt;p&gt;至此，消息已经递交给了 Output 组件。&lt;/p&gt;

&lt;h3 id=&#34;output&#34;&gt;output&lt;/h3&gt;

&lt;p&gt;Filebeat 并不依赖于 Elasticsearch，可以单独存在。我们可以单独使用 Filebeat 进行日志的上报和搜集。filebeat 内置了常用的 Output 组件, 例如 kafka、Elasticsearch、redis 等。出于调试考虑，也可以输出到 console 和 file。我们可以利用现有的 Output 组件，将日志进行上报。&lt;/p&gt;

&lt;p&gt;当然，我们也可以自定义 Output 组件，让 Filebeat 将日志转发到我们想要的地方。&lt;/p&gt;

&lt;p&gt;在上文提到过，在pipeline初始化的时候，就会设置output的clinet，会创建一个clientWorker或者netClientWorker（可重连，默认就是这个），clientWorker的run方法中，会不停的从consumer发送的channel（就是上面的workQueue）里读取日志数据，然后调用client.Publish批量发送日志。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (w *netClientWorker) run() {
    for !w.closed.Load() {
        reconnectAttempts := 0

        // start initial connect loop from first batch, but return
        // batch to pipeline for other outputs to catch up while we&#39;re trying to connect
        for batch := range w.qu {
            batch.Cancelled()

            if w.closed.Load() {
                logp.Info(&amp;quot;Closed connection to %v&amp;quot;, w.client)
                return
            }

            if reconnectAttempts &amp;gt; 0 {
                logp.Info(&amp;quot;Attempting to reconnect to %v with %d reconnect attempt(s)&amp;quot;, w.client, reconnectAttempts)
            } else {
                logp.Info(&amp;quot;Connecting to %v&amp;quot;, w.client)
            }

            err := w.client.Connect()
            if err != nil {
                logp.Err(&amp;quot;Failed to connect to %v: %v&amp;quot;, w.client, err)
                reconnectAttempts++
                continue
            }

            logp.Info(&amp;quot;Connection to %v established&amp;quot;, w.client)
            reconnectAttempts = 0
            break
        }

        // send loop
        for batch := range w.qu {
            if w.closed.Load() {
                if batch != nil {
                    batch.Cancelled()
                }
                return
            }

            err := w.client.Publish(batch)
            if err != nil {
                logp.Err(&amp;quot;Failed to publish events: %v&amp;quot;, err)
                // on error return to connect loop
                break
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;libbeats库中包含了kafka、elasticsearch、logstash等几种client，它们均实现了client接口：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Client interface {
    Close() error
    Publish(publisher.Batch) error
    String() string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然最重要的是实现Publish接口，然后将日志发送出去。比如我们看一下kafka的Publish接口&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *client) Publish(batch publisher.Batch) error {
    events := batch.Events()
    c.observer.NewBatch(len(events))

    ref := &amp;amp;msgRef{
        client: c,
        count:  int32(len(events)),
        total:  len(events),
        failed: nil,
        batch:  batch,
    }

    ch := c.producer.Input()
    for i := range events {
        d := &amp;amp;events[i]
        msg, err := c.getEventMessage(d)
        if err != nil {
            logp.Err(&amp;quot;Dropping event: %v&amp;quot;, err)
            ref.done()
            c.observer.Dropped(1)
            continue
        }

        msg.ref = ref
        msg.initProducerMessage()
        ch &amp;lt;- &amp;amp;msg.msg
    }

    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就是基本的kafka客户端的使用方法，到此为止，数据也就发送的kakfa了。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;其实在pipleline调度的时候就说明了queue的生产消费的关系，数据在各个channel中进行传输，整个日志数据流转的过程还是表复杂的，在各个channel中进行流转，如下图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/datastream.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;registry和ack-机制&#34;&gt;registry和Ack 机制&lt;/h2&gt;

&lt;p&gt;Filebeat 的可靠性很强，可以保证日志 At least once 的上报，同时也考虑了日志搜集中的各类问题，例如日志断点续读、文件名更改、日志 Truncated 等。&lt;/p&gt;

&lt;p&gt;filebeat 之所以可以保证日志可以 at least once 的上报，就是基于其 Ack 机制。&lt;/p&gt;

&lt;p&gt;简单来说，Ack 机制就是，当 Output Publish 成功之后会调用 ACK，最终 Registrar 会收到 ACK，并修改偏移量。&lt;/p&gt;

&lt;p&gt;而且, Registrar 只会在 Output 调用 batch 的相关信号时，才改变文件偏移量。其中 Batch 对外提供了这些信号：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Batch interface {
    Events() []Event

    // signals
    ACK()
    Drop()
    Retry()
    RetryEvents(events []Event)
    Cancelled()
    CancelledEvents(events []Event)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Output 在 Publish 之后，无论失败，必须调用这些函数中的其中一个。&lt;/p&gt;

&lt;p&gt;以下是 Output Publish 成功后调用 Ack 的流程：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/ack.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到其中起核心作用的组件是 Ackloop。AckLoop 中有一个 ackChanList，其中每一个 ackChan，对应于转发给 Output 的一个 Batch。
每次新建一个 Batch，同时会建立一个 ackChan，该 ackChan 会被 append 到 ackChanList 中。&lt;/p&gt;

&lt;p&gt;而 AckLoop 每次只监听处于 ackChanList 最头部的 ackChan。&lt;/p&gt;

&lt;p&gt;当 Batch 被 Output 调用 Ack 后，AckLoop 会收到对应 ackChan 上的事件，并将其最终转发给 Registrar。同时，ackChanList 将会 pop 头部的 ackChan，继续监听接下来的 Ack 事件。&lt;/p&gt;

&lt;p&gt;由于 FileBeat 是 At least once 的上报，但并不保证 Exactly once, 因此一条数据可能会被上报多次，所以接收端需要自行进行去重过滤。&lt;/p&gt;

&lt;p&gt;上面状态的修改，主要是filebeat维护了一个registry文件在本地的磁盘，该registry文件维护了所有已经采集的日志文件的状态。 实际上，每当日志数据发送至后端成功后，会返回ack事件。filebeat启动了一个独立的registry协程负责监听该事件，接收到ack事件后会将日志文件的State状态更新至registry文件中，State中的Offset表示读取到的文件偏移量，所以filebeat会保证Offset记录之前的日志数据肯定被后端的日志存储接收到。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;pipeline初始化的ack&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;首先是pipeline初始化只有一次，在这个时候只是简单的初始化了pipeline的ack相关信息，这边也创建的一个queue，原始是使用一个queue，这边初始化broker的时候会创建ack.run()来监听，后来改造多kafka发送后这一条queue
是不用的，而且每次连接kafka的时候创建一个新queue的时候，会都会创建一个ack.run()来监听，流程是一样的，改造可以看&lt;a href=&#34;https://kingjcy.github.io/post/monitor/log/collect/filebeat/filebeat-principle/#支持多kafka的发送&#34;&gt;支持多kafka的发送&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;p.ackBuilder = &amp;amp;pipelineEmptyACK{p}
p.ackActive = atomic.MakeBool(true)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就是在创建queue的时候，默认是使用mem的queue，会创建ack。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ack := newACKLoop(b, eventLoop.processACK)

b.wg.Add(2)
go func() {
    defer b.wg.Done()
    eventLoop.run()
}()
go func() {
    defer b.wg.Done()
    ack.run()
}()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在创建newBufferingEventLoop队列的同时，会newACKLoop并且调用相应结构体的run函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newACKLoop(b *Broker, processACK func(chanList, int)) *ackLoop {
    l := &amp;amp;ackLoop{broker: b}
    l.processACK = processACK
    return l
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看一下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type ackLoop struct {
    broker *Broker
    sig    chan batchAckMsg
    lst    chanList

    totalACK   uint64
    totalSched uint64

    batchesSched uint64
    batchesACKed uint64

    processACK func(chanList, int)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再看一下run函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (l *ackLoop) run() {
    var (
        // log = l.broker.logger

        // Buffer up acked event counter in acked. If acked &amp;gt; 0, acks will be set to
        // the broker.acks channel for sending the ACKs while potentially receiving
        // new batches from the broker event loop.
        // This concurrent bidirectionally communication pattern requiring &#39;select&#39;
        // ensures we can not have any deadlock between the event loop and the ack
        // loop, as the ack loop will not block on any channel
        acked int
        acks  chan int
    )

    for {
        select {
        case &amp;lt;-l.broker.done:
            // TODO: handle pending ACKs?
            // TODO: panic on pending batches?
            return

        case acks &amp;lt;- acked:
            acks, acked = nil, 0

        case lst := &amp;lt;-l.broker.scheduledACKs:
            count, events := lst.count()
            l.lst.concat(&amp;amp;lst)

            // log.Debug(&amp;quot;ACK List:&amp;quot;)
            // for current := l.lst.head; current != nil; current = current.next {
            //  log.Debugf(&amp;quot;  ack entry(seq=%v, start=%v, count=%v&amp;quot;,
            //      current.seq, current.start, current.count)
            // }

            l.batchesSched += uint64(count)
            l.totalSched += uint64(events)

        case &amp;lt;-l.sig:
            acked += l.handleBatchSig()
            if acked &amp;gt; 0 {
                acks = l.broker.acks
            }
        }

        // log.Debug(&amp;quot;ackloop INFO&amp;quot;)
        // log.Debug(&amp;quot;ackloop:   total events scheduled = &amp;quot;, l.totalSched)
        // log.Debug(&amp;quot;ackloop:   total events ack = &amp;quot;, l.totalACK)
        // log.Debug(&amp;quot;ackloop:   total batches scheduled = &amp;quot;, l.batchesSched)
        // log.Debug(&amp;quot;ackloop:   total batches ack = &amp;quot;, l.batchesACKed)

        l.sig = l.lst.channel()
        // if l.sig == nil {
        //  log.Debug(&amp;quot;ackloop: no ack scheduled&amp;quot;)
        // } else {
        //  log.Debug(&amp;quot;ackloop: schedule ack: &amp;quot;, l.lst.head.seq)
        // }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边其实就是对ack信号的调度处理中心。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;registrar初始化&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;然后就是启动filebeat的时候可能是要初始化registrar&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Setup registrar to persist state
registrar, err := registrar.New(config.Registry, finishedLogger)
if err != nil {
    logp.Err(&amp;quot;Could not init registrar: %v&amp;quot;, err)
    return err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;config.Registry就是registry文件的配置信息&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Registry struct {
    Path         string        `config:&amp;quot;path&amp;quot;`
    Permissions  os.FileMode   `config:&amp;quot;file_permissions&amp;quot;`
    FlushTimeout time.Duration `config:&amp;quot;flush&amp;quot;`
    MigrateFile  string        `config:&amp;quot;migrate_file&amp;quot;`
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;构建方法很简单，就是对文件的一些描述赋值给了这个结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// New creates a new Registrar instance, updating the registry file on
// `file.State` updates. New fails if the file can not be opened or created.
func New(cfg config.Registry, out successLogger) (*Registrar, error) {
    home := paths.Resolve(paths.Data, cfg.Path)
    migrateFile := cfg.MigrateFile
    if migrateFile != &amp;quot;&amp;quot; {
        migrateFile = paths.Resolve(paths.Data, migrateFile)
    }

    err := ensureCurrent(home, migrateFile, cfg.Permissions)
    if err != nil {
        return nil, err
    }

    dataFile := filepath.Join(home, &amp;quot;filebeat&amp;quot;, &amp;quot;data.json&amp;quot;)
    r := &amp;amp;Registrar{
        registryFile: dataFile,
        fileMode:     cfg.Permissions,
        done:         make(chan struct{}),
        states:       file.NewStates(),
        Channel:      make(chan []file.State, 1),
        flushTimeout: cfg.FlushTimeout,
        out:          out,
        wg:           sync.WaitGroup{},
    }
    return r, r.Init()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后返回Registrar结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Registrar struct {
    Channel      chan []file.State
    out          successLogger
    done         chan struct{}
    registryFile string      // Path to the Registry File
    fileMode     os.FileMode // Permissions to apply on the Registry File
    wg           sync.WaitGroup

    states               *file.States // Map with all file paths inside and the corresponding state
    gcRequired           bool         // gcRequired is set if registry state needs to be gc&#39;ed before the next write
    gcEnabled            bool         // gcEnabled indicates the registry contains some state that can be gc&#39;ed in the future
    flushTimeout         time.Duration
    bufferedStateUpdates int
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还进行了初始化，主要是对文件进行了一些检查。然后就是启动：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Start the registrar
err = registrar.Start()
if err != nil {
    return fmt.Errorf(&amp;quot;Could not start registrar: %v&amp;quot;, err)
}

func (r *Registrar) Start() error {
    // Load the previous log file locations now, for use in input
    err := r.loadStates()
    if err != nil {
        return fmt.Errorf(&amp;quot;Error loading state: %v&amp;quot;, err)
    }

    r.wg.Add(1)
    go r.Run()

    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先就是加载了目前存在的文件的状态来赋值给结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// loadStates fetches the previous reading state from the configure RegistryFile file
// The default file is `registry` in the data path.
func (r *Registrar) loadStates() error {
    f, err := os.Open(r.registryFile)
    if err != nil {
        return err
    }

    defer f.Close()

    logp.Info(&amp;quot;Loading registrar data from %s&amp;quot;, r.registryFile)

    states, err := readStatesFrom(f)
    if err != nil {
        return err
    }
    r.states.SetStates(states)
    logp.Info(&amp;quot;States Loaded from registrar: %+v&amp;quot;, len(states))

    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后开始监听来更新文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (r *Registrar) Run() {
    logp.Debug(&amp;quot;registrar&amp;quot;, &amp;quot;Starting Registrar&amp;quot;)
    // Writes registry on shutdown
    defer func() {
        r.writeRegistry()
        r.wg.Done()
    }()

    var (
        timer  *time.Timer
        flushC &amp;lt;-chan time.Time
    )

    for {
        select {
        case &amp;lt;-r.done:
            logp.Info(&amp;quot;Ending Registrar&amp;quot;)
            return
        case &amp;lt;-flushC:
            flushC = nil
            timer.Stop()
            r.flushRegistry()
        case states := &amp;lt;-r.Channel:
            r.onEvents(states)
            if r.flushTimeout &amp;lt;= 0 {
                r.flushRegistry()
            } else if flushC == nil {
                timer = time.NewTimer(r.flushTimeout)
                flushC = timer.C
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当接受到Registrar中channel的发来的文件状态，就更新结构体的值，如果到时间了就将内存中的值刷新到本地文件中，如果没有就定一个timeout时间后刷新到本地文件中。&lt;/p&gt;

&lt;p&gt;我们可以简单的看一下这个channel&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Channel:      make(chan []file.State, 1),
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就是一个文件状态的channel，关于文件状态的结构体如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// State is used to communicate the reading state of a file
type State struct {
    Id          string            `json:&amp;quot;-&amp;quot;` // local unique id to make comparison more efficient
    Finished    bool              `json:&amp;quot;-&amp;quot;` // harvester state
    Fileinfo    os.FileInfo       `json:&amp;quot;-&amp;quot;` // the file info
    Source      string            `json:&amp;quot;source&amp;quot;`
    Offset      int64             `json:&amp;quot;offset&amp;quot;`
    Timestamp   time.Time         `json:&amp;quot;timestamp&amp;quot;`
    TTL         time.Duration     `json:&amp;quot;ttl&amp;quot;`
    Type        string            `json:&amp;quot;type&amp;quot;`
    Meta        map[string]string `json:&amp;quot;meta&amp;quot;`
    FileStateOS file.StateOS
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;记录在registry文件中的数据大致如下所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[{&amp;quot;source&amp;quot;:&amp;quot;/tmp/aa.log&amp;quot;,&amp;quot;offset&amp;quot;:48,&amp;quot;timestamp&amp;quot;:&amp;quot;2019-07-03T13:54:01.298995+08:00&amp;quot;,&amp;quot;ttl&amp;quot;:-1,&amp;quot;type&amp;quot;:&amp;quot;log&amp;quot;,&amp;quot;meta&amp;quot;:null,&amp;quot;FileStateOS&amp;quot;:{&amp;quot;inode&amp;quot;:7048952,&amp;quot;device&amp;quot;:16777220}}]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由于文件可能会被改名或移动，filebeat会根据inode和设备号来标志每个日志文件。&lt;/p&gt;

&lt;p&gt;到这边registrar启动也结束了，下面就是监控registrar中channel的数据，在启动的时候还做了一件事情，那就是把channel设置到pipeline中去。&lt;/p&gt;

&lt;p&gt;在构建registrar的时候，通过registrar中channel构建一个结构体registrarLogger&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type registrarLogger struct {
    done chan struct{}
    ch   chan&amp;lt;- []file.State
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个就是用来交互的结构体,这个结构体中的channel获取的文件状态就是给上面的监听程序进行处理。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Make sure all events that were published in
registrarChannel := newRegistrarLogger(registrar)

func newRegistrarLogger(reg *registrar.Registrar) *registrarLogger {
    return &amp;amp;registrarLogger{
        done: make(chan struct{}),
        ch:   reg.Channel,
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过这个registrarLogger结构体，做了如下的调用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;err = b.Publisher.SetACKHandler(beat.PipelineACKHandler{
    ACKEvents: newEventACKer(finishedLogger, registrarChannel).ackEvents,
})
if err != nil {
    logp.Err(&amp;quot;Failed to install the registry with the publisher pipeline: %v&amp;quot;, err)
    return err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先看一下newEventACKer(finishedLogger, registrarChannel)这个结构体的ackEvents函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newEventACKer(stateless statelessLogger, stateful statefulLogger) *eventACKer {
    return &amp;amp;eventACKer{stateless: stateless, stateful: stateful, log: logp.NewLogger(&amp;quot;acker&amp;quot;)}
}

func (a *eventACKer) ackEvents(data []interface{}) {
    stateless := 0
    states := make([]file.State, 0, len(data))
    for _, datum := range data {
        if datum == nil {
            stateless++
            continue
        }

        st, ok := datum.(file.State)
        if !ok {
            stateless++
            continue
        }

        states = append(states, st)
    }

    if len(states) &amp;gt; 0 {
        a.log.Debugw(&amp;quot;stateful ack&amp;quot;, &amp;quot;count&amp;quot;, len(states))
        a.stateful.Published(states)
    }

    if stateless &amp;gt; 0 {
        a.log.Debugw(&amp;quot;stateless ack&amp;quot;, &amp;quot;count&amp;quot;, stateless)
        a.stateless.Published(stateless)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见是一个eventACKer结构体的函数赋值给了beat.PipelineACKHandler的成员函数，我们再来看一下beat.PipelineACKHandler&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// PipelineACKHandler configures some pipeline-wide event ACK handler.
type PipelineACKHandler struct {
    // ACKCount reports the number of published events recently acknowledged
    // by the pipeline.
    ACKCount func(int)

    // ACKEvents reports the events recently acknowledged by the pipeline.
    // Only the events &#39;Private&#39; field will be reported.
    ACKEvents func([]interface{})

    // ACKLastEvent reports the last ACKed event per pipeline client.
    // Only the events &#39;Private&#39; field will be reported.
    ACKLastEvents func([]interface{})
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就是一个这样的结构体作为参数，最后我们来看一下SetACKHandler这个函数的调用，首先b的就是libbeat中创建的beat，其中的Publisher就是对应的初始化的Pipeline，看一下Pipeline的SetACKHandler方法&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// SetACKHandler sets a global ACK handler on all events published to the pipeline.
// SetACKHandler must be called before any connection is made.
func (p *Pipeline) SetACKHandler(handler beat.PipelineACKHandler) error {
    p.eventer.mutex.Lock()
    defer p.eventer.mutex.Unlock()

    if !p.eventer.modifyable {
        return errors.New(&amp;quot;can not set ack handler on already active pipeline&amp;quot;)
    }

    // TODO: check only one type being configured

    cb, err := newPipelineEventCB(handler)
    if err != nil {
        return err
    }

    if cb == nil {
        p.ackBuilder = &amp;amp;pipelineEmptyACK{p}
        p.eventer.cb = nil
        return nil
    }

    p.eventer.cb = cb
    if cb.mode == countACKMode {
        p.ackBuilder = &amp;amp;pipelineCountACK{
            pipeline: p,
            cb:       cb.onCounts,
        }
    } else {
        p.ackBuilder = &amp;amp;pipelineEventsACK{
            pipeline: p,
            cb:       cb.onEvents,
        }
    }

    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;newPipelineEventCB是根据传递的不同函数，创建不同mode的pipelineEventCB结构体，启动goroutine来work。我们这边传递的是ACKEvents，设置mode为eventsACKMode&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newPipelineEventCB(handler beat.PipelineACKHandler) (*pipelineEventCB, error) {
    mode := noACKMode
    if handler.ACKCount != nil {
        mode = countACKMode
    }
    if handler.ACKEvents != nil {
        if mode != noACKMode {
            return nil, errors.New(&amp;quot;only one callback can be set&amp;quot;)
        }
        mode = eventsACKMode
    }
    if handler.ACKLastEvents != nil {
        if mode != noACKMode {
            return nil, errors.New(&amp;quot;only one callback can be set&amp;quot;)
        }
        mode = lastEventsACKMode
    }

    // yay, no work
    if mode == noACKMode {
        return nil, nil
    }

    cb := &amp;amp;pipelineEventCB{
        acks:          make(chan int),
        mode:          mode,
        handler:       handler,
        events:        make(chan eventsDataMsg),
        droppedEvents: make(chan eventsDataMsg),
    }
    go cb.worker()
    return cb, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再来看看worker工作协程&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (p *pipelineEventCB) worker() {
    defer close(p.acks)
    defer close(p.events)
    defer close(p.droppedEvents)

    for {
        select {
        case count := &amp;lt;-p.acks:
            exit := p.collect(count)
            if exit {
                return
            }

            // short circuit dropped events, but have client block until all events
            // have been processed by pipeline ack handler
        case msg := &amp;lt;-p.droppedEvents:
            p.reportEventsData(msg.data, msg.total)
            if msg.sig != nil {
                close(msg.sig)
            }

        case &amp;lt;-p.done:
            return
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同时对于不同的mode对p.ackBuilder进行了重新构建，因为是代码设置mode为eventsACKMode&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;p.ackBuilder = &amp;amp;pipelineEventsACK{
    pipeline: p,
    cb:       cb.onEvents,
}

type pipelineEventsACK struct {
    pipeline *Pipeline
    cb       func([]interface{}, int)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这里启动就结束了。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;input初始化的ack&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;crawler启动后构建新的input构建的时候，需要获取到pipeline的client，在使用ConnectWith进行构建的时候，会构建client的acker，第一次参数是processors != nil，影响后的结构体的创建，一般是true&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;acker := p.makeACKer(processors != nil, &amp;amp;cfg, waitClose, client.unlink)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们来看一下makeACKer这个函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (p *Pipeline) makeACKer(
    canDrop bool,
    cfg *beat.ClientConfig,
    waitClose time.Duration,
    afterClose func(),
) acker {
    var (
        bld   = p.ackBuilder
        acker acker
    )

    sema := p.eventSema
    switch {
    case cfg.ACKCount != nil:
        acker = bld.createCountACKer(canDrop, sema, cfg.ACKCount)
    case cfg.ACKEvents != nil:
        acker = bld.createEventACKer(canDrop, sema, cfg.ACKEvents)
    case cfg.ACKLastEvent != nil:
        cb := lastEventACK(cfg.ACKLastEvent)
        acker = bld.createEventACKer(canDrop, sema, cb)
    default:
        if waitClose &amp;lt;= 0 {
            acker = bld.createPipelineACKer(canDrop, sema)
        } else {
            acker = bld.createCountACKer(canDrop, sema, func(_ int) {})
        }
    }

    if waitClose &amp;lt;= 0 {
        return newCloseACKer(acker, afterClose)
    }
    return newWaitACK(acker, waitClose, afterClose)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要使用p.ackBuilder的create函数，我们在上面SetACKHandler的时候构建了p.ackBuilder，根据cfg配置调用，默认调用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;acker = bld.createEventACKer(canDrop, sema, cfg.ACKEvents)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是调用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b *pipelineEventsACK) createEventACKer(canDrop bool, sema *sema, fn func([]interface{})) acker {
    return buildClientEventACK(b.pipeline, canDrop, sema, func(guard *clientACKer) func([]interface{}, int) {
        return func(data []interface{}, acked int) {
            b.cb(data, acked)
            if guard.Active() {
                fn(data)
            }
        }
    })
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调用函数buildClientEventACK&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func buildClientEventACK(
    pipeline *Pipeline,
    canDrop bool,
    sema *sema,
    mk func(*clientACKer) func([]interface{}, int),
) acker {
    guard := &amp;amp;clientACKer{}
    guard.lift(newEventACK(pipeline, canDrop, sema, mk(guard)))
    return guard
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看一下返回值clientACKer结构体，其成员acker的赋值就是eventDataACK。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newEventACK(
    pipeline *Pipeline,
    canDrop bool,
    sema *sema,
    fn func([]interface{}, int),
) *eventDataACK {
    a := &amp;amp;eventDataACK{pipeline: pipeline, fn: fn}
    a.acker = makeCountACK(pipeline, canDrop, sema, a.onACK)

    return a
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;创建一个eventDataACK的结构体，fn就是mk(guard)就是&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func(data []interface{}, acked int) {
    b.cb(data, acked)
    if guard.Active() {
        fn(data)
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后调用makeCountACK来赋值给eventDataACK的acker&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func makeCountACK(pipeline *Pipeline, canDrop bool, sema *sema, fn func(int, int)) acker {
    if canDrop {
        return newBoundGapCountACK(pipeline, sema, fn)
    }
    return newCountACK(pipeline, fn)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;canDrop之前说过了，就是ture，所以创建newBoundGapCountACK，将eventDataACK的onACK当参数传递进来。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (a *eventDataACK) onACK(total, acked int) {
    n := total

    a.mutex.Lock()
    data := a.data[:n]
    a.data = a.data[n:]
    a.mutex.Unlock()

    if len(data) &amp;gt; 0 &amp;amp;&amp;amp; a.pipeline.ackActive.Load() {
        a.fn(data, acked)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;继续newBoundGapCountACK&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newBoundGapCountACK(
    pipeline *Pipeline,
    sema *sema,
    fn func(total, acked int),
) *boundGapCountACK {
    a := &amp;amp;boundGapCountACK{active: true, sema: sema, fn: fn}
    a.acker.init(pipeline, a.onACK)
    return a
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;创建了一个boundGapCountACK，调用初始化函数，将这个结构体的onACK传进去就是fn&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (a *gapCountACK) init(pipeline *Pipeline, fn func(int, int)) {
    *a = gapCountACK{
        pipeline: pipeline,
        fn:       fn,
        done:     make(chan struct{}),
        drop:     make(chan struct{}),
        acks:     make(chan int, 1),
    }

    init := &amp;amp;gapInfo{}
    a.lst.head = init
    a.lst.tail = init

    go a.ackLoop()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就是&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (a *gapCountACK) ackLoop() {
    // close channels, as no more events should be ACKed:
    // - once pipeline is closed
    // - all events of the closed client have been acked/processed by the pipeline

    acks, drop := a.acks, a.drop
    closing := false

    for {
        select {
        case &amp;lt;-a.done:
            closing = true
            a.done = nil
            if a.events.Load() == 0 {
                // stop worker, if all events accounted for have been ACKed.
                // If new events are added after this acker won&#39;t handle them, which may
                // result in duplicates
                return
            }

        case &amp;lt;-a.pipeline.ackDone:
            return

        case n := &amp;lt;-acks:
            empty := a.handleACK(n)
            if empty &amp;amp;&amp;amp; closing &amp;amp;&amp;amp; a.events.Load() == 0 {
                // stop worker, if and only if all events accounted for have been ACKed
                return
            }

        case &amp;lt;-drop:
            // TODO: accumulate multiple drop events + flush count with timer
            a.events.Sub(1)
            a.fn(1, 0)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边启动了一个acker的监听，然后使用这个clientACKer结构体又构建了一个新的结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newWaitACK(acker acker, timeout time.Duration, afterClose func()) *waitACK {
    return &amp;amp;waitACK{
        acker:      acker,
        signalAll:  make(chan struct{}, 1),
        signalDone: make(chan struct{}),
        waitClose:  timeout,
        active:     atomic.MakeBool(true),
        afterClose: afterClose,
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这里连接创建就结束了，创建的acker就是waitACK&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;client.acker = acker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;所以pipeline的client的acker就是waitACK。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;publish数据的ack&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;下面是有数据的时候将数据发送到pipeline，调用的client的publish函数，在发送数据的时候调用了addEvent。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;open := c.acker.addEvent(e, publish)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;c.acker也就是上面waitACK的addEvent函数，e就是对应发送的事件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (a *waitACK) addEvent(event beat.Event, published bool) bool {
    if published {
        a.events.Inc()
    }
    return a.acker.addEvent(event, published)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调用的是结构体成员acker的addEvent，也就是eventDataACK的addEvent。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (a *eventDataACK) addEvent(event beat.Event, published bool) bool {
    a.mutex.Lock()
    active := a.pipeline.ackActive.Load()
    if active {
        a.data = append(a.data, event.Private)
    }
    a.mutex.Unlock()

    if active {
        return a.acker.addEvent(event, published)
    }
    return false
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这边就是将数据传输到了data中，同时调用了其对应的acker的addEvent函数。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newEventACK(
    pipeline *Pipeline,
    canDrop bool,
    sema *sema,
    fn func([]interface{}, int),
) *eventDataACK {
    a := &amp;amp;eventDataACK{pipeline: pipeline, fn: fn}
    a.acker = makeCountACK(pipeline, canDrop, sema, a.onACK)

    return a
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们看到a.acker = makeCountACK(pipeline, canDrop, sema, a.onACK)，再看&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func makeCountACK(pipeline *Pipeline, canDrop bool, sema *sema, fn func(int, int)) acker {
    if canDrop {
        return newBoundGapCountACK(pipeline, sema, fn)
    }
    return newCountACK(pipeline, fn)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;canDrop上面说明过了，所以是newBoundGapCountACK&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newBoundGapCountACK(
    pipeline *Pipeline,
    sema *sema,
    fn func(total, acked int),
) *boundGapCountACK {
    a := &amp;amp;boundGapCountACK{active: true, sema: sema, fn: fn}
    a.acker.init(pipeline, a.onACK)
    return a
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;所以返回的结构体是boundGapCountACK，调用的也是这个结构体的addEvent&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (a *boundGapCountACK) addEvent(event beat.Event, published bool) bool {
    a.sema.inc()
    return a.acker.addEvent(event, published)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还有acker.addEvent，再看boundGapCountACK的acker&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type boundGapCountACK struct {
    active bool
    fn     func(total, acked int)

    acker gapCountACK
    sema  *sema
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;是一个gapCountACK的结构体，调用初始化a.acker.init(pipeline, a.onACK)来赋值&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (a *gapCountACK) init(pipeline *Pipeline, fn func(int, int)) {
    *a = gapCountACK{
        pipeline: pipeline,
        fn:       fn,
        done:     make(chan struct{}),
        drop:     make(chan struct{}),
        acks:     make(chan int, 1),
    }

    init := &amp;amp;gapInfo{}
    a.lst.head = init
    a.lst.tail = init

    go a.ackLoop()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同时启动了一个监听程序&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (a *gapCountACK) ackLoop() {
    // close channels, as no more events should be ACKed:
    // - once pipeline is closed
    // - all events of the closed client have been acked/processed by the pipeline

    acks, drop := a.acks, a.drop
    closing := false

    for {
        select {
        case &amp;lt;-a.done:
            closing = true
            a.done = nil
            if a.events.Load() == 0 {
                // stop worker, if all events accounted for have been ACKed.
                // If new events are added after this acker won&#39;t handle them, which may
                // result in duplicates
                return
            }

        case &amp;lt;-a.pipeline.ackDone:
            return

        case n := &amp;lt;-acks:
            empty := a.handleACK(n)
            if empty &amp;amp;&amp;amp; closing &amp;amp;&amp;amp; a.events.Load() == 0 {
                // stop worker, if and only if all events accounted for have been ACKed
                return
            }

        case &amp;lt;-drop:
            // TODO: accumulate multiple drop events + flush count with timer
            a.events.Sub(1)
            a.fn(1, 0)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当drop获取到信号的时候，就会调用fn也就是boundGapCountACK的onACK函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (a *boundGapCountACK) onACK(total, acked int) {
    a.sema.release(total)
    a.fn(total, acked)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边会调用到fn也就是eventDataACK的onACK&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (a *eventDataACK) onACK(total, acked int) {
    n := total

    a.mutex.Lock()
    data := a.data[:n]
    a.data = a.data[n:]
    a.mutex.Unlock()

    if len(data) &amp;gt; 0 &amp;amp;&amp;amp; a.pipeline.ackActive.Load() {
        a.fn(data, acked)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边会调用fn也就是我们创建的ackBuilder的cb成员也就是我们的ackBuilder结构的cb函数，也就是我们的onEvents&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (p *pipelineEventCB) onEvents(data []interface{}, acked int) {
    p.pushMsg(eventsDataMsg{data: data, total: len(data), acked: acked})
}

func (p *pipelineEventCB) onCounts(total, acked int) {
    p.pushMsg(eventsDataMsg{total: total, acked: acked})
}

func (p *pipelineEventCB) pushMsg(msg eventsDataMsg) {
    if msg.acked == 0 {
        p.droppedEvents &amp;lt;- msg
    } else {
        msg.sig = make(chan struct{})
        p.events &amp;lt;- msg
        &amp;lt;-msg.sig
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;获取到了file的具体数据。到这边就是继续监听，我们先看addEvent，published肯定是true，正常都是有事件的publish = event != nil&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (a *gapCountACK) addEvent(_ beat.Event, published bool) bool {
    // if gapList is empty and event is being dropped, forward drop event to ack
    // loop worker:

    a.events.Inc()
    if !published {
        a.addDropEvent()
    } else {
        a.addPublishedEvent()
    }

    return true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;所以看addPublishedEvent，只是给结构体成员send加一&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (a *gapCountACK) addPublishedEvent() {
    // event is publisher -&amp;gt; add a new gap list entry if gap is present in current
    // gapInfo

    a.lst.Lock()

    current := a.lst.tail
    current.Lock()

    if current.dropped &amp;gt; 0 {
        tmp := &amp;amp;gapInfo{}
        a.lst.tail.next = tmp
        a.lst.tail = tmp

        current.Unlock()
        tmp.Lock()
        current = tmp
    }

    a.lst.Unlock()

    current.send++
    current.Unlock()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这边调用的addevent就结束了，下面就是等待output的publish后的返回调用。上面已经有四个相关ack的监听，一个queue消费的监听，一个registry监听，一个是pipeline的监听，一个gapCountACK的ackLoop。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;publish后回调ack&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;然后就是output的publish的时候进行回调了，我们使用的是kafka，kafka在connect的时候会新建两个协程，来监听发送的情况，如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *client) Connect() error {
    c.mux.Lock()
    defer c.mux.Unlock()

    debugf(&amp;quot;connect: %v&amp;quot;, c.hosts)

    // try to connect
    producer, err := sarama.NewAsyncProducer(c.hosts, &amp;amp;c.config)
    if err != nil {
        logp.Err(&amp;quot;Kafka connect fails with: %v&amp;quot;, err)
        return err
    }

    c.producer = producer

    c.wg.Add(2)
    go c.successWorker(producer.Successes())
    go c.errorWorker(producer.Errors())

    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们一共可以看到两个处理方式，一个成功一个失败，producer.Successes()和producer.Errors()为这个producer的成功和错误返回channel。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *client) successWorker(ch &amp;lt;-chan *sarama.ProducerMessage) {
    defer c.wg.Done()
    defer debugf(&amp;quot;Stop kafka ack worker&amp;quot;)

    for libMsg := range ch {
        msg := libMsg.Metadata.(*message)
        msg.ref.done()
    }
}

func (c *client) errorWorker(ch &amp;lt;-chan *sarama.ProducerError) {
    defer c.wg.Done()
    defer debugf(&amp;quot;Stop kafka error handler&amp;quot;)

    for errMsg := range ch {
        msg := errMsg.Msg.Metadata.(*message)
        msg.ref.fail(msg, errMsg.Err)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们看一下成功的响应，失败也是一样的，只不过多了一个错误处理，有兴趣可以自己看一下。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (r *msgRef) done() {
    r.dec()
}

func (r *msgRef) dec() {
    i := atomic.AddInt32(&amp;amp;r.count, -1)
    if i &amp;gt; 0 {
        return
    }

    debugf(&amp;quot;finished kafka batch&amp;quot;)
    stats := r.client.observer

    err := r.err
    if err != nil {
        failed := len(r.failed)
        success := r.total - failed
        r.batch.RetryEvents(r.failed)

        stats.Failed(failed)
        if success &amp;gt; 0 {
            stats.Acked(success)
        }

        debugf(&amp;quot;Kafka publish failed with: %v&amp;quot;, err)
    } else {
        r.batch.ACK()
        stats.Acked(r.total)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在else中也就是接受到成功发送信号后调用了batch.ACK()。我们来看一下batch，首先是msg的类型转化&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;msg := errMsg.Msg.Metadata.(*message)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;转化为我们定义的kafka的message的结构体message&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type message struct {
    msg sarama.ProducerMessage

    topic string
    key   []byte
    value []byte
    ref   *msgRef
    ts    time.Time

    hash      uint32
    partition int32

    data publisher.Event
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在kafka的client使用publish的时候初始化了ref，给batch赋值&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ref := &amp;amp;msgRef{
        client: c,
        count:  int32(len(events)),
        total:  len(events),
        failed: nil,
        batch:  batch,
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个batch就是重netClientWorker的qu workQueue中获取的，看一下这个channel是bantch类型&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type workQueue chan *Batch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个batch就是我们需要找的结构，发送kafka成功后就是调用这个结构他的ACK函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Batch struct {
    original queue.Batch
    ctx      *batchContext
    ttl      int
    events   []publisher.Event
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们来看一下Batch的ACK函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b *Batch) ACK() {
    b.ctx.observer.outBatchACKed(len(b.events))
    b.original.ACK()
    releaseBatch(b)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边继续调用ACK，我们需要看一下b.original赋值，赋值都会调用newBatch函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newBatch(ctx *batchContext, original queue.Batch, ttl int) *Batch {
    if original == nil {
        panic(&amp;quot;empty batch&amp;quot;)
    }

    b := batchPool.Get().(*Batch)
    *b = Batch{
        original: original,
        ctx:      ctx,
        ttl:      ttl,
        events:   original.Events(),
    }
    return b
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;只在eventConsumer消费的时候调用了newBatch，通过get方法获取的queueBatch给了他&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;queueBatch, err := consumer.Get(c.out.batchSize)
if err != nil {
    out = nil
    consumer = nil
    continue
}
if queueBatch != nil {
    batch = newBatch(c.ctx, queueBatch, c.out.timeToLive)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先consumer是基于mem的，看一下get方法&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *consumer) Get(sz int) (queue.Batch, error) {
    // log := c.broker.logger

    if c.closed.Load() {
        return nil, io.EOF
    }

    select {
    case c.broker.requests &amp;lt;- getRequest{sz: sz, resp: c.resp}:
    case &amp;lt;-c.done:
        return nil, io.EOF
    }

    // if request has been send, we do have to wait for a response
    resp := &amp;lt;-c.resp
    return &amp;amp;batch{
        consumer: c,
        events:   resp.buf,
        ack:      resp.ack,
        state:    batchActive,
    }, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到返回使用的是结构体batch如下，我们简单看一下需要先向队列请求channel发送getRequest结构体，等待resp的返回来创建下面的结构体。具体的处理逻辑可以查看&lt;a href=&#34;https://kingjcy.github.io/post/monitor/log/collect/filebeat/filebeat-principle/#pipeline-的消费过程&#34;&gt;pipeline的消费&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type batch struct {
    consumer     *consumer
    events       []publisher.Event
    clientStates []clientState
    ack          *ackChan
    state        ackState
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看一下batch的ACK函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b *batch) ACK() {
    if b.state != batchActive {
        switch b.state {
        case batchACK:
            panic(&amp;quot;Can not acknowledge already acknowledged batch&amp;quot;)
        default:
            panic(&amp;quot;inactive batch&amp;quot;)
        }
    }

    b.report()
}

func (b *batch) report() {
    b.ack.ch &amp;lt;- batchAckMsg{}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就是给batch的ack也就是getResponse的ack的ch发送了一个信号batchAckMsg{}。这个ch接收到信号，牵涉到一个完整的消费的调度过程。&lt;/p&gt;

&lt;p&gt;我们先看一下正常的消费调度，在上面说过，首先在有数据发送到queue的时候，consumer会获取这个数据&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for {
        if !paused &amp;amp;&amp;amp; c.out != nil &amp;amp;&amp;amp; consumer != nil &amp;amp;&amp;amp; batch == nil {
            out = c.out.workQueue
            queueBatch, err := consumer.Get(c.out.batchSize)
            ...
            batch = newBatch(c.ctx, queueBatch, c.out.timeToLive)
        }
        ...
        select {
        case &amp;lt;-c.done:
            return
        case sig := &amp;lt;-c.sig:
            handleSignal(sig)
        case out &amp;lt;- batch:
            batch = nil
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面consumer.Get就是消费者consumer从Broker中获取日志数据，然后发送至out的channel中被output client发送，我们看一下Get方法里的核心代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *consumer) Get(sz int) (queue.Batch, error) {
    // log := c.broker.logger

    if c.closed.Load() {
        return nil, io.EOF
    }

    select {
    case c.broker.requests &amp;lt;- getRequest{sz: sz, resp: c.resp}:
    case &amp;lt;-c.done:
        return nil, io.EOF
    }

    // if request has been send, we do have to wait for a response
    resp := &amp;lt;-c.resp
    return &amp;amp;batch{
        consumer: c,
        events:   resp.buf,
        ack:      resp.ack,
        state:    batchActive,
    }, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当c.broker.requests &amp;lt;- getRequest{sz: sz, resp: c.resp}时候,我们需要看一下bufferingEventLoop的调度中心的响应。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (l *bufferingEventLoop) run() {
    var (
        broker = l.broker
    )

    for {
        select {
        case &amp;lt;-broker.done:
            return

        case req := &amp;lt;-l.events: // producer pushing new event
            l.handleInsert(&amp;amp;req)

        case req := &amp;lt;-l.pubCancel: // producer cancelling active events
            l.handleCancel(&amp;amp;req)

        case req := &amp;lt;-l.get: // consumer asking for next batch
            l.handleConsumer(&amp;amp;req)

        case l.schedACKS &amp;lt;- l.pendingACKs:
            l.schedACKS = nil
            l.pendingACKs = chanList{}

        case count := &amp;lt;-l.acks:
            l.handleACK(count)

        case &amp;lt;-l.idleC:
            l.idleC = nil
            l.timer.Stop()
            if l.buf.length() &amp;gt; 0 {
                l.flushBuffer()
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;l.get会得到信息，为什么l.get会得到信息，因为l.get = l.broker.requests&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (l *bufferingEventLoop) flushBuffer() {
    l.buf.flushed = true

    if l.buf.length() == 0 {
        panic(&amp;quot;flushing empty buffer&amp;quot;)
    }

    l.flushList.add(l.buf)
    l.get = l.broker.requests
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;l.get得到信息后handleConsumer如何处理信息的&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (l *bufferingEventLoop) handleConsumer(req *getRequest) {
    buf := l.flushList.head
    if buf == nil {
        panic(&amp;quot;get from non-flushed buffers&amp;quot;)
    }

    count := buf.length()
    if count == 0 {
        panic(&amp;quot;empty buffer in flush list&amp;quot;)
    }

    if sz := req.sz; sz &amp;gt; 0 {
        if sz &amp;lt; count {
            count = sz
        }
    }

    if count == 0 {
        panic(&amp;quot;empty batch returned&amp;quot;)
    }

    events := buf.events[:count]
    clients := buf.clients[:count]
    ackChan := newACKChan(l.ackSeq, 0, count, clients)
    l.ackSeq++

    req.resp &amp;lt;- getResponse{ackChan, events}
    l.pendingACKs.append(ackChan)
    l.schedACKS = l.broker.scheduledACKs

    buf.events = buf.events[count:]
    buf.clients = buf.clients[count:]
    if buf.length() == 0 {
        l.advanceFlushList()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看到获取到数据封装getResponse发送给output，我们这边不看这个数据具体发送到workqueue，而是关心的是ack。&lt;/p&gt;

&lt;p&gt;先看ack构建的结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newACKChan(seq uint, start, count int, states []clientState) *ackChan {
    ch := ackChanPool.Get().(*ackChan)
    ch.next = nil
    ch.seq = seq
    ch.start = start
    ch.count = count
    ch.states = states
    return ch
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后将这个ackChan新增到chanlist的链表中。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;l.pendingACKs.append(ackChan)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将l.schedACKS = l.broker.scheduledACKs，一开始调度的时候l.schedACKS是阻塞的，l.pendingACKs不能写入到l.schedACKS，但是这边进行赋值后就是将l.pendingACKs写入到l.broker.scheduledACKs，这个在初始化的时候是有缓存的。就直接写入了，然后bufferingEventLoop调度中心将这个数据清空，bufferingEventLoop的ack的调度获取到这个chanenl&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (l *ackLoop) run() {
    var (
        // log = l.broker.logger

        // Buffer up acked event counter in acked. If acked &amp;gt; 0, acks will be set to
        // the broker.acks channel for sending the ACKs while potentially receiving
        // new batches from the broker event loop.
        // This concurrent bidirectionally communication pattern requiring &#39;select&#39;
        // ensures we can not have any deadlock between the event loop and the ack
        // loop, as the ack loop will not block on any channel
        acked int
        acks  chan int
    )

    for {
        select {
        case &amp;lt;-l.broker.done:
            // TODO: handle pending ACKs?
            // TODO: panic on pending batches?
            return

        case acks &amp;lt;- acked:
            acks, acked = nil, 0

        case lst := &amp;lt;-l.broker.scheduledACKs:
            count, events := lst.count()
            l.lst.concat(&amp;amp;lst)

            // log.Debug(&amp;quot;ACK List:&amp;quot;)
            // for current := l.lst.head; current != nil; current = current.next {
            //  log.Debugf(&amp;quot;  ack entry(seq=%v, start=%v, count=%v&amp;quot;,
            //      current.seq, current.start, current.count)
            // }

            l.batchesSched += uint64(count)
            l.totalSched += uint64(events)

        case &amp;lt;-l.sig:
            acked += l.handleBatchSig()
            if acked &amp;gt; 0 {
                acks = l.broker.acks
            }
        }

        // log.Debug(&amp;quot;ackloop INFO&amp;quot;)
        // log.Debug(&amp;quot;ackloop:   total events scheduled = &amp;quot;, l.totalSched)
        // log.Debug(&amp;quot;ackloop:   total events ack = &amp;quot;, l.totalACK)
        // log.Debug(&amp;quot;ackloop:   total batches scheduled = &amp;quot;, l.batchesSched)
        // log.Debug(&amp;quot;ackloop:   total batches ack = &amp;quot;, l.batchesACKed)

        l.sig = l.lst.channel()
        // if l.sig == nil {
        //  log.Debug(&amp;quot;ackloop: no ack scheduled&amp;quot;)
        // } else {
        //  log.Debug(&amp;quot;ackloop: schedule ack: &amp;quot;, l.lst.head.seq)
        // }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;lst := &amp;lt;-l.broker.scheduledACKs就是获取到那个请求是新建的ackchan的channel，也就是获取到了batch回调的ack的函数的信号。也就是&amp;lt;-l.sig获取到了信号，调用handleBatchSig&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// handleBatchSig collects and handles a batch ACK/Cancel signal. handleBatchSig
// is run by the ackLoop.
func (l *ackLoop) handleBatchSig() int {
    lst := l.collectAcked()

    count := 0
    for current := lst.front(); current != nil; current = current.next {
        count += current.count
    }

    if count &amp;gt; 0 {
        if e := l.broker.eventer; e != nil {
            e.OnACK(count)
        }

        // report acks to waiting clients
        l.processACK(lst, count)
    }

    for !lst.empty() {
        releaseACKChan(lst.pop())
    }

    // return final ACK to EventLoop, in order to clean up internal buffer
    l.broker.logger.Debug(&amp;quot;ackloop: return ack to broker loop:&amp;quot;, count)

    l.totalACK += uint64(count)
    l.broker.logger.Debug(&amp;quot;ackloop:  done send ack&amp;quot;)
    return count
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;l.broker.eventer我们可以追溯一下，broker就是创建queue的是newACKLoop的时候传递的，broker也是在这个时候初始化的&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;b := &amp;amp;Broker{
        done:   make(chan struct{}),
        logger: logger,

        // broker API channels
        events:    make(chan pushRequest, chanSize),
        requests:  make(chan getRequest),
        pubCancel: make(chan producerCancelRequest, 5),

        // internal broker and ACK handler channels
        acks:          make(chan int),
        scheduledACKs: make(chan chanList),

        waitOnClose: settings.WaitOnClose,

        eventer: settings.Eventer,
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;eventer是create的时候传递的，create回传的时候是create的方法，真正调用是在pipeline初始化的时候new新建pipeline的时候&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;p.queue, err = queueFactory(&amp;amp;p.eventer)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;所以说l.broker.eventer就是p.eventer也就是结构体pipelineEventer&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type pipelineEventer struct {
    mutex      sync.Mutex
    modifyable bool

    observer  queueObserver
    waitClose *waitCloser
    cb        *pipelineEventCB
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们在pipeline中设置registry的时候p.eventer.cb就是我们创建的pipelineEventCB：p.eventer.cb = cb&lt;/p&gt;

&lt;p&gt;到这边可以看出e.OnACK(count)就是调用pipelineEventer的成员函数OnACK&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (e *pipelineEventer) OnACK(n int) {
    e.observer.queueACKed(n)

    if wc := e.waitClose; wc != nil {
        wc.dec(n)
    }
    if e.cb != nil {
        e.cb.reportQueueACK(n)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个时候就调用我们最初用的pipelineEventCB的reportQueueACK函数，就是将acked发送到了p.acks &amp;lt;- acked中，这个时候pipelineEventCB的监听程序监听到acks信号。&lt;/p&gt;

&lt;p&gt;收到ack的channel信息，调用collect函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (p *pipelineEventCB) collect(count int) (exit bool) {
    var (
        signalers []chan struct{}
        data      []interface{}
        acked     int
        total     int
    )

    for acked &amp;lt; count {
        var msg eventsDataMsg
        select {
        case msg = &amp;lt;-p.events:
        case msg = &amp;lt;-p.droppedEvents:
        case &amp;lt;-p.done:
            exit = true
            return
        }

        if msg.sig != nil {
            signalers = append(signalers, msg.sig)
        }
        total += msg.total
        acked += msg.acked

        if count-acked &amp;lt; 0 {
            panic(&amp;quot;ack count mismatch&amp;quot;)
        }

        switch p.mode {
        case eventsACKMode:
            data = append(data, msg.data...)

        case lastEventsACKMode:
            if L := len(msg.data); L &amp;gt; 0 {
                data = append(data, msg.data[L-1])
            }
        }
    }

    // signal clients we processed all active ACKs, as reported by queue
    for _, sig := range signalers {
        close(sig)
    }
    p.reportEventsData(data, total)
    return
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重pipelineEventCB中的events和droppedEvents中读取数据信息，然后进行上报reportEventsData&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (p *pipelineEventCB) reportEventsData(data []interface{}, total int) {
    // report ACK back to the beat
    switch p.mode {
    case countACKMode:
        p.handler.ACKCount(total)
    case eventsACKMode:
        p.handler.ACKEvents(data)
    case lastEventsACKMode:
        p.handler.ACKLastEvents(data)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这边就调用到一开始的ACKEvents函数，对数据进行处理，其实这些数据就是[]file.State文件信息。在创建pipelineEventCB的时候，也就是在pipeline使用set函数的时候，我们这边传递的是ACKEvents，所以调用的是newEventACKer(finishedLogger, registrarChannel)这个结构体的ackEvents函数。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newEventACKer(stateless statelessLogger, stateful statefulLogger) *eventACKer {
    return &amp;amp;eventACKer{stateless: stateless, stateful: stateful, log: logp.NewLogger(&amp;quot;acker&amp;quot;)}
}

func (a *eventACKer) ackEvents(data []interface{}) {
    stateless := 0
    states := make([]file.State, 0, len(data))
    for _, datum := range data {
        if datum == nil {
            stateless++
            continue
        }

        st, ok := datum.(file.State)
        if !ok {
            stateless++
            continue
        }

        states = append(states, st)
    }

    if len(states) &amp;gt; 0 {
        a.log.Debugw(&amp;quot;stateful ack&amp;quot;, &amp;quot;count&amp;quot;, len(states))
        a.stateful.Published(states)
    }

    if stateless &amp;gt; 0 {
        a.log.Debugw(&amp;quot;stateless ack&amp;quot;, &amp;quot;count&amp;quot;, stateless)
        a.stateless.Published(stateless)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调用的这个registrarLogger的Published来完成文件状态的推送&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (l *registrarLogger) Published(states []file.State) {
    select {
    case &amp;lt;-l.done:
        // set ch to nil, so no more events will be send after channel close signal
        // has been processed the first time.
        // Note: nil channels will block, so only done channel will be actively
        //       report &#39;closed&#39;.
        l.ch = nil
    case l.ch &amp;lt;- states:
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;文件持久化&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;registrarLogger的channel获取的信息是如何处理的？其实是Registrar的channel接受到了信息，在一开始Registrar就启动了监听channel。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for {
    select {
    case &amp;lt;-r.done:
        logp.Info(&amp;quot;Ending Registrar&amp;quot;)
        return
    case &amp;lt;-flushC:
        flushC = nil
        timer.Stop()
        r.flushRegistry()
    case states := &amp;lt;-r.Channel:
        r.onEvents(states)
        if r.flushTimeout &amp;lt;= 0 {
            r.flushRegistry()
        } else if flushC == nil {
            timer = time.NewTimer(r.flushTimeout)
            flushC = timer.C
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接收到文件状态后调用onEvents&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// onEvents processes events received from the publisher pipeline
func (r *Registrar) onEvents(states []file.State) {
    r.processEventStates(states)
    r.bufferedStateUpdates += len(states)

    // check if we need to enable state cleanup
    if !r.gcEnabled {
        for i := range states {
            if states[i].TTL &amp;gt;= 0 || states[i].Finished {
                r.gcEnabled = true
                break
            }
        }
    }

    logp.Debug(&amp;quot;registrar&amp;quot;, &amp;quot;Registrar state updates processed. Count: %v&amp;quot;, len(states))

    // new set of events received -&amp;gt; mark state registry ready for next
    // cleanup phase in case gc&#39;able events are stored in the registry.
    r.gcRequired = r.gcEnabled
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过processEventStates来处理&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// processEventStates gets the states from the events and writes them to the registrar state
func (r *Registrar) processEventStates(states []file.State) {
    logp.Debug(&amp;quot;registrar&amp;quot;, &amp;quot;Processing %d events&amp;quot;, len(states))

    ts := time.Now()
    for i := range states {
        r.states.UpdateWithTs(states[i], ts)
        statesUpdate.Add(1)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就是states的更新UpdateWithTs&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// UpdateWithTs updates a state, assigning the given timestamp.
// If previous state didn&#39;t exist, new one is created
func (s *States) UpdateWithTs(newState State, ts time.Time) {
    s.Lock()
    defer s.Unlock()

    id := newState.ID()
    index := s.findPrevious(id)
    newState.Timestamp = ts

    if index &amp;gt;= 0 {
        s.states[index] = newState
    } else {
        // No existing state found, add new one
        s.idx[id] = len(s.states)
        s.states = append(s.states, newState)
        logp.Debug(&amp;quot;input&amp;quot;, &amp;quot;New state added for %s&amp;quot;, newState.Source)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这边states的状态就发生变化，再来看看states的初始化操作，其实就是在Registrar的New的时候调用了NewStates进行了初始化&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r := &amp;amp;Registrar{
    registryFile: dataFile,
    fileMode:     cfg.Permissions,
    done:         make(chan struct{}),
    states:       file.NewStates(),
    Channel:      make(chan []file.State, 1),
    flushTimeout: cfg.FlushTimeout,
    out:          out,
    wg:           sync.WaitGroup{},
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在Registrar的for循环的时候，定时会对状态进行写文件操作，调用flushRegistry的writeRegistry来完成文件的持久化&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (r *Registrar) flushRegistry() {
    if err := r.writeRegistry(); err != nil {
        logp.Err(&amp;quot;Writing of registry returned error: %v. Continuing...&amp;quot;, err)
    }

    if r.out != nil {
        r.out.Published(r.bufferedStateUpdates)
    }
    r.bufferedStateUpdates = 0
}

// writeRegistry writes the new json registry file to disk.
func (r *Registrar) writeRegistry() error {
    // First clean up states
    r.gcStates()
    states := r.states.GetStates()
    statesCurrent.Set(int64(len(states)))

    registryWrites.Inc()

    tempfile, err := writeTmpFile(r.registryFile, r.fileMode, states)
    if err != nil {
        registryFails.Inc()
        return err
    }

    err = helper.SafeFileRotate(r.registryFile, tempfile)
    if err != nil {
        registryFails.Inc()
        return err
    }

    logp.Debug(&amp;quot;registrar&amp;quot;, &amp;quot;Registry file updated. %d states written.&amp;quot;, len(states))
    registrySuccess.Inc()

    return nil
}

func writeTmpFile(baseName string, perm os.FileMode, states []file.State) (string, error) {
    logp.Debug(&amp;quot;registrar&amp;quot;, &amp;quot;Write registry file: %s (%v)&amp;quot;, baseName, len(states))

    tempfile := baseName + &amp;quot;.new&amp;quot;
    f, err := os.OpenFile(tempfile, os.O_RDWR|os.O_CREATE|os.O_TRUNC|os.O_SYNC, perm)
    if err != nil {
        logp.Err(&amp;quot;Failed to create tempfile (%s) for writing: %s&amp;quot;, tempfile, err)
        return &amp;quot;&amp;quot;, err
    }

    defer f.Close()

    encoder := json.NewEncoder(f)

    if err := encoder.Encode(states); err != nil {
        logp.Err(&amp;quot;Error when encoding the states: %s&amp;quot;, err)
        return &amp;quot;&amp;quot;, err
    }

    // Commit the changes to storage to avoid corrupt registry files
    if err = f.Sync(); err != nil {
        logp.Err(&amp;quot;Error when syncing new registry file contents: %s&amp;quot;, err)
        return &amp;quot;&amp;quot;, err
    }

    return tempfile, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;总结&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;对以上的过程最一个简单的总结&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/registry.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;特殊情况&#34;&gt;特殊情况&lt;/h3&gt;

&lt;p&gt;1.如果filebeat异常重启，每次采集harvester启动的时候都会读取registry文件，从上次记录的状态继续采集，确保不会从头开始重复发送所有的日志文件。
当然，如果日志发送过程中，还没来得及返回ack，filebeat就挂掉，registry文件肯定不会更新至最新的状态，那么下次采集的时候，这部分的日志就会重复发送，所以这意味着filebeat只能保证at least once，无法保证不重复发送。
还有一个比较异常的情况是，linux下如果老文件被移除，新文件马上创建，很有可能它们有相同的inode，而由于filebeat根据inode来标志文件记录采集的偏移，会导致registry里记录的其实是被移除的文件State状态，这样新的文件采集却从老的文件Offset开始，从而会遗漏日志数据。
为了尽量避免inode被复用的情况，同时防止registry文件随着时间增长越来越大，建议使用clean_inactive和clean_remove配置将长时间未更新或者被删除的文件State从registry中移除。&lt;/p&gt;

&lt;p&gt;2.在harvester读取日志中，会更新registry的状态处理一些异常场景。例如，如果一个日志文件被清空，filebeat会在下一次Reader.Next方法中返回ErrFileTruncate异常，将inode标志文件的Offset置为0，结束这次harvester，重新启动新的harvester，虽然文件不变，但是registry中的Offset为0，采集会从头开始。&lt;/p&gt;

&lt;p&gt;3.如果使用容器部署filebeat，需要将registry文件挂载到宿主机上，否则容器重启后registry文件丢失，会使filebeat从头开始重复采集日志文件。&lt;/p&gt;

&lt;h4 id=&#34;日志重复&#34;&gt;日志重复&lt;/h4&gt;

&lt;p&gt;Filebeat对于收集到的数据（即event）的传输保证的是&amp;rdquo;at least once&amp;rdquo;，而不是&amp;rdquo;exactly once&amp;rdquo;，也就是Filebeat传输的数据是有可能有重复的。这里我们讨论一下可能产生重复数据的一些场景，我大概将其分为两类。&lt;/p&gt;

&lt;p&gt;第一类：Filebeat重传导致数据重复。重传是因为Filebeat要保证数据至少发送一次，进而避免数据丢失。具体来说就是每条event发送到output后都要等待ack，只有收到ack了才会认为数据发送成功，然后将状态记录到registry。当然实际操作的时候为了高效是批量发送，批量确认的。而造成重传的场景（也就是没有收到ack）非常多，而且很多都不可避免，比如后端不可达、网络传输失败、程序突然挂掉等等。&lt;/p&gt;

&lt;p&gt;第二类：配置不当或操作不当导致文件重复收集。Filebeat感知文件有没有被收集过靠的是registry文件里面记录的状态，如果一个文件已经被收集过了，但因为各种原因它的状态从registry文件中被移除了，而恰巧这个文件还在收集范围内，那就会再收集一次。&lt;/p&gt;

&lt;p&gt;对于第一类产生的数据重复一般不可避免，而第二类可以避免，但总的来说，Filebeat提供的是at least once的机制，所以我们在使用时要明白数据是可能重复的。如果业务上不能接受数据重复，那就要在Filebeat之后的流程中去重。&lt;/p&gt;

&lt;h4 id=&#34;数据丢失&#34;&gt;数据丢失&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;inode重用的问题&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果一个文件达到了限制（比如大小），不是重新创建一个新的文件写，而是将这个文件truncate掉继续复用（当然实际中这种场景好像比较少，但也并非没有），Filebeat下次来检查这个文件是否有变动的时候，这个文件的大小如果大于之前记录的offset，也会发生上面的情况。这个问题在github上面是有issue的，但目前还没有解决，官方回复是Filebeat的整个机制在重构中。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;还有一些其它情况，比如文件数太多，Filebeat的处理能力有限，在还没来得及处理的时候这些文件就被删掉了（比如rotate给老化掉了）也会造成数据丢失。还有就是后端不可用，所以Filebeat还在重试，但源文件被删了，那数据也就丢了。因为Filebeat的重试并非一直发送已经收集到内存里面的event，必要的时候会重新从源文件读，比如程序重启。这些情况的话，只要不限制Filebeat的收集能力，同时保证后端的可用性，网络的可用性，一般问题不大。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;总结-1&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;其实重数据发送到内存队列中这一套完整的功能就是由libbeat完成的，正常流程如下&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/output.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;日志采集状态监控&#34;&gt;日志采集状态监控&lt;/h2&gt;

&lt;p&gt;我们之前讲到 Registrar 会记录每个文件的状态，当 Filebeat 启动时，会从 Registrar 恢复文件处理状态。&lt;/p&gt;

&lt;p&gt;其实在 filebeat 运行过程中，Input 组件也记录了文件状态。不一样的是，Registrar 是持久化存储，而 Input 中的文件状态仅表示当前文件的读取偏移量，且修改时不会同步到磁盘中。&lt;/p&gt;

&lt;p&gt;每次，Filebeat 刚启动时，Input 都会载入 Registrar 中记录的文件状态，作为初始状态。Input 中的状态有两个非常重要：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;offset: 代表文件当前读取的 offset，从 Registrar 中初始化。Harvest 读取文件后，会同时修改 offset。
finished: 代表该文件对应的 Harvester 是否已经结束，Harvester 开始时置为 false，结束时置为 true。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于每次定时扫描到的文件，概括来说，会有三种大的情况：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Input 找不到该文件状态的记录, 说明是新增文件，则开启一个 Harvester，从头开始解析该文件
如果可以找到文件状态，且 finished 等于 false。这个说明已经有了一个 Harvester 在处理了，这种情况直接忽略就好了。
如果可以找到文件状态，且 finished 等于 true。说明之前有 Harvester 处理过，但已经处理结束了。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于这种第三种情况，我们需要考虑到一些异常情况，Filebeat 是这么处理的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;如果 offset 大于当前文件大小：说明文件被 Truncate 过，此时按做一个新文件处理，直接从头开始解析该文件
如果 offset 小于当前文件大小，说明文件内容有新增，则从上次 offset 处继续读即可。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于第二种情况，Filebeat 似乎有一个逻辑上的问题: 如果文件被 Truncate 过，后来又新增了数据，且文件大小也比之前 offset 大，那么 Filebeat 是检查不出来这个问题的。&lt;/p&gt;

&lt;h2 id=&#34;句柄保持&#34;&gt;句柄保持&lt;/h2&gt;

&lt;p&gt;Filebeat 甚至可以处理文件名修改的问题。即使一个日志的文件名被修改过，Filebeat 重启后，也能找到该文件，从上次读过的地方继续读。&lt;/p&gt;

&lt;p&gt;这是因为 Filebeat 除了在 Registrar 存储了文件名，还存储了文件的唯一标识。对于 Linux 来说，这个文件的唯一标识就是该文件的 inode ID + device ID。&lt;/p&gt;

&lt;h2 id=&#34;重载&#34;&gt;重载&lt;/h2&gt;

&lt;p&gt;重载是在Crawler中启动的，首先是新建的InputsFactory的结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c.InputsFactory = input.NewRunnerFactory(c.out, r, c.beatDone)

// RunnerFactory is a factory for registrars
type RunnerFactory struct {
    outlet    channel.Factory
    registrar *registrar.Registrar
    beatDone  chan struct{}
}

// NewRunnerFactory instantiates a new RunnerFactory
func NewRunnerFactory(outlet channel.Factory, registrar *registrar.Registrar, beatDone chan struct{}) *RunnerFactory {
    return &amp;amp;RunnerFactory{
        outlet:    outlet,
        registrar: registrar,
        beatDone:  beatDone,
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后如果配置了重载，就会新建Reloader结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Reloader is used to register and reload modules
type Reloader struct {
    pipeline beat.Pipeline
    config   DynamicConfig
    path     string
    done     chan struct{}
    wg       sync.WaitGroup
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;新建的过程如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if configInputs.Enabled() {
    c.inputReloader = cfgfile.NewReloader(pipeline, configInputs)
    if err := c.inputReloader.Check(c.InputsFactory); err != nil {
        return err
    }

    go func() {
        c.inputReloader.Run(c.InputsFactory)
    }()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动reloader的run方法并且将RunnerFactory作为参数传递进去&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Run runs the reloader
func (rl *Reloader) Run(runnerFactory RunnerFactory) {
    logp.Info(&amp;quot;Config reloader started&amp;quot;)

    list := NewRunnerList(&amp;quot;reload&amp;quot;, runnerFactory, rl.pipeline)

    rl.wg.Add(1)
    defer rl.wg.Done()

    // Stop all running modules when method finishes
    defer list.Stop()

    gw := NewGlobWatcher(rl.path)

    // If reloading is disable, config files should be loaded immediately
    if !rl.config.Reload.Enabled {
        rl.config.Reload.Period = 0
    }

    overwriteUpdate := true

    for {
        select {
        case &amp;lt;-rl.done:
            logp.Info(&amp;quot;Dynamic config reloader stopped&amp;quot;)
            return

        case &amp;lt;-time.After(rl.config.Reload.Period):
            debugf(&amp;quot;Scan for new config files&amp;quot;)
            configReloads.Add(1)

            //扫描所有的配置文件
            files, updated, err := gw.Scan()
            if err != nil {
                // In most cases of error, updated == false, so will continue
                // to next iteration below
                logp.Err(&amp;quot;Error fetching new config files: %v&amp;quot;, err)
            }

            // no file changes
            if !updated &amp;amp;&amp;amp; !overwriteUpdate {
                overwriteUpdate = false
                continue
            }

            // Load all config objects 加载所有配置文件
            configs, _ := rl.loadConfigs(files)

            debugf(&amp;quot;Number of module configs found: %v&amp;quot;, len(configs))

            //启动加载程序
            if err := list.Reload(configs); err != nil {
                // Make sure the next run also updates because some runners were not properly loaded
                overwriteUpdate = true
            }
        }

        // Path loading is enabled but not reloading. Loads files only once and then stops.
        if !rl.config.Reload.Enabled {
            logp.Info(&amp;quot;Loading of config files completed.&amp;quot;)
            select {
            case &amp;lt;-rl.done:
                logp.Info(&amp;quot;Dynamic config reloader stopped&amp;quot;)
                return
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见有一个定时的循环程序来获取所有的配置文件，交给RunnerList的reload的来加载&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Reload the list of runners to match the given state
func (r *RunnerList) Reload(configs []*reload.ConfigWithMeta) error {
    r.mutex.Lock()
    defer r.mutex.Unlock()

    var errs multierror.Errors

    startList := map[uint64]*reload.ConfigWithMeta{}
    //获取正在运行的runner到stopList
    stopList := r.copyRunnerList()

    r.logger.Debugf(&amp;quot;Starting reload procedure, current runners: %d&amp;quot;, len(stopList))

    // diff current &amp;amp; desired state, create action lists
    for _, config := range configs {
        hash, err := HashConfig(config.Config)
        if err != nil {
            r.logger.Errorf(&amp;quot;Unable to hash given config: %s&amp;quot;, err)
            errs = append(errs, errors.Wrap(err, &amp;quot;Unable to hash given config&amp;quot;))
            continue
        }

        //如果配置文件还在，就重stopList中删除，继续采集，剩下的在stopList中的下面会停止采集
        if _, ok := stopList[hash]; ok {
            delete(stopList, hash)
        } else {
            //如果不在stopList中，说明是新的文件，如果不是重复的就加入到startList中，下来开始采集
            if _,ok := r.runners[hash]; !ok{
                startList[hash] = config
            }
        }
    }

    r.logger.Debugf(&amp;quot;Start list: %d, Stop list: %d&amp;quot;, len(startList), len(stopList))

    // Stop removed runners
    for hash, runner := range stopList {
        r.logger.Debugf(&amp;quot;Stopping runner: %s&amp;quot;, runner)
        delete(r.runners, hash)
        go runner.Stop()
    }

    // Start new runners
    for hash, config := range startList {
        // Pass a copy of the config to the factory, this way if the factory modifies it,
        // that doesn&#39;t affect the hash of the original one.
        c, _ := common.NewConfigFrom(config.Config)
        runner, err := r.factory.Create(r.pipeline, c, config.Meta)
        if err != nil {
            r.logger.Errorf(&amp;quot;Error creating runner from config: %s&amp;quot;, err)
            errs = append(errs, errors.Wrap(err, &amp;quot;Error creating runner from config&amp;quot;))
            continue
        }

        r.logger.Debugf(&amp;quot;Starting runner: %s&amp;quot;, runner)
        r.runners[hash] = runner
        runner.Start()
    }

    return errs.Err()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边的create就是上面传进来的InputsFactory的结构体的成员函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Create creates a input based on a config
func (r *RunnerFactory) Create(
    pipeline beat.Pipeline,
    c *common.Config,
    meta *common.MapStrPointer,
) (cfgfile.Runner, error) {
    connector := r.outlet(pipeline)
    p, err := New(c, connector, r.beatDone, r.registrar.GetStates(), meta)
    if err != nil {
        // In case of error with loading state, input is still returned
        return p, err
    }

    return p, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看看new函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// New instantiates a new Runner
func New(
    conf *common.Config,
    connector channel.Connector,
    beatDone chan struct{},
    states []file.State,
    dynFields *common.MapStrPointer,
) (*Runner, error) {
    input := &amp;amp;Runner{
        config:   defaultConfig,
        wg:       &amp;amp;sync.WaitGroup{},
        done:     make(chan struct{}),
        Once:     false,
        beatDone: beatDone,
    }

    var err error
    if err = conf.Unpack(&amp;amp;input.config); err != nil {
        return nil, err
    }

    var h map[string]interface{}
    conf.Unpack(&amp;amp;h)
    input.ID, err = hashstructure.Hash(h, nil)
    if err != nil {
        return nil, err
    }

    var f Factory
    f, err = GetFactory(input.config.Type)
    if err != nil {
        return input, err
    }

    context := Context{
        States:        states,
        Done:          input.done,
        BeatDone:      input.beatDone,
        DynamicFields: dynFields,
        Meta:          nil,
    }
    var ipt Input
    ipt, err = f(conf, connector, context)
    if err != nil {
        return input, err
    }
    input.input = ipt

    return input, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看见就是新建流程中的新建runner，下面调用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;runner.Start()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就是正常的采集流程，到这边重载也就结束了。&lt;/p&gt;

&lt;h1 id=&#34;基本使用与特性&#34;&gt;基本使用与特性&lt;/h1&gt;

&lt;h2 id=&#34;filebeat自动reload更新&#34;&gt;filebeat自动reload更新&lt;/h2&gt;

&lt;p&gt;目前filebeat支持reload input配置，module配置，但reload的机制只有定时更新。&lt;/p&gt;

&lt;p&gt;在配置中打开reload.enable之后，还可以配置reload.period表示自动reload配置的时间间隔。&lt;/p&gt;

&lt;p&gt;filebeat在启动时，会创建一个专门用于reload的协程。对于每个正在运行的harvester，filebeat会将其加入一个全局的Runner列表，每次到了定时的间隔后，会触发一次配置文件的diff判断，如果是需要停止的加入stopRunner列表，然后逐个关闭，新的则加入startRunner列表，启动新的Runner。&lt;/p&gt;

&lt;h2 id=&#34;filebeat对kubernetes的支持&#34;&gt;filebeat对kubernetes的支持&lt;/h2&gt;

&lt;p&gt;filebeat官方文档提供了在kubernetes下基于daemonset的部署方式，最主要的一个配置如下所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- type: docker
      containers.ids:
      - &amp;quot;*&amp;quot;
      processors:
        - add_kubernetes_metadata:
            in_cluster: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;即设置输入input为docker类型。由于所有的容器的标准输出日志默认都在节点的/var/lib/docker/containers/&lt;containerId&gt;/*-json.log路径，所以本质上采集的是这类日志文件。&lt;/p&gt;

&lt;p&gt;和传统的部署方式有所区别的是，如果服务部署在kubernetes上，我们查看和检索日志的维度不能仅仅局限于节点和服务，还需要有podName，containerName等，所以每条日志我们都需要打标增加kubernetes的元信息才发送至后端。&lt;/p&gt;

&lt;p&gt;filebeat会在配置中增加了add_kubernetes_metadata的processor的情况下，启动监听kubernetes的watch服务，监听所有kubernetes pod的变更，然后将归属本节点的pod最新的事件同步至本地的缓存中。&lt;/p&gt;

&lt;p&gt;节点上一旦发生容器的销毁创建，/var/lib/docker/containers/下会有目录的变动，filebeat根据路径提取出containerId，再根据containerId从本地的缓存中找到pod信息，从而可以获取到podName、label等数据，并加到日志的元信息fields中。&lt;/p&gt;

&lt;p&gt;filebeat还有一个beta版的功能autodiscover，autodiscover的目的是把分散到不同节点上的filebeat配置文件集中管理。目前也支持kubernetes作为provider，本质上还是监听kubernetes事件然后采集docker的标准输出文件。&lt;/p&gt;

&lt;p&gt;大致架构如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/log/filebeat/k8slog.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;但是在实际生产环境使用中，仅采集容器的标准输出日志还是远远不够，我们往往还需要采集容器挂载出来的自定义日志目录，还需要控制每个服务的日志采集方式以及更多的定制化功能。&lt;/p&gt;

&lt;h2 id=&#34;性能分析与调优&#34;&gt;性能分析与调优&lt;/h2&gt;

&lt;p&gt;虽然beats系列主打轻量级，虽然用golang写的filebeat的内存占用确实比较基于jvm的logstash等好太多，但是事实告诉我们其实没那么简单。&lt;/p&gt;

&lt;p&gt;正常启动filebeat，一般确实只会占用3、40MB内存，但是在轻舟容器云上偶发性的我们也会发现某些节点上的filebeat容器内存占用超过配置的pod limit限制（一般设置为200MB），并且不停的触发的OOM。&lt;/p&gt;

&lt;p&gt;究其原因，一般容器化环境中，特别是裸机上运行的容器个数可能会比较多，导致创建大量的harvester去采集日志。如果没有很好的配置filebeat，会有较大概率导致内存急剧上升。
当然，filebeat内存占据较大的部分还是memqueue，所有采集到的日志都会先发送至memqueue聚集，再通过output发送出去。每条日志的数据在filebeat中都被组装为event结构，filebeat默认配置的memqueue缓存的event个数为4096，可通过queue.mem.events设置。默认最大的一条日志的event大小限制为10MB，可通过max_bytes设置。4096 * 10MB = 40GB，可以想象，极端场景下，filebeat至少占据40GB的内存。特别是配置了multiline多行模式的情况下，如果multiline配置有误，单个event误采集为上千条日志的数据，很可能导致memqueue占据了大量内存，致使内存爆炸。&lt;/p&gt;

&lt;p&gt;所以，合理的配置日志文件的匹配规则，限制单行日志大小，根据实际情况配置memqueue缓存的个数，才能在实际使用中规避filebeat的内存占用过大的问题。&lt;/p&gt;

&lt;p&gt;有些文章说filebeat内存消耗很少,不会超过100M, 这简直是不负责任的胡说,假如带着这样的认识把filebeat部署到生产服务器上就等着哭吧.&lt;/p&gt;

&lt;p&gt;那怎么样才能避免以上内存灾难呢?&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;每个日志生产环境生产的日志大小,爆发量都不一样, 要根据自己的日志特点设定合适的event值;什么叫合适,至少能避免内存&amp;gt;200MB的灾难;&lt;/li&gt;
&lt;li&gt;在不知道日志实际情况(单条大小,爆发量), 务必把event设置上,建议128或者256;&lt;/li&gt;
&lt;li&gt;合理的配置日志文件的匹配规则，是否因为通配符的原因，造成同时监控数量巨大的文件，这种情况应该避免用通配符监控无用的文件。&lt;/li&gt;
&lt;li&gt;规范日志，限制单行日志大小，是否文件的单行内容巨大，确定是否需要改造文件内容，或者将其过滤&lt;/li&gt;
&lt;li&gt;限制cpu&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;上面的一系列操作可以做如下配置&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;max_procs: 2
queue:
  mem:
    events: 512
    flush.min_events: 256
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;限制cpu为2core，内存最大为512*10M～=5G&lt;/p&gt;

&lt;p&gt;限制cpu的配置&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;max_procs，限制filebeat的进程数量，其实是内核数，建议手动设为1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;限制内存的配置&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;queue.mem.events消息队列的大小，默认值是4096，这个参数在6.0以前的版本是spool-size，通过命令行，在启动时进行配置
max_message_bytes 单条消息的大小, 默认值是10M
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;filebeat最大的可能占用的内存是max_message_bytes * queue.mem.events = 40G，考虑到这个queue是用于存储encode过的数据，raw数据也是要存储的，所以，在没有对内存进行限制的情况下，最大的内存占用情况是可以达到超过80G。&lt;/p&gt;

&lt;h2 id=&#34;内存使用过多的情况&#34;&gt;内存使用过多的情况&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;非常频繁的rotate日志&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;对于实时大量产生内容的文件，比如日志，常用的做法往往是将日志文件进行rotate，根据策略的不同，每隔一段时间或者达到固定大小之后，将日志rotate。
这样，在文件目录下可能会产生大量的日志文件。
如果我们使用通配符的方式，去监控该目录，则filebeat会启动大量的harvester实例去采集文件。但是，请记住，我这里不是说这样一定会产生内存泄漏，只是在这里观测到了内存泄漏而已，不是说这是造成内存泄漏的原因。&lt;/p&gt;

&lt;p&gt;当filebeat运行了几个月之后，占用了超过10个G的内存。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;因为multiline导致内存占用过多&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;multiline.pattern: &amp;lsquo;^[[:space:]]+|^Caused by:|^.+Exception:|^\d+\serror，比如这个配置，认为空格或者制表符开头的line是上一行的附加内容，需要作为多行模式，存储到同一个event当中。当你监控的文件刚巧在文件的每一行带有一个空格时，会错误的匹配多行，造成filebeat解析过后，单条event的行数达到了上千行，大小达到了10M，并且在这过程中使用的是正则表达式，每一条event的处理都会极大的消耗内存。因为大多数的filebeat output是需应答的，buffer这些event必然会大量的消耗内存。&lt;/p&gt;

&lt;h2 id=&#34;解读日志中的监控数据&#34;&gt;解读日志中的监控数据&lt;/h2&gt;

&lt;p&gt;其实filebeat的日志，已经包含了很多参数用于实时观测filebeat的资源使用情况，（下面是6.0版本的，6.5版本之后，整个日志格式变了，从kv格式变成了json对象格式）&lt;/p&gt;

&lt;p&gt;里面的参数主要分成三个部分：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;beat.*，包含memstats.gc_next，memstats.memory_alloc，memstats.memory_total，这个是所有beat组件都有的指标，是filebeat继承来的，主要是内存相关的，我们这里特别关注memstats.memory_alloc，alloc的越多，占用内存越大
filebeat.*，这部分是filebeat特有的指标，通过event相关的指标，我们知道吞吐，通过harvester，我们知道正在监控多少个文件，未消费event堆积的越多，havester创建的越多，消耗内存越大
libbeat.*，也是beats组件通用的指标，包含outputs和pipeline等信息。这里要主要当outputs发生阻塞的时候，会直接影响queue里面event的消费，造成内存堆积
registrar，filebeat将监控文件的状态放在registry文件里面，当监控文件非常多的时候，比如10万个，而且没有合理的设置close_inactive参数，这个文件能达到100M，载入内存后，直接占用内存
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在6.5之后都是json，但也是kv结构，可以对应查看。&lt;/p&gt;

&lt;h2 id=&#34;如何对filebeat进行扩展开发&#34;&gt;如何对filebeat进行扩展开发&lt;/h2&gt;

&lt;p&gt;一般情况下filebeat可满足大部分的日志采集需求，但是仍然避免不了一些特殊的场景需要我们对filebeat进行定制化开发，当然filebeat本身的设计也提供了良好的扩展性。
beats目前只提供了像elasticsearch、kafka、logstash等几类output客户端，如果我们想要filebeat直接发送至其他后端，需要定制化开发自己的output。同样，如果需要对日志做过滤处理或者增加元信息，也可以自制processor插件。
无论是增加output还是写个processor，filebeat提供的大体思路基本相同。一般来讲有3种方式：&lt;/p&gt;

&lt;p&gt;1.直接fork filebeat，在现有的源码上开发。output或者processor都提供了类似Run、Stop等的接口，只需要实现该类接口，然后在init方法中注册相应的插件初始化方法即可。当然，由于golang中init方法是在import包时才被调用，所以需要在初始化filebeat的代码中手动import。&lt;/p&gt;

&lt;p&gt;2.filebeat还提供了基于golang plugin的插件机制，需要把自研的插件编译成.so共享链接库，然后在filebeat启动参数中通过-plugin指定库所在路径。不过实际上一方面golang plugin还不够成熟稳定，一方面自研的插件依然需要依赖相同版本的libbeat库，而且还需要相同的golang版本编译，坑可能更多，不太推荐。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Golang使用系列---- Ioutil</title>
          <link>https://kingjcy.github.io/post/golang/go-ioutil/</link>
          <pubDate>Sat, 13 Jan 2018 11:04:07 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/golang/go-ioutil/</guid>
          <description>&lt;p&gt;ioutil主要是提供了一些常用、方便的IO操作函数。&lt;/p&gt;

&lt;h1 id=&#34;ioutil&#34;&gt;ioutil&lt;/h1&gt;

&lt;p&gt;ioutil针对reader和writer这两个接口封装的基础操作&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Discard 是一个 io.Writer 接口，调用它的 Write 方法将不做任何事情
// 并且始终成功返回。
var Discard io.Writer = devNull(0)

// ReadAll 读取 r 中的所有数据，返回读取的数据和遇到的错误。
// 如果读取成功，则 err 返回 nil，而不是 EOF，因为 ReadAll 定义为读取
// 所有数据，所以不会把 EOF 当做错误处理。
func ReadAll(r io.Reader) ([]byte, error)

// ReadFile 读取文件中的所有数据，返回读取的数据和遇到的错误。
// 如果读取成功，则 err 返回 nil，而不是 EOF
func ReadFile(filename string) ([]byte, error)

// WriteFile 向文件中写入数据，写入前会清空文件。
// 如果文件不存在，则会以指定的权限创建该文件。
// 返回遇到的错误。
func WriteFile(filename string, data []byte, perm os.FileMode) error

// ReadDir 读取指定目录中的所有目录和文件（不包括子目录）。
// 返回读取到的文件信息列表和遇到的错误，列表是经过排序的。
func ReadDir(dirname string) ([]os.FileInfo, error)

// NopCloser 将 r 包装为一个 ReadCloser 类型，但 Close 方法不做任何事情。
func NopCloser(r io.Reader) io.ReadCloser

// TempFile 在 dir 目录中创建一个以 prefix 为前缀的临时文件，并将其以读
// 写模式打开。返回创建的文件对象和遇到的错误。
// 如果 dir 为空，则在默认的临时目录中创建文件（参见 os.TempDir），多次
// 调用会创建不同的临时文件，调用者可以通过 f.Name() 获取文件的完整路径。
// 调用本函数所创建的临时文件，应该由调用者自己删除。
func TempFile(dir, prefix string) (f *os.File, err error)

// TempDir 功能同 TempFile，只不过创建的是目录，返回目录的完整路径。
func TempDir(dir, prefix string) (name string, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;示例&#34;&gt;示例&lt;/h1&gt;

&lt;h2 id=&#34;读取目录&#34;&gt;读取目录&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    rd, err := ioutil.ReadDir(&amp;quot;/&amp;quot;)
    fmt.Println(err)
    for _, fi := range rd {
        if fi.IsDir() {
            fmt.Printf(&amp;quot;[%s]\n&amp;quot;, fi.Name())

        } else {
            fmt.Println(fi.Name())
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;临时目录-临时文件&#34;&gt;临时目录、临时文件&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    // 创建临时目录
    dir, err := ioutil.TempDir(&amp;quot;&amp;quot;, &amp;quot;Test&amp;quot;)
    if err != nil {
        fmt.Println(err)
    }
    defer os.Remove(dir) // 用完删除
    fmt.Printf(&amp;quot;%s\n&amp;quot;, dir)

    // 创建临时文件
    f, err := ioutil.TempFile(dir, &amp;quot;Test&amp;quot;)
    if err != nil {
        fmt.Println(err)
    }
    defer os.Remove(f.Name()) // 用完删除
    fmt.Printf(&amp;quot;%s\n&amp;quot;, f.Name())
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;读取文件&#34;&gt;读取文件&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;io/ioutil&amp;quot;
)

func main() {
    b, err := ioutil.ReadFile(&amp;quot;test.log&amp;quot;)
    if err != nil {
        fmt.Print(err)
    }
    fmt.Println(b)
    str := string(b)
    fmt.Println(str)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;写文件&#34;&gt;写文件&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
   &amp;quot;io/ioutil&amp;quot;
)

func check(e error) {
   if e != nil {
       panic(e)
   }
}

func main() {

   d1 := []byte(&amp;quot;hello\ngo\n&amp;quot;)
   err := ioutil.WriteFile(&amp;quot;test.txt&amp;quot;, d1, 0644)
   check(err)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;读取文件和写文件内容还可以使用&lt;a href=&#34;https://kingjcy.github.io/post/golang/go-os/#文件io&#34;&gt;os包&lt;/a&gt;来处理。一般也是使用os标准库来处理。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Golang使用系列---- Bytes</title>
          <link>https://kingjcy.github.io/post/golang/go-bytes/</link>
          <pubDate>Mon, 25 Dec 2017 14:28:17 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/golang/go-bytes/</guid>
          <description>&lt;p&gt;该包定义了一些操作 byte slice 的便利操作。因为字符串可以表示为 []byte，因此，bytes 包定义的函数、方法等和 strings 包很类似，所以讲解时会和 strings 包类似甚至可以直接参考。&lt;/p&gt;

&lt;h1 id=&#34;基本使用&#34;&gt;基本使用&lt;/h1&gt;

&lt;h2 id=&#34;是否存在某个子-slice&#34;&gt;是否存在某个子 slice&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;// 子 slice subslice 在 b 中，返回 true
func Contains(b, subslice []byte) bool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该函数的内部调用了 bytes.Index 函数（在后面会讲解）:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Contains(b, subslice []byte) bool {
    return Index(b, subslice) != -1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;题外：对比 strings.Contains 你会发现，一个判断 &amp;gt;=0，一个判断 != -1，可见库不是一个人写的，没有做到一致性。&lt;/p&gt;

&lt;h2 id=&#34;byte-出现次数&#34;&gt;[]byte 出现次数&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;// slice sep 在 s 中出现的次数（无重叠）
func Count(s, sep []byte) int
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;和 strings 实现不同，此包中的 Count 核心代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;count := 0
c := sep[0]
i := 0
t := s[:len(s)-n+1]
for i &amp;lt; len(t) {
    // 判断 sep 第一个字节是否在 t[i:] 中
    // 如果在，则比较之后相应的字节
    if t[i] != c {
        o := IndexByte(t[i:], c)
        if o &amp;lt; 0 {
            break
        }
        i += o
    }
    // 执行到这里表示 sep[0] == t[i]
    if n == 1 || Equal(s[i:i+n], sep) {
        count++
        i += n
        continue
    }
    i++
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;runes-类型转换&#34;&gt;Runes 类型转换&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;// 将 []byte 转换为 []rune
func Runes(s []byte) []rune
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该函数将 []byte 转换为 []rune ，适用于汉字等多字节字符，示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;b:=[]byte(&amp;quot;你好，世界&amp;quot;)
for k,v:=range b{
    fmt.Printf(&amp;quot;%d:%s |&amp;quot;,k,string(v))
}
r:=bytes.Runes(b)
for k,v:=range r{
    fmt.Printf(&amp;quot;%d:%s|&amp;quot;,k,string(v))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0:ä |1:½ |2:  |3:å |4:¥ |5:½ |6:ï |7:¼ |8:  |9:ä |10:¸ |11:  |12:ç |13:  |14: |
0:你|1:好|2:，|3:世|4:界|
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;其它函数&#34;&gt;其它函数&lt;/h2&gt;

&lt;p&gt;其它大部分函数、方法与 strings 包下的函数、方法类似，只是数据源从 string 变为了 []byte ，请参考 strings 包的用法。&lt;/p&gt;

&lt;h1 id=&#34;类型&#34;&gt;类型&lt;/h1&gt;

&lt;h2 id=&#34;reader-类型&#34;&gt;Reader 类型&lt;/h2&gt;

&lt;p&gt;看到名字就能猜到，这是实现了 io 包中的接口。其实这就是缓存io，对缓存中的[]byte进行读写操作。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Reader struct {
    s        []byte
    i        int64 // 当前读取下标
    prevRune int   // 前一个字符的下标，也可能 &amp;lt; 0
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bytes 包下的 Reader 类型实现了 io 包下的 Reader, ReaderAt, RuneReader, RuneScanner, ByteReader, ByteScanner, ReadSeeker, Seeker, WriterTo 等多个接口。主要用于 Read 数据。&lt;/p&gt;

&lt;p&gt;我们需要在通过 bytes.NewReader 方法来初始化 bytes.Reader 类型的对象。初始化时传入 []byte 类型的数据。NewReader 函数签名如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewReader(b []byte) *Reader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果直接声明该对象了，可以通过 Reset 方法重新写入数据，示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x:=[]byte(&amp;quot;你好，世界&amp;quot;)

r1:=bytes.NewReader(x)
d1:=make([]byte,len(x))
n,_:=r1.Read(d1)
fmt.Println(n,string(d1))

r2:=bytes.Reader{}
r2.Reset(x)
d2:=make([]byte,len(x))
n,_=r2.Read(d2)
fmt.Println(n,string(d2))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;15 你好，世界
15 你好，世界
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reader 包含了 8 个读取相关的方法，实现了前面提到的 io 包下的 9 个接口（ReadSeeker 接口内嵌 Reader 和 Seeker 两个接口）：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 读取数据至 b
func (r *Reader) Read(b []byte) (n int, err error)
// 读取一个字节
func (r *Reader) ReadByte() (byte, error)
// 读取一个字符
func (r *Reader) ReadRune() (ch rune, size int, err error)
// 读取数据至 w
func (r *Reader) WriteTo(w io.Writer) (n int64, err error)
// 进度下标指向前一个字节，如果 r.i &amp;lt;= 0 返回错误。
func (r *Reader) UnreadByte()
// 进度下标指向前一个字符，如果 r.i &amp;lt;= 0 返回错误，且只能在每次 ReadRune 方法后使用一次，否则返回错误。
func (r *Reader) UnreadRune()
// 读取 r.s[off:] 的数据至b，该方法忽略进度下标 i，不使用也不修改。
func (r *Reader) ReadAt(b []byte, off int64) (n int, err error)
// 根据 whence 的值，修改并返回进度下标 i ，当 whence == 0 ，进度下标修改为 off，当 whence == 1 ，进度下标修改为 i+off，当 whence == 2 ，进度下标修改为 len[s]+off.
// off 可以为负数，whence 的只能为 0，1，2，当 whence 为其他值或计算后的进度下标越界，则返回错误。
func (r *Reader) Seek(offset int64, whence int) (int64, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x := []byte(&amp;quot;你好，世界&amp;quot;)
r1 := bytes.NewReader(x)

ch, size, _ := r1.ReadRune()
fmt.Println(size, string(ch))
_ = r1.UnreadRune()
ch, size, _ = r1.ReadRune()
fmt.Println(size, string(ch))
_ = r1.UnreadRune()

by, _ := r1.ReadByte()
fmt.Println(by)
_ = r1.UnreadByte()
by, _ = r1.ReadByte()
fmt.Println(by)
_ = r1.UnreadByte()

d1 := make([]byte, 6)
n, _ := r1.Read(d1)
fmt.Println(n, string(d1))

d2 := make([]byte, 6)
n, _ = r1.ReadAt(d2, 0)
fmt.Println(n, string(d2))

w1 := &amp;amp;bytes.Buffer{}
_, _ = r1.Seek(0, 0)
_, _ = r1.WriteTo(w1)
fmt.Println(w1.String())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;3 你
3 你
228
228
6 你好
6 你好
你好，世界
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;buffer-类型&#34;&gt;Buffer 类型&lt;/h2&gt;

&lt;p&gt;buffer类型也实现了缓存io，也是对[]byte进行读写操作，提供了多种实现化函数对象，个人感觉是对string，byte的reader的综合使用实现。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Buffer struct {
    buf      []byte
    off      int
    lastRead readOp
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在上一个示例的最后，我们使用了 bytes.Buffer 类型，该类型实现了 io 包下的 ByteScanner, ByteWriter, ReadWriter, Reader, ReaderFrom, RuneReader, RuneScanner, StringWriter, Writer, WriterTo 等接口，可以方便的进行读写操作。&lt;/p&gt;

&lt;p&gt;对象可读取数据为 buf[off : len(buf)], off 表示进度下标，lastRead 表示最后读取的一个字符所占字节数，方便 Unread* 相关操作。&lt;/p&gt;

&lt;p&gt;Buffer 可以通过 3 中方法初始化对象：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a := bytes.NewBufferString(&amp;quot;Hello World&amp;quot;)
b := bytes.NewBuffer([]byte(&amp;quot;Hello World&amp;quot;))
c := bytes.Buffer{}

fmt.Println(a)
fmt.Println(b)
fmt.Println(c)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Hello World
Hello World
{[] 0 0}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Buffer 包含了 21 个读写相关的方法，大部分同名方法的用法与前面讲的类似，这里只讲演示其中的 3 个方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 读取到字节 delim 后，以字节数组的形式返回该字节及前面读取到的字节。如果遍历 b.buf 也找不到匹配的字节，则返回错误(一般是 EOF)
func (b *Buffer) ReadBytes(delim byte) (line []byte, err error)
// 读取到字节 delim 后，以字符串的形式返回该字节及前面读取到的字节。如果遍历 b.buf 也找不到匹配的字节，则返回错误(一般是 EOF)
func (b *Buffer) ReadString(delim byte) (line string, err error)
// 截断 b.buf , 舍弃 b.off+n 之后的数据。n == 0 时，调用 Reset 方法重置该对象，当 n 越界时（n &amp;lt; 0 || n &amp;gt; b.Len() ）方法会触发 panic.
func (b *Buffer) Truncate(n int)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a := bytes.NewBufferString(&amp;quot;Good Night&amp;quot;)

x, err := a.ReadBytes(&#39;t&#39;)
if err != nil {
    fmt.Println(&amp;quot;delim:t err:&amp;quot;, err)
} else {
    fmt.Println(string(x))
}

a.Truncate(0)
a.WriteString(&amp;quot;Good Night&amp;quot;)
fmt.Println(a.Len())
a.Truncate(5)
fmt.Println(a.Len())
y, err := a.ReadString(&#39;N&#39;)
if err != nil {
    fmt.Println(&amp;quot;delim:N err:&amp;quot;, err)
} else {
    fmt.Println(y)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Good Night
10
5
delim:N err: EOF
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>监控系列---- zabbix源码阅读</title>
          <link>https://kingjcy.github.io/post/monitor/metrics/zabbix/zabbixcode/</link>
          <pubDate>Sat, 25 Nov 2017 09:52:47 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/monitor/metrics/zabbix/zabbixcode/</guid>
          <description>&lt;p&gt;阅读源码，解析基本原理。&lt;/p&gt;

&lt;h1 id=&#34;流程&#34;&gt;流程&lt;/h1&gt;

&lt;p&gt;一个监控系统运行的大概的流程是这样的：&lt;/p&gt;

&lt;p&gt;agentd需要安装到被监控的主机上，它负责定期收集各项数据，并发送到zabbix server端，zabbix server将数据存储到数据库中，zabbix web根据数据在前端进行展现和绘图。这里agentd收集数据分为主动和被动两种模式：&lt;/p&gt;

&lt;p&gt;主动：agent请求server获取主动的监控项列表，并主动将监控项内需要检测的数据提交给server/proxy&lt;/p&gt;

&lt;p&gt;被动：server向agent请求获取监控项的数据，agent返回数据。&lt;/p&gt;

&lt;h1 id=&#34;主动监测&#34;&gt;主动监测&lt;/h1&gt;

&lt;p&gt;通信过程如下：&lt;/p&gt;

&lt;p&gt;zabbix首先向ServerActive配置的IP请求获取active items，获取并提交active tiems数据值server或者proxy。很多人会提出疑问：zabbix多久获取一次active items？它会根据配置文件中的RefreshActiveChecks的频率进行，如果获取失败，那么将会在60秒之后重试。分两个部分：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/monitor/zabbix/z1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;1.获取ACTIVE ITEMS列表&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Agent打开TCP连接（主动检测变成Agent打开）&lt;/li&gt;
&lt;li&gt;Agent请求items检测列表&lt;/li&gt;
&lt;li&gt;Server返回items列表&lt;/li&gt;
&lt;li&gt;Agent 处理响应&lt;/li&gt;
&lt;li&gt;关闭TCP连接&lt;/li&gt;
&lt;li&gt;Agent开始收集数据&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2.主动检测提交数据过程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Agent建立TCP连接&lt;/li&gt;
&lt;li&gt;Agent提交items列表收集的数据&lt;/li&gt;
&lt;li&gt;Server处理数据，并返回响应状态&lt;/li&gt;
&lt;li&gt;关闭TCP连接&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;被动监测&#34;&gt;被动监测&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/monitor/zabbix/z2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通信过程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Server打开一个TCP连接&lt;/li&gt;
&lt;li&gt;Server发送请求agent.ping\n&lt;/li&gt;
&lt;li&gt;Agent接收到请求并且响应&lt;code&gt;&amp;lt;HEADER&amp;gt;&amp;lt;DATALEN&amp;gt;1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Server处理接收到的数据1&lt;/li&gt;
&lt;li&gt;关闭TCP连接&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里，有人可以看出来，被动模式每次都需要打开一个tcp连接，这样当监控项越来越多时，就会出现server端性能问题了。&lt;/p&gt;

&lt;p&gt;比如not supported items通信过程&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Server打开一个TCP连接&lt;/li&gt;
&lt;li&gt;Server发送请求&lt;code&gt;vfs.fs.size[ no]\n&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Agent接收请求并且返回响应数据 &lt;code&gt;&amp;lt;HEADER&amp;gt;&amp;lt;DATALEN&amp;gt;ZBX_NOTSUPPORTED\0Cannot obtain filesystem information: [2] No such file or directory&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Server接收并处理数据, 将item的状态改为“ not supported ”&lt;/li&gt;
&lt;li&gt;关闭TCP连接&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;还有人会问，那实际监控中是用主动的还是被动的呢？这里主要涉及两个地方：&lt;/p&gt;

&lt;p&gt;1、新建监控项目时，选择的是zabbix代理还是zabbix端点代理程式（主动式），前者是被动模式，后者是主动模式。&lt;/p&gt;

&lt;p&gt;2、agentd配置文件中StartAgents参数的设置，如果为0，表示禁止被动模式，否则开启。一般建议不要设置为0，因为监控项目很多时，可以部分使用主动，部分使用被动模式。&lt;/p&gt;

&lt;h1 id=&#34;常用的监控架构平台&#34;&gt;常用的监控架构平台&lt;/h1&gt;

&lt;p&gt;1、server-agentd模式：&lt;/p&gt;

&lt;p&gt;这个是最简单的架构了，常用于监控主机比较少的情况下。&lt;/p&gt;

&lt;p&gt;2、server-proxy-agentd模式：&lt;/p&gt;

&lt;p&gt;这个常用于比较多的机器，使用proxy进行分布式监控，有效的减轻server端的压力。&lt;/p&gt;

&lt;h1 id=&#34;组件解析&#34;&gt;组件解析&lt;/h1&gt;

&lt;h2 id=&#34;agent&#34;&gt;Agent&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;入口函数：zabbix_agentd.c:MAIN_ZABBIX_ENTRY&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;采集线程：stats.c: ZBX_THREAD_ENTRY(collector_thread, args)，采集数据&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;监听线程：listener.c: ZBX_THREAD_ENTRY(listener_thread, args)，监听端口（根据加密格式）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;发送线程：active.c:ZBX_THREAD_ENTRY(active_checks_thread, args)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.发送报文函数: active.c:send_buffer，消息体为消息头+json格式的消息体，根据加密配置，分为不加密，cert加密和psk加密。Json的编码可以在这个函数里看。
2.加密可以使用openssl的库，主要实现在tls.c:zbx_tls_connect函数中。
3.消息头的编码：comms.c:zbx_tcp_send_ext，包括” ZBXD”+1字节flag+32位json消息长度+32位0x00，在发送json体的时候，使用了zlib的compress函数进行压缩，对端接收的时候使用uncompress进行了解压缩。
4.1字节flag有以下取值：

        {
        ZBX_TCP_PROTOCOL(0x01)
        ZBX_TCP_PROTOCOL |ZBX_TCP_COMPRESS (0x03)
        0x00
        }
        当flag&amp;amp; ZBX_TCP_COMPRESS!=0时，发送报文需要对消息体进行compress压缩，接收报文需要对消息体进行uncompress解压缩
        #define ZBX_TCP_PROTOCOL        0x01
        #define ZBX_TCP_COMPRESS        0x02
        当flag==0时，报文没有消息头，只有json消息体

5.消息长度

        发送报文时，如果加密，消息体最长16K
        #define ZBX_TLS_MAX_REC_LEN 16384
        如果不加密，没有限制，写json串时动态申请内存
        接收报文时，最大长度128M，根据接收的消息长度循环动态申请内存
        #define ZBX_MAX_RECV_DATA_SIZE  (128 * ZBX_MEBIBYTE)

6.json编码中request的类型

        #define ZBX_PROTO_VALUE_GET_ACTIVE_CHECKS   &amp;quot;active checks&amp;quot;
        #define ZBX_PROTO_VALUE_PROXY_CONFIG        &amp;quot;proxy config&amp;quot;
        #define ZBX_PROTO_VALUE_PROXY_HEARTBEAT     &amp;quot;proxy heartbeat&amp;quot;
        #define ZBX_PROTO_VALUE_SENDER_DATA     &amp;quot;sender data&amp;quot;
        #define ZBX_PROTO_VALUE_AGENT_DATA      &amp;quot;agent data&amp;quot;
        #define ZBX_PROTO_VALUE_COMMAND         &amp;quot;command&amp;quot;
        #define ZBX_PROTO_VALUE_JAVA_GATEWAY_INTERNAL   &amp;quot;java gateway internal&amp;quot;
        #define ZBX_PROTO_VALUE_JAVA_GATEWAY_JMX    &amp;quot;java gateway jmx&amp;quot;
        #define ZBX_PROTO_VALUE_GET_QUEUE       &amp;quot;queue.get&amp;quot;
        #define ZBX_PROTO_VALUE_GET_STATUS      &amp;quot;status.get&amp;quot;
        #define ZBX_PROTO_VALUE_PROXY_DATA      &amp;quot;proxy data&amp;quot;
        #define ZBX_PROTO_VALUE_PROXY_TASKS     &amp;quot;proxy tasks&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;proxy&#34;&gt;Proxy&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;入口函数：zabbix_proxy.c:MAIN_ZABBIX_ENTRY&lt;/li&gt;

&lt;li&gt;&lt;p&gt;配置同步线程：proxyconfig.c: ZBX_THREAD_ENTRY(proxyconfig_thread, args)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.主要处理函数：proxyconfig.c: process_configuration_sync
2.发送request为#define ZBX_PROTO_VALUE_PROXY_CONFIG        &amp;quot;proxy config&amp;quot;的配置同步请求消息，消息头和消息体的格式和agent消息格式一样，见agent段落的第3节
3.接收对端的配置同步响应消息，并解析消息体中的json段
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;心跳线程：heartbeat.c:ZBX_THREAD_ENTRY(heart_thread, args)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;发送request为#define ZBX_PROTO_VALUE_PROXY_HEARTBEAT       &amp;quot;proxy heartbeat&amp;quot;的心跳消息
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;发送线程：datasender.c: ZBX_THREAD_ENTRY(datasender_thread, args)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.主要处理函数：datasender.c: proxy_data_sender
2.发送request为#define ZBX_PROTO_VALUE_PROXY_DATA      &amp;quot;proxy data&amp;quot;的消息，消息头和消息体的格式和agent消息格式一样，见agent段落的第3节
3.发送的消息体包括下面4个类型的数据，数据源主要从db中获取
    #define ZBX_DATASENDER_AVAILABILITY     0x0001
    #define ZBX_DATASENDER_HISTORY          0x0002
    #define ZBX_DATASENDER_DISCOVERY        0x0004
    #define ZBX_DATASENDER_AUTOREGISTRATION     0x0008
4.从数据库中获取remotetasks，zbx_tm_get_remote_tasks，根据获取的task组织json消息体zbx_tm_json_serialize_tasks
5.接收对端的响应消息，解析消息体中的json段，并更新db中的task数据
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;poller线程：poller.c: ZBX_THREAD_ENTRY(poller_thread, args)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.poller.c: get_values，从队列中获取数据项串并解析substitute_simple_macros，根据接口类型(snmp,java等)获取数值get_values_snmp，get_values_java
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;trapper线程：trapper.c:ZBX_THREAD_ENTRY(trapper_thread, args)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.解析各类响应消息并对应处理：trapper.c:process_trap
2.消息体格式分为json格式，ZBX_GET_ACTIVE_CHECKS开头格式，xml格式，host:key:value格式
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;pinger线程：pinger.c:ZBX_THREAD_ENTRY(pinger_thread, args)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.从snmp或者java接口中获取数据
2.Icmp.c:process_ping，写数据到zbx_get_thread_id()i.pinger文件中
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;housekeeper_thread线程：housekeeper.c:ZBX_THREAD_ENTRY(pinger_thread, args)
    1.连接数据库删除历史数据&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;discoverer线程：httppoller.c:ZBX_THREAD_ENTRY(httppoller_thread, args)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.数据库操作，获取新主机
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;dbsyncer线程：dbsyncer.c:ZBX_THREAD_ENTRY(dbsyncer_thread, args)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.同步数据库和内存
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;snmptrapper线程：snmptrapper.c: ZBX_THREAD_ENTRY(snmptrapper_thread, args)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.读取snmptrapper文件中的数据
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;selfmon线程：selfmon.c: ZBX_THREAD_ENTRY(selfmon_thread, args)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.收集selfmon统计数据
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;vmware线程：selfmon.c: ZBX_THREAD_ENTRY(vmware_thread, args)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.收集vmware统计数据，使用soap协议
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;sever-proxy的交互&#34;&gt;Sever: proxy的交互&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;入口函数Proxypoll.c:ZBX_THREAD_ENTRY(proxypoller_thread, args)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;主要处理函数process_proxy，发送报文send_data_to_proxy，接收报文recv_data_from_proxy，回proxy响应zbx_send_proxy_data_response，报文格式仍然为json格式，同agent的第3部分&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
        </item>
      
    
      
        <item>
          <title>UML</title>
          <link>https://kingjcy.github.io/post/architecture/map/uml/</link>
          <pubDate>Wed, 08 Nov 2017 11:40:49 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/architecture/map/uml/</guid>
          <description>&lt;p&gt;UML（Unified Modeling Language）是一种统一建模语言，为面向对象开发系统的产品进行说明、可视化、和编制文档的一种标准语言。下面将对UML的九种图的基本概念进行介绍以及各个图的使用场景。&lt;/p&gt;

&lt;h1 id=&#34;基本概念&#34;&gt;基本概念　　&lt;/h1&gt;

&lt;p&gt;如下图所示，UML图分为用例视图、设计视图、进程视图、实现视图和拓扑视图，又可以静动分为静态视图和动态视图。&lt;/p&gt;

&lt;p&gt;静态图分为：用例图，类图，对象图，包图，构件图，部署图。&lt;/p&gt;

&lt;p&gt;动态图分为：状态图，活动图，协作图，序列图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;用例图-usecase-diagrams&#34;&gt;用例图（UseCase Diagrams）&lt;/h2&gt;

&lt;p&gt;用例图主要回答了两个问题：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1、是谁用软件。
2、软件的功能。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从用户的角度描述了系统的功能，并指出各个功能的执行者，强调用户的使用者，系统为执行者完成哪些功能。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;类图-class-diagrams&#34;&gt;类图（Class Diagrams）&lt;/h2&gt;

&lt;p&gt;用户根据用例图抽象成类，描述类的内部结构和类与类之间的关系，是一种静态结构图。 在UML类图中，常见的有以下几种关系: 泛化（Generalization）, 实现（Realization），关联（Association)，聚合（Aggregation），组合(Composition)，依赖(Dependency)。&lt;/p&gt;

&lt;p&gt;各种关系的强弱顺序： 泛化 = 实现 &amp;gt; 组合 &amp;gt; 聚合 &amp;gt; 关联 &amp;gt; 依赖&lt;/p&gt;

&lt;p&gt;1.泛化&lt;/p&gt;

&lt;p&gt;泛化关系：是一种继承关系，表示一般与特殊的关系，它指定了子类如何继承父类的所有特征和行为。例如：老虎是动物的一种，即有老虎的特性也有动物的共性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;2.实现&lt;/p&gt;

&lt;p&gt;实现关系：是一种类与接口的关系，表示类是接口所有特征和行为的实现。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;3.关联&lt;/p&gt;

&lt;p&gt;关联关系：是一种拥有的关系，它使一个类知道另一个类的属性和方法；如：老师与学生，丈夫与妻子关联可以是双向的，也可以是单向的。双向的关联可以有两个箭头或者没有箭头，单向的关联有一个箭头。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;4.共享聚合　&lt;/p&gt;

&lt;p&gt;聚合关系：是整体与部分的关系，且部分可以离开整体而单独存在。如车和轮胎是整体和部分的关系，轮胎离开车仍然可以存在。&lt;/p&gt;

&lt;p&gt;聚合关系是关联关系的一种，是强的关联关系；关联和聚合在语法上无法区分，必须考察具体的逻辑关系。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml5.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;5.组合集合&lt;/p&gt;

&lt;p&gt;组合关系：是整体与部分的关系，但部分不能离开整体而单独存在。如公司和部门是整体和部分的关系，没有公司就不存在部门。&lt;/p&gt;

&lt;p&gt;组合关系是关联关系的一种，是比聚合关系还要强的关系，它要求普通的聚合关系中代表整体的对象负责代表部分的对象的生命周期。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml6.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;6.依赖　　&lt;/p&gt;

&lt;p&gt;依赖关系：是一种使用的关系，即一个类的实现需要另一个类的协助，所以要尽量不使用双向的互相依赖.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml7.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;7 各种类图关系&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml8.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;对象图-object-diagrams&#34;&gt;对象图（Object Diagrams）&lt;/h2&gt;

&lt;p&gt;描述的是参与交互的各个对象在交互过程中某一时刻的状态。对象图可以被看作是类图在某一时刻的实例。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml9.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;状态图-statechart-diagrams&#34;&gt;状态图（Statechart Diagrams）&lt;/h2&gt;

&lt;p&gt;一种由状态、变迁、事件和活动组成的状态机，用来描述类的对象所有可能的状态以及时间发生时状态的转移条件。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml10.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;活动图-activity-diagrams&#34;&gt;活动图（Activity Diagrams）：&lt;/h2&gt;

&lt;p&gt;状态图的一种特殊情况，这些状态大都处于活动状态。本质是一种流程图，它描述了活动到活动的控制流。　　　　&lt;/p&gt;

&lt;p&gt;交互图强调的是对象到对象的控制流，而活动图则强调的是从活动到活动的控制流。&lt;/p&gt;

&lt;p&gt;活动图是一种表述过程基理、业务过程以及工作流的技术。它可以用来对业务过程、工作流建模，也可以对用例实现甚至是程序实现来建模。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml11.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;1.带泳道的活动图&lt;/p&gt;

&lt;p&gt;泳道表明每个活动是由哪些人或哪些部门负责完成。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml12.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;2.带对象流的活动图&lt;/p&gt;

&lt;p&gt;用活动图描述某个对象时，可以把涉及到的对象放置在活动图中，并用一个依赖将其连接到进行创建、修改和撤销的动作状态或者活动状态上，对象的这种使用方法就构成了对象流。对象流用带有箭头的虚线表示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml13.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;序列图-时序图-sequence-diagrams&#34;&gt;序列图-时序图（Sequence Diagrams）&lt;/h2&gt;

&lt;p&gt;交互图的一种，描述了对象之间消息发送的先后顺序，强调时间顺序。&lt;/p&gt;

&lt;p&gt;序列图的主要用途是把用例表达的需求，转化为进一步、更加正式层次的精细表达。用例常常被细化为一个或者更多的序列图。同时序列图更有效地描述如何分配各个类的职责以及各类具有相应职责的原因。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml14.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;消息用从一个对象的生命线到另一个对象生命线的箭头表示。箭头以时间顺序在图中从上到下排列。&lt;/p&gt;

&lt;p&gt;序列图中涉及的元素：&lt;/p&gt;

&lt;p&gt;1.角色&lt;/p&gt;

&lt;p&gt;系统角色，可以是人、及其甚至其他的系统或者子系统&lt;/p&gt;

&lt;p&gt;2.对象&lt;/p&gt;

&lt;p&gt;对象包括三种命名方式：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  第一种方式包括对象名和类名；

  第二中方式只显示类名不显示对象名，即表示他是一个匿名对象；

  第三种方式只显示对象名不显示类。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.生命线&lt;/p&gt;

&lt;p&gt;生命线在顺序图中表示为从对象图标向下延伸的一条虚线，表示对象存在的时间。&lt;/p&gt;

&lt;p&gt;生命线名称可带下划线。当使用下划线时，意味着序列图中的生命线代表一个类的特定实例。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml15.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;4.控制焦点&lt;/p&gt;

&lt;p&gt;控制焦点是顺序图中表示时间段的符号，在这个时间段内对象将执行相应的操作。用小矩形表示&lt;/p&gt;

&lt;p&gt;5.同步消息&lt;/p&gt;

&lt;p&gt;同步等待消息&lt;/p&gt;

&lt;p&gt;消息的发送者把控制传递给消息的接收者，然后停止活动，等待消息的接收者放弃或者返回控制。用来表示同步的意义。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml16.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;6.异步消息&lt;/p&gt;

&lt;p&gt;异步发送消息，不需等待&lt;/p&gt;

&lt;p&gt;消息发送者通过消息把信号传递给消息的接收者，然后继续自己的活动，不等待接受者返回消息或者控制。异步消息的接收者和发送者是并发工作的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml17.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;7.注释&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml18.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;8.约束&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml19.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;9.组合　　&lt;/p&gt;

&lt;p&gt;组合片段用来解决交互执行的条件及方式。它允许在序列图中直接表示逻辑组件，用于通过指定条件或子进程的应用区域，为任何生命线的任何部分定义特殊条件和子进程。常用的组合片段有：抉择、选项、循环、并行。&lt;/p&gt;

&lt;h2 id=&#34;协作图-collaboration-diagrams&#34;&gt;协作图（Collaboration Diagrams）&lt;/h2&gt;

&lt;p&gt;交互图的一种，描述了收发消息的对象的组织关系，强调对象之间的合作关系。时序图按照时间顺序布图，而写作图按照空间结构布图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml20.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;构件图-component-diagrams&#34;&gt;构件图（Component Diagrams）：&lt;/h2&gt;

&lt;p&gt;构件图是用来表示系统中构件与构件之间，类或接口与构件之间的关系图。其中，构建图之间的关系表现为依赖关系，定义的类或接口与类之间的关系表现为依赖关系或实现关系。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml21.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;部署图-deployment-diagrams&#34;&gt;部署图（Deployment Diagrams）：&lt;/h2&gt;

&lt;p&gt;描述了系统运行时进行处理的结点以及在结点上活动的构件的配置。强调了物理设备以及之间的连接关系。&lt;/p&gt;

&lt;p&gt;部署模型的目的：&lt;/p&gt;

&lt;p&gt;描述一个具体应用的主要部署结构，通过对各种硬件，在硬件中的软件以及各种连接协议的显示，可以很好的描述系统是如何部署的；平衡系统运行时的计算资源分布；可以通过连接描述组织的硬件网络结构或者是嵌入式系统等具有多种硬件和软件相关的系统运行模型。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/architecture/map/uml/uml22.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Golang使用系列---- Net/Http 应用层</title>
          <link>https://kingjcy.github.io/post/golang/go-net-http/</link>
          <pubDate>Tue, 26 Sep 2017 17:05:22 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/golang/go-net-http/</guid>
          <description>&lt;p&gt;http包提供了HTTP协议的客户端和服务端的实现。&lt;/p&gt;

&lt;h1 id=&#34;http客户端&#34;&gt;HTTP客户端&lt;/h1&gt;

&lt;h2 id=&#34;直接使用http方法&#34;&gt;直接使用http方法&lt;/h2&gt;

&lt;p&gt;直接使用http方法，其实就是使用标准库默认的结构体client，transport等来实现请求。&lt;/p&gt;

&lt;p&gt;http包中封装了Get、Head、Post和PostForm函数可以直接发出HTTP/ HTTPS请求。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resp, err := http.Get(&amp;quot;http://example.com/&amp;quot;)
...
resp, err := http.Post(&amp;quot;http://example.com/upload&amp;quot;, &amp;quot;image/jpeg&amp;quot;, &amp;amp;buf)
...
resp, err := http.PostForm(&amp;quot;http://example.com/form&amp;quot;,
    url.Values{&amp;quot;key&amp;quot;: {&amp;quot;Value&amp;quot;}, &amp;quot;id&amp;quot;: {&amp;quot;123&amp;quot;}})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;程序在使用完回复后必须关闭回复的主体。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resp, err := http.Get(&amp;quot;http://example.com/&amp;quot;)
if err != nil {
    // handle error
}
defer resp.Body.Close()
body, err := ioutil.ReadAll(resp.Body)
// ...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;原理解析&#34;&gt;原理解析&lt;/h3&gt;

&lt;p&gt;http直接提供的Post等方法实现在client.go文件中，以Post为例，其他都是一样&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Post(url, contentType string, body io.Reader) (resp *Response, err error) {
    return DefaultClient.Post(url, contentType, body)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实际是调用了默认结构体client的Post方法&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var DefaultClient = &amp;amp;Client{}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再来看Post方法&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Client) Post(url, contentType string, body io.Reader) (resp *Response, err error) {
    req, err := NewRequest(&amp;quot;POST&amp;quot;, url, body)
    if err != nil {
        return nil, err
    }
    req.Header.Set(&amp;quot;Content-Type&amp;quot;, contentType)
    return c.Do(req)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;根据url和请求体body新建一个reqest，然后调用DefaultClient的Do方法&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Client) Do(req *Request) (*Response, error) {
    return c.do(req)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调用内部的do方法&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Client) do(req *Request) (retres *Response, reterr error) {
    if testHookClientDoResult != nil {
        defer func() { testHookClientDoResult(retres, reterr) }()
    }
    if req.URL == nil {
        req.closeBody()
        return nil, &amp;amp;url.Error{
            Op:  urlErrorOp(req.Method),
            Err: errors.New(&amp;quot;http: nil Request.URL&amp;quot;),
        }
    }

    var (
        deadline      = c.deadline()
        reqs          []*Request
        resp          *Response
        copyHeaders   = c.makeHeadersCopier(req)
        reqBodyClosed = false // have we closed the current req.Body?

        // Redirect behavior:
        redirectMethod string
        includeBody    bool
    )
    uerr := func(err error) error {
        // the body may have been closed already by c.send()
        if !reqBodyClosed {
            req.closeBody()
        }
        var urlStr string
        if resp != nil &amp;amp;&amp;amp; resp.Request != nil {
            urlStr = stripPassword(resp.Request.URL)
        } else {
            urlStr = stripPassword(req.URL)
        }
        return &amp;amp;url.Error{
            Op:  urlErrorOp(reqs[0].Method),
            URL: urlStr,
            Err: err,
        }
    }
    for {
        // For all but the first request, create the next
        // request hop and replace req.
        if len(reqs) &amp;gt; 0 {
            loc := resp.Header.Get(&amp;quot;Location&amp;quot;)
            if loc == &amp;quot;&amp;quot; {
                resp.closeBody()
                return nil, uerr(fmt.Errorf(&amp;quot;%d response missing Location header&amp;quot;, resp.StatusCode))
            }
            u, err := req.URL.Parse(loc)
            if err != nil {
                resp.closeBody()
                return nil, uerr(fmt.Errorf(&amp;quot;failed to parse Location header %q: %v&amp;quot;, loc, err))
            }
            host := &amp;quot;&amp;quot;
            if req.Host != &amp;quot;&amp;quot; &amp;amp;&amp;amp; req.Host != req.URL.Host {
                // If the caller specified a custom Host header and the
                // redirect location is relative, preserve the Host header
                // through the redirect. See issue #22233.
                if u, _ := url.Parse(loc); u != nil &amp;amp;&amp;amp; !u.IsAbs() {
                    host = req.Host
                }
            }
            ireq := reqs[0]
            req = &amp;amp;Request{
                Method:   redirectMethod,
                Response: resp,
                URL:      u,
                Header:   make(Header),
                Host:     host,
                Cancel:   ireq.Cancel,
                ctx:      ireq.ctx,
            }
            if includeBody &amp;amp;&amp;amp; ireq.GetBody != nil {
                req.Body, err = ireq.GetBody()
                if err != nil {
                    resp.closeBody()
                    return nil, uerr(err)
                }
                req.ContentLength = ireq.ContentLength
            }

            // Copy original headers before setting the Referer,
            // in case the user set Referer on their first request.
            // If they really want to override, they can do it in
            // their CheckRedirect func.
            copyHeaders(req)

            // Add the Referer header from the most recent
            // request URL to the new one, if it&#39;s not https-&amp;gt;http:
            if ref := refererForURL(reqs[len(reqs)-1].URL, req.URL); ref != &amp;quot;&amp;quot; {
                req.Header.Set(&amp;quot;Referer&amp;quot;, ref)
            }
            err = c.checkRedirect(req, reqs)

            // Sentinel error to let users select the
            // previous response, without closing its
            // body. See Issue 10069.
            if err == ErrUseLastResponse {
                return resp, nil
            }

            // Close the previous response&#39;s body. But
            // read at least some of the body so if it&#39;s
            // small the underlying TCP connection will be
            // re-used. No need to check for errors: if it
            // fails, the Transport won&#39;t reuse it anyway.
            const maxBodySlurpSize = 2 &amp;lt;&amp;lt; 10
            if resp.ContentLength == -1 || resp.ContentLength &amp;lt;= maxBodySlurpSize {
                io.CopyN(ioutil.Discard, resp.Body, maxBodySlurpSize)
            }
            resp.Body.Close()

            if err != nil {
                // Special case for Go 1 compatibility: return both the response
                // and an error if the CheckRedirect function failed.
                // See https://golang.org/issue/3795
                // The resp.Body has already been closed.
                ue := uerr(err)
                ue.(*url.Error).URL = loc
                return resp, ue
            }
        }

        reqs = append(reqs, req)
        var err error
        var didTimeout func() bool
        //调用 send
        if resp, didTimeout, err = c.send(req, deadline); err != nil {
            // c.send() always closes req.Body
            reqBodyClosed = true
            if !deadline.IsZero() &amp;amp;&amp;amp; didTimeout() {
                err = &amp;amp;httpError{
                    // TODO: early in cycle: s/Client.Timeout exceeded/timeout or context cancelation/
                    err:     err.Error() + &amp;quot; (Client.Timeout exceeded while awaiting headers)&amp;quot;,
                    timeout: true,
                }
            }
            return nil, uerr(err)
        }

        var shouldRedirect bool
        redirectMethod, shouldRedirect, includeBody = redirectBehavior(req.Method, resp, reqs[0])
        if !shouldRedirect {
            return resp, nil
        }

        req.closeBody()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调用send方法&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Client) send(req *Request, deadline time.Time) (resp *Response, didTimeout func() bool, err error) {
    if c.Jar != nil {
        for _, cookie := range c.Jar.Cookies(req.URL) {
            req.AddCookie(cookie)
        }
    }
    resp, didTimeout, err = send(req, c.transport(), deadline)
    if err != nil {
        return nil, didTimeout, err
    }
    if c.Jar != nil {
        if rc := resp.Cookies(); len(rc) &amp;gt; 0 {
            c.Jar.SetCookies(req.URL, rc)
        }
    }
    return resp, nil, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边需要确定实现transport的结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Client) transport() RoundTripper {
    if c.Transport != nil {
        return c.Transport
    }
    return DefaultTransport
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用默认的DefaultTransport（如果transport自定义了，就使用自定义的，否则使用默认的），这边这个接口调用就是DefaultTransport，也就是Transport.go中的Transport结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var DefaultTransport RoundTripper = &amp;amp;Transport{
    Proxy: ProxyFromEnvironment,
    DialContext: (&amp;amp;net.Dialer{
        Timeout:   30 * time.Second,
        KeepAlive: 30 * time.Second,
        DualStack: true,
    }).DialContext,
    MaxIdleConns:          100,
    IdleConnTimeout:       90 * time.Second,
    TLSHandshakeTimeout:   10 * time.Second,
    ExpectContinueTimeout: 1 * time.Second,
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再看Transport结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Transport struct {
    idleMu     sync.Mutex
    wantIdle   bool                                // user has requested to close all idle conns
    idleConn   map[connectMethodKey][]*persistConn // most recently used at end
    idleConnCh map[connectMethodKey]chan *persistConn
    idleLRU    connLRU

    reqMu       sync.Mutex
    reqCanceler map[*Request]func(error)

    altMu    sync.Mutex   // guards changing altProto only
    altProto atomic.Value // of nil or map[string]RoundTripper, key is URI scheme

    connCountMu          sync.Mutex
    connPerHostCount     map[connectMethodKey]int
    connPerHostAvailable map[connectMethodKey]chan struct{}

    // Proxy specifies a function to return a proxy for a given
    // Request. If the function returns a non-nil error, the
    // request is aborted with the provided error.
    //
    // The proxy type is determined by the URL scheme. &amp;quot;http&amp;quot;,
    // &amp;quot;https&amp;quot;, and &amp;quot;socks5&amp;quot; are supported. If the scheme is empty,
    // &amp;quot;http&amp;quot; is assumed.
    //
    // If Proxy is nil or returns a nil *URL, no proxy is used.
    Proxy func(*Request) (*url.URL, error)

    // DialContext specifies the dial function for creating unencrypted TCP connections.
    // If DialContext is nil (and the deprecated Dial below is also nil),
    // then the transport dials using package net.
    //
    // DialContext runs concurrently with calls to RoundTrip.
    // A RoundTrip call that initiates a dial may end up using
    // a connection dialed previously when the earlier connection
    // becomes idle before the later DialContext completes.
    DialContext func(ctx context.Context, network, addr string) (net.Conn, error)

    // Dial specifies the dial function for creating unencrypted TCP connections.
    //
    // Dial runs concurrently with calls to RoundTrip.
    // A RoundTrip call that initiates a dial may end up using
    // a connection dialed previously when the earlier connection
    // becomes idle before the later Dial completes.
    //
    // Deprecated: Use DialContext instead, which allows the transport
    // to cancel dials as soon as they are no longer needed.
    // If both are set, DialContext takes priority.
    Dial func(network, addr string) (net.Conn, error)

    // DialTLS specifies an optional dial function for creating
    // TLS connections for non-proxied HTTPS requests.
    //
    // If DialTLS is nil, Dial and TLSClientConfig are used.
    //
    // If DialTLS is set, the Dial hook is not used for HTTPS
    // requests and the TLSClientConfig and TLSHandshakeTimeout
    // are ignored. The returned net.Conn is assumed to already be
    // past the TLS handshake.
    DialTLS func(network, addr string) (net.Conn, error)

    // TLSClientConfig specifies the TLS configuration to use with
    // tls.Client.
    // If nil, the default configuration is used.
    // If non-nil, HTTP/2 support may not be enabled by default.
    TLSClientConfig *tls.Config

    // TLSHandshakeTimeout specifies the maximum amount of time waiting to
    // wait for a TLS handshake. Zero means no timeout.
    TLSHandshakeTimeout time.Duration

    // DisableKeepAlives, if true, disables HTTP keep-alives and
    // will only use the connection to the server for a single
    // HTTP request.
    //
    // This is unrelated to the similarly named TCP keep-alives.
    DisableKeepAlives bool

    // DisableCompression, if true, prevents the Transport from
    // requesting compression with an &amp;quot;Accept-Encoding: gzip&amp;quot;
    // request header when the Request contains no existing
    // Accept-Encoding value. If the Transport requests gzip on
    // its own and gets a gzipped response, it&#39;s transparently
    // decoded in the Response.Body. However, if the user
    // explicitly requested gzip it is not automatically
    // uncompressed.
    DisableCompression bool

    // MaxIdleConns controls the maximum number of idle (keep-alive)
    // connections across all hosts. Zero means no limit.
    MaxIdleConns int

    // MaxIdleConnsPerHost, if non-zero, controls the maximum idle
    // (keep-alive) connections to keep per-host. If zero,
    // DefaultMaxIdleConnsPerHost is used.
    MaxIdleConnsPerHost int

    // MaxConnsPerHost optionally limits the total number of
    // connections per host, including connections in the dialing,
    // active, and idle states. On limit violation, dials will block.
    //
    // Zero means no limit.
    //
    // For HTTP/2, this currently only controls the number of new
    // connections being created at a time, instead of the total
    // number. In practice, hosts using HTTP/2 only have about one
    // idle connection, though.
    MaxConnsPerHost int

    // IdleConnTimeout is the maximum amount of time an idle
    // (keep-alive) connection will remain idle before closing
    // itself.
    // Zero means no limit.
    IdleConnTimeout time.Duration

    // ResponseHeaderTimeout, if non-zero, specifies the amount of
    // time to wait for a server&#39;s response headers after fully
    // writing the request (including its body, if any). This
    // time does not include the time to read the response body.
    ResponseHeaderTimeout time.Duration

    // ExpectContinueTimeout, if non-zero, specifies the amount of
    // time to wait for a server&#39;s first response headers after fully
    // writing the request headers if the request has an
    // &amp;quot;Expect: 100-continue&amp;quot; header. Zero means no timeout and
    // causes the body to be sent immediately, without
    // waiting for the server to approve.
    // This time does not include the time to send the request header.
    ExpectContinueTimeout time.Duration

    // TLSNextProto specifies how the Transport switches to an
    // alternate protocol (such as HTTP/2) after a TLS NPN/ALPN
    // protocol negotiation. If Transport dials an TLS connection
    // with a non-empty protocol name and TLSNextProto contains a
    // map entry for that key (such as &amp;quot;h2&amp;quot;), then the func is
    // called with the request&#39;s authority (such as &amp;quot;example.com&amp;quot;
    // or &amp;quot;example.com:1234&amp;quot;) and the TLS connection. The function
    // must return a RoundTripper that then handles the request.
    // If TLSNextProto is not nil, HTTP/2 support is not enabled
    // automatically.
    TLSNextProto map[string]func(authority string, c *tls.Conn) RoundTripper

    // ProxyConnectHeader optionally specifies headers to send to
    // proxies during CONNECT requests.
    ProxyConnectHeader Header

    // MaxResponseHeaderBytes specifies a limit on how many
    // response bytes are allowed in the server&#39;s response
    // header.
    //
    // Zero means to use a default limit.
    MaxResponseHeaderBytes int64

    // nextProtoOnce guards initialization of TLSNextProto and
    // h2transport (via onceSetNextProtoDefaults)
    nextProtoOnce sync.Once
    h2transport   h2Transport // non-nil if http2 wired up
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;中文讲解&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Transport struct {
    // Proxy指定一个对给定请求返回代理的函数。
    // 如果该函数返回了非nil的错误值，请求的执行就会中断并返回该错误。
    // 如果Proxy为nil或返回nil的*URL置，将不使用代理。
    Proxy func(*Request) (*url.URL, error)

    // Dial指定创建TCP连接的拨号函数。如果Dial为nil，会使用net.Dial。
    //Dial获取一个tcp 连接，也就是net.Conn结构，你就记住可以往里面写request
    //然后从里面搞到response就行了
    Dial func(network, addr string) (net.Conn, error)

    // TLSClientConfig指定用于tls.Client的TLS配置信息。
    // 如果该字段为nil，会使用默认的配置信息。
    TLSClientConfig *tls.Config

    // TLSHandshakeTimeout指定等待TLS握手完成的最长时间。零值表示不设置超时。
    TLSHandshakeTimeout time.Duration

    // 如果DisableKeepAlives为真，会禁止不同HTTP请求之间TCP连接的重用。
    DisableKeepAlives bool

    // 如果DisableCompression为真，会禁止Transport在请求中没有Accept-Encoding头时，
    // 主动添加&amp;quot;Accept-Encoding: gzip&amp;quot;头，以获取压缩数据。
    // 如果Transport自己请求gzip并得到了压缩后的回复，它会主动解压缩回复的主体。
    // 但如果用户显式的请求gzip压缩数据，Transport是不会主动解压缩的。
    DisableCompression bool

    // 如果MaxIdleConnsPerHost!=0，会控制每个主机下的最大闲置连接。
    // 如果MaxIdleConnsPerHost==0，会使用DefaultMaxIdleConnsPerHost。
    MaxIdleConnsPerHost int

    // ResponseHeaderTimeout指定在发送完请求（包括其可能的主体）之后，
    // 等待接收服务端的回复的头域的最大时间。零值表示不设置超时。
    // 该时间不包括获取回复主体的时间。
    ResponseHeaderTimeout time.Duration

    // 内含隐藏或非导出字段



    //保存从 connectMethodKey （代表着不同的协议 不同的host，也就是不同的请求）到 persistConn 的映射
    idleConn   map[connectMethodKey][]*persistConn // most recently used at end
    //用来在并发http请求的时候在多个 goroutine 里面相互发送持久连接，也就是说， 这些持久连接是可以重复利用的， 你的http请求用某个persistConn用完了，通过这个channel发送给其他http请求使用这个persistConn，然后我们找到transport的RoundTrip方法
    idleConnCh map[connectMethodKey]chan *persistConn
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调用内部send方法&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func send(ireq *Request, rt RoundTripper, deadline time.Time) (resp *Response, didTimeout func() bool, err error) {
    req := ireq // req is either the original request, or a modified fork

    if rt == nil {
        req.closeBody()
        return nil, alwaysFalse, errors.New(&amp;quot;http: no Client.Transport or DefaultTransport&amp;quot;)
    }

    if req.URL == nil {
        req.closeBody()
        return nil, alwaysFalse, errors.New(&amp;quot;http: nil Request.URL&amp;quot;)
    }

    if req.RequestURI != &amp;quot;&amp;quot; {
        req.closeBody()
        return nil, alwaysFalse, errors.New(&amp;quot;http: Request.RequestURI can&#39;t be set in client requests.&amp;quot;)
    }

    // forkReq forks req into a shallow clone of ireq the first
    // time it&#39;s called.
    forkReq := func() {
        if ireq == req {
            req = new(Request)
            *req = *ireq // shallow clone
        }
    }

    // Most the callers of send (Get, Post, et al) don&#39;t need
    // Headers, leaving it uninitialized. We guarantee to the
    // Transport that this has been initialized, though.
    if req.Header == nil {
        forkReq()
        req.Header = make(Header)
    }

    if u := req.URL.User; u != nil &amp;amp;&amp;amp; req.Header.Get(&amp;quot;Authorization&amp;quot;) == &amp;quot;&amp;quot; {
        username := u.Username()
        password, _ := u.Password()
        forkReq()
        req.Header = ireq.Header.clone()
        req.Header.Set(&amp;quot;Authorization&amp;quot;, &amp;quot;Basic &amp;quot;+basicAuth(username, password))
    }

    if !deadline.IsZero() {
        forkReq()
    }
    stopTimer, didTimeout := setRequestCancel(req, rt, deadline)

    resp, err = rt.RoundTrip(req)
    if err != nil {
        stopTimer()
        if resp != nil {
            log.Printf(&amp;quot;RoundTripper returned a response &amp;amp; error; ignoring response&amp;quot;)
        }
        if tlsErr, ok := err.(tls.RecordHeaderError); ok {
            // If we get a bad TLS record header, check to see if the
            // response looks like HTTP and give a more helpful error.
            // See golang.org/issue/11111.
            if string(tlsErr.RecordHeader[:]) == &amp;quot;HTTP/&amp;quot; {
                err = errors.New(&amp;quot;http: server gave HTTP response to HTTPS client&amp;quot;)
            }
        }
        return nil, didTimeout, err
    }
    if !deadline.IsZero() {
        resp.Body = &amp;amp;cancelTimerBody{
            stop:          stopTimer,
            rc:            resp.Body,
            reqDidTimeout: didTimeout,
        }
    }
    return resp, nil, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调用DefaultTransport也就是Transport.go中的Transport结构体的RoundTrip方法（当出现自定义的时候，就调用对应的Transport的RoundTrip方法，这边直接使用这个借口就是DefaultTransport），可见使用golang net/http库发送http请求，最后都是调用 http transport的 RoundTrip方法。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// roundTrip implements a RoundTripper over HTTP.
func (t *Transport) roundTrip(req *Request) (*Response, error) {
    t.nextProtoOnce.Do(t.onceSetNextProtoDefaults)
    ctx := req.Context()
    trace := httptrace.ContextClientTrace(ctx)

    if req.URL == nil {
        req.closeBody()
        return nil, errors.New(&amp;quot;http: nil Request.URL&amp;quot;)
    }
    if req.Header == nil {
        req.closeBody()
        return nil, errors.New(&amp;quot;http: nil Request.Header&amp;quot;)
    }
    scheme := req.URL.Scheme
    isHTTP := scheme == &amp;quot;http&amp;quot; || scheme == &amp;quot;https&amp;quot;
    if isHTTP {
        for k, vv := range req.Header {
            if !httpguts.ValidHeaderFieldName(k) {
                return nil, fmt.Errorf(&amp;quot;net/http: invalid header field name %q&amp;quot;, k)
            }
            for _, v := range vv {
                if !httpguts.ValidHeaderFieldValue(v) {
                    return nil, fmt.Errorf(&amp;quot;net/http: invalid header field value %q for key %v&amp;quot;, v, k)
                }
            }
        }
    }

    if t.useRegisteredProtocol(req) {
        altProto, _ := t.altProto.Load().(map[string]RoundTripper)
        if altRT := altProto[scheme]; altRT != nil {
            if resp, err := altRT.RoundTrip(req); err != ErrSkipAltProtocol {
                return resp, err
            }
        }
    }
    if !isHTTP {
        req.closeBody()
        return nil, &amp;amp;badStringError{&amp;quot;unsupported protocol scheme&amp;quot;, scheme}
    }
    if req.Method != &amp;quot;&amp;quot; &amp;amp;&amp;amp; !validMethod(req.Method) {
        return nil, fmt.Errorf(&amp;quot;net/http: invalid method %q&amp;quot;, req.Method)
    }
    if req.URL.Host == &amp;quot;&amp;quot; {
        req.closeBody()
        return nil, errors.New(&amp;quot;http: no Host in request URL&amp;quot;)
    }

    for {
        select {
        case &amp;lt;-ctx.Done():
            req.closeBody()
            return nil, ctx.Err()
        default:
        }

        // treq gets modified by roundTrip, so we need to recreate for each retry.
        treq := &amp;amp;transportRequest{Request: req, trace: trace}
        cm, err := t.connectMethodForRequest(treq)
        if err != nil {
            req.closeBody()
            return nil, err
        }

        // Get the cached or newly-created connection to either the
        // host (for http or https), the http proxy, or the http proxy
        // pre-CONNECTed to https server. In any case, we&#39;ll be ready
        // to send it requests.
        pconn, err := t.getConn(treq, cm)
        if err != nil {
            t.setReqCanceler(req, nil)
            req.closeBody()
            return nil, err
        }

        var resp *Response
        if pconn.alt != nil {
            // HTTP/2 path.
            t.decHostConnCount(cm.key()) // don&#39;t count cached http2 conns toward conns per host
            t.setReqCanceler(req, nil)   // not cancelable with CancelRequest
            resp, err = pconn.alt.RoundTrip(req)
        } else {
            resp, err = pconn.roundTrip(treq)
        }
        if err == nil {
            return resp, nil
        }
        if !pconn.shouldRetryRequest(req, err) {
            // Issue 16465: return underlying net.Conn.Read error from peek,
            // as we&#39;ve historically done.
            if e, ok := err.(transportReadFromServerError); ok {
                err = e.err
            }
            return nil, err
        }
        testHookRoundTripRetried()

        // Rewind the body if we&#39;re able to.
        if req.GetBody != nil {
            newReq := *req
            var err error
            newReq.Body, err = req.GetBody()
            if err != nil {
                return nil, err
            }
            req = &amp;amp;newReq
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前面对输入的错误处理部分我们忽略， 其实就2步，先获取一个TCP长连接，所谓TCP长连接就是三次握手建立连接后不close而是一直保持重复使用（节约环保） 然后调用这个持久连接persistConn 这个struct的roundTrip方法。我们先看获取连接&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (t *Transport) getConn(req *Request, cm connectMethod) (*persistConn, error) {
    if pc := t.getIdleConn(cm); pc != nil {
        // set request canceler to some non-nil function so we
        // can detect whether it was cleared between now and when
        // we enter roundTrip
        t.setReqCanceler(req, func() {})
        return pc, nil
    }

    type dialRes struct {
        pc  *persistConn
        err error
    }
    dialc := make(chan dialRes)
    //定义了一个发送 persistConn的channel

    prePendingDial := prePendingDial
    postPendingDial := postPendingDial

    handlePendingDial := func() {
        if prePendingDial != nil {
            prePendingDial()
        }
        go func() {
            if v := &amp;lt;-dialc; v.err == nil {
                t.putIdleConn(v.pc)
            }
            if postPendingDial != nil {
                postPendingDial()
            }
        }()
    }

    cancelc := make(chan struct{})
    t.setReqCanceler(req, func() { close(cancelc) })

    // 启动了一个goroutine, 这个goroutine 获取里面调用dialConn搞到
    // persistConn, 然后发送到上面建立的channel  dialc里面，
    go func() {
        pc, err := t.dialConn(cm)
        dialc &amp;lt;- dialRes{pc, err}
    }()

    idleConnCh := t.getIdleConnCh(cm)
    select {
    case v := &amp;lt;-dialc:
        // dialc 我们的 dial 方法先搞到通过 dialc通道发过来了
        return v.pc, v.err
    case pc := &amp;lt;-idleConnCh:
        // 这里代表其他的http请求用完了归还的persistConn通过idleConnCh这个
        // channel发送来的
        handlePendingDial()
        return pc, nil
    case &amp;lt;-req.Cancel:
        handlePendingDial()
        return nil, errors.New(&amp;quot;net/http: request canceled while waiting for connection&amp;quot;)
    case &amp;lt;-cancelc:
        handlePendingDial()
        return nil, errors.New(&amp;quot;net/http: request canceled while waiting for connection&amp;quot;)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里面的代码写的很有讲究 , 上面代码里面我也注释了， 定义了一个发送 persistConn的channel dialc， 启动了一个goroutine, 这个goroutine 获取里面调用dialConn搞到persistConn, 然后发送到dialc里面，主协程goroutine在 select里面监听多个channel,看看哪个通道里面先发过来 persistConn，就用哪个，然后return。&lt;/p&gt;

&lt;p&gt;这里要注意的是 idleConnCh 这个通道里面发送来的是其他的http请求用完了归还的persistConn， 如果从这个通道里面搞到了，dialc这个通道也等着发呢，不能浪费，就通过handlePendingDial这个方法把dialc通道里面的persistConn也发到idleConnCh，等待后续给其他http请求使用。&lt;/p&gt;

&lt;p&gt;每个新建的persistConn的时候都把tcp连接里地输入流，和输出流用br（br *bufio.Reader）,和bw(bw *bufio.Writer)包装了一下，往bw写就写到tcp输入流里面了，读输出流也是通过br读，并启动了读循环和写循环&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pconn.br = bufio.NewReader(noteEOFReader{pconn.conn, &amp;amp;pconn.sawEOF})
pconn.bw = bufio.NewWriter(pconn.conn)
go pconn.readLoop()
go pconn.writeLoop()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们再看pconn.roundTrip 调用这个持久连接persistConn 这个struct的roundTrip方法。先瞄一下 persistConn 这个struct&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type persistConn struct {
    t        *Transport
    cacheKey connectMethodKey
    conn     net.Conn
    tlsState *tls.ConnectionState
    br       *bufio.Reader       // 从tcp输出流里面读
    sawEOF   bool                // whether we&#39;ve seen EOF from conn; owned by readLoop
    bw       *bufio.Writer       // 写到tcp输入流
     reqch    chan requestAndChan // 主goroutine 往channnel里面写，读循环从     
                                 // channnel里面接受
    writech  chan writeRequest   // 主goroutine 往channnel里面写                                      
                                 // 写循环从channel里面接受
    closech  chan struct{}       // 通知关闭tcp连接的channel 

    writeErrCh chan error

    lk                   sync.Mutex // guards following fields
    numExpectedResponses int
    closed               bool // whether conn has been closed
    broken               bool // an error has happened on this connection; marked broken so it&#39;s not reused.
    canceled             bool // whether this conn was broken due a CancelRequest
    // mutateHeaderFunc is an optional func to modify extra
    // headers on each outbound request before it&#39;s written. (the
    // original Request given to RoundTrip is not modified)
    mutateHeaderFunc func(Header)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;里面是各种channel, 用的是出神入化， 各位要好好理解一下，这里有三个goroutine，有两个channel writeRequest 和 requestAndChan&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type writeRequest struct {
    req *transportRequest
    ch  chan&amp;lt;- error
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主goroutine 往writeRequest里面写，写循环从writeRequest里面接受&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type responseAndError struct {
    res *Response
    err error
}

type requestAndChan struct {
    req *Request
    ch  chan responseAndError
    addedGzip bool
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主goroutine 往requestAndChan里面写，读循环从requestAndChan里面接受。&lt;/p&gt;

&lt;p&gt;注意这里的channel都是双向channel，也就是channel 的struct里面有一个chan类型的字段， 比如 reqch chan requestAndChan 这里的 requestAndChan 里面的 ch chan responseAndError。&lt;/p&gt;

&lt;p&gt;这个是很牛叉，主 goroutine 通过 reqch 发送requestAndChan 给读循环，然后读循环搞到response后通过 requestAndChan 里面的通道responseAndError把response返给主goroutine，所以我画了一个双向箭头。&lt;/p&gt;

&lt;p&gt;我们研究一下代码，我理解下来其实就是三个goroutine通过channel互相协作的过程。&lt;/p&gt;

&lt;p&gt;主循环：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (pc *persistConn) roundTrip(req *transportRequest) (resp *Response, err error) {
    ... 忽略
    // Write the request concurrently with waiting for a response,
    // in case the server decides to reply before reading our full
    // request body.
    writeErrCh := make(chan error, 1)
    pc.writech &amp;lt;- writeRequest{req, writeErrCh}
    //把request发送给写循环
    resc := make(chan responseAndError, 1)
    pc.reqch &amp;lt;- requestAndChan{req.Request, resc, requestedGzip}
    //发送给读循环
    var re responseAndError
    var respHeaderTimer &amp;lt;-chan time.Time
    cancelChan := req.Request.Cancel
WaitResponse:
    for {
        select {
        case err := &amp;lt;-writeErrCh:
            if isNetWriteError(err) {
                //写循环通过这个channel报告错误
                select {
                case re = &amp;lt;-resc:
                    pc.close()
                    break WaitResponse
                case &amp;lt;-time.After(50 * time.Millisecond):
                    // Fall through.
                }
            }
            if err != nil {
                re = responseAndError{nil, err}
                pc.close()
                break WaitResponse
            }
            if d := pc.t.ResponseHeaderTimeout; d &amp;gt; 0 {
                timer := time.NewTimer(d)
                defer timer.Stop() // prevent leaks
                respHeaderTimer = timer.C
            }
        case &amp;lt;-pc.closech:
            // 如果长连接挂了， 这里的channel有数据， 进入这个case, 进行处理

            select {
            case re = &amp;lt;-resc:
                if fn := testHookPersistConnClosedGotRes; fn != nil {
                    fn()
                }
            default:
                re = responseAndError{err: errClosed}
                if pc.isCanceled() {
                    re = responseAndError{err: errRequestCanceled}
                }
            }
            break WaitResponse
        case &amp;lt;-respHeaderTimer:
            pc.close()
            re = responseAndError{err: errTimeout}
            break WaitResponse
            // 如果timeout，这里的channel有数据， break掉for循环
        case re = &amp;lt;-resc:
            break WaitResponse
           // 获取到读循环的response, break掉 for循环
        case &amp;lt;-cancelChan:
            pc.t.CancelRequest(req.Request)
            cancelChan = nil
        }
    }

    if re.err != nil {
        pc.t.setReqCanceler(req.Request, nil)
    }
    return re.res, re.err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这段代码主要就干了三件事&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;主goroutine -&amp;gt;requestAndChan -&amp;gt; 读循环goroutine

主goroutine -&amp;gt;writeRequest-&amp;gt; 写循环goroutine

主goroutine 通过select 监听各个channel上的数据， 比如请求取消， timeout，长连接挂了，写流出错，读流出错， 都是其他goroutine 发送过来的， 跟中断一样，然后相应处理，上面也提到了，有些channel是主goroutine通过channel发送给其他goroutine的struct里面包含的channel, 比如 case err := &amp;lt;-writeErrCh: case re = &amp;lt;-resc:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;读循环代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (pc *persistConn) readLoop() {

    ... 忽略
    alive := true
    for alive {

        ... 忽略
        rc := &amp;lt;-pc.reqch

        var resp *Response
        if err == nil {
            resp, err = ReadResponse(pc.br, rc.req)
            if err == nil &amp;amp;&amp;amp; resp.StatusCode == 100 {
                //100  Continue  初始的请求已经接受，客户应当继续发送请求的其 
                // 余部分
                resp, err = ReadResponse(pc.br, rc.req)
                // 读pc.br（tcp输出流）中的数据，这里的代码在response里面
                //解析statusCode，头字段， 转成标准的内存中的response 类型
                //  http在tcp数据流里面，head和body以 /r/n/r/n分开， 各个头
                // 字段 以/r/n分开
            }
        }

        if resp != nil {
            resp.TLS = pc.tlsState
        }

        ...忽略
        //上面处理一些http协议的一些逻辑行为，
        rc.ch &amp;lt;- responseAndError{resp, err} //把读到的response返回给    
                                             //主goroutine

        .. 忽略
        //忽略部分， 处理cancel req中断， 发送idleConnCh归还pc（持久连接）到持久连接池中（map）    
    pc.close()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;无关代码忽略，这段代码主要干了一件事情&lt;/p&gt;

&lt;p&gt;读循环goroutine 通过channel requestAndChan 接受主goroutine发送的request(rc := &amp;lt;-pc.reqch), 并从tcp输出流中读取response， 然后反序列化到结构体中， 最后通过channel 返给主goroutine (rc.ch &amp;lt;- responseAndError{resp, err} )&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (pc *persistConn) writeLoop() {
    for {
        select {
        case wr := &amp;lt;-pc.writech:   //接受主goroutine的 request
            if pc.isBroken() {
                wr.ch &amp;lt;- errors.New(&amp;quot;http: can&#39;t write HTTP request on broken connection&amp;quot;)
                continue
            }
            err := wr.req.Request.write(pc.bw, pc.isProxy, wr.req.extra)   //写入tcp输入流
            if err == nil {
                err = pc.bw.Flush()
            }
            if err != nil {
                pc.markBroken()
                wr.req.Request.closeBody()
            }
            pc.writeErrCh &amp;lt;- err 
            wr.ch &amp;lt;- err         //  出错的时候返给主goroutineto 
        case &amp;lt;-pc.closech:
            return
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;写循环就更简单了，select channel中主gouroutine的request，然后写入tcp输入流，如果出错了，channel 通知调用者。&lt;/p&gt;

&lt;p&gt;整体看下来，过程都很简单，但是代码中有很多值得我们学习的地方，比如高并发请求如何复用tcp连接，这里是连接池的做法，如果使用多个 goroutine相互协作完成一个http请求，出现错误的时候如何通知调用者中断错误，代码风格也有很多可以借鉴的地方。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;http.Client 表示一个http client端，用来处理HTTP相关的工作，例如cookies, redirect, timeout等工作，其内部包含一个Transport，tranport用来建立一个连接，其中维护了一个空闲连接池idleConn map[connectMethodKey][]*persistConn，其中的每个成员都是一个persistConn对象，persistConn是个具体的连接实例，包含了连接的上下文，会启动两个groutine分别执行readLoop和writeLoop, 每当transport调用roundTrip的时候，就会从连接池中选择一个空闲的persistConn，然后调用其roundTrip方法，将读写请求通过channel分别发送到readLoop和writeLoop中，然后会进行select各个channel的信息，包括连接关闭，请求超时，writeLoop出错， readLoop返回读取结果等。在writeLoop中发送请求，在readLoop中获取response并通过channe返回给roundTrip函数中，并再次将自己加入到idleConn中，等待下次请求到来。&lt;/p&gt;

&lt;h2 id=&#34;自定义client&#34;&gt;自定义client&lt;/h2&gt;

&lt;p&gt;在上面我们说到调用结构体的成员函数都是默认的结构体的成员函数，但是如果我们有一些特殊的需求，我们就需要重新定义这些结构体，然后实现自己的逻辑，整个http请求也就会按着我们的逻辑进行处理，这也是我们实现一些功能的必要手段。最基本的就是自定义client，也是我们编程常用的，深入一些就需要了解一些传输transport等。&lt;/p&gt;

&lt;p&gt;1、要管理HTTP客户端的头域、重定向策略和其他设置，创建一个Client：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;client := &amp;amp;http.Client{
    CheckRedirect: redirectPolicyFunc,
}
resp, err := client.Get(&amp;quot;http://example.com&amp;quot;)
// ...
req, err := http.NewRequest(&amp;quot;GET&amp;quot;, &amp;quot;http://example.com&amp;quot;, nil)
// ...
req.Header.Add(&amp;quot;If-None-Match&amp;quot;, `W/&amp;quot;wyzzy&amp;quot;`)
resp, err := client.Do(req)
// ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个就是在上面的基础上增加了对client结构体的设置，而不是使用DefaultClient，我们来看一下client的结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Client struct {
    // Transport指定执行独立、单次HTTP请求的机制。
    // 如果Transport为nil，则使用DefaultTransport。
    Transport RoundTripper
    // CheckRedirect指定处理重定向的策略。
    // 如果CheckRedirect不为nil，客户端会在执行重定向之前调用本函数字段。
    // 参数req和via是将要执行的请求和已经执行的请求（切片，越新的请求越靠后）。
    // 如果CheckRedirect返回一个错误，本类型的Get方法不会发送请求req，
    // 而是返回之前得到的最后一个回复和该错误。（包装进url.Error类型里）
    //
    // 如果CheckRedirect为nil，会采用默认策略：连续10此请求后停止。
    CheckRedirect func(req *Request, via []*Request) error
    // Jar指定cookie管理器。
    // 如果Jar为nil，请求中不会发送cookie，回复中的cookie会被忽略。
    Jar CookieJar
    // Timeout指定本类型的值执行请求的时间限制。
    // 该超时限制包括连接时间、重定向和读取回复主体的时间。
    // 计时器会在Head、Get、Post或Do方法返回后继续运作并在超时后中断回复主体的读取。
    //
    // Timeout为零值表示不设置超时。
    //
    // Client实例的Transport字段必须支持CancelRequest方法，
    // 否则Client会在试图用Head、Get、Post或Do方法执行请求时返回错误。
    // 本类型的Transport字段默认值（DefaultTransport）支持CancelRequest方法。
    Timeout time.Duration
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要是对这些结构体中的成员的如何运用才是重点，然后就调用client的Get，Do等方法就是上面的执行逻辑，这边只是简单的client的处理，后面的逻辑依然使用的是默认的Transport。&lt;/p&gt;

&lt;p&gt;2、要管理代理、TLS配置、keep-alive、压缩和其他设置，创建一个Transport：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tr := &amp;amp;http.Transport{
    TLSClientConfig:    &amp;amp;tls.Config{RootCAs: pool},
    DisableCompression: true,
}
client := &amp;amp;http.Client{Transport: tr}
resp, err := client.Get(&amp;quot;https://example.com&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Client和Transport类型都可以安全的被多个go程同时使用。出于效率考虑，应该一次建立、尽量重用。&lt;/p&gt;

&lt;p&gt;这边在client的基础上对client的transport的管理代理、TLS配置、keep-alive、压缩和其他设置，然后后面的逻辑中主要是切换到自定义的transport的逻辑运行。&lt;/p&gt;

&lt;h1 id=&#34;http服务端&#34;&gt;http服务端&lt;/h1&gt;

&lt;h2 id=&#34;http-status&#34;&gt;http status&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;const (
    StatusContinue           = 100
    StatusSwitchingProtocols = 101
    StatusOK                   = 200
    StatusCreated              = 201
    StatusAccepted             = 202
    StatusNonAuthoritativeInfo = 203
    StatusNoContent            = 204
    StatusResetContent         = 205
    StatusPartialContent       = 206
    StatusMultipleChoices   = 300
    StatusMovedPermanently  = 301
    StatusFound             = 302
    StatusSeeOther          = 303
    StatusNotModified       = 304
    StatusUseProxy          = 305
    StatusTemporaryRedirect = 307
    StatusBadRequest                   = 400
    StatusUnauthorized                 = 401
    StatusPaymentRequired              = 402
    StatusForbidden                    = 403
    StatusNotFound                     = 404
    StatusMethodNotAllowed             = 405
    StatusNotAcceptable                = 406
    StatusProxyAuthRequired            = 407
    StatusRequestTimeout               = 408
    StatusConflict                     = 409
    StatusGone                         = 410
    StatusLengthRequired               = 411
    StatusPreconditionFailed           = 412
    StatusRequestEntityTooLarge        = 413
    StatusRequestURITooLong            = 414
    StatusUnsupportedMediaType         = 415
    StatusRequestedRangeNotSatisfiable = 416
    StatusExpectationFailed            = 417
    StatusTeapot                       = 418
    StatusInternalServerError     = 500
    StatusNotImplemented          = 501
    StatusBadGateway              = 502
    StatusServiceUnavailable      = 503
    StatusGatewayTimeout          = 504
    StatusHTTPVersionNotSupported = 505
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们比较常用的就是404（服务未发现），503（服务不可用）等。&lt;/p&gt;

&lt;h2 id=&#34;http-header&#34;&gt;http header&lt;/h2&gt;

&lt;p&gt;Header代表HTTP头域的键值对。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Header map[string][]string
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;基本操作&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (h Header) Get(key string) string
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Get返回键对应的第一个值，如果键不存在会返回&amp;rdquo;&amp;ldquo;。如要获取该键对应的值切片，请直接用规范格式的键访问map。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (h Header) Set(key, value string)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Set添加键值对到h，如键已存在则会用只有新值一个元素的切片取代旧值切片。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (h Header) Add(key, value string)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add添加键值对到h，如键已存在则会将新的值附加到旧值切片后面。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (h Header) Del(key string)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Del删除键值对。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (h Header) Write(w io.Writer) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Write以有线格式将头域写入w。&lt;/p&gt;

&lt;h2 id=&#34;用于http客户端和服务端的结构体&#34;&gt;用于http客户端和服务端的结构体&lt;/h2&gt;

&lt;p&gt;type Request&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Request struct {
    // Method指定HTTP方法（GET、POST、PUT等）。对客户端，&amp;quot;&amp;quot;代表GET。
    Method string
    // URL在服务端表示被请求的URI，在客户端表示要访问的URL。
    //
    // 在服务端，URL字段是解析请求行的URI（保存在RequestURI字段）得到的，
    // 对大多数请求来说，除了Path和RawQuery之外的字段都是空字符串。
    // （参见RFC 2616, Section 5.1.2）
    //
    // 在客户端，URL的Host字段指定了要连接的服务器，
    // 而Request的Host字段（可选地）指定要发送的HTTP请求的Host头的值。
    URL *url.URL
    // 接收到的请求的协议版本。本包生产的Request总是使用HTTP/1.1
    Proto      string // &amp;quot;HTTP/1.0&amp;quot;
    ProtoMajor int    // 1
    ProtoMinor int    // 0
    // Header字段用来表示HTTP请求的头域。如果头域（多行键值对格式）为：
    //  accept-encoding: gzip, deflate
    //  Accept-Language: en-us
    //  Connection: keep-alive
    // 则：
    //  Header = map[string][]string{
    //      &amp;quot;Accept-Encoding&amp;quot;: {&amp;quot;gzip, deflate&amp;quot;},
    //      &amp;quot;Accept-Language&amp;quot;: {&amp;quot;en-us&amp;quot;},
    //      &amp;quot;Connection&amp;quot;: {&amp;quot;keep-alive&amp;quot;},
    //  }
    // HTTP规定头域的键名（头名）是大小写敏感的，请求的解析器通过规范化头域的键名来实现这点。
    // 在客户端的请求，可能会被自动添加或重写Header中的特定的头，参见Request.Write方法。
    Header Header
    // Body是请求的主体。
    //
    // 在客户端，如果Body是nil表示该请求没有主体买入GET请求。
    // Client的Transport字段会负责调用Body的Close方法。
    //
    // 在服务端，Body字段总是非nil的；但在没有主体时，读取Body会立刻返回EOF。
    // Server会关闭请求的主体，ServeHTTP处理器不需要关闭Body字段。
    Body io.ReadCloser
    // ContentLength记录相关内容的长度。
    // 如果为-1，表示长度未知，如果&amp;gt;=0，表示可以从Body字段读取ContentLength字节数据。
    // 在客户端，如果Body非nil而该字段为0，表示不知道Body的长度。
    ContentLength int64
    // TransferEncoding按从最外到最里的顺序列出传输编码，空切片表示&amp;quot;identity&amp;quot;编码。
    // 本字段一般会被忽略。当发送或接受请求时，会自动添加或移除&amp;quot;chunked&amp;quot;传输编码。
    TransferEncoding []string
    // Close在服务端指定是否在回复请求后关闭连接，在客户端指定是否在发送请求后关闭连接。
    Close bool
    // 在服务端，Host指定URL会在其上寻找资源的主机。
    // 根据RFC 2616，该值可以是Host头的值，或者URL自身提供的主机名。
    // Host的格式可以是&amp;quot;host:port&amp;quot;。
    //
    // 在客户端，请求的Host字段（可选地）用来重写请求的Host头。
    // 如过该字段为&amp;quot;&amp;quot;，Request.Write方法会使用URL字段的Host。
    Host string
    // Form是解析好的表单数据，包括URL字段的query参数和POST或PUT的表单数据。
    // 本字段只有在调用ParseForm后才有效。在客户端，会忽略请求中的本字段而使用Body替代。
    Form url.Values
    // PostForm是解析好的POST或PUT的表单数据。
    // 本字段只有在调用ParseForm后才有效。在客户端，会忽略请求中的本字段而使用Body替代。
    PostForm url.Values
    // MultipartForm是解析好的多部件表单，包括上传的文件。
    // 本字段只有在调用ParseMultipartForm后才有效。
    // 在客户端，会忽略请求中的本字段而使用Body替代。
    MultipartForm *multipart.Form
    // Trailer指定了会在请求主体之后发送的额外的头域。
    //
    // 在服务端，Trailer字段必须初始化为只有trailer键，所有键都对应nil值。
    // （客户端会声明哪些trailer会发送）
    // 在处理器从Body读取时，不能使用本字段。
    // 在从Body的读取返回EOF后，Trailer字段会被更新完毕并包含非nil的值。
    // （如果客户端发送了这些键值对），此时才可以访问本字段。
    //
    // 在客户端，Trail必须初始化为一个包含将要发送的键值对的映射。（值可以是nil或其终值）
    // ContentLength字段必须是0或-1，以启用&amp;quot;chunked&amp;quot;传输编码发送请求。
    // 在开始发送请求后，Trailer可以在读取请求主体期间被修改，
    // 一旦请求主体返回EOF，调用者就不可再修改Trailer。
    //
    // 很少有HTTP客户端、服务端或代理支持HTTP trailer。
    Trailer Header
    // RemoteAddr允许HTTP服务器和其他软件记录该请求的来源地址，一般用于日志。
    // 本字段不是ReadRequest函数填写的，也没有定义格式。
    // 本包的HTTP服务器会在调用处理器之前设置RemoteAddr为&amp;quot;IP:port&amp;quot;格式的地址。
    // 客户端会忽略请求中的RemoteAddr字段。
    RemoteAddr string
    // RequestURI是被客户端发送到服务端的请求的请求行中未修改的请求URI
    // （参见RFC 2616, Section 5.1）
    // 一般应使用URI字段，在客户端设置请求的本字段会导致错误。
    RequestURI string
    // TLS字段允许HTTP服务器和其他软件记录接收到该请求的TLS连接的信息
    // 本字段不是ReadRequest函数填写的。
    // 对启用了TLS的连接，本包的HTTP服务器会在调用处理器之前设置TLS字段，否则将设TLS为nil。
    // 客户端会忽略请求中的TLS字段。
    TLS *tls.ConnectionState
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Request类型代表一个服务端接受到的或者客户端发送出去的HTTP请求。&lt;/p&gt;

&lt;p&gt;Request各字段的意义和用途在服务端和客户端是不同的。除了字段本身上方文档，还可参见Request.Write方法和RoundTripper接口的文档。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Response struct {
    Status     string // 例如&amp;quot;200 OK&amp;quot;
    StatusCode int    // 例如200
    Proto      string // 例如&amp;quot;HTTP/1.0&amp;quot;
    ProtoMajor int    // 例如1
    ProtoMinor int    // 例如0
    // Header保管头域的键值对。
    // 如果回复中有多个头的键相同，Header中保存为该键对应用逗号分隔串联起来的这些头的值
    // （参见RFC 2616 Section 4.2）
    // 被本结构体中的其他字段复制保管的头（如ContentLength）会从Header中删掉。
    //
    // Header中的键都是规范化的，参见CanonicalHeaderKey函数
    Header Header
    // Body代表回复的主体。
    // Client类型和Transport类型会保证Body字段总是非nil的，即使回复没有主体或主体长度为0。
    // 关闭主体是调用者的责任。
    // 如果服务端采用&amp;quot;chunked&amp;quot;传输编码发送的回复，Body字段会自动进行解码。
    Body io.ReadCloser
    // ContentLength记录相关内容的长度。
    // 其值为-1表示长度未知（采用chunked传输编码）
    // 除非对应的Request.Method是&amp;quot;HEAD&amp;quot;，其值&amp;gt;=0表示可以从Body读取的字节数
    ContentLength int64
    // TransferEncoding按从最外到最里的顺序列出传输编码，空切片表示&amp;quot;identity&amp;quot;编码。
    TransferEncoding []string
    // Close记录头域是否指定应在读取完主体后关闭连接。（即Connection头）
    // 该值是给客户端的建议，Response.Write方法的ReadResponse函数都不会关闭连接。
    Close bool
    // Trailer字段保存和头域相同格式的trailer键值对，和Header字段相同类型
    Trailer Header
    // Request是用来获取此回复的请求
    // Request的Body字段是nil（因为已经被用掉了）
    // 这个字段是被Client类型发出请求并获得回复后填充的
    Request *Request
    // TLS包含接收到该回复的TLS连接的信息。 对未加密的回复，本字段为nil。
    // 返回的指针是被（同一TLS连接接收到的）回复共享的，不应被修改。
    TLS *tls.ConnectionState
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Response代表一个HTTP请求的回复&lt;/p&gt;

&lt;p&gt;type ResponseWriter&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type ResponseWriter interface {
    // Header返回一个Header类型值，该值会被WriteHeader方法发送。
    // 在调用WriteHeader或Write方法后再改变该对象是没有意义的。
    Header() Header
    // WriteHeader该方法发送HTTP回复的头域和状态码。
    // 如果没有被显式调用，第一次调用Write时会触发隐式调用WriteHeader(http.StatusOK)
    // WriterHeader的显式调用主要用于发送错误码。
    WriteHeader(int)
    // Write向连接中写入作为HTTP的一部分回复的数据。
    // 如果被调用时还未调用WriteHeader，本方法会先调用WriteHeader(http.StatusOK)
    // 如果Header中没有&amp;quot;Content-Type&amp;quot;键，
    // 本方法会使用包函数DetectContentType检查数据的前512字节，将返回值作为该键的值。
    Write([]byte) (int, error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ResponseWriter接口被HTTP处理器用于构造HTTP回复。这个一般用于服务端处理请求&lt;/p&gt;

&lt;p&gt;实例&lt;/p&gt;

&lt;p&gt;正常我们使用的返回方式&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
 &amp;quot;net/http&amp;quot;
)

func main() {

 http.HandleFunc(&amp;quot;/&amp;quot;, func (w http.ResponseWriter, r *http.Request){


   w.Header().Set(&amp;quot;name&amp;quot;, &amp;quot;my name is smallsoup&amp;quot;)
   w.WriteHeader(500)
   w.Write([]byte(&amp;quot;hello world\n&amp;quot;))

 })

 http.ListenAndServe(&amp;quot;:8080&amp;quot;, nil)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;type CloseNotifier&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type CloseNotifier interface {
    // CloseNotify返回一个通道，该通道会在客户端连接丢失时接收到唯一的值
    CloseNotify() &amp;lt;-chan bool
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;HTTP处理器ResponseWriter接口参数的下层如果实现了CloseNotifier接口，可以让用户检测下层的连接是否停止。如果客户端在回复准备好之前关闭了连接，该机制可以用于取消服务端耗时较长的操作。&lt;/p&gt;

&lt;h2 id=&#34;http-服务端使用和原理解析&#34;&gt;http 服务端使用和原理解析&lt;/h2&gt;

&lt;p&gt;ListenAndServe使用指定的监听地址和处理器启动一个HTTP服务端。处理器参数通常是nil，这表示采用包变量DefaultServeMux作为处理器。Handle和HandleFunc函数可以向DefaultServeMux添加处理器。如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http.Handle(&amp;quot;/foo&amp;quot;, fooHandler)
http.HandleFunc(&amp;quot;/bar&amp;quot;, func(w http.ResponseWriter, r *http.Request) {
    fmt.Fprintf(w, &amp;quot;Hello, %q&amp;quot;, html.EscapeString(r.URL.Path))
})
log.Fatal(http.ListenAndServe(&amp;quot;:8080&amp;quot;, nil))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ListenAndServe该方法用于在指定的TCP网络地址addr进行监听，然后调用服务端处理程序来处理传入的连接请求。该方法有两个参数：第一个参数addr 即监听地址；第二个参数表示服务端处理程序，通常为空，这意味着服务端调用 http.DefaultServeMux 进行处理，而服务端编写的业务逻辑处理程序 http.Handle() 或 http.HandleFunc() 默认注入 http.DefaultServeMux 中。&lt;/p&gt;

&lt;p&gt;理解HTTP相关的网络应用，主要关注两个地方-客户端(client)和服务端(server)，两者的交互主要是client的request以及server的response,主要就在于如何接受client的request并向client返回response。&lt;/p&gt;

&lt;p&gt;接收request的过程中，最重要的莫过于路由（router），即实现一个Multiplexer器。Go http中既可以使用内置的mutilplexer &amp;mdash; DefautServeMux，也可以自定义。Multiplexer路由的目的就是为了找到处理器函数（handler），后者将对request进行处理，同时构建response&lt;/p&gt;

&lt;p&gt;流程为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Clinet -&amp;gt; Requests -&amp;gt;  Multiplexer(router) -&amp;gt; handler  -&amp;gt; Response -&amp;gt; Clinet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于一个http服务，大致需要理解这两个封装的过程就可以理解上面的实现了&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.首先需要注册路由，即提供url模式和handler函数的映射.
2.其次就是实例化一个server对象，并开启对客户端的监听。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再看go http服务的代码&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http.HandleFunc(&amp;quot;/&amp;quot;, indexHandler) -----即是注册路由。
http.ListenAndServe(&amp;quot;127.0.0.1:8000&amp;quot;, nil)---启动server
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;或者&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server := &amp;amp;Server{Addr: addr, Handler: handler}
server.ListenAndServe()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;注册路由&#34;&gt;注册路由&lt;/h3&gt;

&lt;p&gt;net/http包暴露的注册路由的api很简单&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http.HandleFunc(&amp;quot;/&amp;quot;, indexHandler) -----即是注册路由。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;HandlerFunc是一个函数类型，如下定义，同时实现了Handler接口的ServeHTTP方法。使用HandlerFunc类型包装一下路由定义的indexHandler函数，其目的就是为了让这个函数也实现ServeHTTP方法，即转变成一个handler处理器(函数)。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type HandlerFunc func(ResponseWriter, *Request)

// ServeHTTP calls f(w, r).
func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) {
    f(w, r)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们最开始写的例子中&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http.HandleFunc(&amp;quot;/&amp;quot;,Indexhandler)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样 IndexHandler 函数也有了ServeHTTP方法。&lt;/p&gt;

&lt;p&gt;ServeMux和handler处理器函数的连接桥梁就是Handler接口。ServeMux的ServeHTTP方法实现了寻找注册路由的handler的函数（可以看下面的监控服务流程），并调用该handler的ServeHTTP方法。ServeHTTP方法就是真正处理请求和构造响应的地方。&lt;/p&gt;

&lt;p&gt;Go其实支持外部实现的路由器 ListenAndServe的第二个参数就是 用以配置外部路由器的，它是一个Handler接口，即外部路由器只要实现了Handler接口就可以,我们可以在自己实现 的路由器的ServHTTP里面实现自定义路由功能。&lt;/p&gt;

&lt;p&gt;如下代码所示，我们自己实现了一个简易的路由器&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import ( 
    &amp;quot;fmt&amp;quot;
    &amp;quot;net/http&amp;quot; 
    )
type MyMux struct { }

func (p *MyMux) ServeHTTP(w http.ResponseWriter, r *http.Request) { if r.URL.Path == &amp;quot;/&amp;quot; {
    sayhelloName(w, r)
    return 
}
    http.NotFound(w, r)
    return 
}

func sayhelloName(w http.ResponseWriter, r *http.Request) { f
    mt.Fprintf(w, &amp;quot;Hello myroute!&amp;quot;)
}

func main() {
    mux := &amp;amp;MyMux{}
    http.ListenAndServe(&amp;quot;:9090&amp;quot;, mux) 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;multiplexer&#34;&gt;multiplexer&lt;/h3&gt;

&lt;p&gt;http.HandleFunc选取了DefaultServeMux作为multiplexer：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) {
    DefaultServeMux.HandleFunc(pattern, handler)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;DefaultServeMux是ServeMux的一个实例。当然http包也提供了NewServeMux方法创建一个ServeMux实例，默认则创建一个DefaultServeMux：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// NewServeMux allocates and returns a new ServeMux.
func NewServeMux() *ServeMux { return new(ServeMux) }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;DefaultServeMux的代码定义&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// DefaultServeMux is the default ServeMux used by Serve.
var DefaultServeMux = &amp;amp;defaultServeMux
var defaultServeMux ServeMux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然也可以是其他可以实现的实例 ，比如上面实现的mux。&lt;/p&gt;

&lt;p&gt;路由结构体ServeMux&lt;/p&gt;

&lt;p&gt;ServeMux的源码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type ServeMux struct {
    mu    sync.RWMutex                      //锁，由于请求涉及到并发处理，因此这里需要一个锁机制
    m     map[string]muxEntry               // 路由规则，一个string对应一个mux实体，这里的string就是注册的路由
    hosts bool 
}

type muxEntry struct {
    explicit bool                // 是否精确匹配
    h        Handler              // 这个路由表达式对应哪个handler
    pattern  string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ServeMux结构中最重要的字段为m，这是一个map，key是一些url模式，value是一个muxEntry结构，后者里定义存储了具体的url模式和handler。&lt;/p&gt;

&lt;p&gt;当然，所谓的ServeMux也实现了ServeHTTP接口，也算是一个handler，不过ServeMux的ServeHTTP方法不是用来处理request和respone，而是用来找到路由注册的handler，可以看服务监听时候的调用过程。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// HandleFunc registers the handler function for the given pattern.
func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) {
    if handler == nil {
        panic(&amp;quot;http: nil handler&amp;quot;)
    }
    mux.Handle(pattern, HandlerFunc(handler))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ServeMux的Handle方法，将会对pattern和handler函数做一个map映射：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Handle registers the handler for the given pattern.
// If a handler already exists for pattern, Handle panics.
func (mux *ServeMux) Handle(pattern string, handler Handler) {
    mux.mu.Lock()
    defer mux.mu.Unlock()

    if pattern == &amp;quot;&amp;quot; {
        panic(&amp;quot;http: invalid pattern &amp;quot; + pattern)
    }
    if handler == nil {
        panic(&amp;quot;http: nil handler&amp;quot;)
    }
    if mux.m[pattern].explicit {
        panic(&amp;quot;http: multiple registrations for &amp;quot; + pattern)
    }

    if mux.m == nil {
        mux.m = make(map[string]muxEntry)
    }
    mux.m[pattern] = muxEntry{explicit: true, h: handler, pattern: pattern}

    if pattern[0] != &#39;/&#39; {
        mux.hosts = true
    }

    // Helpful behavior:
    // If pattern is /tree/, insert an implicit permanent redirect for /tree.
    // It can be overridden by an explicit registration.
    n := len(pattern)
    if n &amp;gt; 0 &amp;amp;&amp;amp; pattern[n-1] == &#39;/&#39; &amp;amp;&amp;amp; !mux.m[pattern[0:n-1]].explicit {
        // If pattern contains a host name, strip it and use remaining
        // path for redirect.
        path := pattern
        if pattern[0] != &#39;/&#39; {
            // In pattern, at least the last character is a &#39;/&#39;, so
            // strings.Index can&#39;t be -1.
            path = pattern[strings.Index(pattern, &amp;quot;/&amp;quot;):]
        }
        url := &amp;amp;url.URL{Path: path}
        mux.m[pattern[0:n-1]] = muxEntry{h: RedirectHandler(url.String(), StatusMovedPermanently), pattern: pattern}
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Handle函数的主要目的在于把handler和pattern模式绑定到map[string]muxEntry的map上，其中muxEntry保存了更多pattern和handler的信息，还记得前面讨论的Server结构吗？Server的m字段就是map[string]muxEntry这样一个map。&lt;/p&gt;

&lt;p&gt;此时，pattern和handler的路由注册完成。接下来就是如何开始server的监听，以接收客户端的请求。&lt;/p&gt;

&lt;h3 id=&#34;启动服务&#34;&gt;启动服务&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;http.ListenAndServe(&amp;quot;127.0.0.1:8000&amp;quot;, nil)---启动server
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;或者&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server := &amp;amp;Server{Addr: addr, Handler: handler}

server.ListenAndServe()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注册好路由之后，启动web服务还需要开启服务器监听。http的ListenAndServer方法中可以看到创建了一个Server对象，并调用了Server对象的同名方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func ListenAndServe(addr string, handler Handler) error {
    server := &amp;amp;Server{Addr: addr, Handler: handler}
    return server.ListenAndServe()
}
// ListenAndServe listens on the TCP network address srv.Addr and then
// calls Serve to handle requests on incoming connections.
// Accepted connections are configured to enable TCP keep-alives.
// If srv.Addr is blank, &amp;quot;:http&amp;quot; is used.
// ListenAndServe always returns a non-nil error.
func (srv *Server) ListenAndServe() error {
    addr := srv.Addr
    if addr == &amp;quot;&amp;quot; {
        addr = &amp;quot;:http&amp;quot;
    }
    ln, err := net.Listen(&amp;quot;tcp&amp;quot;, addr)
    if err != nil {
        return err
    }
    return srv.Serve(tcpKeepAliveListener{ln.(*net.TCPListener)})
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Server的ListenAndServe方法中，会初始化监听地址Addr，同时调用Listen方法设置监听。最后将监听的TCP对象传入Serve方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Serve accepts incoming connections on the Listener l, creating a
// new service goroutine for each. The service goroutines read requests and
// then call srv.Handler to reply to them.
//
// For HTTP/2 support, srv.TLSConfig should be initialized to the
// provided listener&#39;s TLS Config before calling Serve. If
// srv.TLSConfig is non-nil and doesn&#39;t include the string &amp;quot;h2&amp;quot; in
// Config.NextProtos, HTTP/2 support is not enabled.
//
// Serve always returns a non-nil error. After Shutdown or Close, the
// returned error is ErrServerClosed.
func (srv *Server) Serve(l net.Listener) error {
    defer l.Close()
    if fn := testHookServerServe; fn != nil {
        fn(srv, l)
    }
    var tempDelay time.Duration // how long to sleep on accept failure

    if err := srv.setupHTTP2_Serve(); err != nil {
        return err
    }

    srv.trackListener(l, true)
    defer srv.trackListener(l, false)

    baseCtx := context.Background() // base is always background, per Issue 16220
    ctx := context.WithValue(baseCtx, ServerContextKey, srv)
    for {
        rw, e := l.Accept()
        if e != nil {
            select {
            case &amp;lt;-srv.getDoneChan():
                return ErrServerClosed
            default:
            }
            if ne, ok := e.(net.Error); ok &amp;amp;&amp;amp; ne.Temporary() {
                if tempDelay == 0 {
                    tempDelay = 5 * time.Millisecond
                } else {
                    tempDelay *= 2
                }
                if max := 1 * time.Second; tempDelay &amp;gt; max {
                    tempDelay = max
                }
                srv.logf(&amp;quot;http: Accept error: %v; retrying in %v&amp;quot;, e, tempDelay)
                time.Sleep(tempDelay)
                continue
            }
            return e
        }
        tempDelay = 0
        c := srv.newConn(rw)
        c.setState(c.rwc, StateNew) // before Serve can return
        go c.serve(ctx)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;监听开启之后，一旦客户端请求到达，创建一个conn结构体，这个conn中保留了这次请求的信息，go就开启一个协程serve处理请求，主要逻辑都在serve方法之中。&lt;/p&gt;

&lt;p&gt;serve方法比较长，其主要职能就是，创建一个上下文对象，然后调用Listener的Accept方法用来　获取连接数据并使用newConn方法创建连接对象。最后使用goroutein协程的方式处理连接请求。因为每一个连接都开起了一个协程，请求的上下文都不同，同时又保证了go的高并发。serve也是一个长长的方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Serve a new connection.
func (c *conn) serve(ctx context.Context) {
    c.remoteAddr = c.rwc.RemoteAddr().String()
    ctx = context.WithValue(ctx, LocalAddrContextKey, c.rwc.LocalAddr())
    defer func() {
        if err := recover(); err != nil &amp;amp;&amp;amp; err != ErrAbortHandler {
            const size = 64 &amp;lt;&amp;lt; 10
            buf := make([]byte, size)
            buf = buf[:runtime.Stack(buf, false)]
            c.server.logf(&amp;quot;http: panic serving %v: %v\n%s&amp;quot;, c.remoteAddr, err, buf)
        }
        if !c.hijacked() {
            c.close()
            c.setState(c.rwc, StateClosed)
        }
    }()

    if tlsConn, ok := c.rwc.(*tls.Conn); ok {
        if d := c.server.ReadTimeout; d != 0 {
            c.rwc.SetReadDeadline(time.Now().Add(d))
        }
        if d := c.server.WriteTimeout; d != 0 {
            c.rwc.SetWriteDeadline(time.Now().Add(d))
        }
        if err := tlsConn.Handshake(); err != nil {
            c.server.logf(&amp;quot;http: TLS handshake error from %s: %v&amp;quot;, c.rwc.RemoteAddr(), err)
            return
        }
        c.tlsState = new(tls.ConnectionState)
        *c.tlsState = tlsConn.ConnectionState()
        if proto := c.tlsState.NegotiatedProtocol; validNPN(proto) {
            if fn := c.server.TLSNextProto[proto]; fn != nil {
                h := initNPNRequest{tlsConn, serverHandler{c.server}}
                fn(c.server, tlsConn, h)
            }
            return
        }
    }

    // HTTP/1.x from here on.

    ctx, cancelCtx := context.WithCancel(ctx)
    c.cancelCtx = cancelCtx
    defer cancelCtx()

    c.r = &amp;amp;connReader{conn: c}
    c.bufr = newBufioReader(c.r)
    c.bufw = newBufioWriterSize(checkConnErrorWriter{c}, 4&amp;lt;&amp;lt;10)

    for {
        w, err := c.readRequest(ctx)
        if c.r.remain != c.server.initialReadLimitSize() {
            // If we read any bytes off the wire, we&#39;re active.
            c.setState(c.rwc, StateActive)
        }
        if err != nil {
            const errorHeaders = &amp;quot;\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n&amp;quot;

            if err == errTooLarge {
                // Their HTTP client may or may not be
                // able to read this if we&#39;re
                // responding to them and hanging up
                // while they&#39;re still writing their
                // request. Undefined behavior.
                const publicErr = &amp;quot;431 Request Header Fields Too Large&amp;quot;
                fmt.Fprintf(c.rwc, &amp;quot;HTTP/1.1 &amp;quot;+publicErr+errorHeaders+publicErr)
                c.closeWriteAndWait()
                return
            }
            if isCommonNetReadError(err) {
                return // don&#39;t reply
            }

            publicErr := &amp;quot;400 Bad Request&amp;quot;
            if v, ok := err.(badRequestError); ok {
                publicErr = publicErr + &amp;quot;: &amp;quot; + string(v)
            }

            fmt.Fprintf(c.rwc, &amp;quot;HTTP/1.1 &amp;quot;+publicErr+errorHeaders+publicErr)
            return
        }

        // Expect 100 Continue support
        req := w.req
        if req.expectsContinue() {
            if req.ProtoAtLeast(1, 1) &amp;amp;&amp;amp; req.ContentLength != 0 {
                // Wrap the Body reader with one that replies on the connection
                req.Body = &amp;amp;expectContinueReader{readCloser: req.Body, resp: w}
            }
        } else if req.Header.get(&amp;quot;Expect&amp;quot;) != &amp;quot;&amp;quot; {
            w.sendExpectationFailed()
            return
        }

        c.curReq.Store(w)

        if requestBodyRemains(req.Body) {
            registerOnHitEOF(req.Body, w.conn.r.startBackgroundRead)
        } else {
            if w.conn.bufr.Buffered() &amp;gt; 0 {
                w.conn.r.closeNotifyFromPipelinedRequest()
            }
            w.conn.r.startBackgroundRead()
        }

        // HTTP cannot have multiple simultaneous active requests.[*]
        // Until the server replies to this request, it can&#39;t read another,
        // so we might as well run the handler in this goroutine.
        // [*] Not strictly true: HTTP pipelining. We could let them all process
        // in parallel even if their responses need to be serialized.
        // But we&#39;re not going to implement HTTP pipelining because it
        // was never deployed in the wild and the answer is HTTP/2.
        serverHandler{c.server}.ServeHTTP(w, w.req)
        w.cancelCtx()
        if c.hijacked() {
            return
        }
        w.finishRequest()
        if !w.shouldReuseConnection() {
            if w.requestBodyLimitHit || w.closedRequestBodyEarly() {
                c.closeWriteAndWait()
            }
            return
        }
        c.setState(c.rwc, StateIdle)
        c.curReq.Store((*response)(nil))

        if !w.conn.server.doKeepAlives() {
            // We&#39;re in shutdown mode. We might&#39;ve replied
            // to the user without &amp;quot;Connection: close&amp;quot; and
            // they might think they can send another
            // request, but such is life with HTTP/1.1.
            return
        }

        if d := c.server.idleTimeout(); d != 0 {
            c.rwc.SetReadDeadline(time.Now().Add(d))
            if _, err := c.bufr.Peek(4); err != nil {
                return
            }
        }
        c.rwc.SetReadDeadline(time.Time{})
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用defer定义了函数退出时，连接关闭相关的处理。然后就是读取连接的网络数据，并处理读取完毕时候的状态。接下来就是调用serverHandler{c.server}.ServeHTTP(w, w.req)方法处理请求了。最后就是请求处理完毕的逻辑。serverHandler是一个重要的结构，它近有一个字段，即Server结构，同时它也实现了Handler接口方法ServeHTTP，并在该接口方法中做了一个重要的事情，初始化multiplexer路由多路复用器。如果server对象没有指定Handler，则使用默认的DefaultServeMux作为路由Multiplexer。并调用初始化Handler的ServeHTTP方法。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// serverHandler delegates to either the server&#39;s Handler or
// DefaultServeMux and also handles &amp;quot;OPTIONS *&amp;quot; requests.
type serverHandler struct {
    srv *Server
}

func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) {
    handler := sh.srv.Handler
    if handler == nil {
        handler = DefaultServeMux
    }
    if req.RequestURI == &amp;quot;*&amp;quot; &amp;amp;&amp;amp; req.Method == &amp;quot;OPTIONS&amp;quot; {
        handler = globalOptionsHandler{}
    }
    handler.ServeHTTP(rw, req)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里DefaultServeMux的ServeHTTP方法其实也是定义在ServeMux结构中的，相关代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Find a handler on a handler map given a path string.
// Most-specific (longest) pattern wins.
func (mux *ServeMux) match(path string) (h Handler, pattern string) {
    // Check for exact match first.
    v, ok := mux.m[path]
    if ok {
        return v.h, v.pattern
    }

    // Check for longest valid match.
    var n = 0
    for k, v := range mux.m {
        if !pathMatch(k, path) {
            continue
        }
        if h == nil || len(k) &amp;gt; n {
            n = len(k)
            h = v.h
            pattern = v.pattern
        }
    }
    return
}
func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) {

    // CONNECT requests are not canonicalized.
    if r.Method == &amp;quot;CONNECT&amp;quot; {
        return mux.handler(r.Host, r.URL.Path)
    }

    // All other requests have any port stripped and path cleaned
    // before passing to mux.handler.
    host := stripHostPort(r.Host)
    path := cleanPath(r.URL.Path)
    if path != r.URL.Path {
        _, pattern = mux.handler(host, path)
        url := *r.URL
        url.Path = path
        return RedirectHandler(url.String(), StatusMovedPermanently), pattern
    }

    return mux.handler(host, r.URL.Path)
}

// handler is the main implementation of Handler.
// The path is known to be in canonical form, except for CONNECT methods.
func (mux *ServeMux) handler(host, path string) (h Handler, pattern string) {
    mux.mu.RLock()
    defer mux.mu.RUnlock()

    // Host-specific pattern takes precedence over generic ones
    if mux.hosts {
        h, pattern = mux.match(host + path)
    }
    if h == nil {
        h, pattern = mux.match(path)
    }
    if h == nil {
        h, pattern = NotFoundHandler(), &amp;quot;&amp;quot;
    }
    return
}

// ServeHTTP dispatches the request to the handler whose
// pattern most closely matches the request URL.
func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) {
    if r.RequestURI == &amp;quot;*&amp;quot; {
        if r.ProtoAtLeast(1, 1) {
            w.Header().Set(&amp;quot;Connection&amp;quot;, &amp;quot;close&amp;quot;)
        }
        w.WriteHeader(StatusBadRequest)
        return
    }
    h, _ := mux.Handler(r)
    h.ServeHTTP(w, r)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;mux的ServeHTTP方法通过调用其Handler方法寻找注册到路由上的handler函数，并调用该函数的ServeHTTP方法，本例则是IndexHandler函数。&lt;/p&gt;

&lt;p&gt;mux的Handler方法对URL简单的处理，然后调用handler方法，后者会创建一个锁，同时调用match方法返回一个handler和pattern。&lt;/p&gt;

&lt;p&gt;在match方法中，mux的m字段是map[string]muxEntry图，后者存储了pattern和handler处理器函数，因此通过迭代m寻找出注册路由的patten模式与实际url匹配的handler函数并返回。&lt;/p&gt;

&lt;p&gt;返回的结构一直传递到mux的ServeHTTP方法，接下来调用handler函数的ServeHTTP方法，即IndexHandler函数，然后把response写到http.RequestWirter对象返回给客户端。&lt;/p&gt;

&lt;p&gt;上述函数运行结束即serverHandler{c.server}.ServeHTTP(w, w.req)运行结束。接下来就是对请求处理完毕之后上希望和连接断开的相关逻辑。&lt;/p&gt;

&lt;p&gt;至此，Golang中一个完整的http服务介绍完毕，包括注册路由，开启监听，处理连接，路由处理函数。
多数的web应用基于HTTP协议，客户端和服务器通过request-response的方式交互。一个server并不可少的两部分莫过于路由注册和连接处理。Golang通过一个ServeMux实现了的multiplexer路由多路复用器来管理路由。同时提供一个Handler接口提供ServeHTTP用来实现handler处理其函数，后者可以处理实际request并构造response。&lt;/p&gt;

&lt;h3 id=&#34;总结-1&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;理解go中的http服务，最重要就是要理解Multiplexer和handler，Golang中的Multiplexer基于ServeMux结构，同时也实现了Handler接口。下面对几个重要概念说明，两个重要的结构体和一个接口&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Handler类型&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Golang没有继承，类多态的方式可以通过接口实现。所谓接口则是定义声明了函数签名，任何结构只要实现了与接口函数签名相同的方法，就等同于实现了接口。go的http服务都是基于handler进行处理。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Handler interface {
    ServeHTTP(ResponseWriter, *Request)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;任何结构体，只要实现了ServeHTTP方法，这个结构就可以称之为handler对象。ServeMux会使用handler并调用其ServeHTTP方法处理请求并返回响应。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;handler处理器(函数)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;handler处理器(函数)-就是HandleFunc的第二个参数，是一个函数： 具有func(w http.ResponseWriter, r *http.Requests)签名的函数，经过HandlerFunc结构包装的handler函数，它实现了ServeHTTP接口方法的函数。调用handler处理器的ServeHTTP方法时，即调用handler函数本身。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;handler对象：实现了Handler接口ServeHTTP方法的结构。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ServeMux和handler处理器函数的连接桥梁就是Handler接口。ServeMux的ServeHTTP方法实现了寻找注册路由的handler的函数，并调用该handler的ServeHTTP方法。ServeHTTP方法就是真正处理请求和构造响应的地方。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Server结构体&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;从http.ListenAndServe的源码可以看出，它还是创建了一个server对象，并调用server对象的ListenAndServe方法来实现监听路由：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func ListenAndServe(addr string, handler Handler) error {
    server := &amp;amp;Server{Addr: addr, Handler: handler}
    return server.ListenAndServe()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看server的结构如下，其实上面已经解释过：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Server struct {
    Addr         string        
    Handler      Handler       
    ReadTimeout  time.Duration 
    WriteTimeout time.Duration 
    TLSConfig    *tls.Config   

    MaxHeaderBytes int

    TLSNextProto map[string]func(*Server, *tls.Conn, Handler)

    ConnState func(net.Conn, ConnState)
    ErrorLog *log.Logger
    disableKeepAlives int32     nextProtoOnce     sync.Once 
    nextProtoErr      error     
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;server结构存储了服务器处理请求常见的字段。其中Handler字段也保留Handler接口。如果Server接口没有提供Handler结构对象，那么会使用DefautServeMux做multiplexer，后面再做分析。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;路由结构体ServeMux&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ServeMux的源码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type ServeMux struct {
    mu    sync.RWMutex                      //锁，由于请求涉及到并发处理，因此这里需要一个锁机制
    m     map[string]muxEntry               // 路由规则，一个string对应一个mux实体，这里的string就是注册的路由
    hosts bool 
}

type muxEntry struct {
    explicit bool                // 是否精确匹配
    h        Handler              // 这个路由表达式对应哪个handler
    pattern  string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ServeMux结构中最重要的字段为m，这是一个map，key是一些url模式，value是一个muxEntry结构，后者里定义存储了具体的url模式和handler。&lt;/p&gt;

&lt;p&gt;当然，所谓的ServeMux也实现了ServeHTTP接口，也算是一个handler，不过ServeMux的ServeHTTP方法不是用来处理request和respone，而是用来找到路由注册的handler&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Go代码的执行流程&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;过对http包的分析之后，现在让我们来梳理一下整个的代码执行过程。&lt;/p&gt;

&lt;p&gt;1、首先调用Http.HandleFunc&lt;/p&gt;

&lt;p&gt;按顺序做了几件事:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1 调用了DefaultServerMux的HandleFunc
2 调用了DefaultServerMux的Handle
3 往DefaultServeMux的map[string]muxEntry中增加对应的handler和路由规则
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2、其次调用http.ListenAndServe(&amp;rdquo;:9090&amp;rdquo;, nil)&lt;/p&gt;

&lt;p&gt;按顺序做了几件事情:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1 实例化Server
2 调用Server的ListenAndServe()
3 调用net.Listen(&amp;quot;tcp&amp;quot;, addr)监听端口
4 启动一个for循环，在循环体中Accept请求
5 对每个请求实例化一个Conn，并且开启一个goroutine为这个请求进行服务go c.serve()
6 读取每个请求的内容w, err := c.readRequest()
7 判断handler是否为空，如果没有设置handler(这个例子就没有设置handler)，handler就设置为 DefaultServeMux
8 调用handler的ServeHttp
9 在这个例子中，下面就进入到DefaultServerMux.ServeHttp
10 根据request选择handler，并且进入到这个handler的ServeHTTP mux.handler(r).ServeHTTP(w, r)
11 选择handler:
    A 判断是否有路由能满足这个request(循环遍历ServerMux的muxEntry)
    B 如果有路由满足，调用这个路由handler的ServeHttp
    C 如果没有路由满足，调用NotFoundHandler的ServeHttp
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;自定义server&#34;&gt;自定义server&lt;/h2&gt;

&lt;p&gt;要管理服务端的行为，可以创建一个自定义的Server：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;s := &amp;amp;http.Server{
    Addr:           &amp;quot;:8080&amp;quot;,
    Handler:        myHandler,
    ReadTimeout:    10 * time.Second,
    WriteTimeout:   10 * time.Second,
    MaxHeaderBytes: 1 &amp;lt;&amp;lt; 20,
}
log.Fatal(s.ListenAndServe())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也是上面的流程，就是新增了一个server结构体的，做对应的操作，来看一下server&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Server struct {
    Addr           string        // TCP address to listen on, &amp;quot;:http&amp;quot; if empty
    Handler        Handler       // handler to invoke, http.DefaultServeMux if nil
    ReadTimeout    time.Duration // maximum duration before timing out read of the request
    WriteTimeout   time.Duration // maximum duration before timing out write of the response
    MaxHeaderBytes int           // maximum size of request headers, DefaultMaxHeaderBytes if 0
    TLSConfig      *tls.Config   // optional TLS config, used by ListenAndServeTLS

    // TLSNextProto optionally specifies a function to take over
    // ownership of the provided TLS connection when an NPN
    // protocol upgrade has occurred.  The map key is the protocol
    // name negotiated. The Handler argument should be used to
    // handle HTTP requests and will initialize the Request&#39;s TLS
    // and RemoteAddr if not already set.  The connection is
    // automatically closed when the function returns.
    TLSNextProto map[string]func(*Server, *tls.Conn, Handler)

    // ConnState specifies an optional callback function that is
    // called when a client connection changes state. See the
    // ConnState type and associated constants for details.
    ConnState func(net.Conn, ConnState)

    // ErrorLog specifies an optional logger for errors accepting
    // connections and unexpected behavior from handlers.
    // If nil, logging goes to os.Stderr via the log package&#39;s
    // standard logger.
    ErrorLog *log.Logger
    // contains filtered or unexported fields
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;都是什么作用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Server struct {
    Addr           string        // 监听的TCP地址，如果为空字符串会使用&amp;quot;:http&amp;quot;
    Handler        Handler       // 调用的处理器，如为nil会调用http.DefaultServeMux
    ReadTimeout    time.Duration // 请求的读取操作在超时前的最大持续时间
    WriteTimeout   time.Duration // 回复的写入操作在超时前的最大持续时间
    MaxHeaderBytes int           // 请求的头域最大长度，如为0则用DefaultMaxHeaderBytes
    TLSConfig      *tls.Config   // 可选的TLS配置，用于ListenAndServeTLS方法
    // TLSNextProto（可选地）指定一个函数来在一个NPN型协议升级出现时接管TLS连接的所有权。
    // 映射的键为商谈的协议名；映射的值为函数，该函数的Handler参数应处理HTTP请求，
    // 并且初始化Handler.ServeHTTP的*Request参数的TLS和RemoteAddr字段（如果未设置）。
    // 连接在函数返回时会自动关闭。
    TLSNextProto map[string]func(*Server, *tls.Conn, Handler)
    // ConnState字段指定一个可选的回调函数，该函数会在一个与客户端的连接改变状态时被调用。
    // 参见ConnState类型和相关常数获取细节。
    ConnState func(net.Conn, ConnState)
    // ErrorLog指定一个可选的日志记录器，用于记录接收连接时的错误和处理器不正常的行为。
    // 如果本字段为nil，日志会通过log包的标准日志记录器写入os.Stderr。
    ErrorLog *log.Logger
    // 内含隐藏或非导出字段
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Server
func (s *Server) SetKeepAlivesEnabled(v bool)
func (srv *Server) Serve(l net.Listener) error
func (srv *Server) ListenAndServe() error
func (srv *Server) ListenAndServeTLS(certFile, keyFile string) error

func (*Server) SetKeepAlivesEnabled
func (s *Server) SetKeepAlivesEnabled(v bool)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SetKeepAlivesEnabled控制是否允许HTTP闲置连接重用（keep-alive）功能。默认该功能总是被启用的。只有资源非常紧张的环境或者服务端在关闭进程中时，才应该关闭该功能。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (*Server) Serve
func (srv *Server) Serve(l net.Listener) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Serve会接手监听器l收到的每一个连接，并为每一个连接创建一个新的服务go程。该go程会读取请求，然后调用srv.Handler回复请求。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (*Server) ListenAndServe
func (srv *Server) ListenAndServe() error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ListenAndServe监听srv.Addr指定的TCP地址，并且会调用Serve方法接收到的连接。如果srv.Addr为空字符串，会使用&amp;rdquo;:http&amp;rdquo;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (*Server) ListenAndServeTLS
func (srv *Server) ListenAndServeTLS(certFile, keyFile string) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ListenAndServeTLS监听srv.Addr确定的TCP地址，并且会调用Serve方法处理接收到的连接。必须提供证书文件和对应的私钥文件。如果证书是由权威机构签发的，certFile参数必须是顺序串联的服务端证书和CA证书。如果srv.Addr为空字符串，会使用&amp;rdquo;:https&amp;rdquo;。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>监控系列---- Zabbix基本使用</title>
          <link>https://kingjcy.github.io/post/monitor/metrics/zabbix/zabbix/</link>
          <pubDate>Sat, 04 Mar 2017 17:54:04 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/monitor/metrics/zabbix/zabbix/</guid>
          <description>&lt;p&gt;zabbix是目前各大互联网公司使用最广泛的开源监控之一,其历史最早可追溯到1998年,在业内拥有各种成熟的解决方案.&lt;/p&gt;

&lt;h1 id=&#34;网站可用性&#34;&gt;网站可用性&lt;/h1&gt;

&lt;p&gt;在软件系统的高可靠性（也称为可用性，英文描述为HA，High Available）里有个衡量其可靠性的标准——X个9，这个X是代表数字3~5。X个9表示在软件系统1年时间的使用过程中，系统可以正常使用时间与总时间（1年）之比，我们通过下面的计算来感受下X个9在不同级别的可靠性差异。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1个9：(1-90%)*365=36.5天，表示该软件系统在连续运行1年时间里最多可能的业务中断时间是36.5天
2个9：(1-99%)*365=3.65天 ， 表示该软件系统在连续运行1年时间里最多可能的业务中断时间是3.65天
3个9：(1-99.9%)*365*24=8.76小时，表示该软件系统在连续运行1年时间里最多可能的业务中断时间是8.76小时。
4个9：(1-99.99%)*365*24=0.876小时=52.6分钟，表示该软件系统在连续运行1年时间里最多可能的业务中断时间是52.6分钟。
5个9：(1-99.999%)*365*24*60=5.26分钟，表示该软件系统在连续运行1年时间里最多可能的业务中断时间是5.26分钟。
6个9：(1-99.9999%)*365*24*60*60=31秒， 示该软件系统在连续运行1年时间里最多可能的业务中断时间是31秒
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;目前能达到4个9就很好了。&lt;/p&gt;

&lt;h1 id=&#34;组件&#34;&gt;组件&lt;/h1&gt;

&lt;p&gt;zabbix属于CS架构,Server端基于C语言编写,相比其他语言具有一定的性能优势(在数据量不大的情况下!).Web管理端则使用了PHP. 而其client端有各种流行语言的库实现,方便使用其API&lt;/p&gt;

&lt;p&gt;在数据的存储方面,zabbix使用了关系性数据库,包括SQLite,MySQL,PostgreSQL,Oracle,DB2&lt;/p&gt;

&lt;h1 id=&#34;安装&#34;&gt;安装&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;yum安装&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;zabbix的安装比较繁琐,但也不算困难(主要是因为网上提供的资料足够多)&lt;/p&gt;

&lt;p&gt;我们需要一种关系型关系型数据库,目前提供的选择有MySQL,SQLite, PostgreSQL,Oracle,DB2&lt;/p&gt;

&lt;p&gt;接下来需要安装PHP的运行环境,Web服务器可是使用Apache或者Nginx都可以.&lt;/p&gt;

&lt;p&gt;最后一步是安装zabbix服务.&lt;/p&gt;

&lt;p&gt;完整的安装教程可以参考:&lt;a href=&#34;http://support.supermap.com.cn/DataWarehouse/WebDocHelp/icm/Appdix/Zabbix_server/Zabbix_Installation.htm&#34;&gt;zabbix安装指南&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;主要步骤&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;配置zabbix官方yum源，还有base和epel源&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;安装server&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yum install zabbix-server-mysql zabbix-get
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;初始化database&lt;/p&gt;

&lt;p&gt;导入zabbix-server-mysql包中的create.sql来初始化数据库&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rpm -ql zabbix-server-mysql
mysql -uroot -p -Dzabbix &amp;lt; create.sql
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就可以查看表了。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;配置服务端配置文件并启动&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;安装web&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yum install httpd php php-mysql php-mbstring php-gd php-bamath php-ladp php-xml
yum install zabbix-web-mysql zabbix-web
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;然后访问　　&lt;a href=&#34;http://zabbix-web-ip/zabbix/setup.php进行zabbix初始化&#34;&gt;http://zabbix-web-ip/zabbix/setup.php进行zabbix初始化&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;安装zabbix-agent&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yum install zabbix-agent zabbix-sender
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;配置客户端端配置文件并启动&lt;/p&gt;

&lt;p&gt;服务端快速安装脚本&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/bash
#clsn

#设置解析 注意：网络条件较好时，可以不用自建yum源
# echo &#39;10.0.0.1 mirrors.aliyuncs.com mirrors.aliyun.com repo.zabbix.com&#39; &amp;gt;&amp;gt; /etc/hosts

#安装zabbix源、aliyun YUM源
curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
rpm -ivh http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm

#安装zabbix
yum install -y zabbix-server-mysql zabbix-web-mysql

#安装启动 mariadb数据库
yum install -y  mariadb-server
systemctl start mariadb.service

#创建数据库
mysql -e &#39;create database zabbix character set utf8 collate utf8_bin;&#39;
mysql -e &#39;grant all privileges on zabbix.* to zabbix@localhost identified by &amp;quot;zabbix&amp;quot;;&#39;

#导入数据
zcat /usr/share/doc/zabbix-server-mysql-3.0.13/create.sql.gz|mysql -uzabbix -pzabbix zabbix

#配置zabbixserver连接mysql
sed -i.ori &#39;115a DBPassword=zabbix&#39; /etc/zabbix/zabbix_server.conf

#添加时区
sed -i.ori &#39;18a php_value date.timezone  Asia/Shanghai&#39; /etc/httpd/conf.d/zabbix.conf

#解决中文乱码
yum -y install wqy-microhei-fonts
\cp /usr/share/fonts/wqy-microhei/wqy-microhei.ttc /usr/share/fonts/dejavu/DejaVuSans.ttf

#启动服务
systemctl start zabbix-server
systemctl start httpd

#写入开机自启动
chmod +x /etc/rc.d/rc.local
cat &amp;gt;&amp;gt;/etc/rc.d/rc.local&amp;lt;&amp;lt;EOF
systemctl start mariadb.service
systemctl start httpd
systemctl start zabbix-server
EOF

#输出信息
echo &amp;quot;浏览器访问 http://`hostname -I|awk &#39;{print $1}&#39;`/zabbix&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;客户端快速部署脚本&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/bash
#clsn

#设置解析
echo &#39;10.0.0.1 mirrors.aliyuncs.com mirrors.aliyun.com repo.zabbix.com&#39; &amp;gt;&amp;gt; /etc/hosts

#安装zabbix源、aliyu nYUM源
curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
rpm -ivh http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm

#安装zabbix客户端
yum install zabbix-agent -y
sed -i.ori &#39;s#Server=127.0.0.1#Server=172.16.1.61#&#39; /etc/zabbix/zabbix_agentd.conf
systemctl start  zabbix-agent.service

#写入开机自启动
chmod +x /etc/rc.d/rc.local
cat &amp;gt;&amp;gt;/etc/rc.d/rc.local&amp;lt;&amp;lt;EOF
systemctl start  zabbix-agent.service
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;编译安装&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;系统环境&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    OS:         centos7.5
    software：  zabbix 4.0 LTS
    DBSever:    MariaDB-10.2.15
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一、需要先把数据库装上，这里用到的是mariadb 二进制包安装&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1、下载二进制包，
     官网的下载路径：
  wget http://mirrors.neusoft.edu.cn/mariadb//mariadb-10.2.15/bintar-linux-x86_64/mariadb-10.2.15-linux-x86_64.tar.gz

2、添加组和用户
  [root@node2 ~]# groupadd -r -g 306 mysql
  [root@node2 ~]# useradd -g mysql -u 306 -r mysql

3、解压mariadb二进制包到/usr/local下去
   [root@node2 ~]# tar xf mariadb-10.2.15-linux-x86_64.tar.gz -C /usr/local/

4、进入到/usr/local下面创建mysql的软连接
   [root@node2 ~]# cd /usr/local/
   [root@node2 /usr/local]# ln -s mariadb-10.2.15-linux-x86_64/ mysql

5、修改mysql的相对应的属主和属组权限
    [root@node2 /usr/local]# chown -R root.mysql mysql/

6、创建数据文件的存放路径，并修改所属组的权限为mysql
     [root@node2 ~]#   cd /app/
     [root@node2 /app]# mkdir mydata
     [root@node2 ]#  chown -R mysql.mysql  /app

7、初始化数据库，指定好数据文件的存放路径和用户
       [root@node2 ]# cd /usr/local/mysql/
       [root@node2 /usr/local/mysql/]# scripts/mysql_install_db --datadir=/app/mydata --user=mysql

8、拷贝mariadb的启动脚本到/etc/rc.d/init.d下命名为mysqld
       [root@node2 /usr/local/mysql/]# cp support-files/mysql.server /etc/rc.d/init.d/mysqld

9、把mysqld设置为开机启动
       [root@node2 /usr/local/mysql/]# chkconfig --add mysqld

10、创建mariadb的配置文件存放路径，并拷贝模版文件到这个目录下命名为my.cnf
      [root@node2 /usr/local/mysql/]# mkdir /etc/mysql
      [root@node2 /usr/local/mysql/]#cp support-files/my-large.cnf /etc/mysql/my.cnf

11、配置系统环境变量，重读配置文件让它生效
      [root@node2 /usr/local/mysql/]# vim /etc/profile.d/mysql.sh
      [root@node2 /usr/local/mysql/]#export PATH=/usr/local/mysql/bin:$PATH
      [root@node2 /usr/local/mysql/]# . /etc/profile.d/mysql.sh

12、修改mariadb的配置文件需要增加几条内容
      [root@node2 /usr/local/mysql/]# vim /etc/mysql/my.cnf
          lower_case_table_names = 1
          character-set-server = utf8
          datadir = /app/mydata
          innodb_file_per_table = on
          skip_name_resolve = o

13、启动数据库服务
      [root@node2 /usr/local/mysql/]#  service mysqld start

14、查看mariadb的服务端口是否正常监听
    [root@node2 /app]#ss -tnl
    State      Recv-Q Send-Q       Local Address:Port                      Peer Address:Port
    LISTEN     0      128                      *:52874                                *:*
    LISTEN     0      128                      *:11211                                *:*
    LISTEN     0      128                      *:111                                  *:*
    LISTEN     0      128                      *:22                                   *:*
    LISTEN     0      128              127.0.0.1:631                                  *:*
    LISTEN     0      100              127.0.0.1:25                                   *:*
    LISTEN     0      80                      :::3306                                :::*

15、数据库的安全初始操作，设置完之后就可以先创建zabbix相关的库和用户
    [root@node2 /app]#mysql_secure_installation
    [root@node2 /app]#mysql -uroot -p
16、创建zabbix库
    MariaDB [(none)]&amp;gt; create database zabbix character set utf8 collate utf8_bin;
17、给zabbix库授权并指定用户
    MariaDB [(none)]&amp;gt; grant all privileges on zabbix.* to zabbix@&#39;192.168.137.%&#39; identified by &#39;123456&#39;;

18、在另一台主机上测试用zabbix用是否能正常登陆数据库
    [root@node7 ~]#mysql -uzabbix -p123456 -h192.168.137.54
    Welcome to the MariaDB monitor.  Commands end with ; or \g.
    Your MariaDB connection id is 12
    Server version: 10.2.15-MariaDB-log MariaDB Server

    Copyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.

    Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement.

    MariaDB [(none)]&amp;gt; show databases;
    +--------------------+
    | Database           |
    +--------------------+
    | information_schema |
    | zabbix             |
    +--------------------+
    2 rows in set (0.00 sec)
    MariaDB [(none)]&amp;gt;
19、在zabbix server主机上导入zabbix自带的三个表，路径在/root/zabbix-4.0.1/database/mysql下后缀为.sql的三个文件
    [root@node6 ~/zabbix-4.0.1]#ls -l database/mysql/
    total 5816
    -rw-r--r-- 1 1001 1001 3795433 Oct 30 01:36 data.sql
    -rw-r--r-- 1 1001 1001 1978341 Oct 30 01:36 images.sql
    -rw-r--r-- 1 root root   15323 Nov 26 22:44 Makefile
    -rw-r--r-- 1 1001 1001     392 Oct 30 01:36 Makefile.am
    -rw-r--r-- 1 1001 1001   15711 Oct 30 01:36 Makefile.in
    -rw-r--r-- 1 1001 1001  140265 Oct 30 01:36 schema.sql

20、导入sql文件是有先后顺序的，先导schema.sql、images.sql、data.sql.
    [root@node6 ~/zabbix-4.0.1/database/mysql]#mysql -uzabbix -h192.168.137.54 -p123456 zabbix &amp;lt; schema.sql
    [root@node6 ~/zabbix-4.0.1/database/mysql]#mysql -uzabbix -h192.168.137.54 -p123456 zabbix &amp;lt; images.sql
    [root@node6 ~/zabbix-4.0.1/database/mysql]#mysql -uzabbix -h192.168.137.54 -p123456 zabbix &amp;lt; data.sql

21、进到数据库里面查看zabbix库是否导入成功
    [root@node6 ~/zabbix-4.0.1/database/mysql]#mysql -uzabbix -h192.168.137.54 -p123456
    MariaDB [(none)]&amp;gt; use zabbix
    MariaDB [zabbix]&amp;gt; show tables;
    +----------------------------+
    | Tables_in_zabbix           |
    +----------------------------+
    | acknowledges               |
    | actions                    |
    | alerts                     |
    | application_discovery      |
    | application_prototype      |
    | application_template       |
    | applications               |
    | auditlog                   |
    | auditlog_details           |
    | autoreg_host               |
    | conditions                 |
    | config                     |
    | corr_condition             |
    | corr_condition_group       |
    .......
    | users                      |
    | users_groups               |
    | usrgrp                     |
    | valuemaps                  |
    | widget                     |
    | widget_field               |
    +----------------------------+
    144 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;二、编译zabbix&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1、安装编译环境所需要的依赖包组
    [root@node6 ~]#yum install gcc  libxml2-devel libevent-devel net-snmp net-snmp-devel  curl  curl-devel php  php-bcmath  php-mbstring mariadb mariadb-devel –y

    还需要安装一些php的依赖包后续在网页端安装zabbix时需要用到所以先提前安装好
    [root@node6 ~]#yum install php-gettext php-session php-ctype php-xmlreader php-xmlwrer php-xml php-net-socket php-gd php-mysql -y

2、安装jdk环境，装的是jdk-8u191-linux-x64.rpm的包，要不后面编译时会报Java找不到。
    [root@node6 ~]#yum -y install jdk-8u191-linux-x64.rpm

3、创建zabbix用户
    [root@node6 ~]#useradd zabbix -s /sbin/nologin

4、下载zabbix的源码包
    [root@node6 ~]#wget http://192.168.137.53/yum/zabbix/zabbix-4.0.1.tar.gz

5、解压源码包，并进入到解压后的目录里去
    [root@node6 ~]#tar xf zabbix-4.0.1.tar.gz
    [root@node6 ~]#cd zabbix-4.0.1/
    [root@node6 ~/zabbix-4.0.1]#

6、开始编译安装zabbix
    [root@node6 ~/zabbix-4.0.1./configure  \
    --prefix=/usr/local/zabbix  \
    --enable-server  \
    --enable-agent  \
    --with-mysql   \
    --with-net-snmp  \
    --with-libcurl  \
    --with-libxml2  \
    --enable-java

7、执行make install
    [root@node6 ~/zabbix-4.0.1]#make -j 2 &amp;amp;&amp;amp; make install

8、拷贝启动脚本文件到/etc/init.d目录下
    [root@node6 ~/zabbix-4.0.1]#cp misc/init.d/fedora/core/* /etc/init.d/

9、拷贝过去的脚本需要修改下目录路径，server和agent都需要改
    [root@node6 ~/zabbix-4.0.1]#vim /etc/init.d/zabbix_server
        22         BASEDIR=/usr/local
    改成：
        22         BASEDIR=/usr/local/zabbix

    agent启动脚本修改也是一样
        [root@node6 ~/zabbix-4.0.1vim /etc/init.d/zabbix_agentd
        22         BASEDIR=/usr/local
    改成：
        22         BASEDIR=/usr/local/zabbix

10、创建zabbix的日志存放路径和修改/usr/local/zabbix的所属主为zabbix
    [root@node6 ~/zabbix-4.0.1]#mkdir /var/log/zabbix
    [root@node6 ~/zabbix-4.0.1]#chown -R zabbix.zabbix /var/log/zabbix
    [root@node6 ~/zabbix-4.0.1]#ll /var/log/zabbix/ -d
    drwxr-xr-x 2 zabbix zabbix 6 Nov 27 09:17 /var/log/zabbix/
    [root@node6 ~]#chown -R zabbix.zabbix /usr/local/zabbix/
    [root@node6 ~]#ll -d /usr/local/zabbix/
    drwxr-xr-x 7 zabbix zabbix 64 Nov 26 22:45 /usr/local/zabbix/

11、修改配置文件
    [root@node6 ~/zabbix-4.0.1]#vim /usr/local/zabbix/etc/zabbix_server.conf
    ListenPort=10051   启用监听端口，不过默认也是启用的。

    LogFile=/var/log/zabbix/zabbix_server.log    修改日志存放路径，默认是在/tmp下

    LogFileSize=5   开启日志滚动，单位为MB、达到指定值之后就生成新的日志文件。
    DebugLevel=4   日志级别等级，4为debug，利于排除错误，排错之后可以改成3级别的。
    PidFile=/usr/local/zabbix/zabbix_server.pid   zabbix pid文件路径默认为tmp下需要改成安装目录，并且安装目录的所属组要改成zabbix用户
    # SocketDir=/tmp
    User=zabbix                    启动的用户默认也是zabbix,如果要改成root的话 还需要修改一项
    # AllowRoot=0                  需要改成1才能使用root来启动，默认0的话是被禁止用root启动，不过最好别用root
    SocketDir=/usr/local/zabbix   socket 文件存放路径默认在/tmp下
    DBHost=192.168.137.54          数据库地址必须要填
    DBName=zabbix                  数据库名称
    DBUser=zabbix                  数据库连接用户
    DBPassword=123456              数据库连接密码，建议在生产中密码不要太简单了。
    DBPort=3306                    数据库端口，其实也不用开默认就是3306

12、启动zabbix、并查看端口是否正常监听
    [root@node6 ~/zabbix-4.0.1]#service zabbix_server start
    Reloading systemd:                                         [  OK  ]
    Starting zabbix_server (via systemctl):                    [  OK  ]
    [root@node6 ~/zabbix-4.0.1]#ss -tnl
    State       Recv-Q Send-Q          Local Address:Port                Peer Address:Port
    LISTEN      0      128                         *:10051                    *:*
    LISTEN      0      128                         *:111                      *:*
    LISTEN      0      128                         *:22                       *:*
    LISTEN      0      100                 127.0.0.1:25                       *:*

13、装前端展示端
    [root@node6 ~/zabbix-4.0.1]#yum -y install httpd

14、在httpd的默认工作目录下创建一个zabbix目录
    [root@node6 ~/zabbix-4.0.1]#mkdir /var/www/html/zabbix

15、从zabbix解压包里面把php的所有文件拷贝到/var/www/html/zabbix目录下
    [root@node6 ~/zabbix-4.0.1]#cp -a frontends/php/* /var/www/html/zabbix/

16、启动httpd、查看端口是否正常监听
    [root@node6 ~]#systemctl start httpd
    [root@node6 ~]#ss -tnl
    State       Recv-Q Send-Q          Local Address:Port                         Peer Address:Port
    LISTEN      0      128                         *:10051                                   *:*
    LISTEN      0      128                         *:111                                     *:*
    LISTEN      0      128                         *:22                                      *:*
    LISTEN      0      100                 127.0.0.1:25                                      *:*
    LISTEN      0      128                        :::111                                    :::*
    LISTEN      0      128                        :::80                                     :::*

17、通过网页来安装zabbix
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;zabbix使用&#34;&gt;zabbix使用&lt;/h1&gt;

&lt;p&gt;zabbix的使用基本上都是在界面完成操作的，比较简单，基本使用流程&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;添加需要监控的主机&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;为监控的主机添加监控项，也就是key，zabbix自身带有很多设定好的监控项，直接选择就好，比如cpu，内存，都是界面操作&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;监控项中可以直接输入参数，来获取指定的数据&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;监控项可以自定义key，主要设定key，和执行的脚本命令command，可见zabbix都是通过执行命令来获取监控数据的&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;zabbix有对应的告警机制，也就是触发器，设置触发器也就是表达式，达到阈值，就会产生事件，然后可以通过各种通信方式发送，都是支持界面操作。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;zabbix对比promethes&#34;&gt;zabbix对比promethes&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;zabbix采集数据只能通过脚本命令，比较局限，基本都是物理机上的一些命令，所以zabbix比较适合物理机的监控，prometheus不但能够监控物理机，更适合云环境（频繁变动），比如k8s，&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;数据存储在mysql等关系型数据库中，存储有限，而且很难扩展监控维度，prometheus则是一个时序数据库，还可以远程存储，更适合&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;zabbix监控界面不够实时，相比于grafana也是一点都不美观，而且定制化特别难，而grafana则是得到公认的可编辑可扩展美观软件。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;zabbix集群规模有限，上线为10000个节点，但是promtheus监控节点可以有更大的规模，速度也快。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;zabbix已经发展比较成熟，确实在管理界面上比较完善。但是prometheus比较灵活。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;zabbix的报文协议&#34;&gt;zabbix的报文协议&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;cmppingloss[&lt;target&gt;,&lt;packets&gt;,&lt;interval&gt;,&lt;size&gt;,&lt;timeout&gt;] 目标服务器，包数量，包发送间隔，包大小，超时&lt;/li&gt;
&lt;li&gt;value是string，一般是出错信息&lt;/li&gt;
&lt;li&gt;redis.cpunu.discovery这个是一个做发现的配置，最后生成了如下的配置可以舍去  ￼&lt;/li&gt;
&lt;li&gt;state表示在key不支持，或者是监控数据的过程中出错时候会出来&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;zabbix配置文件&#34;&gt;zabbix配置文件&lt;/h1&gt;

&lt;p&gt;zabbix的配置文件一般有三种：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zabbixserver的配置文件zabbix_server.conf

zabbixproxy的配置文件zabbix_proxy.conf

zabbix_agentd的配置文件zabbix_agentd.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.zabbixserver的配置文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;NodeID=0 #分布式节点id号，0代表是独立服务器，默认是被注释掉的，不强制配置
ListenPort=10051 #zabbix server的端口，默认是10051，可以自行修改，
范围是1024-32767 ，一般默认即可
SourceIP=  #连接的源ip地址，默认为空，默认即可
LogFile=/tmp/zabbix_server.log #日志文件的存放位置
LogFileSize=1 #日志文件的大小，单位为MB，当设置为0时，表示不仅行日志轮询，
默认设置为1，默认即可
DebugLevel=3 #指定调试级别，默认即可
PidFile=/tmp/zabbix_server.pid #pid文件的存放位置
DBHost=localhost #数据库主机名，当设置为localhost时，连接mysql通过sock
DBName=zabbix #指定存放zabbix数据数据库的名字
DBUser=zabbix #指定连接数据库的用户名
DBPassword=123456 #用户连接数据库需要的密码
DBSocket=/var/lib/mysql/mysql.sock #前文主机设置为localhost，用户
连接数据库所用的sock位置，
DBPort=3306 #数据库的端口号，当用sock连接时，无关紧要，当通过网络连接时需设置
StartPollers=5 #默认即可
StartIPMIPollers=0 #使用IPMI协议时，用到的参数
StartTrappers=5 #打开的进程数，
StartPingers=1 同上
StartDiscoverers=1
StartHTTPPollers=1
JavaGateway=127.0.0.1 #JavaGateway的ip地址或主机名
JavaGatewayPort=10052 #JavaGateway的端口号
StartJavaPollers=5 #开启连接javagatey的进程数
SNMPTrapperFile=/tmp/zabbix_traps.tmp
StartSNMPTrapper=0 #如果设置为1，snmp trapper进程就会开启
ListenIP=0.0.0.0 #监听来自trapper的ip地址
ListenIP=127.0.0.1
HousekeepingFrequency=1 #zabbix执行Housekeeping的频率，单位为hours
MaxHousekeeperDelete=500 #每次最多删除历史数据的行
SenderFrequency=30 #zabbix试图发送未发送的警报的时间，单位为秒
CacheSize=8M #缓存的大小
CacheUpdateFrequency=60#执行更新缓存配置的时间，单位为秒数
StartDBSyncers=4
HistoryCacheSize=8M
TrendCacheSize=4M
HistoryTextCacheSize=16M
NodeNoEvents=0
NodeNoHistory=0
Timeout=3
TrapperTimeout=300
UnreachablePeriod=45
UnavailableDelay=60
UnreachableDelay=15
AlertScriptsPath=/usr/local/zabbix/shell #脚本的存放路径
FpingLocation=/usr/local/sbin/fping #fping指令的绝对路径
SSHKeyLocation=
LogSlowQueries=0
TmpDir=/tmp
Include=/usr/local/etc/zabbix_server.general.conf
Include=/usr/local/etc/zabbix_server.conf.d/ #子配置文件路径
StartProxyPollers=1 #在zabbix proxy被动模式下用此参数
ProxyConfigFrequency=3600#同上
ProxyDataFrequency=1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实际使用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ListenPort=10051 #监听端口



LogFile=/opt/zabbix/logs/zabbix_server.log

LogFileSize=1024

DebugLevel=3

PidFile=/var/run/zabbix/zabbix_server.pid

#mysql 数据库配置
DBHost=10.243.51.107
DBName=zabbix
DBUser=zabbix
DBPassword=zabbix@suning
DBPort=3306


StartPollers=500

StartIPMIPollers=1

StartPollersUnreachable=100

StartTrappers=100

StartPingers=50

StartDiscoverers=10

StartHTTPPollers=10

StartTimers=10










SNMPTrapperFile=/opt/zabbix/zabbix_traps.tmp

StartSNMPTrapper=1

# 监听地址
ListenIP=0.0.0.0

CacheSize=8G

CacheUpdateFrequency=3600

StartDBSyncers=50

HistoryCacheSize=2G

TrendCacheSize=2G


ValueCacheSize=10G


Timeout=25
TrapperTimeout=120
UnreachablePeriod=300
UnavailableDelay=60
UnreachableDelay=60
AlertScriptsPath=/opt/zabbix/alertscripts
ExternalScripts=/opt/zabbix/externalscripts
FpingLocation=/usr/sbin/fping


LogSlowQueries=10

StartProxyPollers=100
ProxyConfigFrequency=3600
ProxyDataFrequency=30
AllowRoot=1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.zabbixagentd的配置文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PidFile=/tmp/zabbix_agentd.pid #pid文件的存放位置
LogFile=/tmp/zabbix_agentd.log #日志文件的位置
LogFileSize=1 #当日志文件达到多大时进行轮询操作
DebugLevel=3 #日志信息级别
SourceIP= #连接的源ip地址，默认为空，即可
EnableRemoteCommands=0 #是否允许zabbix server端的远程指令，
0表示不允许，
1表示允许
LogRemoteCommands=0 #是否开启日志记录shell命令作为警告 0表示不允许，1表示允许
Server=127.0.0.1 #zabbix server的ip地址或主机名，可同时列出多个，需要用逗号隔开
ListenPort=10050 #zabbix agent监听的端口
ListenIP=0.0.0.0 #zabbix agent监听的ip地址
StartAgents=3 #zabbix agent开启进程数
ServerActive=127.0.0.1 #开启主动检查
Hostname=Zabbix server#在zabbix server前端配置时指定的主机名要相同，最重要的配置
RefreshActiveChecks=120 #主动检查刷新的时间，单位为秒数
BufferSend=5 #数据缓冲的时间
BufferSize=100 #zabbix agent数据缓冲区的大小，当达到该值便会发送所有的数据到zabbix server
MaxLinesPerSecond=100 #zabbix agent发送给zabbix server最大的数据行
AllowRoot=0 #是否允许zabbix agent 以root用户运行
Timeout=3 #设定处理超时的时间
Include=/usr/local/etc/zabbix_agentd.userparams.conf
Include=/usr/local/etc/zabbix_agentd.conf.d/ #包含子配置文件的路径
UnsafeUserParameters=0 #是否允许所有字符参数的传递
UserParameter= #指定用户自定义参数
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实际使用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PidFile=/var/run/zabbix/zabbix_agentd.pid

LogFile=/var/log/zabbix/zabbix_agentd.log

LogFileSize=0
Server=10.243.51.50

# 推送指标连接的服务器，格式如下addr:port
ServerActive=10.243.51.48

Hostname=10.243.51.50

HostMetadataItem=system.uname
Timeout=15

AllowRoot=1

Include=/etc/zabbix/zabbix_agentd.d/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.zabbixproxy的配置文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Server=192.168.70.133 #指定zabbix server的ip地址或主机名
Hostname=zabbix-proxy-1.35 #定义监控代理的主机名，需和zabbix server前端配置时指定的节点名相同
LogFile=/tmp/zabbix_proxy.log #指定日志文件的位置
PidFile=/tmp/zabbix_proxy.pid #pid文件的位置
DBName=zabbix_proxy #数据库名
DBUser=zabbix #连接数据库的用户
DBPassword=123456#连接数据库用户的密码
ConfigFrequency=60 #zabbix proxy从zabbix server取得配置数据的频率
DataSenderFrequency=60 #zabbix proxy发送监控到的数据给zabbix server的频率
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实际使用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#连接server的地址
Server=10.243.51.48

ServerPort=10052

Hostname=10.243.51.48

#启动监听的地址和端口
ListenPort=10051
ListenIP=0.0.0.0

LogFile=/opt/zabbix/logs/zabbix_proxy.log

LogFileSize=1024

DebugLevel=3

PidFile=/var/run/zabbix/zabbix_proxy.pid

#自带数据库
DBHost=localhost
DBName=zabbix_proxy
DBUser=zabbix
DBPassword=zabbix@suning
DBSocket=/opt/mysql/run/mysqld.sock
DBPort=3306



ProxyOfflineBuffer=1


ConfigFrequency=3600

DataSenderFrequency=20


StartPollers=300

StartIPMIPollers=10

StartPollersUnreachable=100

StartTrappers=100

StartPingers=20

StartDiscoverers=50

StartHTTPPollers=100




StartVMwareCollectors=10

VMwareFrequency=60

VMwareCacheSize=256M

CacheSize=8G

StartDBSyncers=10

HistoryCacheSize=2G

HistoryTextCacheSize=2G

Timeout=30

TrapperTimeout=300

UnreachablePeriod=300

UnavailableDelay=60

UnreachableDelay=15

ExternalScripts=/opt/zabbix/externalscripts

FpingLocation=/usr/sbin/fping

LogSlowQueries=0


AllowRoot=1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;官网配置文件：&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.zabbix.com/documentation/2.2/manual/appendix/config/zabbix_proxy&#34;&gt;https://www.zabbix.com/documentation/2.2/manual/appendix/config/zabbix_proxy&lt;/a&gt;
&lt;a href=&#34;https://www.zabbix.com/documentation/2.2/manual/appendix/config/zabbix_server&#34;&gt;https://www.zabbix.com/documentation/2.2/manual/appendix/config/zabbix_server&lt;/a&gt;
&lt;a href=&#34;https://www.zabbix.com/documentation/2.2/manual/appendix/config/zabbix_agentd&#34;&gt;https://www.zabbix.com/documentation/2.2/manual/appendix/config/zabbix_agentd&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Golang使用系列---- Strings</title>
          <link>https://kingjcy.github.io/post/golang/go-strings/</link>
          <pubDate>Wed, 12 Oct 2016 19:37:30 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/golang/go-strings/</guid>
          <description>&lt;p&gt;平时在开发过程中， 和字符串打交道还是比较多的，比如分割， 去除， 替换等等常用的方法， 这些都是由strings包来提供的。&lt;/p&gt;

&lt;h1 id=&#34;基本应用&#34;&gt;基本应用&lt;/h1&gt;

&lt;h2 id=&#34;字符串比较&#34;&gt;字符串比较&lt;/h2&gt;

&lt;p&gt;Compare 函数，用于比较两个字符串的大小，如果两个字符串相等，返回为 0。如果 a 小于 b ，返回 -1 ，反之返回 1 。不推荐使用这个函数，直接使用 == != &amp;gt; &amp;lt; &amp;gt;= &amp;lt;= 等一系列运算符更加直观。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Compare(a, b string) int
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;EqualFold 函数，计算 s 与 t 忽略字母大小写后是否相等。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func EqualFold(s, t string) bool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a := &amp;quot;gopher&amp;quot;
b := &amp;quot;hello world&amp;quot;
fmt.Println(strings.Compare(a, b))
fmt.Println(strings.Compare(a, a))
fmt.Println(strings.Compare(b, a))

fmt.Println(strings.EqualFold(&amp;quot;GO&amp;quot;, &amp;quot;go&amp;quot;))
fmt.Println(strings.EqualFold(&amp;quot;壹&amp;quot;, &amp;quot;一&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-1
0
1
true
false
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;是否存在某个字符或子串&#34;&gt;是否存在某个字符或子串&lt;/h2&gt;

&lt;p&gt;有三个函数做这件事：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 子串 substr 在 s 中，返回 true
func Contains(s, substr string) bool
// chars 中任何一个 Unicode 代码点在 s 中，返回 true
func ContainsAny(s, chars string) bool
// Unicode 代码点 r 在 s 中，返回 true
func ContainsRune(s string, r rune) bool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里对 ContainsAny 函数进行一下说明，看如下例子：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Println(strings.ContainsAny(&amp;quot;team&amp;quot;, &amp;quot;i&amp;quot;))
fmt.Println(strings.ContainsAny(&amp;quot;failure&amp;quot;, &amp;quot;u &amp;amp; i&amp;quot;))
fmt.Println(strings.ContainsAny(&amp;quot;in failure&amp;quot;, &amp;quot;s g&amp;quot;))
fmt.Println(strings.ContainsAny(&amp;quot;foo&amp;quot;, &amp;quot;&amp;quot;))
fmt.Println(strings.ContainsAny(&amp;quot;&amp;quot;, &amp;quot;&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;false
true
true
false
false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是说，第二个参数 chars 中任意一个字符（Unicode Code Point）如果在第一个参数 s 中存在，则返回 true。&lt;/p&gt;

&lt;p&gt;查看这三个函数的源码，发现它们只是调用了相应的 Index 函数（子串出现的位置），然后和 0 作比较返回 true 或 fale。如，Contains：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Contains(s, substr string) bool {
  return Index(s, substr) &amp;gt;= 0
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;index则使用了我们常用的字符串匹配算法的rk算法。&lt;/p&gt;

&lt;h2 id=&#34;子串出现次数-字符串匹配&#34;&gt;子串出现次数 ( 字符串匹配 )&lt;/h2&gt;

&lt;p&gt;在数据结构与算法中，可能会讲解以下字符串匹配算法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;朴素匹配算法
KMP 算法
Rabin-Karp 算法
Boyer-Moore 算法
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还有其他的算法，这里不一一列举，感兴趣的可以网上搜一下。&lt;/p&gt;

&lt;p&gt;在 Go 中，查找子串出现次数即字符串模式匹配，根据长度，分别实现的是BF和 Rabin-Karp 算法。Count 函数的签名如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Count(s, sep string) int
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 Count 的实现中，处理了几种特殊情况，属于字符匹配预处理的一部分。这里要特别说明一下的是当 sep 为空时，Count 的返回值是：utf8.RuneCountInString(s) + 1&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Println(strings.Count(&amp;quot;cheese&amp;quot;, &amp;quot;e&amp;quot;))
fmt.Println(len(&amp;quot;谷歌中国&amp;quot;))
fmt.Println(strings.Count(&amp;quot;谷歌中国&amp;quot;, &amp;quot;&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;3
12
5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;关于 Rabin-Karp 算法的实现，有兴趣的可以看看 Count 的源码。&lt;/p&gt;

&lt;p&gt;另外，Count 是计算子串在字符串中出现的无重叠的次数，比如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Println(strings.Count(&amp;quot;fivevev&amp;quot;, &amp;quot;vev&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;字符串分割为-string&#34;&gt;字符串分割为[]string&lt;/h2&gt;

&lt;p&gt;这个需求很常见，倒不一定是为了得到[]string。&lt;/p&gt;

&lt;p&gt;该包提供了六个三组分割函数：Fields和FieldsFunc、Split和SplitAfter、SplitN和SplitAfterN。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Fields和FieldsFunc&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;func Fields(s string) []string
func FieldsFunc(s string, f func(rune) bool) []string
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Fields 用一个或多个连续的空格分隔字符串 s，返回子字符串的数组（slice）。如果字符串 s 只包含空格，则返回空列表 ([]string 的长度为 0）。其中，空格的定义是 unicode.IsSpace，之前已经介绍过。&lt;/p&gt;

&lt;p&gt;常见间隔符包括：&amp;rsquo;\t&amp;rsquo;, &amp;lsquo;\n&amp;rsquo;, &amp;lsquo;\v&amp;rsquo;, &amp;lsquo;\f&amp;rsquo;, &amp;lsquo;\r&amp;rsquo;, &amp;lsquo; &amp;lsquo;, U+0085 (NEL), U+00A0 (NBSP)&lt;/p&gt;

&lt;p&gt;由于是用空格分隔，因此结果中不会含有空格或空子字符串，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Printf(&amp;quot;Fields are: %q&amp;quot;, strings.Fields(&amp;quot;  foo bar  baz   &amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Fields are: [&amp;quot;foo&amp;quot; &amp;quot;bar&amp;quot; &amp;quot;baz&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;FieldsFunc通过实现一个回调函数来指定分隔字符串 s 的字符。比如上面的例子，我们通过 FieldsFunc 来实现：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Println(strings.FieldsFunc(&amp;quot;  foo bar  baz   &amp;quot;, unicode.IsSpace))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实际上，Fields 函数就是调用 FieldsFunc 实现的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Fields(s string) []string {
  return FieldsFunc(s, unicode.IsSpace)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Split和SplitAfter、SplitN和SplitAfterN&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;之所以将这四个函数放在一起讲，是因为它们都是通过一个同一个内部函数来实现的。它们的函数签名及其实现：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Split(s, sep string) []string { return genSplit(s, sep, 0, -1) }
func SplitAfter(s, sep string) []string { return genSplit(s, sep, len(sep), -1) }
func SplitN(s, sep string, n int) []string { return genSplit(s, sep, 0, n) }
func SplitAfterN(s, sep string, n int) []string { return genSplit(s, sep, len(sep), n) }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;它们都调用了 genSplit 函数。&lt;/p&gt;

&lt;p&gt;这四个函数都是通过 sep 进行分割，返回[]string。如果 sep 为空，相当于分成一个个的 UTF-8 字符，如 Split(&amp;ldquo;abc&amp;rdquo;,&amp;ldquo;&amp;rdquo;)，得到的是[a b c]。&lt;/p&gt;

&lt;p&gt;Split(s, sep) 和 SplitN(s, sep, -1) 等价；SplitAfter(s, sep) 和 SplitAfterN(s, sep, -1) 等价。&lt;/p&gt;

&lt;p&gt;那么，Split 和 SplitAfter 有啥区别呢？通过这两句代码的结果就知道它们的区别了：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Printf(&amp;quot;%q\n&amp;quot;, strings.Split(&amp;quot;foo,bar,baz&amp;quot;, &amp;quot;,&amp;quot;))
fmt.Printf(&amp;quot;%q\n&amp;quot;, strings.SplitAfter(&amp;quot;foo,bar,baz&amp;quot;, &amp;quot;,&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[&amp;quot;foo&amp;quot; &amp;quot;bar&amp;quot; &amp;quot;baz&amp;quot;]
[&amp;quot;foo,&amp;quot; &amp;quot;bar,&amp;quot; &amp;quot;baz&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是说，Split 会将 s 中的 sep 去掉，而 SplitAfter 会保留 sep。&lt;/p&gt;

&lt;p&gt;带 N 的方法可以通过最后一个参数 n 控制返回的结果中的 slice 中的元素个数，当 n &amp;lt; 0 时，返回所有的子字符串；当 n == 0 时，返回的结果是 nil；当 n &amp;gt; 0 时，表示返回的 slice 中最多只有 n 个元素，其中，最后一个元素不会分割，比如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Printf(&amp;quot;%q\n&amp;quot;, strings.SplitN(&amp;quot;foo,bar,baz&amp;quot;, &amp;quot;,&amp;quot;, 2))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[&amp;quot;foo&amp;quot; &amp;quot;bar,baz&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外看一下官方文档提供的例子，注意一下输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Printf(&amp;quot;%q\n&amp;quot;, strings.Split(&amp;quot;a,b,c&amp;quot;, &amp;quot;,&amp;quot;))
fmt.Printf(&amp;quot;%q\n&amp;quot;, strings.Split(&amp;quot;a man a plan a canal panama&amp;quot;, &amp;quot;a &amp;quot;))
fmt.Printf(&amp;quot;%q\n&amp;quot;, strings.Split(&amp;quot; xyz &amp;quot;, &amp;quot;&amp;quot;))
fmt.Printf(&amp;quot;%q\n&amp;quot;, strings.Split(&amp;quot;&amp;quot;, &amp;quot;Bernardo O&#39;Higgins&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[&amp;quot;a&amp;quot; &amp;quot;b&amp;quot; &amp;quot;c&amp;quot;]
[&amp;quot;&amp;quot; &amp;quot;man &amp;quot; &amp;quot;plan &amp;quot; &amp;quot;canal panama&amp;quot;]
[&amp;quot; &amp;quot; &amp;quot;x&amp;quot; &amp;quot;y&amp;quot; &amp;quot;z&amp;quot; &amp;quot; &amp;quot;]
[&amp;quot;&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;字符串是否有某个前缀或后缀&#34;&gt;字符串是否有某个前缀或后缀&lt;/h2&gt;

&lt;p&gt;这两个函数比较简单，源码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// s 中是否以 prefix 开始
func HasPrefix(s, prefix string) bool {
  return len(s) &amp;gt;= len(prefix) &amp;amp;&amp;amp; s[0:len(prefix)] == prefix
}
// s 中是否以 suffix 结尾
func HasSuffix(s, suffix string) bool {
  return len(s) &amp;gt;= len(suffix) &amp;amp;&amp;amp; s[len(s)-len(suffix):] == suffix
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果 prefix 或 suffix 为 &amp;ldquo;&amp;rdquo; , 返回值总是 true。&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Println(strings.HasPrefix(&amp;quot;Gopher&amp;quot;, &amp;quot;Go&amp;quot;))
fmt.Println(strings.HasPrefix(&amp;quot;Gopher&amp;quot;, &amp;quot;C&amp;quot;))
fmt.Println(strings.HasPrefix(&amp;quot;Gopher&amp;quot;, &amp;quot;&amp;quot;))
fmt.Println(strings.HasSuffix(&amp;quot;Amigo&amp;quot;, &amp;quot;go&amp;quot;))
fmt.Println(strings.HasSuffix(&amp;quot;Amigo&amp;quot;, &amp;quot;Ami&amp;quot;))
fmt.Println(strings.HasSuffix(&amp;quot;Amigo&amp;quot;, &amp;quot;&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;true
false
true
true
false
true
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;字符或子串在字符串中出现的位置&#34;&gt;字符或子串在字符串中出现的位置&lt;/h2&gt;

&lt;p&gt;有一序列函数与该功能有关：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 在 s 中查找 sep 的第一次出现，返回第一次出现的索引
func Index(s, sep string) int
// 在 s 中查找字节 c 的第一次出现，返回第一次出现的索引
func IndexByte(s string, c byte) int
// chars 中任何一个 Unicode 代码点在 s 中首次出现的位置
func IndexAny(s, chars string) int
// 查找字符 c 在 s 中第一次出现的位置，其中 c 满足 f(c) 返回 true
func IndexFunc(s string, f func(rune) bool) int
// Unicode 代码点 r 在 s 中第一次出现的位置
func IndexRune(s string, r rune) int

// 有三个对应的查找最后一次出现的位置
func LastIndex(s, sep string) int
func LastIndexByte(s string, c byte) int
func LastIndexAny(s, chars string) int
func LastIndexFunc(s string, f func(rune) bool) int
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这一序列函数，只举 IndexFunc 的例子：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;han := func(c rune) bool {
    return unicode.Is(unicode.Han, c) // 汉字
}
fmt.Println(strings.IndexFunc(&amp;quot;Hello, world&amp;quot;, han))
fmt.Println(strings.IndexFunc(&amp;quot;Hello, 世界&amp;quot;, han))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-1
7
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;字符串-join-操作&#34;&gt;字符串 JOIN 操作&lt;/h2&gt;

&lt;p&gt;将字符串数组（或 slice）连接起来可以通过 Join 实现，函数签名如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Join(a []string, sep string) string
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;假如没有这个库函数，我们自己实现一个，我们会这么实现：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Join(str []string, sep string) string {
  // 特殊情况应该做处理
  if len(str) == 0 {
      return &amp;quot;&amp;quot;
  }
  if len(str) == 1 {
      return str[0]
  }
  buffer := bytes.NewBufferString(str[0])
  for _, s := range str[1:] {
      buffer.WriteString(sep)
      buffer.WriteString(s)
  }
  return buffer.String()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里，我们使用了 bytes 包的 Buffer 类型，避免大量的字符串连接操作（因为 Go 中字符串是不可变的）。我们再看一下标准库的实现：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Join(a []string, sep string) string {
  if len(a) == 0 {
      return &amp;quot;&amp;quot;
  }
  if len(a) == 1 {
      return a[0]
  }
  n := len(sep) * (len(a) - 1)
  for i := 0; i &amp;lt; len(a); i++ {
      n += len(a[i])
  }

  b := make([]byte, n)
  bp := copy(b, a[0])
  for _, s := range a[1:] {
      bp += copy(b[bp:], sep)
      bp += copy(b[bp:], s)
  }
  return string(b)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;标准库的实现没有用 bytes 包，当然也不会简单的通过 + 号连接字符串。Go 中是不允许循环依赖的，标准库中很多时候会出现代码拷贝，而不是引入某个包。这里 Join 的实现方式挺好，我个人观点认为，不直接使用 bytes 包，也是不想依赖 bytes 包（其实 bytes 中的实现也是 copy 方式）。&lt;/p&gt;

&lt;p&gt;简单使用示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Println(Join([]string{&amp;quot;name=xxx&amp;quot;, &amp;quot;age=xx&amp;quot;}, &amp;quot;&amp;amp;&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;name=xxx&amp;amp;age=xx
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;字符串重复几次&#34;&gt;字符串重复几次&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;func Repeat(s string, count int) string
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将 s 重复 count 次，如果 count 为负数或返回值长度 len(s)*count 超出 string 上限会导致 panic，这个函数使用很简单：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Println(&amp;quot;ba&amp;quot; + strings.Repeat(&amp;quot;na&amp;quot;, 2))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;banana
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;字符替换&#34;&gt;字符替换&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;map&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;func Map(mapping func(rune) rune, s string) string
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Map 函数，将 s 的每一个字符按照 mapping 的规则做映射替换，如果 mapping 返回值 &amp;lt;0 ，则舍弃该字符。该方法只能对每一个字符做处理，但处理方式很灵活，可以方便的过滤，筛选汉字等。&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mapping := func(r rune) rune {
    switch {
    case r &amp;gt;= &#39;A&#39; &amp;amp;&amp;amp; r &amp;lt;= &#39;Z&#39;: // 大写字母转小写
        return r + 32
    case r &amp;gt;= &#39;a&#39; &amp;amp;&amp;amp; r &amp;lt;= &#39;z&#39;: // 小写字母不处理
        return r
    case unicode.Is(unicode.Han, r): // 汉字换行
        return &#39;\n&#39;
    }
    return -1 // 过滤所有非字母、汉字的字符
}
fmt.Println(strings.Map(mapping, &amp;quot;Hello你#￥%……\n（&#39;World\n,好Hello^(&amp;amp;(*界gopher...&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hello
world
hello
gopher
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;replace&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;进行字符串替换时，考虑到性能问题，能不用正则尽量别用，应该用这里的函数。&lt;/p&gt;

&lt;p&gt;字符串替换的函数签名如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 用 new 替换 s 中的 old，一共替换 n 个。
// 如果 n &amp;lt; 0，则不限制替换次数，即全部替换
func Replace(s, old, new string, n int) string
// 该函数内部直接调用了函数 Replace(s, old, new , -1)
func ReplaceAll(s, old, new string) string
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Println(strings.Replace(&amp;quot;oink oink oink&amp;quot;, &amp;quot;k&amp;quot;, &amp;quot;ky&amp;quot;, 2))
fmt.Println(strings.Replace(&amp;quot;oink oink oink&amp;quot;, &amp;quot;oink&amp;quot;, &amp;quot;moo&amp;quot;, -1))
fmt.Println(strings.ReplaceAll(&amp;quot;oink oink oink&amp;quot;, &amp;quot;oink&amp;quot;, &amp;quot;moo&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;oinky oinky oink
moo moo moo
moo moo moo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果我们希望一次替换多个，比如我们希望替换 This is &lt;b&gt;HTML&lt;/b&gt; 中的 &amp;lt; 和 &amp;gt; 为 &amp;lt; 和 &amp;gt;，可以调用上面的函数两次。但标准库提供了另外的方法进行这种替换。&lt;/p&gt;

&lt;h2 id=&#34;大小写转换&#34;&gt;大小写转换&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;func ToLower(s string) string
func ToLowerSpecial(c unicode.SpecialCase, s string) string
func ToUpper(s string) string
func ToUpperSpecial(c unicode.SpecialCase, s string) string
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;大小写转换包含了 4 个相关函数，ToLower,ToUpper 用于大小写转换。ToLowerSpecial,ToUpperSpecial 可以转换特殊字符的大小写。 举个例子：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Println(strings.ToLower(&amp;quot;HELLO WORLD&amp;quot;))
fmt.Println(strings.ToLower(&amp;quot;Ā Á Ǎ À&amp;quot;))
fmt.Println(strings.ToLowerSpecial(unicode.TurkishCase, &amp;quot;壹&amp;quot;))
fmt.Println(strings.ToLowerSpecial(unicode.TurkishCase, &amp;quot;HELLO WORLD&amp;quot;))
fmt.Println(strings.ToLower(&amp;quot;Önnek İş&amp;quot;))
fmt.Println(strings.ToLowerSpecial(unicode.TurkishCase, &amp;quot;Önnek İş&amp;quot;))

fmt.Println(strings.ToUpper(&amp;quot;hello world&amp;quot;))
fmt.Println(strings.ToUpper(&amp;quot;ā á ǎ à&amp;quot;))
fmt.Println(strings.ToUpperSpecial(unicode.TurkishCase, &amp;quot;一&amp;quot;))
fmt.Println(strings.ToUpperSpecial(unicode.TurkishCase, &amp;quot;hello world&amp;quot;))
fmt.Println(strings.ToUpper(&amp;quot;örnek iş&amp;quot;))
fmt.Println(strings.ToUpperSpecial(unicode.TurkishCase, &amp;quot;örnek iş&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hello world
ā á ǎ à
壹
hello world
önnek iş
önnek iş
HELLO WORLD
Ā Á Ǎ À       // 汉字拼音有效
一           //  汉字无效
HELLO WORLD
ÖRNEK IŞ
ÖRNEK İŞ    // 有细微差别
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;标题处理&#34;&gt;标题处理&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;func Title(s string) string
func ToTitle(s string) string
func ToTitleSpecial(c unicode.SpecialCase, s string) string
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;标题处理包含 3 个相关函数，其中 Title 会将 s 每个单词的首字母大写，不处理该单词的后续字符。ToTitle 将 s 的每个字母大写。ToTitleSpecial 将 s 的每个字母大写，并且会将一些特殊字母转换为其对应的特殊大写字母。&lt;/p&gt;

&lt;p&gt;举个例子：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Println(strings.Title(&amp;quot;hElLo wOrLd&amp;quot;))
fmt.Println(strings.ToTitle(&amp;quot;hElLo wOrLd&amp;quot;))
fmt.Println(strings.ToTitleSpecial(unicode.TurkishCase, &amp;quot;hElLo wOrLd&amp;quot;))
fmt.Println(strings.Title(&amp;quot;āáǎà ōóǒò êēéěè&amp;quot;))
fmt.Println(strings.ToTitle(&amp;quot;āáǎà ōóǒò êēéěè&amp;quot;))
fmt.Println(strings.ToTitleSpecial(unicode.TurkishCase, &amp;quot;āáǎà ōóǒò êēéěè&amp;quot;))
fmt.Println(strings.Title(&amp;quot;dünyanın ilk borsa yapısı Aizonai kabul edilir&amp;quot;))
fmt.Println(strings.ToTitle(&amp;quot;dünyanın ilk borsa yapısı Aizonai kabul edilir&amp;quot;))
fmt.Println(strings.ToTitleSpecial(unicode.TurkishCase, &amp;quot;dünyanın ilk borsa yapısı Aizonai kabul edilir&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;HElLo WOrLd
HELLO WORLD
HELLO WORLD
Āáǎà Ōóǒò Êēéěè
ĀÁǍÀ ŌÓǑÒ ÊĒÉĚÈ
ĀÁǍÀ ŌÓǑÒ ÊĒÉĚÈ
Dünyanın Ilk Borsa Yapısı Aizonai Kabul Edilir
DÜNYANIN ILK BORSA YAPISI AIZONAI KABUL EDILIR
DÜNYANIN İLK BORSA YAPISI AİZONAİ KABUL EDİLİR
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;修剪&#34;&gt;修剪&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;// 将 s 左侧和右侧中匹配 cutset 中的任一字符的字符去掉
func Trim(s string, cutset string) string
// 将 s 左侧的匹配 cutset 中的任一字符的字符去掉
func TrimLeft(s string, cutset string) string
// 将 s 右侧的匹配 cutset 中的任一字符的字符去掉
func TrimRight(s string, cutset string) string
// 如果 s 的前缀为 prefix 则返回去掉前缀后的 string , 否则 s 没有变化。
func TrimPrefix(s, prefix string) string
// 如果 s 的后缀为 suffix 则返回去掉后缀后的 string , 否则 s 没有变化。
func TrimSuffix(s, suffix string) string
// 将 s 左侧和右侧的间隔符去掉。常见间隔符包括：&#39;\t&#39;, &#39;\n&#39;, &#39;\v&#39;, &#39;\f&#39;, &#39;\r&#39;, &#39; &#39;, U+0085 (NEL)
func TrimSpace(s string) string
// 将 s 左侧和右侧的匹配 f 的字符去掉
func TrimFunc(s string, f func(rune) bool) string
// 将 s 左侧的匹配 f 的字符去掉
func TrimLeftFunc(s string, f func(rune) bool) string
// 将 s 右侧的匹配 f 的字符去掉
func TrimRightFunc(s string, f func(rune) bool) string
包含了 9 个相关函数用于修剪字符串。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;举个例子：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x := &amp;quot;!!!@@@你好,!@#$ Gophers###$$$&amp;quot;
fmt.Println(strings.Trim(x, &amp;quot;@#$!%^&amp;amp;*()_+=-&amp;quot;))
fmt.Println(strings.TrimLeft(x, &amp;quot;@#$!%^&amp;amp;*()_+=-&amp;quot;))
fmt.Println(strings.TrimRight(x, &amp;quot;@#$!%^&amp;amp;*()_+=-&amp;quot;))
fmt.Println(strings.TrimSpace(&amp;quot; \t\n Hello, Gophers \n\t\r\n&amp;quot;))
fmt.Println(strings.TrimPrefix(x, &amp;quot;!&amp;quot;))
fmt.Println(strings.TrimSuffix(x, &amp;quot;$&amp;quot;))

f := func(r rune) bool {
    return !unicode.Is(unicode.Han, r) // 非汉字返回 true
}
fmt.Println(strings.TrimFunc(x, f))
fmt.Println(strings.TrimLeftFunc(x, f))
fmt.Println(strings.TrimRightFunc(x, f))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;你好,!@#$ Gophers
你好,!@#$ Gophers###$$$
!!!@@@你好,!@#$ Gophers
Hello, Gophers
!!@@@你好,!@#$ Gophers###$$$
!!!@@@你好,!@#$ Gophers###$$
你好
你好,!@#$ Gophers###$$$
!!!@@@你好
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;类型&#34;&gt;类型&lt;/h1&gt;

&lt;h2 id=&#34;replacer-类型&#34;&gt;Replacer 类型&lt;/h2&gt;

&lt;p&gt;这是一个结构，没有导出任何字段，实例化通过 func NewReplacer(oldnew &amp;hellip;string) *Replacer 函数进行，其中不定参数 oldnew 是 old-new 对，即进行多个替换。如果 oldnew 长度与奇数，会导致 panic.&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r := strings.NewReplacer(&amp;quot;&amp;lt;&amp;quot;, &amp;quot;&amp;amp;lt;&amp;quot;, &amp;quot;&amp;gt;&amp;quot;, &amp;quot;&amp;amp;gt;&amp;quot;)
fmt.Println(r.Replace(&amp;quot;This is &amp;lt;b&amp;gt;HTML&amp;lt;/b&amp;gt;!&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;This is &amp;amp;lt;b&amp;amp;gt;HTML&amp;amp;lt;/b&amp;amp;gt;!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外，Replacer 还提供了另外一个方法，它在替换之后将结果写入 io.Writer 中。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (r *Replacer) WriteString(w io.Writer, s string) (n int, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;reader-类型&#34;&gt;Reader 类型&lt;/h2&gt;

&lt;p&gt;看到名字就能猜到，这是实现了 io 包中的接口。其实这就是缓存io，对缓存中的string进行读写操作。&lt;/p&gt;

&lt;p&gt;它实现了 io.Reader（Read 方法），io.ReaderAt（ReadAt 方法），io.Seeker（Seek 方法），io.WriterTo（WriteTo 方法），io.ByteReader（ReadByte 方法），io.ByteScanner（ReadByte 和 UnreadByte 方法），io.RuneReader（ReadRune 方法） 和 io.RuneScanner（ReadRune 和 UnreadRune 方法）。&lt;/p&gt;

&lt;p&gt;Reader 结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Reader struct {
    s        string    // Reader 读取的数据来源
    i        int // current reading index（当前读的索引位置）
    prevRune int // index of previous rune; or &amp;lt; 0（前一个读取的 rune 索引位置）
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见 Reader 结构没有导出任何字段，而是提供一个实例化方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewReader(s string) *Reader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该方法接收一个字符串，返回的 Reader 实例就是从该参数字符串读数据。&lt;/p&gt;

&lt;p&gt;在后面学习了 &lt;a href=&#34;https://kingjcy.github.io/post/golang/go-bytes/#reader-类型&#34;&gt;bytes&lt;/a&gt; 包之后，可以知道 bytes.NewBufferString 有类似的功能，不过，如果只是为了读取，NewReader 会更高效。&lt;/p&gt;

&lt;h2 id=&#34;builder-类型&#34;&gt;Builder 类型&lt;/h2&gt;

&lt;p&gt;这个类型也是缓存io的一种实现方式。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Builder struct {
    addr *Builder // of receiver, to detect copies by value
    buf  []byte
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该类型实现了 io 包下的 Writer, ByteWriter, StringWriter 等接口，可以向该对象内写入数据，Builder 没有实现 Reader 等接口，所以该类型不可读，但提供了 String 方法可以获取对象内的数据。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 该方法向 b 写入一个字节
func (b *Builder) WriteByte(c byte) error
// WriteRune 方法向 b 写入一个字符
func (b *Builder) WriteRune(r rune) (int, error)
// WriteRune 方法向 b 写入字节数组 p
func (b *Builder) Write(p []byte) (int, error)
// WriteRune 方法向 b 写入字符串 s
func (b *Builder) WriteString(s string) (int, error)
// Len 方法返回 b 的数据长度。
func (b *Builder) Len() int
// Cap 方法返回 b 的 cap。
func (b *Builder) Cap() int
// Grow 方法将 b 的 cap 至少增加 n (可能会更多)。如果 n 为负数，会导致 panic。
func (b *Builder) Grow(n int)
// Reset 方法将 b 清空 b 的所有内容。
func (b *Builder) Reset()
// String 方法将 b 的数据以 string 类型返回。
func (b *Builder) String() string
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Builder 有 4 个与写入相关的方法，这 4 个方法的 error 都总是为 nil.&lt;/p&gt;

&lt;p&gt;Builder 的 cap 会自动增长，一般不需要手动调用 Grow 方法。&lt;/p&gt;

&lt;p&gt;String 方法可以方便的获取 Builder 的内容。&lt;/p&gt;

&lt;p&gt;举个例子：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;b := strings.Builder{}
_ = b.WriteByte(&#39;7&#39;)
n, _ := b.WriteRune(&#39;夕&#39;)
fmt.Println(n)
n, _ = b.Write([]byte(&amp;quot;Hello, World&amp;quot;))
fmt.Println(n)
n, _ = b.WriteString(&amp;quot;你好，世界&amp;quot;)
fmt.Println(n)
fmt.Println(b.Len())
fmt.Println(b.Cap())
b.Grow(100)
fmt.Println(b.Len())
fmt.Println(b.Cap())
fmt.Println(b.String())
b.Reset()
fmt.Println(b.String())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;3
12
15
31
32
31
164
7夕Hello, World你好，世界
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;这边主要是要注意，使用返回值作为新值，原来值是不变的。&lt;/strong&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Golang使用系列---- Strconv</title>
          <link>https://kingjcy.github.io/post/golang/go-strconv/</link>
          <pubDate>Wed, 12 Oct 2016 19:33:24 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/golang/go-strconv/</guid>
          <description>&lt;p&gt;strconv包实现了基本数据类型和其字符串表示的相互转换。&lt;/p&gt;

&lt;h1 id=&#34;基本使用&#34;&gt;基本使用&lt;/h1&gt;

&lt;p&gt;strconv主要就是字符之间的转化，我们直接看我们经常的使用就好。&lt;/p&gt;

&lt;h2 id=&#34;parseint&#34;&gt;ParseInt&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;func ParseInt(s string, base int, bitSize int) (i int64, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;返回字符串表示的整数值，接受正负号。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;base指定进制（2到36），如果base为0，则会从字符串前置判断，&amp;rdquo;0x&amp;rdquo;是16进制，&amp;rdquo;0&amp;rdquo;是8进制，否则是10进制；&lt;/li&gt;
&lt;li&gt;bitSize指定结果必须能无溢出赋值的整数类型，0、8、16、32、64 分别代表 int、int8、int16、int32、int64；返回的err是*NumErr类型的，如果语法有误，err.Error = ErrSyntax；如果结果超出类型范围err.Error = ErrRange。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;int和string的转化&#34;&gt;int和string的转化&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;int转string&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;s := strconv.Itoa(i)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;等价于&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;s := strconv.FormatInt(int64(i), 10)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;int64转string&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;i := int64(123)
s := strconv.FormatInt(i, 10)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第二个参数为基数，可选2~36&lt;/p&gt;

&lt;p&gt;注：对于无符号整形，可以使用FormatUint(i uint64, base int)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;string转int&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;i, err := strconv.Atoi(s)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;string转int64&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;i, err := strconv.ParseInt(s, 10, 64)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第二个参数为基数（2~36），第三个参数位大小表示期望转换的结果类型，其值可以为0, 8, 16, 32和64，分别对应 int, int8, int16, int32和int64&lt;/p&gt;

&lt;h2 id=&#34;float相关&#34;&gt;float相关&lt;/h2&gt;

&lt;p&gt;float转string：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;v := 3.1415926535
s1 := strconv.FormatFloat(v, &#39;E&#39;, -1, 32)//float32s2 := strconv.FormatFloat(v, &#39;E&#39;, -1, 64)//float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;函数原型及参数含义具体可查看：&lt;a href=&#34;https://golang.org/pkg/strconv/#FormatFloat&#34;&gt;https://golang.org/pkg/strconv/#FormatFloat&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;string转float：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;s := &amp;quot;3.1415926535&amp;quot;
v1, err := strconv.ParseFloat(v, 32)
v2, err := strconv.ParseFloat(v, 64)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;error相关&#34;&gt;error相关&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;error转string&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;err.Error()
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>Golang使用系列---- Io</title>
          <link>https://kingjcy.github.io/post/golang/go-io/</link>
          <pubDate>Sat, 30 Jul 2016 20:39:03 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/golang/go-io/</guid>
          <description>&lt;p&gt;io包提供了所有需要交互的输入输出模式的基础。&lt;/p&gt;

&lt;h1 id=&#34;基本概念&#34;&gt;基本概念&lt;/h1&gt;

&lt;h2 id=&#34;stream&#34;&gt;stream&lt;/h2&gt;

&lt;p&gt;我们先介绍一下stream的概念。stream就是数据流，数据流的概念其实非常基础，最早是在通讯领域使用的概念，这个概念最初在 1998 年由 Henzinger 在文献中提出，他将数据流定义为 “只能以事先规定好的顺序被读取一次的数据的一个序列”&lt;/p&gt;

&lt;p&gt;数据流就是由数据形成的流，就像由水形成的水流，非常形象，现代语言中，基本上都会有流的支持，比如 C++ 的 iostream，Node.js 的 stream 模块，以及 golang 的 io 包。&lt;/p&gt;

&lt;p&gt;Stream in Golang与流密切相关的就是 bufio io io/ioutil 这几个包：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1、io 为 IO 原语（I/O primitives）提供基本的接口
2、io/ioutil 封装一些实用的 I/O 函数
3、fmt 实现格式化 I/O，类似 C 语言中的 printf 和 scanf
4、bufio 实现带缓冲I/O
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;io&#34;&gt;io&lt;/h2&gt;

&lt;p&gt;io 包为 I/O 原语提供了基本的接口。在 io 包中最重要的是两个接口：Reader 和 Writer 接口。本章所提到的各种 IO 包，都跟这两个接口有关，也就是说，只要满足这两个接口，它就可以使用 IO 包的功能。&lt;/p&gt;

&lt;h1 id=&#34;接口&#34;&gt;接口&lt;/h1&gt;

&lt;h2 id=&#34;读取器&#34;&gt;读取器&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;type Reader interface {
    //Read() 方法有两个返回值，一个是读取到的字节数，一个是发生错误时的错误。如果资源内容已全部读取完毕，应该返回 io.EOF 错误。
    Read(p []byte) (n int, err error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;io.Reader 表示一个读取器，它将数据从某个资源读取到传输缓冲区p。在缓冲区中，数据可以被流式传输和使用。&lt;/p&gt;

&lt;p&gt;实现这个接口需要实现如下功能&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Read 将 len(p) 个字节读取到 p 中。它返回读取的字节数 n（0 &amp;lt;= n &amp;lt;= len(p)） 以及任何遇到的错误。

&lt;ul&gt;
&lt;li&gt;即使 Read 返回的 n &amp;lt; len(p)，它也会在调用过程中占用 len(p) 个字节作为暂存空间。&lt;/li&gt;
&lt;li&gt;若可读取的数据不到 len(p) 个字节，Read 会返回可用数据，而不是等待更多数据。&lt;/li&gt;
&lt;li&gt;当读取的时候没有数据也没有EOF的时候，会阻塞在这边等待。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;当 Read 在成功读取 n &amp;gt; 0 个字节后遇到一个错误或 EOF (end-of-file)，它会返回读取的字节数。

&lt;ul&gt;
&lt;li&gt;它可能会同时在本次的调用中返回一个non-nil错误,或在下一次的调用中返回这个错误（且 n 为 0）。&lt;/li&gt;
&lt;li&gt;一般情况下, Reader会返回一个非0字节数n, 若 n = len(p) 个字节从输入源的结尾处由 Read 返回，Read可能返回 err == EOF 或者 err == nil。并且之后的 Read() 都应该返回 (n:0, err:EOF)。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;调用者在考虑错误之前应当首先处理返回的数据。这样做可以正确地处理在读取一些字节后产生的 I/O 错误，同时允许EOF的出现。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于要用作读取器的类型，它必须实现 io.Reader 接口的唯一一个方法 Read(p []byte)。换句话说，只要实现了 Read(p []byte) ，那它就是一个读取器，使用标准库中已经实现的读写器，来举例&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    reader := strings.NewReader(&amp;quot;Clear is better than clever&amp;quot;)
    p := make([]byte, 4)

    for {
        n, err := reader.Read(p)
        if err != nil{
            if err == io.EOF {
                fmt.Println(&amp;quot;EOF:&amp;quot;, n)
                break
            }
            fmt.Println(err)
            os.Exit(1)
        }
        fmt.Println(n, string(p[:n]))
    }
}

输出打印的内容：

4 Clea
4 r is
4  bet
4 ter 
4 than
4  cle
3 ver
EOF: 0 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;自定义reader&#34;&gt;自定义Reader&lt;/h3&gt;

&lt;p&gt;现在，让我们看看如何自己实现一个。它的功能是从流中过滤掉非字母字符。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type alphaReader struct {
    // 资源
    src string
    // 当前读取到的位置 
    cur int
}

// 创建一个实例
func newAlphaReader(src string) *alphaReader {
    return &amp;amp;alphaReader{src: src}
}

// 过滤函数
func alpha(r byte) byte {
    if (r &amp;gt;= &#39;A&#39; &amp;amp;&amp;amp; r &amp;lt;= &#39;Z&#39;) || (r &amp;gt;= &#39;a&#39; &amp;amp;&amp;amp; r &amp;lt;= &#39;z&#39;) {
        return r
    }
    return 0
}

// Read 方法，read函数是阻塞的
func (a *alphaReader) Read(p []byte) (int, error) {
    // 当前位置 &amp;gt;= 字符串长度 说明已经读取到结尾 返回 EOF
    if a.cur &amp;gt;= len(a.src) {
        return 0, io.EOF
    }

    // x 是剩余未读取的长度
    x := len(a.src) - a.cur
    n, bound := 0, 0
    if x &amp;gt;= len(p) {
        // 剩余长度超过缓冲区大小，说明本次可完全填满缓冲区
        bound = len(p)
    } else if x &amp;lt; len(p) {
        // 剩余长度小于缓冲区大小，使用剩余长度输出，缓冲区不补满
        bound = x
    }

    buf := make([]byte, bound)
    for n &amp;lt; bound {
        // 每次读取一个字节，执行过滤函数
        if char := alpha(a.src[a.cur]); char != 0 {
            buf[n] = char
        }
        n++
        a.cur++
    }
    // 将处理后得到的 buf 内容复制到 p 中
    copy(p, buf)
    return n, nil
}

func main() {
    reader := newAlphaReader(&amp;quot;Hello! It&#39;s 9am, where is the sun?&amp;quot;)
    p := make([]byte, 4)
    for {
        n, err := reader.Read(p)
        if err == io.EOF {
            break
        }
        fmt.Print(string(p[:n]))
    }
    fmt.Println()
}
输出打印的内容：
HelloItsamwhereisthesun
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;tcp粘包拆包&#34;&gt;TCP粘包拆包&lt;/h3&gt;

&lt;p&gt;这边讲解一下TCP粘包拆包问题，先看下面这个实例&lt;/p&gt;

&lt;p&gt;服务端代码 server/main.go&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    l, err := net.Listen(&amp;quot;tcp&amp;quot;, &amp;quot;:4044&amp;quot;)
    if err != nil {
        panic(err)
    }
    fmt.Println(&amp;quot;listen to 4044&amp;quot;)
    for {
        // 监听到新的连接，创建新的 goroutine 交给 handleConn函数 处理
        conn, err := l.Accept()
        if err != nil {
            fmt.Println(&amp;quot;conn err:&amp;quot;, err)
        } else {
            go handleConn(conn)
        }
    }
}

func handleConn(conn net.Conn) {
    defer conn.Close()
    defer fmt.Println(&amp;quot;关闭&amp;quot;)
    fmt.Println(&amp;quot;新连接：&amp;quot;, conn.RemoteAddr())

    result := bytes.NewBuffer(nil)
    var buf [1024]byte
    for {
        n, err := conn.Read(buf[0:])
        result.Write(buf[0:n])
        if err != nil {
            if err == io.EOF {
                continue
            } else {
                fmt.Println(&amp;quot;read err:&amp;quot;, err)
                break
            }
        } else {
            fmt.Println(&amp;quot;recv:&amp;quot;, result.String())
        }
        result.Reset()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;客户端代码 client/main.go&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    data := []byte(&amp;quot;[这里才是一个完整的数据包]&amp;quot;)
    conn, err := net.DialTimeout(&amp;quot;tcp&amp;quot;, &amp;quot;localhost:4044&amp;quot;, time.Second*30)
    if err != nil {
        fmt.Printf(&amp;quot;connect failed, err : %v\n&amp;quot;, err.Error())
        return
    }
    for i := 0; i &amp;lt;1000; i++ {
        _, err = conn.Write(data)
        if err != nil {
            fmt.Printf(&amp;quot;write failed , err : %v\n&amp;quot;, err)
            break
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;listen to 4044
新连接： [::1]:53079
recv: [这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据�
recv: �][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包]
recv: [这里才是一个完整的数据包]
recv: [这里才是一个完整的数据包]
recv: [这里才是一个完整的数据包][这里才是一个完整的数据包][这里才是一个完整的数据包]
recv: [这里才是一个完整的数据包]
...省略其它的...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从服务端的控制台输出可以看出，存在三种类型的输出：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一种是正常的一个数据包输出。&lt;/li&gt;
&lt;li&gt;一种是多个数据包“粘”在了一起，我们定义这种读到的包为粘包。&lt;/li&gt;
&lt;li&gt;一种是一个数据包被“拆”开，形成一个破碎的包，我们定义这种包为半包。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为什么会出现半包和粘包？&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;客户端一段时间内发送包的速度太多，服务端没有全部处理完。于是数据就会积压起来，产生粘包。&lt;/li&gt;
&lt;li&gt;定义的读的buffer不够大，而数据包太大或者由于粘包产生，服务端不能一次全部读完，产生半包。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;什么时候需要考虑处理半包和粘包？&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TCP连接是长连接，即一次连接多次发送数据。&lt;/li&gt;
&lt;li&gt;每次发送的数据是结构的，比如 JSON格式的数据 或者 数据包的协议是由我们自己定义的（包头部包含实际数据长度、协议魔数等）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;解决思路&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;定长分隔(每个数据包最大为该长度，不足时使用特殊字符填充) ，但是数据不足时会浪费传输资源&lt;/li&gt;
&lt;li&gt;使用特定字符来分割数据包，但是若数据中含有分割字符则会出现Bug&lt;/li&gt;
&lt;li&gt;在数据包中添加长度字段，弥补了以上两种思路的不足，推荐使用&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通过上述分析，我们最好通过第三种思路来解决拆包粘包问题。&lt;/p&gt;

&lt;p&gt;Golang的bufio库中有为我们提供了Scanner，来解决这类分割数据的问题。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Scanner
Scanner provides a convenient interface for reading data such as a file of newline-delimited lines of text. Successive calls to the Scan method will step through the &#39;tokens&#39; of a file, skipping the bytes between the tokens. The specification of a token is defined by a split function of type SplitFunc; the default split function breaks the input into lines with line termination stripped. Split functions are defined in this package for scanning a file into lines, bytes, UTF-8-encoded runes, and space-delimited words. The client may instead provide a custom split function.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;简单来讲即是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Scanner为 读取数据 提供了方便的 接口。连续调用Scan方法会逐个得到文件的“tokens”，跳过 tokens 之间的字节。token 的规范由 SplitFunc 类型的函数定义。我们可以改为提供自定义拆分功能。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接下来看看 SplitFunc 类型的函数是什么样子的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type SplitFunc func(data []byte, atEOF bool) (advance int, token []byte, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例子&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    // An artificial input source.
    const input = &amp;quot;1234 5678 1234567901234567890&amp;quot;
    scanner := bufio.NewScanner(strings.NewReader(input))
    // Create a custom split function by wrapping the existing ScanWords function.
    split := func(data []byte, atEOF bool) (advance int, token []byte, err error) {
        advance, token, err = bufio.ScanWords(data, atEOF)
        if err == nil &amp;amp;&amp;amp; token != nil {
            _, err = strconv.ParseInt(string(token), 10, 32)
        }
        return
    }
    // Set the split function for the scanning operation.
    scanner.Split(split)
    // Validate the input
    for scanner.Scan() {
        fmt.Printf(&amp;quot;%s\n&amp;quot;, scanner.Text())
    }

    if err := scanner.Err(); err != nil {
        fmt.Printf(&amp;quot;Invalid input: %s&amp;quot;, err)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;于是，我们可以这样改写我们的程序：&lt;/p&gt;

&lt;p&gt;服务端代码 server/main.go&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    l, err := net.Listen(&amp;quot;tcp&amp;quot;, &amp;quot;:4044&amp;quot;)
    if err != nil {
        panic(err)
    }
    fmt.Println(&amp;quot;listen to 4044&amp;quot;)
    for {
        conn, err := l.Accept()
        if err != nil {
            fmt.Println(&amp;quot;conn err:&amp;quot;, err)
        } else {
            go handleConn2(conn)
        }
    }
}

func packetSlitFunc(data []byte, atEOF bool) (advance int, token []byte, err error) {
        // 检查 atEOF 参数 和 数据包头部的四个字节是否 为 0x123456(我们定义的协议的魔数)
    if !atEOF &amp;amp;&amp;amp; len(data) &amp;gt; 6 &amp;amp;&amp;amp; binary.BigEndian.Uint32(data[:4]) == 0x123456 {
        var l int16
                // 读出 数据包中 实际数据 的长度(大小为 0 ~ 2^16)
        binary.Read(bytes.NewReader(data[4:6]), binary.BigEndian, &amp;amp;l)
        pl := int(l) + 6
        if pl &amp;lt;= len(data) {
            return pl, data[:pl], nil
        }
    }
    return
}

func handleConn2(conn net.Conn) {
    defer conn.Close()
    defer fmt.Println(&amp;quot;关闭&amp;quot;)
    fmt.Println(&amp;quot;新连接：&amp;quot;, conn.RemoteAddr())
    result := bytes.NewBuffer(nil)
        var buf [65542]byte // 由于 标识数据包长度 的只有两个字节 故数据包最大为 2^16+4(魔数)+2(长度标识)
    for {
        n, err := conn.Read(buf[0:])
        result.Write(buf[0:n])
        if err != nil {
            if err == io.EOF {
                continue
            } else {
                fmt.Println(&amp;quot;read err:&amp;quot;, err)
                break
            }
        } else {
            scanner := bufio.NewScanner(result)
            scanner.Split(packetSlitFunc)
            for scanner.Scan() {
                fmt.Println(&amp;quot;recv:&amp;quot;, string(scanner.Bytes()[6:]))
            }
        }
        result.Reset()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;复制代码客户端代码 client/main.go&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    data := []byte(&amp;quot;[这里才是一个完整的数据包]&amp;quot;)
    l := len(data)
    fmt.Println(l)
    magicNum := make([]byte, 4)
    binary.BigEndian.PutUint32(magicNum, 0x123456)
    lenNum := make([]byte, 2)
    binary.BigEndian.PutUint16(lenNum, uint16(l))
    packetBuf := bytes.NewBuffer(magicNum)
    packetBuf.Write(lenNum)
    packetBuf.Write(data)
    conn, err := net.DialTimeout(&amp;quot;tcp&amp;quot;, &amp;quot;localhost:4044&amp;quot;, time.Second*30)
    if err != nil {
        fmt.Printf(&amp;quot;connect failed, err : %v\n&amp;quot;, err.Error())
                return
    }
    for i := 0; i &amp;lt;1000; i++ {
        _, err = conn.Write(packetBuf.Bytes())
        if err != nil {
            fmt.Printf(&amp;quot;write failed , err : %v\n&amp;quot;, err)
            break
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;复制代码运行结果&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;listen to 4044
新连接： [::1]:55738
recv: [这里才是一个完整的数据包]
recv: [这里才是一个完整的数据包]
recv: [这里才是一个完整的数据包]
recv: [这里才是一个完整的数据包]
recv: [这里才是一个完整的数据包]
recv: [这里才是一个完整的数据包]
recv: [这里才是一个完整的数据包]
recv: [这里才是一个完整的数据包]
...省略其它的...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;编写器&#34;&gt;编写器&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;type Writer
type Writer interface {
    //Write() 方法有两个返回值，一个是写入到目标资源的字节数，一个是发生错误时的错误。
    Write(p []byte) (n int, err error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;io.Writer 表示一个编写器，它从缓冲区读取数据，并将数据写入目标资源。&lt;/p&gt;

&lt;p&gt;实现这个接口就需要实现如下的功能&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Write 将 len(p) 个字节从 p 中写入到基本数据流中。它返回从 p 中被写入的字节数 n（0 &amp;lt;= n &amp;lt;= len(p)）以及任何遇到的引起写入提前停止的错误。若 Write 返回的 n &amp;lt; len(p)，它就必须返回一个 非nil 的错误。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于要用作编写器的类型，必须实现 io.Writer 接口的唯一一个方法 Write(p []byte),同样，只要实现了 Write(p []byte) ，那它就是一个编写器。举例，标准库&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    proverbs := []string{
        &amp;quot;Channels orchestrate mutexes serialize&amp;quot;,
        &amp;quot;Cgo is not Go&amp;quot;,
        &amp;quot;Errors are values&amp;quot;,
        &amp;quot;Don&#39;t panic&amp;quot;,
    }
    var writer bytes.Buffer

    for _, p := range proverbs {
        n, err := writer.Write([]byte(p))
        if err != nil {
            fmt.Println(err)
            os.Exit(1)
        }
        if n != len(p) {
            fmt.Println(&amp;quot;failed to write data&amp;quot;)
            os.Exit(1)
        }
    }

    fmt.Println(writer.String())
}
输出打印的内容：
Channels orchestrate mutexes serializeCgo is not GoErrors are valuesDon&#39;t panic
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;自定义writer&#34;&gt;自定义Writer&lt;/h3&gt;

&lt;p&gt;下面我们来实现一个名为 chanWriter 的自定义 io.Writer ，它将其内容作为字节序列写入 channel 。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type chanWriter struct {
    // ch 实际上就是目标资源
    ch chan byte
}

func newChanWriter() *chanWriter {
    return &amp;amp;chanWriter{make(chan byte, 1024)}
}

func (w *chanWriter) Chan() &amp;lt;-chan byte {
    return w.ch
}

func (w *chanWriter) Write(p []byte) (int, error) {
    n := 0
    // 遍历输入数据，按字节写入目标资源
    for _, b := range p {
        w.ch &amp;lt;- b
        n++
    }
    return n, nil
}

func (w *chanWriter) Close() error {
    close(w.ch)
    return nil
}

func main() {
    writer := newChanWriter()
    go func() {
        defer writer.Close()
        writer.Write([]byte(&amp;quot;Stream &amp;quot;))
        writer.Write([]byte(&amp;quot;me!&amp;quot;))
    }()
    for c := range writer.Chan() {
        fmt.Printf(&amp;quot;%c&amp;quot;, c)
    }
    fmt.Println()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;要使用这个 Writer，只需在函数 main() 中调用 writer.Write()（在单独的goroutine中）。&lt;/p&gt;

&lt;p&gt;因为 chanWriter 还实现了接口 io.Closer ，所以调用方法 writer.Close() 来正确地关闭channel，以避免发生泄漏和死锁。&lt;/p&gt;

&lt;h2 id=&#34;closer&#34;&gt;closer&lt;/h2&gt;

&lt;p&gt;Closer 接口包装了基本的 Close 方法，用于关闭数据读写。Close 一般用于关闭文件，关闭通道，关闭连接，关闭数据库等，在不同的标准库实现中实现。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Closer interface {
    Close() error
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;seeker&#34;&gt;seeker&lt;/h2&gt;

&lt;p&gt;Seeker 接口包装了基本的 Seek 方法，用于移动数据的读写指针。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Seeker interface {
    Seek(offset int64, whence int) (ret int64, err error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Seek 设置下一次读写操作的指针位置，每次的读写操作都是从指针位置开始的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;whence 的含义：

&lt;ul&gt;
&lt;li&gt;如果 whence 为 0：表示从数据的开头开始移动指针。&lt;/li&gt;
&lt;li&gt;如果 whence 为 1：表示从数据的当前指针位置开始移动指针。&lt;/li&gt;
&lt;li&gt;如果 whence 为 2：表示从数据的尾部开始移动指针。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;offset 是指针移动的偏移量。&lt;/li&gt;
&lt;li&gt;返回新指针位置和遇到的错误。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;whence 的值，在 io 包中定义了相应的常量，应该使用这些常量&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const (
  SeekStart   = 0 // seek relative to the origin of the file
  SeekCurrent = 1 // seek relative to the current offset
  SeekEnd     = 2 // seek relative to the end
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;而原先 os 包中的常量已经被标注为Deprecated&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Deprecated: Use io.SeekStart, io.SeekCurrent, and io.SeekEnd.
const (
  SEEK_SET int = 0 // seek relative to the origin of the file
  SEEK_CUR int = 1 // seek relative to the current offset
  SEEK_END int = 2 // seek relative to the end
)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;组合接口&#34;&gt;组合接口&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;type ReadWriter interface {
    Reader
    Writer
}

type ReadSeeker interface {
    Reader
    Seeker
}

type WriteSeeker interface {
    Writer
    Seeker
}

type ReadWriteSeeker interface {
    Reader
    Writer
    Seeker
}

type ReadCloser interface {
    Reader
    Closer
}

type WriteCloser interface {
    Writer
    Closer
}

type ReadWriteCloser interface {
    Reader
    Writer
    Closer
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这些接口的作用是：有些时候同时需要某两个接口的所有功能，即必须同时实现了某两个接口的类型才能够被传入使用。可见，io 包中有大量的“小接口”，这样方便组合为“大接口”。&lt;/p&gt;

&lt;h2 id=&#34;其他接口&#34;&gt;其他接口&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;ReaderFrom&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ReaderFrom 接口包装了基本的 ReadFrom 方法，用于从 r 中读取数据存入自身。直到遇到 EOF 或读取出错为止，返回读取的字节数和遇到的错误。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type ReaderFrom interface {
    ReadFrom(r Reader) (n int64, err error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要实现接口的功能&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ReadFrom 从 r 中读取数据，直到 EOF 或发生错误。其返回值 n 为读取的字节数。除 io.EOF 之外，在读取过程中遇到的任何错误也将被返回。&lt;/li&gt;
&lt;li&gt;如果 ReaderFrom 可用，Copy 函数就会使用它。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;实例：将文件中的数据全部读取（显示在标准输出）：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;file, err := os.Open(&amp;quot;writeAt.txt&amp;quot;)
if err != nil {
    panic(err)
}
defer file.Close()
writer := bufio.NewWriter(os.Stdout)
writer.ReadFrom(file)
writer.Flush()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然，我们可以通过 ioutil 包的 ReadFile 函数获取文件全部内容。其实，跟踪一下 ioutil.ReadFile 的源码，会发现其实也是通过 ReadFrom 方法实现（用的是 bytes.Buffer，它实现了 ReaderFrom 接口）。&lt;/p&gt;

&lt;p&gt;如果不通过 ReadFrom 接口来做这件事，而是使用 io.Reader 接口，我们有两种思路：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;先获取文件的大小（File 的 Stat 方法），之后定义一个该大小的 []byte，通过 Read 一次性读取&lt;/li&gt;
&lt;li&gt;定义一个小的 []byte，不断的调用 Read 方法直到遇到 EOF，将所有读取到的 []byte 连接到一起&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;WriterTo&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;WriterTo 接口包装了基本的 WriteTo 方法，用于将自身的数据写入 w 中。直到数据全部写入完毕或遇到错误为止，返回写入的字节数和遇到的错误。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type WriterTo interface {
    WriteTo(w Writer) (n int64, err error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要实现接口的功能&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;WriteTo 将数据写入 w 中，直到没有数据可写或发生错误。其返回值 n 为写入的字节数。 在写入过程中遇到的任何错误也将被返回。&lt;/li&gt;
&lt;li&gt;如果 WriterTo 可用，Copy 函数就会使用它。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;读者是否发现，其实 ReaderFrom 和 WriterTo 接口的方法接收的参数是 io.Reader 和 io.Writer 类型。根据 io.Reader 和 io.Writer 接口的讲解，对该接口的使用应该可以很好的掌握。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ReaderAt&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ReaderAt 接口包装了基本的 ReadAt 方法，用于将自身的数据写入 p 中。ReadAt 忽略之前的读写位置，从起始位置的 off 偏移处开始读取。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type ReaderAt interface {
    ReadAt(p []byte, off int64) (n int, err error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要实现接口的功能&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ReadAt 从基本输入源的偏移量 off 处开始，将 len(p) 个字节读取到 p 中。它返回读取的字节数 n（0 &amp;lt;= n &amp;lt;= len(p)）以及任何遇到的错误。&lt;/li&gt;
&lt;li&gt;当 ReadAt 返回的 n &amp;lt; len(p) 时，它就会返回一个 非nil 的错误来解释 为什么没有返回更多的字节。在这一点上，ReadAt 比 Read 更严格。&lt;/li&gt;
&lt;li&gt;即使 ReadAt 返回的 n &amp;lt; len(p)，它也会在调用过程中使用 p 的全部作为暂存空间。若可读取的数据不到 len(p) 字节，ReadAt 就会阻塞,直到所有数据都可用或一个错误发生。 在这一点上 ReadAt 不同于 Read。&lt;/li&gt;
&lt;li&gt;若 n = len(p) 个字节从输入源的结尾处由 ReadAt 返回，Read可能返回 err == EOF 或者 err == nil&lt;/li&gt;
&lt;li&gt;若 ReadAt 携带一个偏移量从输入源读取，ReadAt 应当既不影响偏移量也不被它所影响。&lt;/li&gt;
&lt;li&gt;可对相同的输入源并行执行 ReadAt 调用。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;标准库上面说的很多都是实现了这个接口，简单示例代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;reader := strings.NewReader(&amp;quot;Go语言中文网&amp;quot;)
p := make([]byte, 6)
n, err := reader.ReadAt(p, 2)
if err != nil {
    panic(err)
}
fmt.Printf(&amp;quot;%s, %d\n&amp;quot;, p, n)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;语言, 6
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;WriterAt&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;WriterAt 接口包装了基本的 WriteAt 方法，用于将 p 中的数据写入自身。ReadAt 忽略之前的读写位置，从起始位置的 off 偏移处开始写入。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type WriterAt interface {
    WriteAt(p []byte, off int64) (n int, err error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要实现接口的功能&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;WriteAt 从 p 中将 len(p) 个字节写入到偏移量 off 处的基本数据流中。它返回从 p 中被写入的字节数 n（0 &amp;lt;= n &amp;lt;= len(p)）以及任何遇到的引起写入提前停止的错误。若 WriteAt 返回的 n &amp;lt; len(p)，它就必须返回一个 非nil 的错误。&lt;/li&gt;
&lt;li&gt;若 WriteAt 携带一个偏移量写入到目标中，WriteAt 应当既不影响偏移量也不被它所影响。&lt;/li&gt;
&lt;li&gt;若被写区域没有重叠，可对相同的目标并行执行 WriteAt 调用。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;os.File 实现了 WriterAt 接口，实例如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;file, err := os.Create(&amp;quot;writeAt.txt&amp;quot;)
if err != nil {
    panic(err)
}
defer file.Close()
file.WriteString(&amp;quot;Golang中文社区——这里是多余&amp;quot;)
n, err := file.WriteAt([]byte(&amp;quot;Go语言中文网&amp;quot;), 24)
if err != nil {
    panic(err)
}
fmt.Println(n)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Golang中文社区——Go语言中文网。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;分析：file.WriteString(&amp;ldquo;Golang中文社区——这里是多余&amp;rdquo;) 往文件中写入 Golang中文社区——这里是多余，之后 file.WriteAt([]byte(&amp;ldquo;Go语言中文网&amp;rdquo;), 24) 在文件流的 offset=24 处写入 Go语言中文网（会覆盖该位置的内容）。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ByteReader和ByteWriter&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ByteReader 接口包装了基本的 ReadByte 方法，用于从自身读出一个字节。返回读出的字节和遇到的错误。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type ByteReader interface {
    ReadByte() (c byte, err error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ByteWriter 接口包装了基本的 WriteByte 方法，用于将一个字节写入自身返回遇到的错误&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type ByteWriter interface {
    WriteByte(c byte) error
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这组接口在标准库中也有实现&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bufio.Reader/Writer 分别实现了io.ByteReader 和 io.ByteWriter
bytes.Buffer 同时实现了 io.ByteReader 和 io.ByteWriter
bytes.Reader 实现了 io.ByteReader
strings.Reader 实现了 io.ByteReader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实例&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var ch byte
fmt.Scanf(&amp;quot;%c\n&amp;quot;, &amp;amp;ch)

buffer := new(bytes.Buffer)
err := buffer.WriteByte(ch)
if err == nil {
    fmt.Println(&amp;quot;写入一个字节成功！准备读取该字节……&amp;quot;)
    newCh, _ := buffer.ReadByte()
    fmt.Printf(&amp;quot;读取的字节：%c\n&amp;quot;, newCh)
} else {
    fmt.Println(&amp;quot;写入错误&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;ByteScanner&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ByteScanner 在 ByteReader 的基础上增加了一个 UnreadByte 方法，用于撤消最后一次的 ReadByte 操作，以便下次的 ReadByte 操作可以读出与前一次一样的数据。UnreadByte 之前必须是 ReadByte 才能撤消成功，否则可能会返回一个错误信息（根据不同的需求，UnreadByte 也可能返回 nil，允许随意调用 UnreadByte，但只有最后一次的 ReadByte 可以被撤销，其它 UnreadByte 不执行任何操作）。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type ByteScanner interface {
    ByteReader
    UnreadByte() error
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;RuneReader&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;RuneReader 接口包装了基本的 ReadRune 方法，用于从自身读取一个 UTF-8 编码的字符到 r 中。返回读取的字符、字符的编码长度和遇到的错误。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type RuneReader interface {
    ReadRune() (r rune, size int, err error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;RuneScanner&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;RuneScanner 在 RuneReader 的基础上增加了一个 UnreadRune 方法，用于撤消最后一次的 ReadRune 操作，以便下次的 ReadRune 操作可以读出与前一次一样的数据。UnreadRune 之前必须是 ReadRune 才能撤消成功，否则可能会返回一个错误信息（根据不同的需求，UnreadRune 也可能返回 nil，允许随意调用 UnreadRune，但只有最后一次的 ReadRune 可以被撤销，其它 UnreadRune 不执行任何操作）。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type RuneScanner interface {
    RuneReader
    UnreadRune() error
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;实例&#34;&gt;实例&lt;/h2&gt;

&lt;p&gt;bytes.NewBuffer 实现了很多基本的接口，可以通过 bytes 包学习接口的实现&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    buf := bytes.NewBuffer([]byte(&amp;quot;Hello World!&amp;quot;))
    b := make([]byte, buf.Len())

    n, err := buf.Read(b)
    fmt.Printf(&amp;quot;%s   %v\n&amp;quot;, b[:n], err)
    // Hello World!   &amp;lt;nil&amp;gt;

    buf.WriteString(&amp;quot;ABCDEFG\n&amp;quot;)
    buf.WriteTo(os.Stdout)
    // ABCDEFG

    n, err = buf.Write(b)
    fmt.Printf(&amp;quot;%d   %s   %v\n&amp;quot;, n, buf.String(), err)
    // 12   Hello World!   &amp;lt;nil&amp;gt;

    c, err := buf.ReadByte()
    fmt.Printf(&amp;quot;%c   %s   %v\n&amp;quot;, c, buf.String(), err)
    // H   ello World!   &amp;lt;nil&amp;gt;

    c, err = buf.ReadByte()
    fmt.Printf(&amp;quot;%c   %s   %v\n&amp;quot;, c, buf.String(), err)
    // e   llo World!   &amp;lt;nil&amp;gt;

    err = buf.UnreadByte()
    fmt.Printf(&amp;quot;%s   %v\n&amp;quot;, buf.String(), err)
    // ello World!   &amp;lt;nil&amp;gt;

    err = buf.UnreadByte()
    fmt.Printf(&amp;quot;%s   %v\n&amp;quot;, buf.String(), err)
    // ello World!   bytes.Buffer: UnreadByte: previous operation was not a read
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;类型&#34;&gt;类型&lt;/h1&gt;

&lt;p&gt;io包中定义了很多原生的类型。都是实现了上面的接口，可以直接创建使用的类型。&lt;/p&gt;

&lt;h2 id=&#34;sectionreader-类型&#34;&gt;SectionReader 类型&lt;/h2&gt;

&lt;p&gt;SectionReader 是一个 struct（没有任何导出的字段），实现了 Read, Seek 和 ReadAt，同时，内嵌了 ReaderAt 接口。结构定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type SectionReader struct {
    r     ReaderAt    // 该类型最终的 Read/ReadAt 最终都是通过 r 的 ReadAt 实现
    base  int64        // NewSectionReader 会将 base 设置为 off
    off   int64        // 从 r 中的 off 偏移处开始读取数据
    limit int64        // limit - off = SectionReader 流的长度
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从名称我们可以猜到，该类型读取数据流中部分数据。看一下常见的创建函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewSectionReader(r ReaderAt, off int64, n int64) *SectionReader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NewSectionReader 返回一个 SectionReader，它从 r 中的偏移量 off 处读取 n 个字节后以 EOF 停止。也就是说，SectionReader 只是内部（内嵌）ReaderAt 表示的数据流的一部分：从 off 开始后的 n 个字节。这个类型的作用是：方便重复操作某一段 (section) 数据流；或者同时需要 ReadAt 和 Seek 的功能。&lt;/p&gt;

&lt;h2 id=&#34;limitedreader-类型&#34;&gt;LimitedReader 类型&lt;/h2&gt;

&lt;p&gt;LimitedReader 结构定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type LimitedReader struct {
    R Reader // underlying reader，最终的读取操作通过 R.Read 完成
    N int64  // max bytes remaining
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从 R 读取但将返回的数据量限制为 N 字节。每调用一次 Read 都将更新 N 来反应新的剩余数量。也就是说，最多只能返回 N 字节数据。LimitedReader 只实现了 Read 方法（Reader 接口）。&lt;/p&gt;

&lt;p&gt;使用示例如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;content := &amp;quot;This Is LimitReader Example&amp;quot;
reader := strings.NewReader(content)
limitReader := &amp;amp;io.LimitedReader{R: reader, N: 8}
for limitReader.N &amp;gt; 0 {
    tmp := make([]byte, 2)
    limitReader.Read(tmp)
    fmt.Printf(&amp;quot;%s&amp;quot;, tmp)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;This Is
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见，通过该类型可以达到 只允许读取一定长度数据 的目的。&lt;/p&gt;

&lt;p&gt;在 io 包中，LimitReader 函数的实现其实就是调用 LimitedReader：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func LimitReader(r Reader, n int64) Reader { return &amp;amp;LimitedReader{r, n} }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pipereader-和-pipewriter-类型&#34;&gt;PipeReader 和 PipeWriter 类型&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;PipeReader&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;PipeReader（一个没有任何导出字段的 struct）是管道的读取端。它实现了 io.Reader 和 io.Closer 接口。结构定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type PipeReader struct {
    p *pipe
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;关于 PipeReader.Read 方法的说明：从管道中读取数据。该方法会堵塞，直到管道写入端开始写入数据或写入端被关闭。如果写入端关闭时带有 error（即调用 CloseWithError 关闭），该Read返回的 err 就是写入端传递的error；否则 err 为 EOF。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;PipeWriter&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;PipeWriter（一个没有任何导出字段的 struct）是管道的写入端。它实现了 io.Writer 和 io.Closer 接口。结构定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type PipeWriter struct {
    p *pipe
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;关于 PipeWriter.Write 方法的说明：写数据到管道中。该方法会堵塞，直到管道读取端读完所有数据或读取端被关闭。如果读取端关闭时带有 error（即调用 CloseWithError 关闭），该Write返回的 err 就是读取端传递的error；否则 err 为 ErrClosedPipe。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Pipe&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;io.Pipe() 用于创建一个同步的内存管道 (synchronous in-memory pipe)，函数签名：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Pipe() (*PipeReader, *PipeWriter)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;它将 io.Reader 连接到 io.Writer。一端的读取匹配另一端的写入，直接在这两端之间复制数据；它没有内部缓存。它对于并行调用 Read 和 Write 以及其它函数或 Close 来说都是安全的。一旦等待的 I/O 结束，Close 就会完成。并行调用 Read 或并行调用 Write 也同样安全：同种类的调用将按顺序进行控制。&lt;/p&gt;

&lt;p&gt;正因为是同步的，因此不能在一个 goroutine 中进行读和写。&lt;/p&gt;

&lt;p&gt;读关闭管道&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (r *PipeReader) Close() error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;读关闭管道并传入错误信息。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (r *PipeReader) CloseWithError(err error) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从管道中读取数据，如果管道被关闭，则会返会一个错误信息：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1、如果写入端通过 CloseWithError 方法关闭了管道，则返回关闭时传入的错误信息。&lt;/li&gt;
&lt;li&gt;2、如果写入端通过 Close 方法关闭了管道，则返回 io.EOF。&lt;/li&gt;
&lt;li&gt;3、如果是读取端关闭了管道，则返回 io.ErrClosedPipe。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;示例：管道（读取端关闭）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    r, w := io.Pipe()
    // 启用一个例程进行读取
    go func() {
        buf := make([]byte, 5)
        for n, err := 0, error(nil); err == nil; {
            n, err = r.Read(buf)
            r.CloseWithError(errors.New(&amp;quot;管道被读取端关闭&amp;quot;))
            fmt.Printf(&amp;quot;读取：%d, %v, %s\n&amp;quot;, n, err, buf[:n])
        }
    }()
    // 主例程进行写入
    n, err := w.Write([]byte(&amp;quot;Hello World !&amp;quot;))
    fmt.Printf(&amp;quot;写入：%d, %v\n&amp;quot;, n, err)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;写关闭管道&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (w *PipeWriter) Close() error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;写关闭管道并传入错误信息。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (w *PipeWriter) CloseWithError(err error) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;向管道中写入数据，如果管道被关闭，则会返会一个错误信息：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1、如果读取端通过 CloseWithError 方法关闭了管道，则返回关闭时传入的错误信息。&lt;/li&gt;
&lt;li&gt;2、如果读取端通过 Close 方法关闭了管道，则返回 io.ErrClosedPipe。&lt;/li&gt;
&lt;li&gt;3、如果是写入端关闭了管道，则返回 io.ErrClosedPipe。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;示例：管道（写入端关闭）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    r, w := io.Pipe()
    // 启用一个例程进行读取
    go func() {
        buf := make([]byte, 5)
        for n, err := 0, error(nil); err == nil; {
            n, err = r.Read(buf)
            fmt.Printf(&amp;quot;读取：%d, %v, %s\n&amp;quot;, n, err, buf[:n])
        }
    }()
    // 主例程进行写入
    n, err := w.Write([]byte(&amp;quot;Hello World !&amp;quot;))
    fmt.Printf(&amp;quot;写入：%d, %v\n&amp;quot;, n, err)

    w.CloseWithError(errors.New(&amp;quot;管道被写入端关闭&amp;quot;))
    n, err = w.Write([]byte(&amp;quot;Hello World !&amp;quot;))
    fmt.Printf(&amp;quot;写入：%d, %v\n&amp;quot;, n, err)
    time.Sleep(time.Second * 1)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;综合使用实例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    pipeReader, pipeWriter := io.Pipe()
    go PipeWrite(pipeWriter)
    go PipeRead(pipeReader)
    time.Sleep(30 * time.Second)
}

func PipeWrite(writer *io.PipeWriter){
    data := []byte(&amp;quot;Go语言中文网&amp;quot;)
    for i := 0; i &amp;lt; 3; i++{
        n, err := writer.Write(data)
        if err != nil{
            fmt.Println(err)
            return
        }
        fmt.Printf(&amp;quot;写入字节 %d\n&amp;quot;,n)
    }
    writer.CloseWithError(errors.New(&amp;quot;写入段已关闭&amp;quot;))
}

func PipeRead(reader *io.PipeReader){
    buf := make([]byte, 128)
    for{
        fmt.Println(&amp;quot;接口端开始阻塞5秒钟...&amp;quot;)
        time.Sleep(5 * time.Second)
        fmt.Println(&amp;quot;接收端开始接受&amp;quot;)
        n, err := reader.Read(buf)
        if err != nil{
            fmt.Println(err)
            return
        }
        fmt.Printf(&amp;quot;收到字节: %d\n buf内容: %s\n&amp;quot;,n,buf)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;函数&#34;&gt;函数&lt;/h1&gt;

&lt;p&gt;io包中也有一下原生实现可以使用的函数。其实都是直接操作结构体的函数。&lt;/p&gt;

&lt;h2 id=&#34;writestring&#34;&gt;WriteString&lt;/h2&gt;

&lt;p&gt;WriteString 将字符串 s 写入到 w 中，返回写入的字节数和遇到的错误。如果 w 实现了 WriteString 方法，则优先使用该方法将 s 写入 w 中。否则，将 s 转换为 []byte，然后调用 w.Write 方法将数据写入 w 中。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func WriteString(w Writer, s string) (n int, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;readatleast&#34;&gt;ReadAtLeast&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;ReadAtLeast&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ReadAtLeast 从 r 中读取数据到 buf 中，要求至少读取 min 个字节。返回读取的字节数和遇到的错误。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func ReadAtLeast(r Reader, buf []byte, min int) (n int, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果 min 超出了 buf 的容量，则 err 返回 io.ErrShortBuffer，否则：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1、读出的数据长度 == 0  ，则 err 返回 EOF。&lt;/li&gt;
&lt;li&gt;2、读出的数据长度 &amp;lt;  min，则 err 返回 io.ErrUnexpectedEOF。&lt;/li&gt;
&lt;li&gt;3、读出的数据长度 &amp;gt;= min，则 err 返回 nil。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;ReadFull&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ReadFull 的功能和 ReadAtLeast 一样，只不过 min = len(buf)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func ReadFull(r Reader, buf []byte) (n int, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例：WriteString、ReadAtLeast、ReadFull&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    io.WriteString(os.Stdout, &amp;quot;Hello World!\n&amp;quot;)
    // Hello World!

    r := strings.NewReader(&amp;quot;Hello World!&amp;quot;)
    b := make([]byte, 15)

    n, err := io.ReadAtLeast(r, b, 20)
    fmt.Printf(&amp;quot;%q   %d   %v\n&amp;quot;, b[:n], n, err)
    // &amp;quot;&amp;quot;   0   short buffer

    r.Seek(0, 0)
    b = make([]byte, 15)

    n, err = io.ReadFull(r, b)
    fmt.Printf(&amp;quot;%q   %d   %v\n&amp;quot;, b[:n], n, err)
    // &amp;quot;Hello World!&amp;quot;   12   unexpected EOF
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;LimitReader&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;LimitReader 对 r 进行封装，使其最多只能读取 n 个字节的数据。相当于对 r 做了一个切片 r[:n] 返回。底层实现是一个 *LimitedReader（只有一个 Read 方法）。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func LimitReader(r Reader, n int64) Reader
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;MultiReader&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;MultiReader 将多个 Reader 封装成一个单独的 Reader，多个 Reader 会按顺序读取，当多个 Reader 都返回 EOF 之后，单独的 Reader 才返回 EOF，否则返回读取过程中遇到的任何错误。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func MultiReader(readers ...Reader) Reader
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;MultiWriter&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;MultiWriter 将向自身写入的数据同步写入到所有 writers 中。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func MultiWriter(writers ...Writer) Writer
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;TeeReader&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;TeeReader 对 r 进行封装，使 r 在读取数据的同时，自动向 w 中写入数据。它是一个无缓冲的 Reader，所以对 w 的写入操作必须在 r 的 Read 操作结束之前完成。所有写入时遇到的错误都会被作为 Read 方法的 err 返回。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func TeeReader(r Reader, w Writer) Reader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例 LimitReader&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    r := strings.NewReader(&amp;quot;Hello World!&amp;quot;)
    lr := io.LimitReader(r, 5)

    n, err := io.Copy(os.Stdout, lr)  // Hello
    fmt.Printf(&amp;quot;\n%d   %v\n&amp;quot;, n, err) // 5   &amp;lt;nil&amp;gt;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例 MultiReader&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    r1 := strings.NewReader(&amp;quot;Hello World!&amp;quot;)
    r2 := strings.NewReader(&amp;quot;ABCDEFG&amp;quot;)
    r3 := strings.NewReader(&amp;quot;abcdefg&amp;quot;)
    b := make([]byte, 15)
    mr := io.MultiReader(r1, r2, r3)

    for n, err := 0, error(nil); err == nil; {
        n, err = mr.Read(b)
        fmt.Printf(&amp;quot;%q\n&amp;quot;, b[:n])
    }
    // &amp;quot;Hello World!&amp;quot;
    // &amp;quot;ABCDEFG&amp;quot;
    // &amp;quot;abcdefg&amp;quot;
    // &amp;quot;&amp;quot;

    r1.Seek(0, 0)
    r2.Seek(0, 0)
    r3.Seek(0, 0)
    mr = io.MultiReader(r1, r2, r3)
    io.Copy(os.Stdout, mr)
    // Hello World!ABCDEFGabcdefg
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例 MultiWriter&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    r := strings.NewReader(&amp;quot;Hello World!\n&amp;quot;)
    mw := io.MultiWriter(os.Stdout, os.Stdout, os.Stdout)

    r.WriteTo(mw)
    // Hello World!
    // Hello World!
    // Hello World!
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例 TeeReader&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    r := strings.NewReader(&amp;quot;Hello World!&amp;quot;)
    b := make([]byte, 15)
    tr := io.TeeReader(r, os.Stdout)

    n, err := tr.Read(b)                  // Hello World!
    fmt.Printf(&amp;quot;\n%s   %v\n&amp;quot;, b[:n], err) // Hello World!   &amp;lt;nil&amp;gt;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;copy&#34;&gt;Copy&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;CopyN&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;CopyN 从 src 中复制 n 个字节的数据到 dst 中，返回复制的字节数和遇到的错误。只有当 written = n 时，err 才返回 nil。如果 dst 实现了 ReadFrom 方法，则优先调用该方法执行复制操作。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func CopyN(dst Writer, src Reader, n int64) (written int64, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Copy&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Copy 从 src 中复制数据到 dst 中，直到所有数据都复制完毕，返回复制的字节数和遇到的错误。如果复制过程成功结束，则 err 返回 nil，而不是 EOF，因为 Copy 的定义为“直到所有数据都复制完毕”，所以不会将 EOF 视为错误返回。如果 src 实现了 WriteTo 方法，则调用 src.WriteTo(dst) 复制数据，否则如果 dst 实现了 ReadeFrom 方法，则调用 dst.ReadeFrom(src) 复制数据&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Copy(dst Writer, src Reader) (written int64, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;CopyBuffer&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;CopyBuffer 相当于 Copy，只不 Copy 在执行的过程中会创建一个临时的缓冲区来中转数据，而 CopyBuffer 则可以单独提供一个缓冲区，让多个复制操作共用同一个缓冲区，避免每次复制操作都创建新的缓冲区。如果 buf == nil，则 CopyBuffer 会自动创建缓冲区。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func CopyBuffer(dst Writer, src Reader, buf []byte) (written int64, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例：CopyN、Copy、CopyBuffer&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    r := strings.NewReader(&amp;quot;Hello World!&amp;quot;)
    buf := make([]byte, 32)

    n, err := io.CopyN(os.Stdout, r, 5) // Hello
    fmt.Printf(&amp;quot;\n%d   %v\n\n&amp;quot;, n, err) // 5   &amp;lt;nil&amp;gt;

    r.Seek(0, 0)
    n, err = io.Copy(os.Stdout, r)      // Hello World!
    fmt.Printf(&amp;quot;\n%d   %v\n\n&amp;quot;, n, err) // 12   &amp;lt;nil&amp;gt;

    r.Seek(0, 0)
    r2 := strings.NewReader(&amp;quot;ABCDEFG&amp;quot;)
    r3 := strings.NewReader(&amp;quot;abcdefg&amp;quot;)

    n, err = io.CopyBuffer(os.Stdout, r, buf) // Hello World!
    fmt.Printf(&amp;quot;\n%d   %v\n&amp;quot;, n, err)         // 12   &amp;lt;nil&amp;gt;

    n, err = io.CopyBuffer(os.Stdout, r2, buf) // ABCDEFG
    fmt.Printf(&amp;quot;\n%d   %v\n&amp;quot;, n, err)          // 7   &amp;lt;nil&amp;gt;

    n, err = io.CopyBuffer(os.Stdout, r3, buf) // abcdefg
    fmt.Printf(&amp;quot;\n%d   %v\n&amp;quot;, n, err)          // 7   &amp;lt;nil&amp;gt;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个函数还是我们在网络消息流量转发的时候还是经常使用的。&lt;/p&gt;

&lt;h1 id=&#34;场景举例&#34;&gt;场景举例&lt;/h1&gt;

&lt;h2 id=&#34;base64编码成字符串&#34;&gt;base64编码成字符串&lt;/h2&gt;

&lt;p&gt;encoding/base64包中：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewEncoder(enc *Encoding, w io.Writer) io.WriteCloser
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个用来做base64编码，但是仔细观察发现，它需要一个io.Writer作为输出目标，并用返回的WriteCloser的Write方法将结果写入目标，下面是Go官方文档的例子&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;input := []byte(&amp;quot;foo\x00bar&amp;quot;)
encoder := base64.NewEncoder(base64.StdEncoding, os.Stdout)
encoder.Write(input)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个例子是将结果写入到Stdout，如果我们希望得到一个字符串呢？可以用bytes.Buffer作为目标io.Writer：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;input := []byte(&amp;quot;foo\x00bar&amp;quot;)
buffer := new(bytes.Buffer)
encoder := base64.NewEncoder(base64.StdEncoding, buffer)
encoder.Write(input)
fmt.Println(string(buffer.Bytes())
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;byte和struct之间正反序列化&#34;&gt;[]byte和struct之间正反序列化&lt;/h2&gt;

&lt;p&gt;这种场景经常用在基于字节的协议上，比如有一个具有固定长度的结构：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Protocol struct {
    Version     uint8
    BodyLen     uint16
    Reserved    [2]byte
    Unit        uint8
    Value       uint32
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过一个[]byte来反序列化得到这个Protocol，一种思路是遍历这个[]byte，然后逐一赋值。其实在encoding/binary包中有个方便的方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Read(r io.Reader, order ByteOrder, data interface{}) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个方法从一个io.Reader中读取字节，并已order指定的端模式，来给填充data（data需要是fixed-sized的结构或者类型）。要用到这个方法首先要有一个io.Reader，从上面的图中不难发现，我们可以这么写：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var p Protocol
var bin []byte
//...
binary.Read(bytes.NewReader(bin), binary.LittleEndian, &amp;amp;p)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;换句话说，我们将一个[]byte转成了一个io.Reader。&lt;/p&gt;

&lt;p&gt;反过来，我们需要将Protocol序列化得到[]byte，使用encoding/binary包中有个对应的Write方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Write(w io.Writer, order ByteOrder, data interface{}) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过将[]byte转成一个io.Writer即可：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var p Protocol
buffer := new(bytes.Buffer)
//...
binary.Writer(buffer, binary.LittleEndian, p)
bin := buffer.Bytes()
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;从流中按行读取&#34;&gt;从流中按行读取&lt;/h2&gt;

&lt;p&gt;比如对于常见的基于文本行的HTTP协议的读取，我们需要将一个流按照行来读取。本质上，我们需要一个基于缓冲的读写机制（读一些到缓冲，然后遍历缓冲中我们关心的字节或字符）。在Go中有一个bufio的包可以实现带缓冲的读写：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewReader(rd io.Reader) *Reader
func (b *Reader) ReadString(delim byte) (string, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个ReadString方法从io.Reader中读取字符串，直到delim，就返回delim和之前的字符串。如果将delim设置为\n，相当于按行来读取了：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var conn net.Conn
//...
reader := NewReader(conn)
for {
    line, err := reader.ReadString([]byte(&#39;\n&#39;))
    //...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;string-to-byte&#34;&gt;string to byte&lt;/h2&gt;

&lt;p&gt;花式技（zuo）巧（si）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;string转[]byte
a := &amp;quot;Hello, playground&amp;quot;
fmt.Println([]byte(a))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;等价于&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a := &amp;quot;Hello, playground&amp;quot;
buf := new(bytes.Buffer)
buf.ReadFrom(strings.NewReader(a))
fmt.Println(buf.Bytes())
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;标准库中实现的读取器和编写器的实例&#34;&gt;标准库中实现的读取器和编写器的实例&lt;/h1&gt;

&lt;p&gt;目前，Go 文档中还没有直接列出实现了某个接口的所有类型。不过，我们可以通过查看标准库文档，列出实现了 io.Reader 或 io.Writer 接口的类型（导出的类型）：（注：godoc 命令支持额外参数 -analysis ，能列出都有哪些类型实现了某个接口，相关参考 godoc -h 或 Static analysis features of godoc。另外，还有一个地址：&lt;a href=&#34;http://docs.studygolang.com。&#34;&gt;http://docs.studygolang.com。&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kingjcy.github.io/post/golang/go-os/&#34;&gt;os.File&lt;/a&gt; 同时实现了 io.Reader 和 io.Writer&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kingjcy.github.io/post/golang/go-strings/#reader-类型&#34;&gt;strings.Reader&lt;/a&gt; 实现了 io.Reader&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kingjcy.github.io/post/golang/go-bufio/&#34;&gt;bufio.Reader/Writer&lt;/a&gt; 分别实现了 io.Reader 和 io.Writer&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kingjcy.github.io/post/golang/go-bytes/&#34;&gt;bytes.Buffer&lt;/a&gt; 同时实现了 io.Reader 和 io.Writer&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kingjcy.github.io/post/golang/go-bytes/&#34;&gt;bytes.Reader&lt;/a&gt; 实现了 io.Reader&lt;/li&gt;
&lt;li&gt;compress/gzip.Reader/Writer 分别实现了 io.Reader 和 io.Writer&lt;/li&gt;
&lt;li&gt;crypto/cipher.StreamReader/StreamWriter 分别实现了 io.Reader 和 io.Writer&lt;/li&gt;
&lt;li&gt;crypto/tls.Conn 同时实现了 io.Reader 和 io.Writer&lt;/li&gt;
&lt;li&gt;encoding/csv.Reader/Writer 分别实现了 io.Reader 和 io.Writer&lt;/li&gt;
&lt;li&gt;mime/multipart.Part 实现了 io.Reader&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kingjcy.github.io/post/golang/go-net/&#34;&gt;net.Conn&lt;/a&gt; 分别实现了 io.Reader 和 io.Writer(Conn接口定义了Read/Write)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;除此之外，io 包本身也有这两个接口的实现类型。如：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;实现了 Reader 的类型：&lt;a href=&#34;#limitedreader-类型&#34;&gt;LimitedReader&lt;/a&gt;、&lt;a href=&#34;#pipereader-和-pipewriter-类型&#34;&gt;PipeReader&lt;/a&gt;、&lt;a href=&#34;#sectionreader-类型&#34;&gt;SectionReader&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;实现了 Writer 的类型：&lt;a href=&#34;#pipereader-和-pipewriter-类型&#34;&gt;PipeWriter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以上类型中，常用的类型有，文件IO，缓冲IO，网络IO，在标准库中都有实现&lt;/p&gt;

&lt;p&gt;网络io/文件io/标准io&amp;ndash;其实就是操作网络数据和文件中的数据
- &lt;a href=&#34;https://kingjcy.github.io/post/golang/go-net/&#34;&gt;net.Conn&lt;/a&gt;, &lt;a href=&#34;https://kingjcy.github.io/post/golang/go-os/&#34;&gt;os.Stdin&lt;/a&gt;, &lt;a href=&#34;https://kingjcy.github.io/post/golang/go-os/&#34;&gt;os.File&lt;/a&gt;: 网络、标准输入输出、文件的流读取，对应&amp;mdash;frp就是基于这个基础上实现的&lt;/p&gt;

&lt;p&gt;缓存io&amp;ndash;其实就是操作缓存中的string，[]byte
- &lt;a href=&#34;https://kingjcy.github.io/post/golang/go-strings/#reader-类型&#34;&gt;strings.Reader&lt;/a&gt;，&lt;a href=&#34;https://kingjcy.github.io/post/golang/go-strings/#builder-类型&#34;&gt;strings.Builder&lt;/a&gt;: 把字符串抽象成Reader
- &lt;a href=&#34;https://kingjcy.github.io/post/golang/go-bytes/#reader-类型&#34;&gt;bytes.Reader&lt;/a&gt;: 把[]byte抽象成Reader
- &lt;a href=&#34;https://kingjcy.github.io/post/golang/go-bytes/#buffer-类型&#34;&gt;bytes.Buffer&lt;/a&gt;: 把[]byte抽象成Reader和Writer&lt;/p&gt;

&lt;p&gt;缓存io&amp;ndash;还是使用缓存，但是主要是对io.reader实例进行读写
- &lt;a href=&#34;https://kingjcy.github.io/post/golang/go-bufio/&#34;&gt;bufio.Reader/Writer&lt;/a&gt;: 抽象成带缓冲的流读取（比如按行读写）&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Golang使用系列---- Go Net 协议层</title>
          <link>https://kingjcy.github.io/post/golang/go-net/</link>
          <pubDate>Mon, 11 Jul 2016 17:34:34 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/golang/go-net/</guid>
          <description>&lt;p&gt;网络编程是go语言使用的一个核心模块。golang的网络封装使用对于底层socket或者上层的http，甚至是web服务都很友好。&lt;/p&gt;

&lt;h1 id=&#34;net&#34;&gt;net&lt;/h1&gt;

&lt;p&gt;net包提供了可移植的网络I/O接口，包括TCP/IP、UDP、域名解析和Unix域socket等方式的通信。其中每一种通信方式都使用 xxConn 结构体来表示，诸如IPConn、TCPConn等，这些结构体都实现了Conn接口，Conn接口实现了基本的读、写、关闭、获取远程和本地地址、设置timeout等功能。&lt;/p&gt;

&lt;p&gt;conn的接口定义&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Conn interface {
    // Read从连接中读取数据
    // Read方法可能会在超过某个固定时间限制后超时返回错误，该错误的Timeout()方法返回真
    Read(b []byte) (n int, err error)
    // Write从连接中写入数据
    // Write方法可能会在超过某个固定时间限制后超时返回错误，该错误的Timeout()方法返回真
    Write(b []byte) (n int, err error)
    // Close方法关闭该连接
    // 并会导致任何阻塞中的Read或Write方法不再阻塞并返回错误
    Close() error
    // 返回本地网络地址
    LocalAddr() Addr
    // 返回远端网络地址
    RemoteAddr() Addr
    // 设定该连接的读写deadline，等价于同时调用SetReadDeadline和SetWriteDeadline
    // deadline是一个绝对时间，超过该时间后I/O操作就会直接因超时失败返回而不会阻塞
    // deadline对之后的所有I/O操作都起效，而不仅仅是下一次的读或写操作
    // 参数t为零值表示不设置期限
    SetDeadline(t time.Time) error
    // 设定该连接的读操作deadline，参数t为零值表示不设置期限
    SetReadDeadline(t time.Time) error
    // 设定该连接的写操作deadline，参数t为零值表示不设置期限
    // 即使写入超时，返回值n也可能&amp;gt;0，说明成功写入了部分数据
    SetWriteDeadline(t time.Time) error
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后每种类型都是对应的结构体实现这些接口。&lt;/p&gt;

&lt;p&gt;还有一个常用的接口定义PacketConn&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type PacketConn interface {
    // ReadFrom方法从连接读取一个数据包，并将有效信息写入b
    // ReadFrom方法可能会在超过某个固定时间限制后超时返回错误，该错误的Timeout()方法返回真
    // 返回写入的字节数和该数据包的来源地址
    ReadFrom(b []byte) (n int, addr Addr, err error)
    // WriteTo方法将有效数据b写入一个数据包发送给addr
    // WriteTo方法可能会在超过某个固定时间限制后超时返回错误，该错误的Timeout()方法返回真
    // 在面向数据包的连接中，写入超时非常罕见
    WriteTo(b []byte, addr Addr) (n int, err error)
    // Close方法关闭该连接
    // 会导致任何阻塞中的ReadFrom或WriteTo方法不再阻塞并返回错误
    Close() error
    // 返回本地网络地址
    LocalAddr() Addr
    // 设定该连接的读写deadline
    SetDeadline(t time.Time) error
    // 设定该连接的读操作deadline，参数t为零值表示不设置期限
    // 如果时间到达deadline，读操作就会直接因超时失败返回而不会阻塞
    SetReadDeadline(t time.Time) error
    // 设定该连接的写操作deadline，参数t为零值表示不设置期限
    // 如果时间到达deadline，写操作就会直接因超时失败返回而不会阻塞
    // 即使写入超时，返回值n也可能&amp;gt;0，说明成功写入了部分数据
    SetWriteDeadline(t time.Time) error
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ip&#34;&gt;ip&lt;/h2&gt;

&lt;p&gt;使用IPConn结构体来表示，它实现了Conn、PacketConn两种接口。使用如下两个函数进行Dial（连接）和Listen（监听）。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func DialIP(netProto string, laddr, raddr *IPAddr) (*IPConn, error)   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;DialIP在网络协议netProto上连接本地地址laddr和远端地址raddr，netProto必须是&amp;rdquo;ip&amp;rdquo;、&amp;rdquo;ip4&amp;rdquo;或&amp;rdquo;ip6&amp;rdquo;后跟冒号和协议名或协议号。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func ListenIP(netProto string, laddr *IPAddr) (*IPConn, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ListenIP创建一个接收目的地是本地地址laddr的IP数据包的网络连接，返回的*IPConn的ReadFrom和WriteTo方法可以用来发送和接收IP数据包。（每个包都可获取来源址或者设置目标地址）&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;类型&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;1、IPAddr类型&lt;/p&gt;

&lt;p&gt;位于iprawsock.go中在net包的许多函数和方法会返回一个指向IPAddr的指针。这不过只是一个包含IP类型的结构体。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type IPAddr struct {
    IP   IP
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个类型的另一个主要用途是通过IP主机名执行DNS查找。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ResolveIPAddr
ResolveIPAddr有两个参数第一个参数.必须为&amp;quot;ip&amp;quot;,&amp;quot;ip4&amp;quot;,&amp;quot;ip6&amp;quot;,第二个参数多为要解析的域名.返回一个IPAddr的指针类型

addr, _ := net.ResolveIPAddr(&amp;quot;ip&amp;quot;, &amp;quot;www.baidu.com&amp;quot;)
fmt.Println(addr)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ip.go 中还定义了三个类型.分别是IP,IPMask,IPNet&lt;/p&gt;

&lt;p&gt;2、IP类型&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type IP []byte
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;IP类型被定义为一个字节数组。 ParseIP(String) 可以将字符窜转换为一个IP类型.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;name := &amp;quot;127.0.0.1&amp;quot;
addr := net.ParseIP(name)
fmt.Println(addr.IsLoopback())// IsLoopback reports whether ip is a loopback address.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3、IPMask类型&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// An IP mask is an IP address.
type IPMask []byte
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一个掩码的字符串形式是一个十六进制数，如掩码255.255.0.0为ffff0000。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func IPv4Mask(a, b, c, d byte) IPMask :用一个4字节的IPv4地址来创建一个掩码.
func CIDRMask(ones, bits int) IPMask : 用ones和bits来创建一个掩码
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4、IPNet类型&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// An IPNet represents an IP network.
type IPNet struct {
    IP   IP     // network number
    Mask IPMask // network mask
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由IP类型和IPMask组成一个网段,其字符串形式是CIDR地址,如:“192.168.100.1/24”或“2001:DB8::/ 48”&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    mask := net.IPv4Mask(byte(255), byte(255), byte(255), byte(0))
    ip := net.ParseIP(&amp;quot;192.168.1.125&amp;quot;).Mask(mask)
    in := &amp;amp;net.IPNet{ip, mask}
    fmt.Println(in)         //  192.168.1.0/24
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;实例&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这边插播一个经常使用的实例：获取本地IP&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main
import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;net&amp;quot;
    &amp;quot;os&amp;quot;
)
func main() {
    addrs, err := net.InterfaceAddrs()
    if err != nil {
        fmt.Println(err)
        os.Exit(1)
    }
    for _, address := range addrs {
        // 检查ip地址判断是否回环地址
        if ipnet, ok := address.(*net.IPNet); ok &amp;amp;&amp;amp; !ipnet.IP.IsLoopback() {
            if ipnet.IP.To4() != nil {
                fmt.Println(ipnet.IP.String())
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tcp&#34;&gt;tcp&lt;/h2&gt;

&lt;p&gt;使用TCPConn结构体来表示，它实现了Conn接口。&lt;/p&gt;

&lt;p&gt;使用DialTCP进行Dial操作：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func DialTCP(net string, laddr, raddr *TCPAddr) (*TCPConn, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;DialTCP在网络协议net上连接本地地址laddr和远端地址raddr。net必须是&amp;rdquo;tcp&amp;rdquo;、&amp;rdquo;tcp4&amp;rdquo;、&amp;rdquo;tcp6&amp;rdquo;；如果laddr不是nil，将使用它作为本地地址，否则自动选择一个本地地址。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func ListenTCP(net string, laddr *TCPAddr) (*TCPListener, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 ListenTCP函数进行Listen，产生一个TCPListener结构体，使用TCPListener的AcceptTCP方法建立通信链路，得到TCPConn。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;TCPAddr类型&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;位于tcpsock.go中TCPAddr类型包含一个IP和一个port的结构:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type TCPAddr struct {
    IP   IP
    Port int
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ResolveTCPAddr&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func ResolveTCPAddr(net, addr string) (*TCPAddr, os.Error) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该函数用来创建一个TCPAddr,第一个参数为,tcp,tcp4或者tcp6,addr是一个字符串，由主机名或IP地址，以及&amp;rdquo;:&amp;ldquo;后跟随着端口号组成，例如： &amp;ldquo;www.google.com:80&amp;rdquo; 或 &amp;lsquo;127.0.0.1:22&amp;rdquo;。如果地址是一个IPv6地址，由于已经有冒号，主机部分，必须放在方括号内, 例如：&amp;rdquo;[::1]:23&amp;rdquo;. 另一种特殊情况是经常用于服务器, 主机地址为0, 因此，TCP地址实际上就是端口名称, 例如：&amp;rdquo;:80&amp;rdquo; 用来表示HTTP服务器。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;addr, _ := net.ResolveTCPAddr(&amp;quot;tcp&amp;quot;, &amp;quot;www.baidu.com:80&amp;quot;)
fmt.Println(addr)   //220.181.111.147:80
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;udp&#34;&gt;udp&lt;/h2&gt;

&lt;p&gt;使用UDPConn接口体来表示，它实现了Conn、PacketConn两种接口。使用如下两个函数进行Dial和Listen。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func DialUDP(net string, laddr, raddr *UDPAddr) (*UDPConn, error)    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;DialTCP在网络协议net上连接本地地址laddr和远端地址raddr。net必须是&amp;rdquo;udp&amp;rdquo;、&amp;rdquo;udp4&amp;rdquo;、&amp;rdquo;udp6&amp;rdquo;；如果laddr不是nil，将使用它作为本地地址，否则自动选择一个本地地址。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func ListenUDP(net string, laddr *UDPAddr) (*UDPConn, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ListenUDP创建一个接收目的地是本地地址laddr的UDP数据包的网络连接。net必须是&amp;rdquo;udp&amp;rdquo;、&amp;rdquo;udp4&amp;rdquo;、&amp;rdquo;udp6&amp;rdquo;；如果laddr端口为0，函数将选择一个当前可用的端口，可以用Listener的Addr方法获得该端口。返回的*UDPConn的ReadFrom和WriteTo方法可以用来发送和接收UDP数据包（每个包都可获得来源地址或设置目标地址）。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;类型&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;1、UDPAddr类型&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type UDPAddr struct {
    IP   IP
    Port int
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ResolveUDPAddr同样的功能&lt;/p&gt;

&lt;p&gt;2、UnixAddr类型&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type UnixAddr struct {
    Name string
    Net  string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ResolveUnixAddr同样的功能&lt;/p&gt;

&lt;h2 id=&#34;unix&#34;&gt;unix&lt;/h2&gt;

&lt;p&gt;UnixConn实现了Conn、PacketConn两种接口，其中unix又分为SOCK_DGRAM、SOCK_STREAM。&lt;/p&gt;

&lt;p&gt;1.对于unix（SOCK_DGRAM），使用如下两个函数进行Dial和Listen。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func DialUnix(net string, laddr, raddr *UnixAddr) (*UnixConn, error)    

func ListenUnixgram(net string, laddr *UnixAddr) (*UnixConn, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.对于unix（SOCK_STREAM）&lt;/p&gt;

&lt;p&gt;客户端使用DialUnix进行Dial操作&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func DialUnix(net string, laddr, raddr *UnixAddr) (*UnixConn, error)   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;服务端使用ListenUnix函数进行Listen操作，然后使用UnixListener进行AcceptUnix&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func ListenUnix(net string, laddr *UnixAddr) (*UnixListener, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;函数整合&#34;&gt;函数整合&lt;/h1&gt;

&lt;p&gt;为了使用方便，golang将上面一些重复的操作集中到一个函数中。在参数中制定上面不同协议类型。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func ListenPacket(net, laddr string) (PacketConn, error)　
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个函数用于侦听ip、udp、unix（DGRAM）等协议，返回一个PacketConn接口，同样根据侦听的协议不同，这个接口可以包含IPCon、UDPConn、UnixConn等，它们都实现了PacketConn。可以发现与ip、unix（stream）协议不同，直接返回的是xxConn，不是间接的通过Listener进行Accept操作后，才得到一个Conn。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Listen(net, laddr string) (Listener, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个函数用于侦听tcp、unix（stream）等协议，返回一个Listener接口、根据侦听的协议不同，这个接口可以包含TCPListener、UnixListener等，它们都实现了Listener接口，然后通过调用其Accept方法可以得到Conn接口，进行通信。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Dial(network, address string) (Conn, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个函数对于所有的协议都是相同的操作，返回一个Conn接口，根据协议的不同实际上包含IPConn、UDPConn、UnixConn、IPConn，它们都实现了Conn接口&lt;/p&gt;

&lt;h1 id=&#34;基本c-s功能&#34;&gt;基本c/s功能&lt;/h1&gt;

&lt;p&gt;在 Unix/Linux 中的 Socket 编程主要通过调用 listen, accept, write read 等函数来实现的. 具体如下图所示:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/golang/net/unix_socket.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;服务端&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;服务端listen, accept&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func connHandler(c net.Conn) {
    for {
        cnt, err := c.Read(buf)
        c.Write(buf)
    }
}
func main() {
    server, err := net.Listen(&amp;quot;tcp&amp;quot;, &amp;quot;:1208&amp;quot;)
    for {
        conn, err := server.Accept()
        go connHandler(conn)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;直接使用net的listen返回的就是对应协议已经定义好的结构体，比如tcp&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type TCPListener struct {
    fd *netFD
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个结构体实现了listener接口的所有接口，所以可以作为返回值返回。其他协议类型也是一样。&lt;/p&gt;

&lt;p&gt;accept后返回的conn是一个存储着连接信息的结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Network file descriptor.
type netFD struct {
    pfd poll.FD

    // immutable until Close
    family      int
    sotype      int
    isConnected bool // handshake completed or use of association with peer
    net         string
    laddr       Addr
    raddr       Addr
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;客户端&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;客户端dial&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func connHandler(c net.Conn) {
    for {
        c.Write(...)
        c.Read(...)
    }
}
func main() {
    conn, err := net.Dial(&amp;quot;tcp&amp;quot;, &amp;quot;localhost:1208&amp;quot;)
    connHandler(conn)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Dial(net, addr string) (Conn, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中net参数是网络协议的名字， addr参数是IP地址或域名，而端口号以“:”的形式跟随在地址
或域名的后面，端口号可选。如果连接成功，返回连接对象，否则返回error。&lt;/p&gt;

&lt;p&gt;Dial() 函数支持如下几种网络协议：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;tcp&amp;quot; 、 &amp;quot;tcp4&amp;quot; （仅限IPv4）、 &amp;quot;tcp6&amp;quot; （仅限IPv6）、 &amp;quot;udp&amp;quot; 、 &amp;quot;udp4&amp;quot;（仅限IPv4）、 &amp;quot;udp6&amp;quot;（仅限IPv6）、 &amp;quot;ip&amp;quot; 、 &amp;quot;ip4&amp;quot;（仅限IPv4）和&amp;quot;ip6&amp;quot;（仅限IPv6）。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以直接用相关协议的函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func DialTCP(net string, laddr, raddr *TCPAddr) (c *TCPConn, err error)
func DialUDP(net string, laddr, raddr *UDPAddr) (c *UDPConn, err error)
func DialIP(netProto string, laddr, raddr *IPAddr) (*IPConn, error)
func DialUnix(net string, laddr, raddr *UnixAddr) (c *UnixConn, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;特性功能&#34;&gt;特性功能&lt;/h2&gt;

&lt;p&gt;1、控制TCP连接&lt;/p&gt;

&lt;p&gt;TCP连接有很多控制函数，我们平常用到比较多的有如下几个函数：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *TCPConn) SetTimeout(nsec int64) os.Error
func (c *TCPConn) SetKeepAlive(keepalive bool) os.Error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一个函数用来设置超时时间，客户端和服务器端都适用，当超过设置的时间时那么该链接就失效。&lt;/p&gt;

&lt;p&gt;第二个函数用来设置客户端是否和服务器端一直保持着连接，即使没有任何的数据发送&lt;/p&gt;

&lt;h1 id=&#34;实例&#34;&gt;实例&lt;/h1&gt;

&lt;p&gt;从零开始写Socket Server： Socket-Client框架&lt;/p&gt;

&lt;p&gt;在golang中，网络协议已经被封装的非常完好了，想要写一个Socket的Server，我们并不用像其他语言那样需要为socket、bind、listen、receive等一系列操作头疼，只要使用Golang中自带的net包即可很方便的完成连接等操作~&lt;/p&gt;

&lt;p&gt;在这里，给出一个最最基础的基于Socket的Server的写法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main
import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;net&amp;quot;
    &amp;quot;log&amp;quot;
    &amp;quot;os&amp;quot;
)


func main() {

//建立socket，监听端口
    netListen, err := net.Listen(&amp;quot;tcp&amp;quot;, &amp;quot;localhost:1024&amp;quot;)
    CheckError(err)
    defer netListen.Close()

    Log(&amp;quot;Waiting for clients&amp;quot;)
    for {
        conn, err := netListen.Accept()
        if err != nil {
            continue
        }

        Log(conn.RemoteAddr().String(), &amp;quot; tcp connect success&amp;quot;)
        handleConnection(conn)
    }
}
//处理连接
func handleConnection(conn net.Conn) {

    buffer := make([]byte, 2048)

    for {

        n, err := conn.Read(buffer)

        if err != nil {
            Log(conn.RemoteAddr().String(), &amp;quot; connection error: &amp;quot;, err)
            return
        }


        Log(conn.RemoteAddr().String(), &amp;quot;receive data string:\n&amp;quot;, string(buffer[:n]))

    }

}
func Log(v ...interface{}) {
    log.Println(v...)
}

func CheckError(err error) {
    if err != nil {
        fmt.Fprintf(os.Stderr, &amp;quot;Fatal error: %s&amp;quot;, err.Error())
        os.Exit(1)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;唔，抛除Go语言里面10行代码有5行error的蛋疼之处,你可以看到，Server想要建立并接受一个Socket，其核心流程就是&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;netListen, err := net.Listen(&amp;quot;tcp&amp;quot;, &amp;quot;localhost:1024&amp;quot;)
conn, err := netListen.Accept()
n, err := conn.Read(buffer)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这三步，通过Listen、Accept 和Read，我们就成功的绑定了一个端口，并能够读取从该端口传来的内容~&lt;/p&gt;

&lt;p&gt;这边插播一个内容，关于read是阻塞的，如果读取不到内容，代码会阻塞在这边，直到有内容可以读取，包括connection断掉返回的io.EOF,一般对这个都有特殊处理。一般重conn读取数据也是在for循环中。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;io&amp;quot;
    &amp;quot;net&amp;quot;
)

func main(){
    ln, err := net.Listen(&amp;quot;tcp&amp;quot;,&amp;quot;127.0.0.1:10051&amp;quot;)

    if err != nil {
        panic(err)
    }

    for {
        conn, _ := ln.Accept() //The loop will be held here
        fmt.Println(&amp;quot;get connect&amp;quot;)
        go handleread(conn)


    }
}

func handleread(conn net.Conn){
    defer conn.Close()

    var tatalBuffer  []byte
    var all int
    for {
        buffer := make([]byte, 2)
        n,err := conn.Read(buffer)
        if err == io.EOF{
            fmt.Println(err,n)
            break
        }

        tatalBuffer = append(tatalBuffer,buffer...)
        all += n

        fmt.Println(string(buffer),n,string(tatalBuffer[:all]),all)
    }



}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面这个例子中，会重conn中两个字符循环读取内容，这边slice不会动态扩容，所以需要使用append来获取全部内容。&lt;/p&gt;

&lt;p&gt;还有一点，buffer := make([]byte, 2)这个代码，放在for循环中，浪费内存，可以放在gor循环外部，然后使用n来截取buf[:n]可以解决buf最后一部分重复的问题。&lt;/p&gt;

&lt;p&gt;插播结束，回到server。&lt;/p&gt;

&lt;p&gt;Server写好之后，接下来就是Client方面啦，我手写一个HelloWorld给大家：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;net&amp;quot;
    &amp;quot;os&amp;quot;
)

func sender(conn net.Conn) {
        words := &amp;quot;hello world!&amp;quot;
        conn.Write([]byte(words))
    fmt.Println(&amp;quot;send over&amp;quot;)

}



func main() {
    server := &amp;quot;127.0.0.1:1024&amp;quot;
    tcpAddr, err := net.ResolveTCPAddr(&amp;quot;tcp4&amp;quot;, server)
    if err != nil {
        fmt.Fprintf(os.Stderr, &amp;quot;Fatal error: %s&amp;quot;, err.Error())
        os.Exit(1)
    }

    conn, err := net.DialTCP(&amp;quot;tcp&amp;quot;, nil, tcpAddr)
    if err != nil {
        fmt.Fprintf(os.Stderr, &amp;quot;Fatal error: %s&amp;quot;, err.Error())
        os.Exit(1)
    }


    fmt.Println(&amp;quot;connect success&amp;quot;)
    sender(conn)

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，Client这里的关键在于&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tcpAddr, err := net.ResolveTCPAddr(&amp;quot;tcp4&amp;quot;, server)
conn, err := net.DialTCP(&amp;quot;tcp&amp;quot;, nil, tcpAddr)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这两步，主要是负责解析端口和连接。&lt;/p&gt;

&lt;p&gt;这边插播一个tcp协议的三次握手图，加强理解。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/golang/net/tcp_open_close.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;扩展&#34;&gt;扩展&lt;/h1&gt;

&lt;p&gt;其实我们最常用的还是&lt;a href=&#34;https://kingjcy.github.io/post/golang/go-net-http/&#34;&gt;http协议&lt;/a&gt;，也即是应用层的协议，其实http协议是在tcp协议的基础上进行封装，最终还是使用的这边基本的网络IO，所以在网络传输中，网络IO的基本协议的实现是基础。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Golang使用系列---- Os</title>
          <link>https://kingjcy.github.io/post/golang/go-os/</link>
          <pubDate>Thu, 02 Jun 2016 09:52:35 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/golang/go-os/</guid>
          <description>&lt;p&gt;os包中实现了不依赖平台的操作系统函数接口(平台无关的接口)，设计向Unix风格，但是错误处理是go风格，当os包使用时，如果失败之后返回错误类型而不是错误数量,返回错误值而非错误码,可以包含更多信息。&lt;/p&gt;

&lt;h1 id=&#34;os&#34;&gt;os&lt;/h1&gt;

&lt;p&gt;os 依赖于 syscall。在实际编程中，我们应该总是优先使用 os 中提供的功能，而不是 syscall。&lt;/p&gt;

&lt;p&gt;os包提供了操作系统函数的不依赖平台的接口。一般都是linux下的一些基本命令的操作，比如文件，目录操作之类。&lt;/p&gt;

&lt;p&gt;我们运行程序常用的命令行参数就是在这个包中可以获取&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var Args []string
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Args保管了命令行参数，第一个是程序名。&lt;/p&gt;

&lt;h2 id=&#34;文件io&#34;&gt;文件io&lt;/h2&gt;

&lt;p&gt;文件IO就是对文件的读写操作，我们先了解一些os中的基本概念。&lt;/p&gt;

&lt;h3 id=&#34;基本概念&#34;&gt;基本概念&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;文件描述符&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;所有 I/O 操作以文件描述符 ( 一个非负整数 , 通常是小整数 ) 来指代打开的文件。文件描述符用以表示所有类型的已打开文件，包括管道（pipe）、FIFO、socket、终端、设备和普通文件。&lt;/p&gt;

&lt;p&gt;在 Go 中，文件描述符封装在 os.File 结构中，通过 File.Fd() 可以获得底层的文件描述符：fd。&lt;/p&gt;

&lt;p&gt;File结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type File struct {
    *file
}
// file is the real representation of *File.
// The extra level of indirection ensures that no clients of os
// can overwrite this data, which could cause the finalizer
// to close the wrong file descriptor.
type file struct {
    fd      int
    name    string
    dirinfo *dirInfo // nil unless directory being read
}

// Auxiliary information if the File describes a directory
type dirInfo struct {
    buf  []byte // buffer for directory I/O
    nbuf int    // length of buf; return value from Getdirentries
    bufp int    // location of next record in buf.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;标准定义&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;按照惯例，大多数程序都期望能够使用 3 种标准的文件描述符：0- 标准输入；1- 标准输出；2- 标准错误。os 包提供了 3 个 File 对象，分别代表这 3 种标准描述符：Stdin、Stdout 和 Stderr，它们对应的文件名分别是：/dev/stdin、/dev/stdout 和 /dev/stderr。&lt;/p&gt;

&lt;h3 id=&#34;基本操作&#34;&gt;基本操作&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;创建&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;func NewFile(fd uintptr, name string) *File
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NewFile使用给出的Unix文件描述符和名称创建一个文件。&lt;/p&gt;

&lt;p&gt;正常使用create来创建一个文件，比如文件不存在，就创建一个&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;file,er:=os.Open(&amp;quot;xxx&amp;quot;)
defer func(){file.Close()}()
if er!=nil &amp;amp;&amp;amp; os.IfNotExist(er
r){
  file = os.Create(&amp;quot;xx&amp;quot;)

}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;打开&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;func Open(name string) (file *File, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Open打开一个文件用于读取。如果操作成功，返回的文件对象的方法可用于读取数据；对应的文件描述符具有O_RDONLY模式。如果出错，错误底层类型是*PathError。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func OpenFile(name string, flag int, perm FileMode) (file *File, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OpenFile是一个更一般性的文件打开函数，大多数调用者都应用Open或Create代替本函数。它会使用指定的选项（如O_RDONLY等）、指定的模式（如0666等）打开指定名称的文件。如果操作成功，返回的文件对象可用于I/O。如果出错，错误底层类型是*PathError。&lt;/p&gt;

&lt;p&gt;位掩码参数 flag 用于指定文件的访问模式，可用的值在 os 中定义为常量（以下值并非所有操作系统都可用）：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const (
    O_RDONLY int = syscall.O_RDONLY // 只读模式打开文件
    O_WRONLY int = syscall.O_WRONLY // 只写模式打开文件
    O_RDWR   int = syscall.O_RDWR   // 读写模式打开文件
    O_APPEND int = syscall.O_APPEND // 写操作时将数据附加到文件尾部
    O_CREATE int = syscall.O_CREAT  // 如果不存在将创建一个新文件
    O_EXCL   int = syscall.O_EXCL   // 和 O_CREATE 配合使用，文件必须不存在
    O_SYNC   int = syscall.O_SYNC   // 打开文件用于同步 I/O
    O_TRUNC  int = syscall.O_TRUNC  // 如果可能，打开时清空文件
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;O_TRUNC这个参数可以用来清空文件，如果可以的话，还可以用这个函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;os.Truncate(name, size)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;或者&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (f *File) Truncate(size int64) error
size 填0 就把文件清空了。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面有详细的说明&lt;/p&gt;

&lt;p&gt;位掩码参数 perm 指定了文件的模式和权限位，类型是 os.FileMode，文件模式位常量定义在 os 中：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const (
    // 单字符是被 String 方法用于格式化的属性缩写。
    ModeDir        FileMode = 1 &amp;lt;&amp;lt; (32 - 1 - iota) // d: 目录
    ModeAppend                                     // a: 只能写入，且只能写入到末尾
    ModeExclusive                                  // l: 用于执行
    ModeTemporary                                  // T: 临时文件（非备份文件）
    ModeSymlink                                    // L: 符号链接（不是快捷方式文件）
    ModeDevice                                     // D: 设备
    ModeNamedPipe                                  // p: 命名管道（FIFO）
    ModeSocket                                     // S: Unix 域 socket
    ModeSetuid                                     // u: 表示文件具有其创建者用户 id 权限
    ModeSetgid                                     // g: 表示文件具有其创建者组 id 的权限
    ModeCharDevice                                 // c: 字符设备，需已设置 ModeDevice
    ModeSticky                                     // t: 只有 root/ 创建者能删除 / 移动文件

    // 覆盖所有类型位（用于通过 &amp;amp; 获取类型位），对普通文件，所有这些位都不应被设置
    ModeType = ModeDir | ModeSymlink | ModeNamedPipe | ModeSocket | ModeDevice
    ModePerm FileMode = 0777 // 覆盖所有 Unix 权限位（用于通过 &amp;amp; 获取类型位）
)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;read&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;func (f *File) Read(b []byte) (n int, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Read 方法从 f 中读取最多 len(b) 字节数据并写入 b。它返回读取的字节数和可能遇到的任何错误。文件终止标志是读取 0 个字节且返回值 err 为 io.EOF。&lt;/p&gt;

&lt;p&gt;从方法声明可以知道，File 实现了 io.Reader 接口。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (f *File) ReadAt(b []byte, off int64) (n int, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ReadAt 从指定的位置（相对于文件开始位置）读取长度为 len(b) 个字节数据并写入 b。它返回读取的字节数和可能遇到的任何错误。当 n&amp;lt;len(b) 时，本方法总是会返回错误；如果是因为到达文件结尾，返回值 err 会是 io.EOF。它对应的系统调用是 pread。&lt;/p&gt;

&lt;p&gt;实例&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var chunks []byte
buf := make([]byte, 1024)
var count = 0
for {
    n, err := f.Read(buf)
    if err != nil &amp;amp;&amp;amp; err != io.EOF {
        panic(err)
    }
    if 0 == n {
        break
    }
    count = count + n
    chunks = append(chunks, buf[:n]...)
}
r.logger.Debugf(&amp;quot;read file content : %s&amp;quot;,string(chunks[:count]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边这个实例主要是要说明一下几个重点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1、buf必须make，不然会panic
2、read必须for循环，直到io.EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;write&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;func (f *File) Write(b []byte) (n int, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Write 向文件中写入 len(b) 字节数据。它返回写入的字节数和可能遇到的任何错误。如果返回值 n!=len(b)，本方法会返回一个非 nil 的错误。&lt;/p&gt;

&lt;p&gt;从方法声明可以知道，File 实现了 io.Writer 接口。&lt;/p&gt;

&lt;p&gt;Write 与 WriteAt 的区别同 Read 与 ReadAt 的区别一样。为了方便，还提供了 WriteString 方法，它实际是对 Write 的封装。&lt;/p&gt;

&lt;p&gt;注意：Write 调用成功并不能保证数据已经写入磁盘，因为内核会缓存磁盘的 I/O 操作。如果希望立刻将数据写入磁盘（一般场景不建议这么做，因为会影响性能），有两种办法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. 打开文件时指定 `os.O_SYNC`；
2. 调用 `File.Sync()` 方法。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;说明：File.Sync() 底层调用的是 fsync 系统调用，这会将数据和元数据都刷到磁盘；如果只想刷数据到磁盘（比如，文件大小没变，只是变了文件数据），需要自己封装，调用 fdatasync（syscall.Fdatasync） 系统调用。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;close&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;close() 系统调用关闭一个打开的文件描述符，并将其释放回调用进程，供该进程继续使用。当进程终止时，将自动关闭其已打开的所有文件描述符。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (f *File) Close() error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;os.File.Close() 是对 close() 的封装。我们应该养成关闭不需要的文件的良好编程习惯。文件描述符是资源，Go 的 gc 是针对内存的，并不会自动回收资源，如果不关闭文件描述符，长期运行的服务可能会把文件描述符耗尽。&lt;/p&gt;

&lt;p&gt;以下两种情况会导致 Close 返回错误：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. 关闭一个未打开的文件；
2. 两次关闭同一个文件；
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通常，我们不会去检查 Close 的错误&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;seek&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;func (f *File) Seek(offset int64, whence int) (ret int64, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Seek 设置下一次读 / 写的位置。offset 为相对偏移量，而 whence 决定相对位置：0 为相对文件开头，1 为相对当前位置，2 为相对文件结尾。它返回新的偏移量（相对开头）和可能的错误。使用中，whence 应该使用 os 包中的常量：SEEK_SET、SEEK_CUR 和 SEEK_END&lt;/p&gt;

&lt;p&gt;实例&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;file.Seek(0, os.SEEK_SET)    // 文件开始处
file.Seek(0, SEEK_END)        // 文件结尾处的下一个字节
file.Seek(-1, SEEK_END)        // 文件最后一个字节
file.Seek(-10, SEEK_CUR)     // 当前位置前 10 个字节
file.Seek(1000, SEEK_END)    // 文件结尾处的下 1001 个字节
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;trucate&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;trucate 和 ftruncate 系统调用将文件大小设置为 size 参数指定的值；Go 语言中相应的包装函数是 os.Truncate 和 os.File.Truncate。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Truncate(name string, size int64) error
func (f *File) Truncate(size int64) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果文件当前长度大于参数 size，调用将丢弃超出部分，若小于参数 size，调用将在文件尾部添加一系列空字节或是一个文件空洞。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;remove&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;func Remove(name string) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remove删除name指定的文件或目录。如果出错，会返回*PathError底层类型的错误。&lt;/p&gt;

&lt;h2 id=&#34;文件属性&#34;&gt;文件属性&lt;/h2&gt;

&lt;h3 id=&#34;文件信息&#34;&gt;文件信息&lt;/h3&gt;

&lt;p&gt;可以通过包里的函数 Stat、Lstat 和 File.Stat 可以得到os.FileInfo 接口的信息。这三个函数对应三个系统调用：stat、lstat 和 fstat。&lt;/p&gt;

&lt;p&gt;这三个函数的区别：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;stat 会返回所命名文件的相关信息。&lt;/li&gt;
&lt;li&gt;lstat 与 stat 类似，区别在于如果文件是符号链接，那么所返回的信息针对的是符号链接自身（而非符号链接所指向的文件）。&lt;/li&gt;
&lt;li&gt;fstat 则会返回由某个打开文件描述符（Go 中则是当前打开文件 File）所指代文件的相关信息。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Stat 和 Lstat 无需对其所操作的文件本身拥有任何权限，但针对指定 name 的父目录要有执行（搜索）权限。而只要 File 对象 ok，File.Stat 总是成功。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (f *File) Stat() (fi FileInfo, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Stat返回描述文件f的FileInfo类型值。如果出错，错误底层类型是*PathError。这个方法也可以用于检查文件是否有问题，上面说到文件的信息是存储在FileInfo 接口中的，我们来看一下这个接口&lt;/p&gt;

&lt;p&gt;FileInfo是一个接口，如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// A FileInfo describes a file and is returned by Stat and Lstat.
type FileInfo interface {
    Name() string       // base name of the file 文件的名字（不含扩展名）
    Size() int64        // length in bytes for regular files; system-dependent for others  普通文件返回值表示其大小；其他文件的返回值含义各系统不同
    Mode() FileMode     // file mode bits   文件的模式位
    ModTime() time.Time // modification time    文件的修改时间
    IsDir() bool        // abbreviation for Mode().IsDir()  等价于 Mode().IsDir()
    Sys() interface{}   // underlying data source (can return nil)  底层数据来源（可以返回 nil）
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该接口提供了一个sys函数，Sys() 底层数据的 C 语言 结构 statbuf 格式如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct stat {
  dev_t    st_dev;    // 设备 ID
  ino_t    st_ino;    // 文件 i 节点号
  mode_t    st_mode;    // 位掩码，文件类型和文件权限
  nlink_t    st_nlink;    // 硬链接数
  uid_t    st_uid;    // 文件属主，用户 ID
  gid_t    st_gid;    // 文件属组，组 ID
  dev_t    st_rdev;    // 如果针对设备 i 节点，则此字段包含主、辅 ID
  off_t    st_size;    // 常规文件，则是文件字节数；符号链接，则是链接所指路径名的长度，字节为单位；对于共享内存对象，则是对象大小
  blksize_t    st_blsize;    // 分配给文件的总块数，块大小为 512 字节
  blkcnt_t    st_blocks;    // 实际分配给文件的磁盘块数量
  time_t    st_atime;        // 对文件上次访问时间
  time_t    st_mtime;        // 对文件上次修改时间
  time_t    st_ctime;        // 文件状态发生改变的上次时间
}
Go 中 syscal.Stat_t 与该结构对应。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果我们要获取 FileInfo 接口没法直接返回的信息，比如想获取文件的上次访问时间，示例如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fileInfo, err := os.Stat(&amp;quot;test.log&amp;quot;)
if err != nil {
  log.Fatal(err)
}
sys := fileInfo.Sys()
stat := sys.(*syscall.Stat_t)
fmt.Println(time.Unix(stat.Atimespec.Unix()))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正常返回的是实现这个接口的结构体，也就是fileStat，如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// A fileStat is the implementation of FileInfo returned by Stat and Lstat.
type fileStat struct {
    name    string
    size    int64
    mode    FileMode
    modTime time.Time
    sys     syscall.Stat_t
}

func (fs *fileStat) Size() int64        { return fs.size }
func (fs *fileStat) Mode() FileMode     { return fs.mode }
func (fs *fileStat) ModTime() time.Time { return fs.modTime }
func (fs *fileStat) Sys() interface{}   { return &amp;amp;fs.sys }

func sameFile(fs1, fs2 *fileStat) bool {
    return fs1.sys.Dev == fs2.sys.Dev &amp;amp;&amp;amp; fs1.sys.Ino == fs2.sys.Ino
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中有一个syscall.Stat_t，源于syscall的结构体，这个结构体是需要区分系统的，不同的系统调用不一样，不然编译不通过，报错如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;registry/delete.go:49:27: stat.Ctimespec undefined (type *syscall.Stat_t has no field or method Ctimespec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;是因为在linux下结构体成名名是Ctim，在drawin下是Ctimespec，导致跨平台编译报错。&lt;/p&gt;

&lt;h3 id=&#34;文件时间&#34;&gt;文件时间&lt;/h3&gt;

&lt;p&gt;通过包里的Chtimes函数可以显式改变文件的访问时间和修改时间。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Chtimes(name string, atime time.Time, mtime time.Time) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Chtimes 修改 name 指定的文件对象的访问时间和修改时间，类似 Unix 的 utime() 或 utimes() 函数。底层的文件系统可能会截断 / 舍入时间单位到更低的精确度。如果出错，会返回 *PathError 类型的错误。在 Unix 中，底层实现会调用 utimenstat()，它提供纳秒级别的精度&lt;/p&gt;

&lt;h3 id=&#34;文件权限&#34;&gt;文件权限&lt;/h3&gt;

&lt;p&gt;系统调用 chown、lchown 和 fchown 可用来改变文件的属主和属组，Go 中os包中对应的函数或方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Chown(name string, uid, gid int) error
func Lchown(name string, uid, gid int) error
func (f *File) Chown(uid, gid int) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;它们的区别和上文提到的 Stat 相关函数类似。&lt;/p&gt;

&lt;p&gt;在文件相关操作报错时，可以通过 os.IsPermission 检查是否是权限的问题。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func IsPermission(err error) bool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;返回一个布尔值说明该错误是否表示因权限不足要求被拒绝。ErrPermission 和一些系统调用错误会使它返回真。&lt;/p&gt;

&lt;p&gt;另外，syscall.Access 可以获取文件的权限。这对应系统调用 access。&lt;/p&gt;

&lt;p&gt;os.Chmod 和 os.File.Chmod 可以修改文件权限（包括 sticky 位），分别对应系统调用 chmod 和 fchmod。&lt;/p&gt;

&lt;h2 id=&#34;目录&#34;&gt;目录&lt;/h2&gt;

&lt;p&gt;在 Unix 文件系统中，目录的存储方式类似于普通文件。目录和普通文件的区别有二：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在其 i-node 条目中，会将目录标记为一种不同的文件类型。&lt;/li&gt;
&lt;li&gt;目录是经特殊组织而成的文件。本质上说就是一个表格，包含文件名和 i-node 标号&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;目录操作&#34;&gt;目录操作&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;创建&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;func Mkdir(name string, perm FileMode) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Mkdir 使用指定的权限和名称创建一个目录。如果出错，会返回 *PathError 类型的错误。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;name 参数指定了新目录的路径名，可以是相对路径，也可以是绝对路径。如果已经存在，则调用失败并返回 os.ErrExist 错误。&lt;/li&gt;
&lt;li&gt;perm 参数指定了新目录的权限。对该位掩码值的指定方式和 os.OpenFile 相同，也可以直接赋予八进制数值。注意，perm 值还将于进程掩码相与（&amp;amp;）。如果 perm 中设置了 sticky 位，那么将对新目录设置该权限。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因为 Mkdir 所创建的只是路径名中的最后一部分，如果父目录不存在，创建会失败。os.MkdirAll 用于递归创建所有不存在的目录&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func MkdirAll(path string, perm FileMode) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MkdirAll使用指定的权限和名称创建一个目录，包括任何必要的上级目录，并返回nil，否则返回错误。权限位perm会应用在每一个被本函数创建的目录上。如果path指定了一个已经存在的目录，MkdirAll不做任何操作并返回nil。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;删除&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;func Remove(name string) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remove 删除 name 指定的文件或目录。如果出错，会返回 *PathError 类型的错误。如果目录不为空，Remove 会返回失败。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func RemoveAll(path string) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RemoveAll 删除 path 指定的文件，或目录及它包含的任何下级对象。它会尝试删除所有东西，除非遇到错误并返回。如果 path 指定的对象不存在，RemoveAll 会返回 nil 而不返回错误。&lt;/p&gt;

&lt;p&gt;RemoveAll 的内部实现逻辑如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;调用 Remove 尝试进行删除，如果成功或返回 path 不存在，则直接返回 nil；&lt;/li&gt;
&lt;li&gt;调用 Lstat 获取 path 信息，以便判断是否是目录。注意，这里使用 Lstat，表示不对符号链接解引用；&lt;/li&gt;
&lt;li&gt;调用 Open 打开目录，递归读取目录中内容，执行删除操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;读&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;func (f *File) Readdirnames(n int) (names []string, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Readdirnames 读取目录 f 的内容，返回一个最多有 n 个成员的[]string，切片成员为目录中文件对象的名字，采用目录顺序。对本函数的下一次调用会返回上一次调用未读取的内容的信息。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果 n&amp;gt;0，Readdirnames 函数会返回一个最多 n 个成员的切片。这时，如果 Readdirnames 返回一个空切片，它会返回一个非 nil 的错误说明原因。如果到达了目录 f 的结尾，返回值 err 会是 io.EOF。&lt;/li&gt;
&lt;li&gt;如果 n&amp;lt;=0，Readdirnames 函数返回目录中剩余所有文件对象的名字构成的切片。此时，如果 Readdirnames 调用成功（读取所有内容直到结尾），它会返回该切片和 nil 的错误值。如果在到达结尾前遇到错误，会返回之前成功读取的名字构成的切片和该错误。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Readdir 内部会调用 Readdirnames，将得到的 names 构造路径，通过 Lstat 构造出 []FileInfo。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (f *File) Readdir(n int) (fi []FileInfo, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;连接&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;func Link(oldname, newname string) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Link 创建一个名为 newname 指向 oldname 的硬链接。如果出错，会返回 *LinkError 类型的错误。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Symlink(oldname, newname string) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Symlink 创建一个名为 newname 指向 oldname 的符号链接。如果出错，会返回 *LinkError 类型的错误。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Readlink(name string) (string, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Readlink 获取 name 指定的符号链接指向的文件的路径。如果出错，会返回 *PathError 类型的错误。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;更改文件名&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;func Rename(oldpath, newpath string) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Rename 修改一个文件的名字或移动一个文件。如果 newpath 已经存在，则替换它。注意，可能会有一些个操作系统特定的限制。&lt;/p&gt;

&lt;h1 id=&#34;os-singal&#34;&gt;os/singal&lt;/h1&gt;

&lt;h2 id=&#34;类型&#34;&gt;类型&lt;/h2&gt;

&lt;p&gt;Signal是一个接口，所有的信号都实现了这个接口，可以直接传递，我们传递信号的时候，需要定义这个类型的channel来传递信号。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Signal interface {
    String() string
    Signal() // to distinguish from other Stringers
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;syscall 包中定义了所有的信号常量，比如syscall.SIGINT，其实就是一个int的数字信号。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SIGINT    = Signal(0x2)
type Signal int

func (s Signal) Signal() {}

func (s Signal) String() string {
    if 0 &amp;lt;= s &amp;amp;&amp;amp; int(s) &amp;lt; len(signals) {
        str := signals[s]
        if str != &amp;quot;&amp;quot; {
            return str
        }
    }
    return &amp;quot;signal &amp;quot; + itoa(int(s))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;函数&#34;&gt;函数&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Notify&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;singnal主要是用于信号的传递，一般程序中需要使用信号的时候使用。主要使用下面两个方法。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Notify(c chan&amp;lt;- os.Signal, sig ...os.Signal)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notify函数让signal包将输入信号转发到c。如果没有列出要传递的信号，会将所有输入信号传递到c；否则只传递列出的输入信号。&lt;/p&gt;

&lt;p&gt;signal包不会为了向c发送信息而阻塞（就是说如果发送时c阻塞了，signal包会直接放弃）：调用者应该保证c有足够的缓存空间可以跟上期望的信号频率。对使用单一信号用于通知的通道，缓存为1就足够了。&lt;/p&gt;

&lt;p&gt;可以使用同一通道多次调用Notify：每一次都会扩展该通道接收的信号集。可以使用同一信号和不同通道多次调用Notify：每一个通道都会独立接收到该信号的一个拷贝。&lt;/p&gt;

&lt;p&gt;实例&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main
import &amp;quot;fmt&amp;quot;
import &amp;quot;os&amp;quot;
import &amp;quot;os/signal&amp;quot;
import &amp;quot;syscall&amp;quot;
func main() {
    sigs := make(chan os.Signal, 1)
    done := make(chan bool, 1)
    signal.Notify(sigs, syscall.SIGINT, syscall.SIGTERM)

    go func() {
        sig := &amp;lt;-sigs
        fmt.Println()
        fmt.Println(sig)
        done &amp;lt;- true
    }()

    fmt.Println(&amp;quot;awaiting signal&amp;quot;)
    &amp;lt;-done
    fmt.Println(&amp;quot;exiting&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;stop&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;唯一从信号集去除信号的方法是调用Stop。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Stop(c chan&amp;lt;- os.Signal)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Stop函数让signal包停止向c转发信号。它会取消之前使用c调用的所有Notify的效果。当Stop返回后，会保证c不再接收到任何信号。&lt;/p&gt;

&lt;h1 id=&#34;os-exec&#34;&gt;os/exec&lt;/h1&gt;

&lt;h2 id=&#34;进程io&#34;&gt;进程io&lt;/h2&gt;

&lt;p&gt;exec包用于执行外部命令。它包装了os.StartProcess函数以便更容易的修正输入和输出，使用管道连接I/O。主要用于创建一个子进程来执行相关的命令。创建子进程一定要wait，不能出现僵死进程。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;调用脚本命令&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在golang标准库中提供了两种方式可以用来启动进程调用脚本&lt;/p&gt;

&lt;p&gt;第一种是在os库中的Process类型，Process类型包含一系列方法用来启动进程并对进程进行操作（参考： &lt;a href=&#34;https://golang.org/pkg/os/#Process）&#34;&gt;https://golang.org/pkg/os/#Process）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;示例 使用Process执行脚本&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;os&amp;quot;
)

func main() {
    shellPath := &amp;quot;/home/xx/test.sh&amp;quot;
    argv := make([]string, 1) 
    attr := new(os.ProcAttr)
    newProcess, err := os.StartProcess(shellPath, argv, attr)  //运行脚本
    if err != nil {
        fmt.Println(err)
    }
    fmt.Println(&amp;quot;Process PID&amp;quot;, newProcess.Pid)
    processState, err := newProcess.Wait() //等待命令执行完
    if err != nil {
        fmt.Println(err)
    }
    fmt.Println(&amp;quot;processState PID:&amp;quot;, processState.Pid())//获取PID
    fmt.Println(&amp;quot;ProcessExit:&amp;quot;, processState.Exited())//获取进程是否退出
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第二种是在os/exec库种通过Cmd类型的各个函数实现对脚本的调用，实际上Cmd是对Process中各种方法的高层次封装（参考： &lt;a href=&#34;https://golang.org/pkg/os/exec/）&#34;&gt;https://golang.org/pkg/os/exec/）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;1、LookPath&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func LookPath(file string) (string, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在环境变量PATH指定的目录中搜索可执行文件，如file中有斜杠，则只在当前目录搜索。返回完整路径或者相对于当前目录的一个相对路径。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    output, err := exec.LookPath(&amp;quot;ls&amp;quot;)
    if err != nil {
        log.Fatal(err)
    }

    fmt.Printf(output)
}

output:

[ `go run test.go` | done: 616.254982ms ]
  /bin/ls
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2、Cmd&lt;/p&gt;

&lt;p&gt;Cmd代表一个正在准备或者在执行中的外部命令&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Cmd struct {
    // Path是将要执行的命令的路径。
    //
    // 该字段不能为空，如为相对路径会相对于Dir字段。
    Path string
    // Args保管命令的参数，包括命令名作为第一个参数；如果为空切片或者nil，相当于无参数命令。
    //
    // 典型用法下，Path和Args都应被Command函数设定。
    Args []string
    // Env指定进程的环境，如为nil，则是在当前进程的环境下执行。
    Env []string
    // Dir指定命令的工作目录。如为空字符串，会在调用者的进程当前目录下执行。
    Dir string
    // Stdin指定进程的标准输入，如为nil，进程会从空设备读取（os.DevNull）
    Stdin io.Reader
    // Stdout和Stderr指定进程的标准输出和标准错误输出。
    //
    // 如果任一个为nil，Run方法会将对应的文件描述符关联到空设备（os.DevNull）
    //
    // 如果两个字段相同，同一时间最多有一个线程可以写入。
    Stdout io.Writer
    Stderr io.Writer
    // ExtraFiles指定额外被新进程继承的已打开文件流，不包括标准输入、标准输出、标准错误输出。
    // 如果本字段非nil，entry i会变成文件描述符3+i。
    //
    // BUG: 在OS X 10.6系统中，子进程可能会继承不期望的文件描述符。
    // http://golang.org/issue/2603
    ExtraFiles []*os.File
    // SysProcAttr保管可选的、各操作系统特定的sys执行属性。
    // Run方法会将它作为os.ProcAttr的Sys字段传递给os.StartProcess函数。
    SysProcAttr *syscall.SysProcAttr
    // Process是底层的，只执行一次的进程。
    Process *os.Process
    // ProcessState包含一个已经存在的进程的信息，只有在调用Wait或Run后才可用。
    ProcessState *os.ProcessState
    // 内含隐藏或非导出字段
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以使用Command来创建cmd&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Command(name string, arg ...string) *Cmd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;函数返回一个*Cmd，用于使用给出的参数执行name指定的程序。返回值只设定了Path和Args两个参数。&lt;/p&gt;

&lt;p&gt;如果name不含路径分隔符，将使用LookPath获取完整路径；否则直接使用name。参数arg不应包含命令名&lt;/p&gt;

&lt;p&gt;使用Run运行cmd命令&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Cmd) Run() error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Run执行c包含的命令，并阻塞直到完成。如果命令成功执行，stdin、stdout、stderr的转交没有问题，并且返回状态码为0，方法的返回值为nil；如果命令没有执行或者执行失败，会返回错误；&lt;/p&gt;

&lt;p&gt;使用Start和wait来运行命令&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Cmd) Start() error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Start开始执行c包含的命令，但并不会等待该命令完成即返回。可以配合使用Wait方法来达到和Run一样的效果。wait方法会返回命令的返回状态码并在命令返回后释放相关的资源。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Cmd) Wait() error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wait会阻塞直到该命令执行完成，该命令必须是被Start方法开始执行的。&lt;/p&gt;

&lt;p&gt;通过Run的源码可以看出其实Run方法内部也是调用了Start和Wait方法。Run方法如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Cmd) Run() error {
    if err := c.Start(); err != nil {
        return err
    }
    return c.Wait()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实例&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    cmd := exec.Command(&amp;quot;tr&amp;quot;, &amp;quot;a-z&amp;quot;, &amp;quot;A-Z&amp;quot;)
    cmd.Stdin = strings.NewReader(&amp;quot;abc def&amp;quot;)
    var out bytes.Buffer
    cmd.Stdout = &amp;amp;out
    err := cmd.Run()
    if err != nil {
        log.Fatal(err)
    }
    fmt.Printf(&amp;quot;GOGOGO: %q\n&amp;quot;, out.String())
}

output:

[ `go run test.go` | done: 286.798242ms ]
  GOGOGO: &amp;quot;ABC DEF&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用Output输出&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Cmd) Output() ([]byte, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行命令并返回标准输出的切片。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Cmd) CombinedOutput() ([]byte, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行命令并返回标准输出和错误输出合并的切片.&lt;/p&gt;

&lt;p&gt;实例&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    out, err := exec.Command(&amp;quot;date&amp;quot;).Output()
    if err != nil {
        log.Fatal(err)
    }
    fmt.Printf(&amp;quot;The date is %s\n&amp;quot;, out)
}

output:

[ `go run test.go` | done: 585.495467ms ]
  The date is Tue Aug  1 19:24:11 CST 2017
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用pipe&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (*Cmd) StdinPipe
func (c *Cmd) StdinPipe() (io.WriteCloser, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;StdinPipe方法返回一个在命令Start后与命令标准输入关联的管道。Wait方法获知命令结束后会关闭这个管道。必要时调用者可以调用Close方法来强行关闭管道，例如命令在输入关闭后才会执行返回时需要显式关闭管道。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (*Cmd) StdoutPipe
func (c *Cmd) StdoutPipe() (io.ReadCloser, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;StdoutPipe方法返回一个在命令Start后与命令标准输出关联的管道。Wait方法获知命令结束后会关闭这个管道，一般不需要显式的关闭该管道。但是在从管道读取完全部数据之前调用Wait是错误的；同样使用StdoutPipe方法时调用Run函数也是错误的。例子如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (*Cmd) StderrPipe
func (c *Cmd) StderrPipe() (io.ReadCloser, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;StderrPipe方法返回一个在命令Start后与命令标准错误输出关联的管道。Wait方法获知命令结束后会关闭这个管道，一般不需要显式的关闭该管道。但是在从管道读取完全部数据之前调用Wait是错误的；同样使用StderrPipe方法时调用Run函数也是错误的。请参照StdoutPipe的例子。&lt;/p&gt;

&lt;p&gt;实例&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    cmd := exec.Command(&amp;quot;echo&amp;quot;, &amp;quot;-n&amp;quot;, `{&amp;quot;Name&amp;quot;: &amp;quot;Bob&amp;quot;, &amp;quot;Age&amp;quot;: 32}`)
    stdout, err := cmd.StdoutPipe()
    if err != nil {
        log.Fatal(err)
    }
    if err := cmd.Start(); err != nil {
        log.Fatal(err)
    }
    var person struct {
        Name string
        Age  int
    }
    json.NewDecoder(r)
    if err := json.NewDecoder(stdout).Decode(&amp;amp;person); err != nil {
        log.Fatal(err)
    }
    if err := cmd.Wait(); err != nil {
        log.Fatal(err)
    }
    fmt.Printf(&amp;quot;%s is %d years old\n&amp;quot;, person.Name, person.Age)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;获取命令返回值&lt;/p&gt;

&lt;p&gt;实际上脚本或命令执行完后，会将结果返回到ProcessState中的status去， 但是status不是export的，所以我们需要通过一些手段将脚本返回值从syscall.WaitStatus找出来&lt;/p&gt;

&lt;p&gt;ProcessState定义&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type ProcessState struct {
    pid    int                // The process&#39;s id.
    status syscall.WaitStatus // System-dependent status info.
    rusage *syscall.Rusage
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于上面使用Cmd的例子，可以在进程退出后可以通过以下语句获取到返回值&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Println(&amp;quot;Exit Code&amp;quot;, command.ProcessState.Sys().(syscall.WaitStatus).ExitStatus())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用Process方式的也可以通过对ProcessState通过相同的方式获取到返回结果。&lt;/p&gt;

&lt;h1 id=&#34;os-user&#34;&gt;os/user&lt;/h1&gt;

&lt;p&gt;os/user 模块的主要作用是通过用户名或者 id 从而获取系统用户的相关属性。&lt;/p&gt;

&lt;h2 id=&#34;类型-1&#34;&gt;类型&lt;/h2&gt;

&lt;p&gt;User 结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type User struct {
    Uid      string
    Gid      string
    Username string
    Name     string
    HomeDir  string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;User 代表一个用户账户：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Uid ：用户的 ID&lt;/li&gt;
&lt;li&gt;Gid ：用户所属组的 ID，如果属于多个组，那么此 ID 为主组的 ID&lt;/li&gt;
&lt;li&gt;Username ：用户名&lt;/li&gt;
&lt;li&gt;Name ：属组名称，如果属于多个组，那么此名称为主组的名称&lt;/li&gt;
&lt;li&gt;HomeDir ：用户的宿主目录&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;方法&#34;&gt;方法&lt;/h2&gt;

&lt;p&gt;返回当前用户。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Current() (*User, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过用户名查找用户，如果没有找到这个用户那么将返回 UnknownUserError 错误类型。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Lookup(username string) (*User, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过用户 ID 查找用户，如果没有找到这个用户那么将返回 UnknownUserIdError 错误类型。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func LookupId(uid string) (*User, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实例&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;os/user&amp;quot;
    &amp;quot;reflect&amp;quot;
)

func main() {
    fmt.Println(&amp;quot;== 测试 Current 正常情况 ==&amp;quot;)
    if u, err := user.Current(); err == nil {
        fmt.Println(&amp;quot;用户ID: &amp;quot; + u.Uid)
        fmt.Println(&amp;quot;主组ID: &amp;quot; + u.Gid)
        fmt.Println(&amp;quot;用户名: &amp;quot; + u.Username)
        fmt.Println(&amp;quot;主组名: &amp;quot; + u.Name)
        fmt.Println(&amp;quot;家目录: &amp;quot; + u.HomeDir)
    }

    fmt.Println(&amp;quot;== 测试 Lookup 正常情况 ==&amp;quot;)
    if u, err := user.Lookup(&amp;quot;root&amp;quot;); err == nil {
        fmt.Println(&amp;quot;用户ID: &amp;quot; + u.Uid)
        fmt.Println(&amp;quot;主组ID: &amp;quot; + u.Gid)
        fmt.Println(&amp;quot;用户名: &amp;quot; + u.Username)
        fmt.Println(&amp;quot;主组名: &amp;quot; + u.Name)
        fmt.Println(&amp;quot;家目录: &amp;quot; + u.HomeDir)
    }
    fmt.Println(&amp;quot;== 测试 Lookup 异常情况 ==&amp;quot;)
    if _, err := user.Lookup(&amp;quot;roo&amp;quot;); err == nil {
    } else {
        fmt.Println(&amp;quot;错误信息: &amp;quot; + err.Error())
        fmt.Print(&amp;quot;错误类型: &amp;quot;)
        fmt.Println(reflect.TypeOf(err))
    }

    fmt.Println(&amp;quot;== 测试 LookupId 正常情况 ==&amp;quot;)
    if u, err := user.LookupId(&amp;quot;0&amp;quot;); err == nil {
        fmt.Println(&amp;quot;用户ID: &amp;quot; + u.Uid)
        fmt.Println(&amp;quot;主组ID: &amp;quot; + u.Gid)
        fmt.Println(&amp;quot;用户名: &amp;quot; + u.Username)
        fmt.Println(&amp;quot;主组名: &amp;quot; + u.Name)
        fmt.Println(&amp;quot;家目录: &amp;quot; + u.HomeDir)
    }
    fmt.Println(&amp;quot;== 测试 LookupId 异常情况 ==&amp;quot;)
    if _, err := user.LookupId(&amp;quot;10000&amp;quot;); err == nil {
    } else {
        fmt.Println(&amp;quot;错误信息: &amp;quot; + err.Error())
        fmt.Print(&amp;quot;错误类型: &amp;quot;)
        fmt.Println(reflect.TypeOf(err))
    }

}
输出结果如下：

== 测试 Current 正常情况 ==
用户ID: 0
主组ID: 0
用户名: root
主组名: root
家目录: /root
== 测试 Lookup 正常情况 ==
用户ID: 0
主组ID: 0
用户名: root
主组名: root
家目录: /root
== 测试 Lookup 异常情况 ==
错误信息: user: unknown user roo
错误类型: user.UnknownUserError
== 测试 LookupId 正常情况 ==
用户ID: 0
主组ID: 0
用户名: root
主组名: root
家目录: /root
== 测试 LookupId 异常情况 ==
错误信息: user: unknown userid 10000
错误类型: user.UnknownUserIdError
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>Golang使用系列---- Fmt</title>
          <link>https://kingjcy.github.io/post/golang/go-fmt/</link>
          <pubDate>Mon, 30 May 2016 11:57:05 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/golang/go-fmt/</guid>
          <description>&lt;p&gt;fmt是实现了格式化的I/O函数，这点类似Ｃ语言中的printf和scanf，但是更加简单。&lt;/p&gt;

&lt;h1 id=&#34;print&#34;&gt;Print&lt;/h1&gt;

&lt;h2 id=&#34;基本函数&#34;&gt;基本函数&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Print&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;// Print 将参数列表 a 中的各个参数转换为字符串并写入到标准输出中。
// 非字符串参数之间会添加空格，返回写入的字节数。
func Print(a ...interface{}) (n int, err error)

// Println 功能类似 Print，只不过最后会添加一个换行符。
// 所有参数之间会添加空格，返回写入的字节数。
func Println(a ...interface{}) (n int, err error)

// Printf 将参数列表 a 填写到格式字符串 format 的占位符中。
// 填写后的结果写入到标准输出中，返回写入的字节数。
func Printf(format string, a ...interface{}) (n int, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Fprint&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;功能同上面三个函数，只不过将转换结果写入到 w 中。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Fprint(w io.Writer, a ...interface{}) (n int, err error)
func Fprintln(w io.Writer, a ...interface{}) (n int, err error)
func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Sprint&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;功能同上面三个函数，只不过将转换结果以字符串形式返回。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Sprint(a ...interface{}) string
func Sprintln(a ...interface{}) string
func Sprintf(format string, a ...interface{}) string
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Errorf&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;功能同 Sprintf，只不过结果字符串被包装成了 error 类型。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Errorf(format string, a ...interface{}) error
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;示例&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    fmt.Print(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, 1, 2, 3, &amp;quot;c&amp;quot;, &amp;quot;d&amp;quot;, &amp;quot;\n&amp;quot;)
    fmt.Println(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, 1, 2, 3, &amp;quot;c&amp;quot;, &amp;quot;d&amp;quot;)
    fmt.Printf(&amp;quot;ab %d %d %d cd\n&amp;quot;, 1, 2, 3)
    // ab1 2 3cd
    // a b 1 2 3 c d
    // ab 1 2 3 cd

    if err := percent(30, 70, 90, 160); err != nil {
        fmt.Println(err)
    }
    // 30%
    // 70%
    // 90%
    // 数值 160 超出范围（100）
}

func percent(i ...int) error {
    for _, n := range i {
        if n &amp;gt; 100 {
            return fmt.Errorf(&amp;quot;数值 %d 超出范围（100）&amp;quot;, n)
        }
        fmt.Print(n, &amp;quot;%\n&amp;quot;)
    }
    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;自定义format类型&#34;&gt;自定义format类型&lt;/h2&gt;

&lt;p&gt;Formatter 由自定义类型实现，用于实现该类型的自定义格式化过程。&lt;/p&gt;

&lt;p&gt;当格式化器需要格式化该类型的变量时，会调用其 Format 方法。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Formatter interface {
    // f 用于获取占位符的旗标、宽度、精度等信息，也用于输出格式化的结果
    // c 是占位符中的动词
    Format(f State, c rune)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由格式化器（Print 之类的函数）实现，用于给自定义格式化过程提供信息&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type State interface {
    // Formatter 通过 Write 方法将格式化结果写入格式化器中，以便输出。
    Write(b []byte) (ret int, err error)
    // Formatter 通过 Width 方法获取占位符中的宽度信息及其是否被设置。
    Width() (wid int, ok bool)
    // Formatter 通过 Precision 方法获取占位符中的精度信息及其是否被设置。
    Precision() (prec int, ok bool)
    // Formatter 通过 Flag 方法获取占位符中的旗标[+- 0#]是否被设置。
    Flag(c int) bool
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Stringer 由自定义类型实现，用于实现该类型的自定义格式化过程。&lt;/p&gt;

&lt;p&gt;当格式化器需要输出该类型的字符串格式时就会调用其 String 方法。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Stringer interface {
    String() string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Stringer 由自定义类型实现，用于实现该类型的自定义格式化过程。&lt;/p&gt;

&lt;p&gt;当格式化器需要输出该类型的 Go 语法字符串（%#v）时就会调用其 String 方法。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type GoStringer interface {
    GoString() string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Ustr string

func (us Ustr) String() string {
    return strings.ToUpper(string(us))
}

func (us Ustr) GoString() string {
    return `&amp;quot;` + strings.ToUpper(string(us)) + `&amp;quot;`
}

func (u Ustr) Format(f fmt.State, c rune) {
    write := func(s string) {
        f.Write([]byte(s))
    }
    switch c {
    case &#39;m&#39;, &#39;M&#39;:
        write(&amp;quot;旗标：[&amp;quot;)
        for s := &amp;quot;+- 0#&amp;quot;; len(s) &amp;gt; 0; s = s[1:] {
            if f.Flag(int(s[0])) {
                write(s[:1])
            }
        }
        write(&amp;quot;]&amp;quot;)
        if v, ok := f.Width(); ok {
            write(&amp;quot; | 宽度：&amp;quot; + strconv.FormatInt(int64(v), 10))
        }
        if v, ok := f.Precision(); ok {
            write(&amp;quot; | 精度：&amp;quot; + strconv.FormatInt(int64(v), 10))
        }
    case &#39;s&#39;, &#39;v&#39;: // 如果使用 Format 函数，则必须自己处理所有格式，包括 %#v
        if c == &#39;v&#39; &amp;amp;&amp;amp; f.Flag(&#39;#&#39;) {
            write(u.GoString())
        } else {
            write(u.String())
        }
    default: // 如果使用 Format 函数，则必须自己处理默认输出
        write(&amp;quot;无效格式：&amp;quot; + string(c))
    }
}

func main() {
    u := Ustr(&amp;quot;Hello World!&amp;quot;)
    // &amp;quot;-&amp;quot; 标记和 &amp;quot;0&amp;quot; 标记不能同时存在
    fmt.Printf(&amp;quot;%-+ 0#8.5m\n&amp;quot;, u) // 旗标：[+- #] | 宽度：8 | 精度：5
    fmt.Printf(&amp;quot;%+ 0#8.5M\n&amp;quot;, u)  // 旗标：[+ 0#] | 宽度：8 | 精度：5
    fmt.Println(u)                // HELLO WORLD!
    fmt.Printf(&amp;quot;%s\n&amp;quot;, u)         // HELLO WORLD!
    fmt.Printf(&amp;quot;%#v\n&amp;quot;, u)        // &amp;quot;HELLO WORLD!&amp;quot;
    fmt.Printf(&amp;quot;%d\n&amp;quot;, u)         // 无效格式：d
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;scan&#34;&gt;Scan&lt;/h1&gt;

&lt;h2 id=&#34;基本函数-1&#34;&gt;基本函数&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Scan&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Scan 从标准输入中读取数据，并将数据用空白分割并解析后存入 a 提供的变量中（换行符会被当作空白处理），变量必须以指针传入。当读到 EOF 或所有变量都填写完毕则停止扫描。返回成功解析的参数数量。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Scan(a ...interface{}) (n int, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Scanln 和 Scan 类似，只不过遇到换行符就停止扫描。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Scanln(a ...interface{}) (n int, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Scanf 从标准输入中读取数据，并根据格式字符串 format 对数据进行解析，将解析结果存入参数 a 所提供的变量中，变量必须以指针传入。输入端的换行符必须和 format 中的换行符相对应（如果格式字符串中有换行符，则输入端必须输入相应的换行符）。占位符 %c 总是匹配下一个字符，包括空白，比如空格符、制表符、换行符。返回成功解析的参数数量。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Scanf(format string, a ...interface{}) (n int, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Fscan&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;功能同上面三个函数，只不过从 r 中读取数据。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Fscan(r io.Reader, a ...interface{}) (n int, err error)
func Fscanln(r io.Reader, a ...interface{}) (n int, err error)
func Fscanf(r io.Reader, format string, a ...interface{}) (n int, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Sscan&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;功能同上面三个函数，只不过从 str 中读取数据。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Sscan(str string, a ...interface{}) (n int, err error)
func Sscanln(str string, a ...interface{}) (n int, err error)
func Sscanf(str string, format string, a ...interface{}) (n int, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;示例&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;// 对于 Scan 而言，回车视为空白
func main() {
    a, b, c := &amp;quot;&amp;quot;, 0, false
    fmt.Scan(&amp;amp;a, &amp;amp;b, &amp;amp;c)
    fmt.Println(a, b, c)
    // 在终端执行后，输入 abc 1 回车 true 回车
    // 结果 abc 1 true
}

// 对于 Scanln 而言，回车结束扫描
func main() {
    a, b, c := &amp;quot;&amp;quot;, 0, false
    fmt.Scanln(&amp;amp;a, &amp;amp;b, &amp;amp;c)
    fmt.Println(a, b, c)
    // 在终端执行后，输入 abc 1 true 回车
    // 结果 abc 1 true
}

// 格式字符串可以指定宽度
func main() {
    a, b, c := &amp;quot;&amp;quot;, 0, false
    fmt.Scanf(&amp;quot;%4s%d%t&amp;quot;, &amp;amp;a, &amp;amp;b, &amp;amp;c)
    fmt.Println(a, b, c)
    // 在终端执行后，输入 1234567true 回车
    // 结果 1234 567 true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从键盘和标准输入 os.Stdin 读取输入，最简单的办法是使用 fmt 包提供的 Scan 和 Sscan 开头的函数。&lt;/p&gt;

&lt;p&gt;从控制台读取输入:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main
import &amp;quot;fmt&amp;quot;

var (
   firstName, lastName, s string
   i int
   f float32
   input = &amp;quot;56.12 / 5212 / Go&amp;quot;
   format = &amp;quot;%f / %d / %s&amp;quot;
)

func main() {
   fmt.Println(&amp;quot;Please enter your full name: &amp;quot;)
   fmt.Scanln(&amp;amp;firstName, &amp;amp;lastName)
   // fmt.Scanf(&amp;quot;%s %s&amp;quot;, &amp;amp;firstName, &amp;amp;lastName)
   fmt.Printf(&amp;quot;Hi %s %s!\n&amp;quot;, firstName, lastName) // Hi Chris Naegels
   fmt.Sscanf(input, format, &amp;amp;f, &amp;amp;i, &amp;amp;s)
   fmt.Println(&amp;quot;From the string we read: &amp;quot;, f, i, s)
    // 输出结果: From the string we read: 56.12 5212 Go
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Scanln 扫描来自标准输入的文本，将空格分隔的值依次存放到后续的参数内，直到碰到换行。&lt;/p&gt;

&lt;p&gt;Scanf 与其类似，除了 Scanf 的第一个参数用作格式字符串，用来决定如何读取。&lt;/p&gt;

&lt;p&gt;Sscan 和以 Sscan 开头的函数则是从字符串读取，除此之外，与 Scanf相同。如果这些函数读取到的结果与您预想的不同，您可以检查成功读入数据的个数和返回的错误。&lt;/p&gt;

&lt;p&gt;也可以使用 bufio 包提供的缓冲读取（buffered reader）来读取数据&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main
import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;bufio&amp;quot;
    &amp;quot;os&amp;quot;
)

var inputReader *bufio.Reader
var input string
var err error

func main() {
    inputReader = bufio.NewReader(os.Stdin)
    fmt.Println(&amp;quot;Please enter some input: &amp;quot;)
    input, err = inputReader.ReadString(&#39;\n&#39;)
    if err == nil {
        fmt.Printf(&amp;quot;The input was: %s\n&amp;quot;, input)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;自定义format类型-1&#34;&gt;自定义format类型&lt;/h2&gt;

&lt;p&gt;Scanner 由自定义类型实现，用于实现该类型的自定义扫描过程。&lt;/p&gt;

&lt;p&gt;当扫描器需要解析该类型的数据时，会调用其 Scan 方法。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Scanner interface {
    // state 用于获取占位符中的宽度信息，也用于从扫描器中读取数据进行解析。
    // verb 是占位符中的动词
    Scan(state ScanState, verb rune) error
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由扫描器（Scan 之类的函数）实现，用于给自定义扫描过程提供数据和信息。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type ScanState interface {
    // ReadRune 从扫描器中读取一个字符，如果用在 Scanln 类的扫描器中，
    // 则该方法会在读到第一个换行符之后或读到指定宽度之后返回 EOF。
    // 返回“读取的字符”和“字符编码所占用的字节数”
    ReadRune() (r rune, size int, err error)
    // UnreadRune 撤消最后一次的 ReadRune 操作，
    // 使下次的 ReadRune 操作得到与前一次 ReadRune 相同的结果。
    UnreadRune() error
    // SkipSpace 为 Scan 方法提供跳过开头空白的能力。
    // 根据扫描器的不同（Scan 或 Scanln）决定是否跳过换行符。
    SkipSpace()
    // Token 用于从扫描器中读取符合要求的字符串，
    // Token 从扫描器中读取连续的符合 f(c) 的字符 c，准备解析。
    // 如果 f 为 nil，则使用 !unicode.IsSpace(c) 代替 f(c)。
    // skipSpace：是否跳过开头的连续空白。返回读取到的数据。
    // 注意：token 指向共享的数据，下次的 Token 操作可能会覆盖本次的结果。
    Token(skipSpace bool, f func(rune) bool) (token []byte, err error)
    // Width 返回占位符中的宽度值以及宽度值是否被设置
    Width() (wid int, ok bool)
    // 因为上面实现了 ReadRune 方法，所以 Read 方法永远不应该被调用。
    // 一个好的 ScanState 应该让 Read 直接返回相应的错误信息。
    Read(buf []byte) (n int, err error)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;示例&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;type Ustr string

func (u *Ustr) Scan(state fmt.ScanState, verb rune) (err error) {
    var s []byte
    switch verb {
    case &#39;S&#39;:
        s, err = state.Token(true, func(c rune) bool { return &#39;A&#39; &amp;lt;= c &amp;amp;&amp;amp; c &amp;lt;= &#39;Z&#39; })
        if err != nil {
            return
        }
    case &#39;s&#39;, &#39;v&#39;:
        s, err = state.Token(true, func(c rune) bool { return &#39;a&#39; &amp;lt;= c &amp;amp;&amp;amp; c &amp;lt;= &#39;z&#39; })
        if err != nil {
            return
        }
    default:
        return fmt.Errorf(&amp;quot;无效格式：%c&amp;quot;, verb)
    }
    *u = Ustr(s)
    return nil
}

func main() {
    var a, b, c, d, e Ustr
    n, err := fmt.Scanf(&amp;quot;%3S%S%3s%2v%x&amp;quot;, &amp;amp;a, &amp;amp;b, &amp;amp;c, &amp;amp;d, &amp;amp;e)
    fmt.Println(a, b, c, d, e)
    fmt.Println(n, err)
    // 在终端执行后，输入 ABCDEFGabcdefg 回车
    // 结果：
    // ABC DEFG abc de
    // 4 无效格式：x
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>golang使用系列---- Time</title>
          <link>https://kingjcy.github.io/post/golang/go-time/</link>
          <pubDate>Tue, 12 Apr 2016 20:11:01 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/golang/go-time/</guid>
          <description>&lt;p&gt;time包中包括两类时间：时间点（某一时刻）和时长（某一段时间）的基本操作。&lt;/p&gt;

&lt;h1 id=&#34;time&#34;&gt;time&lt;/h1&gt;

&lt;h2 id=&#34;基本结构&#34;&gt;基本结构&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Time&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;type Time struct {
    wall uint64
    ext  int64
    loc *Location
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;wall  秒&lt;/li&gt;
&lt;li&gt;ext   纳秒&lt;/li&gt;
&lt;li&gt;loc *Location

&lt;ul&gt;
&lt;li&gt;time.UTC utc时间&lt;/li&gt;
&lt;li&gt;time.Local 本地时间&lt;/li&gt;
&lt;li&gt;FixedZone(name string, offset int) *Location   设置时区名,以及与UTC0的时间偏差.返回Location&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Duration&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;type Duration int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Duration类型代表两个时间点之间经过的时间，以纳秒为单位。可表示的最长时间段大约290年。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;时间常量&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Duration的单位为 nanosecond，为了便于使用，time中定义了时间常量：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const (
    Nanosecond Duration = 1
    Microsecond = 1000 * Nanosecond
    Millisecond = 1000 * Microsecond
    Second = 1000 * Millisecond
    Minute = 60 * Second
    Hour = 60 * Minute
)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Ticker&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;type Ticker
type Ticker struct {
    C &amp;lt;-chan Time // 周期性传递时间信息的通道
    // 内含隐藏或非导出字段
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ticker保管一个通道，并每隔一段时间向其传递&amp;rdquo;tick&amp;rdquo;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewTicker
func NewTicker(d Duration) *Ticker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NewTicker返回一个新的Ticker，该Ticker包含一个通道字段，并会每隔时间段d就向该通道发送当时的时间。它会调整时间间隔或者丢弃tick信息以适应反应慢的接收者。如果d&amp;lt;=0会panic。关闭该Ticker可以释放相关资源。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (*Ticker) Stop
func (t *Ticker) Stop()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Stop关闭一个Ticker。在关闭后，将不会发送更多的tick信息。Stop不会关闭通道t.C，以避免从该通道的读取不正确的成功。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;总结&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;time.Duration（时长，耗时）&lt;/li&gt;
&lt;li&gt;time.Time（时间点）&lt;/li&gt;
&lt;li&gt;time.C（放时间点的管道）[ Time.C:=make(chan time.Time) ]&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;基本函数&#34;&gt;基本函数&lt;/h2&gt;

&lt;p&gt;time包提供了时间的显示和测量用的函数。日历的计算采用的是公历。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Now
func Now() Time
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now返回当前本地时间。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (Time) Before
func (t Time) Before(u Time) bool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果t代表的时间点在u之前，返回真；否则返回假。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (Time) Add
func (t Time) Add(d Duration) Time
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add返回时间点t+d。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (Time) Second
func (t Time) Second() int
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;返回t对应的那一分钟的第几秒，范围[0, 59]。&lt;/p&gt;

&lt;h1 id=&#34;常规使用&#34;&gt;常规使用&lt;/h1&gt;

&lt;h2 id=&#34;sleep&#34;&gt;sleep&lt;/h2&gt;

&lt;p&gt;golang的休眠可以使用time包中的sleep。&lt;/p&gt;

&lt;p&gt;函数原型为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Sleep(d Duration)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面实现休眠2秒功能。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;time&amp;quot;
)

func main() {

    fmt.Println(&amp;quot;begin&amp;quot;)
    time.Sleep(time.Duration(2)*time.Second)
    fmt.Println(&amp;quot;end&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;time使用变量的时候需要强制转换&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;time.Duration(cfg.CTimeOut) * time.Second
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;定时器&#34;&gt;定时器&lt;/h2&gt;

&lt;p&gt;定时器只会传达一次到期事件，&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Timer struct {
    C &amp;lt;-chan Time
    r runtimeTimer
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;每天定时0点执行&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import (
    &amp;quot;time&amp;quot;
    &amp;quot;fmt&amp;quot;
)

//定时结算Boottime表数据
func BoottimeTimingSettlement() {
    for {
        now := time.Now()
        // 计算下一个零点
        next := now.Add(time.Hour * 24)
        next = time.Date(next.Year(), next.Month(), next.Day(), 0, 0, 0, 0, next.Location())
        t := time.NewTimer(next.Sub(now))
        &amp;lt;-t.C
        Printf(&amp;quot;定时结算Boottime表数据，结算完成: %v\n&amp;quot;,time.Now())
        //以下为定时执行的操作
        BoottimeSettlement()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;断续器&#34;&gt;断续器&lt;/h2&gt;

&lt;p&gt;周期性的传达到期事件的装置，定时器只会传达一次到期事件，断续器会持续工作直到停止。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Ticker struct {
    C &amp;lt;-chan Time // The channel on which the ticks are delivered.
    r runtimeTimer
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;初始化&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NewTicker(d Duration) *Ticker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NewTicker返回一个新的Ticker，该Ticker包含一个通道字段，并会每隔时间段d就向该通道发送当时的时间。它会调整时间间隔或者丢弃tick信息以适应反应慢的接收者。如果d&amp;lt;=0会panic。关闭该Ticker可以释放相关资源。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ticker := time.NewTicker(time.Millisecond * 500)
go func() {
    for t := range ticker.C {
        fmt.Println(&amp;quot;Tick at&amp;quot;, t)
    }
}()

time.Sleep(time.Millisecond * 1500)   //阻塞，则执行次数为sleep的休眠时间/ticker的时间
ticker.Stop()    
fmt.Println(&amp;quot;Ticker stopped&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;获取时间&#34;&gt;获取时间&lt;/h2&gt;

&lt;p&gt;各种现有时间的获取&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    fmt.Printf(&amp;quot;时间戳（秒）：%v;\n&amp;quot;, time.Now().Unix())
    fmt.Printf(&amp;quot;时间戳（纳秒）：%v;\n&amp;quot;,time.Now().UnixNano())
    fmt.Printf(&amp;quot;时间戳（毫秒）：%v;\n&amp;quot;,time.Now().UnixNano() / 1e6)
    fmt.Printf(&amp;quot;时间戳（纳秒转换为秒）：%v;\n&amp;quot;,time.Now().UnixNano() / 1e9)
}


时间戳（秒）：1530027865;
时间戳（纳秒）：1530027865231834600;
时间戳（毫秒）：1530027865231;
时间戳（纳秒转换为秒）：1530027865;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;时间转化&#34;&gt;时间转化&lt;/h2&gt;

&lt;p&gt;处理时间单位自动转化问题&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func ParseDuration(s string) (Duration, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;传入字符串，返回响应的时间，其中传入的字符串中的有效时间单位如下：h,m,s,ms,us,ns，其他单位均无效，如果传入无效时间单位，则会返回０&lt;/p&gt;

&lt;p&gt;获取前n天的时间&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//获取两天前的时间
currentTime := time.Now()
oldTime := currentTime.AddDate(0, 0, -2)        //若要获取3天前的时间，则应将-2改为-3
//oldTime 的结果为go的时间time类型，2018-09-25 13:24:58.287714118 +0000 UTC
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;比较时间，使用before&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;time1 := &amp;quot;2015-03-20 08:50:29&amp;quot;
time2 := &amp;quot;2015-03-21 09:04:25&amp;quot;
//先把时间字符串格式化成相同的时间类型
t1, err := time.Parse(&amp;quot;2006-01-02 15:04:05&amp;quot;, time1)
t2, err := time.Parse(&amp;quot;2006-01-02 15:04:05&amp;quot;, time2)
if err == nil &amp;amp;&amp;amp; t1.Before(t2) {
    //处理逻辑
    fmt.Println(&amp;quot;true&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;获取文件的各种时间&#34;&gt;获取文件的各种时间&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    finfo, _ := os.Stat(filename)
    // Sys()返回的是interface{}，所以需要类型断言，不同平台需要的类型不一样，linux上为*syscall.Stat_t
    stat_t := finfo.Sys().(*syscall.Stat_t)
    fmt.Println(stat_t)
    // atime，ctime，mtime分别是访问时间，创建时间和修改时间，具体参见man 2 stat
    fmt.Println(timespecToTime(stat_t.Atim))
    fmt.Println(timespecToTime(stat_t.Ctim))
    fmt.Println(timespecToTime(stat_t.Mtim))
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
      
    
      
        <item>
          <title>监控系列---- Zabbix监控方案</title>
          <link>https://kingjcy.github.io/post/monitor/metrics/zabbix/zabbix-scheme/</link>
          <pubDate>Fri, 04 Mar 2016 17:54:04 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/monitor/metrics/zabbix/zabbix-scheme/</guid>
          <description>&lt;p&gt;zabbix是目前各大互联网公司使用最广泛的开源监控之一,其历史最早可追溯到1998年,在业内拥有各种成熟的解决方案，但是对容器的监控还是比较薄弱，我们也不多说，主要用于基础设施VM的监控。&lt;/p&gt;

&lt;h1 id=&#34;架构&#34;&gt;架构&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://kingjcy.github.io/media/monitor/zabbix/zabbix.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;详细说明&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;agent：负载采集数据，所有的采集都在这一个进程中，不像prometheus的exporter有很多。&lt;/li&gt;
&lt;li&gt;proxy：是一个汇聚层，将数据聚合后发送到server。&lt;/li&gt;
&lt;li&gt;server：服务端，用于存储数据，对外进行查询展示。&lt;/li&gt;
&lt;li&gt;DB：数据库，存储数据&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;zabbix的核心组件&#34;&gt;zabbix的核心组件&lt;/h1&gt;

&lt;p&gt;1、zabbix server 负责采集和收取agent采集的信息。&lt;/p&gt;

&lt;p&gt;2、zabbix database   用于存储zabbix的配置信息，监控数据&lt;/p&gt;

&lt;p&gt;3、zabbix web zabbix的管理界面，监控界面，可以独立部署，只要能连接到database就可以&lt;/p&gt;

&lt;p&gt;4、zabbix agent 不数据监控主机主机上，负责采集数据，把数据推送到server或者server来去数据（主动和被动模式，可以同时设置）&lt;/p&gt;

&lt;p&gt;5、zabbix proxy 用于分布式监控，作用就是用于聚合部分数据，最后统一发完server&lt;/p&gt;

&lt;p&gt;zabbix对分布式的数据采集非常好,支持两种分布式架构,一种是Proxy,一种是Node.Proxy作为zabbix server的代理去监控服务器,并发数据汇聚到Zabbix server.而Node本身就是一个完整的Zabbix server, 使用Node可以将多个Zabbix server组成一个具有基层关系的分布式架构.&lt;/p&gt;

&lt;p&gt;两者的区别如下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                proxy   Node
轻量级         √       ×
GUI前端           ×       √
是否可以独立运行    √       ×
容易运维            √       ×
本地Admin管理   ×       √
中心化配置       √       ×
产生通知            ×       √
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6、zabbix get 安装服务器上，来测试获取agent的数据的工具&lt;/p&gt;

&lt;p&gt;7、zabbix sender 安装在客户端机器上，用于测试推送数据到server的的工具&lt;/p&gt;

&lt;h1 id=&#34;zabbix监控方式&#34;&gt;Zabbix监控方式&lt;/h1&gt;

&lt;p&gt;1、被动模式&lt;/p&gt;

&lt;p&gt;被动检测：相对于agent而言；agent, server向agent请求获取配置的各监控项相关的数据，agent接收请求、获取数据并响应给server；&lt;/p&gt;

&lt;p&gt;2、主动模式&lt;/p&gt;

&lt;p&gt;主动检测：相对于agent而言；agent(active),agent向server请求与自己相关监控项配置，主动地将server配置的监控项相关的数据发送给server；&lt;/p&gt;

&lt;p&gt;主动监控能极大节约监控server 的资源。&lt;/p&gt;

&lt;h1 id=&#34;zabbix的使用&#34;&gt;zabbix的使用&lt;/h1&gt;

&lt;p&gt;基本安装使用可以看&lt;a href=&#34;https://kingjcy.github.io/post/monitor/metrics/zabbix/zabbix/&#34;&gt;这里&lt;/a&gt;,相关源码解析可以看&lt;a href=&#34;https://kingjcy.github.io/post/monitor/metrics/zabbix/zabbixcode/&#34;&gt;这里&lt;/a&gt;,这些就不多说了。&lt;/p&gt;

&lt;h1 id=&#34;扩展&#34;&gt;扩展&lt;/h1&gt;

&lt;p&gt;随着系统监控规模的越来越大，zabbix出现越来越多的瓶颈，随着时序数据库的广泛使用，监控已经渐渐切换到了时序数据库，对于原始的zabbix监控项，监控数据如何处理？我们可以将zabbix数据存到时序数据库中，统一使用，相关&lt;a href=&#34;https://kingjcy.github.io/post/monitor/metrics/zabbix/zabbix2tsdb/&#34;&gt;实现方案&lt;/a&gt;就需要自己实现了。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>用hugo&#43;github构建自己的blog</title>
          <link>https://kingjcy.github.io/post/tool/hugo-blog-build/</link>
          <pubDate>Fri, 29 Aug 2014 09:29:40 CST</pubDate>
          <author></author>
          <guid>https://kingjcy.github.io/post/tool/hugo-blog-build/</guid>
          <description>&lt;p&gt;这个是我用hugo+github搭建起个人blog写的第一篇文章，有点小兴奋。。。首先把搭建测过程写起来和大家分享一下吧。&lt;/p&gt;

&lt;p&gt;首先，作为一个程序员，不拥有自己搭建的blog，而去用别人搭建好的去注册一下，我是无法接受的！！搭建个人blog需要两个东西：&lt;/p&gt;

&lt;p&gt;1、静态网页生成器，有jekyll，hexo，hugo等，由于最近在玩go语言，所以就选择了hugo，其他的也没有深入了解，后面搭建起来，发现hugo还是比较简单。&lt;/p&gt;

&lt;p&gt;2、github pages 这个是github提供的一个托管工作，相当好用。&lt;/p&gt;

&lt;h1 id=&#34;静态页面生成器hugo&#34;&gt;静态页面生成器hugo&lt;/h1&gt;

&lt;p&gt;这个比较方便的静态页面生成器，首先需要安装，我的系统是centos 64位的.&lt;/p&gt;

&lt;p&gt;现在换成了macos系统了。&lt;/p&gt;

&lt;blockquote&gt;
&lt;h2 id=&#34;install&#34;&gt;install&lt;/h2&gt;
&lt;/blockquote&gt;

&lt;p&gt;1、直接下载二进制文件，这也是我说的方便的地方。&lt;/p&gt;

&lt;p&gt;Hugo二进制下载地址：&lt;a href=&#34;https://github.com/spf13/hugo/releases&#34;&gt;https://github.com/spf13/hugo/releases&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2。使用macos系统后直接使用homebrew进行安装更新，这个就是一个类似于linux的yum的工具。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew install hugo
brew upgrade hugo
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;h2 id=&#34;use&#34;&gt;use&lt;/h2&gt;
&lt;/blockquote&gt;

&lt;p&gt;下载下来后，首先要生成自己的站点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;`hugo new site mysite`--这边hugo的二进制文件不一定是这个名字，可以起个别名alias来用
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时会在mysite目录下生成一些目录和文件，这边简单的介绍一下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1、config.toml是网站的配置文件，这是它的作者GitHub联合创始人Tom Preston-Werner 觉得YAML不够优雅，捣鼓出来的一个新格式。如果你不喜欢这种格式，你可以将config.toml替换为YAML格式的config.yaml，或者json格式的config.json。hugo都支持。
2、content目录里放的是你写的markdown文章。
3、layouts目录里放的是网站的模板文件。
4、static目录里放的是一些图片、css、js等资源。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后进入站点目录mysite，新建文档&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;`cd mysite`

`hugo new about.md`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边新建一个md文件会出现在content目录下，一般这个about.md文件是一个关于本站的介绍或者blog个人介绍，在这边将一下md文件的编辑，其实就是MarkDown格式文件的编写，具体的格式可以参考本文的编辑，或者去网上去搜索一下就ok,这边我说几点，我经常记错&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1、就是&amp;quot;+++&amp;quot;内的赋值用&amp;quot;=&amp;quot;，&amp;quot;---&amp;quot;内的用&amp;quot;:&amp;quot;。

2、`###`后面必须有空格。

3、有空行才能换行。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一般我们写博文，会放在content/post下，正如我这边编写的第一篇文&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;`hugo new post/first.md`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后用vim编辑器进行编辑，编辑好后，就可以将你编辑的文字生成静态网页了，当然你肯定需要一个模板，这样可以使你的网页根据美观，这边在讲一下模板的使用&lt;/p&gt;

&lt;blockquote&gt;
&lt;h2 id=&#34;模版&#34;&gt;模版&lt;/h2&gt;
&lt;/blockquote&gt;

&lt;p&gt;1、模板放在站点的themes下，一般木有这个文件夹，我们需要新增一个&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;`mkdir themes`

`cd themes`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2、模板可以到hugo官网上去找,那边可以showcase预览一下自己喜欢的，具体的安装方式也有介绍，就是用&lt;code&gt;git clone&lt;/code&gt;把源码下到themes目录下就好&lt;/p&gt;

&lt;p&gt;官网：&lt;a href=&#34;https://gohugo.io/overview/introduction/&#34;&gt;https://gohugo.io/overview/introduction/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;3、编辑模板的配置文件，这个视具体模板，可以参考我的配置&lt;a href=&#34;https://github.com/kingjcy/&#34;&gt;https://github.com/kingjcy/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;下面就是生成我们需要的静态网页了，也就是前端的html文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;`hugo --theme=hyde --baseUrl=&amp;quot;http://kingjcy.github.io/&amp;quot;`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不出意外的话，应该在站点目录下生成一个public文件夹，这个就是我们需要的所有文件了，至此第一步已经完成了。可以看见直接编译是hugo，启动一个web服务是hugo server&lt;/p&gt;

&lt;blockquote&gt;
&lt;h2 id=&#34;使用&#34;&gt;使用&lt;/h2&gt;
&lt;/blockquote&gt;

&lt;p&gt;1、huo new XXXX生成文件是可以直接生成自己想要的内容的，取决于模版，默认是archetypes/default.md，可以对其进行修改，变成自己的样子。&lt;/p&gt;

&lt;p&gt;2、使用图片，默认把图片放在media目录下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;![](/media/worklife/baby/XXX.JPG)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;github-pages托管&#34;&gt;github pages托管&lt;/h1&gt;

&lt;p&gt;这个就简单了，因为本身就是github提供现成的东西，首先新增一个repo，命名为：&lt;code&gt;kingjcy.github.io&lt;/code&gt; （kingjcy替换为你的github用户名）。&lt;/p&gt;

&lt;p&gt;然后将第一步的public加入git版本，上传到这个项目，就可以访问你的个人blog：&lt;code&gt;http://kingjcy.github.io/&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;至于git版本控制和github直接的传输，这边就不多讲了，如果需要可以参考我的另外一篇博文《git和github的使用》。&lt;/p&gt;

&lt;p&gt;这边简单列举一些过程&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cd public
$ git init
$ git remote add origin https://github.com/kingjcy/kingjcy.github.io.git
$ git add -A
$ git commit -m &amp;quot;first commit&amp;quot;
$ git push -u origin master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;终于搭建完了，欢迎指正,tks。&lt;/p&gt;</description>
        </item>
      
    
      
    

  </channel>
</rss>
